Search.setIndex({"alltitles": {"--perf-dump-path (Stage/Step Timing Dump)": [[90, "perf-dump-path-stage-step-timing-dump"]], "/generate Endpoint": [[46, "generate-endpoint"]], "0. Prerequisites": [[80, "prerequisites"], [83, "prerequisites"]], "1. Commit Message Convention": [[90, "commit-message-convention"]], "1. Image Preparation": [[80, "image-preparation"], [83, "image-preparation"]], "1. Launch SGLang Server": [[38, "launch-sglang-server"]], "1. Launch a Matryoshka\u2011capable model": [[91, "launch-a-matryoshkacapable-model"]], "1. Raw Images - Simplest approach": [[28, "1.-Raw-Images---Simplest-approach"]], "2. All In One manifest file": [[83, "all-in-one-manifest-file"]], "2. Deployment Manifest Files": [[80, "deployment-manifest-files"]], "2. Make requests with different output dimensions": [[91, "make-requests-with-different-output-dimensions"]], "2. Performance Reporting": [[90, "performance-reporting"]], "2. Processor Output - For custom preprocessing": [[28, "2.-Processor-Output---For-custom-preprocessing"]], "2. Use Ollama CLI": [[38, "use-ollama-cli"]], "3. CI-Based Change Protection": [[90, "ci-based-change-protection"]], "3. Precomputed Embeddings - For maximum performance": [[28, "3.-Precomputed-Embeddings---For-maximum-performance"]], "3. Use Ollama Python Library": [[38, "use-ollama-python-library"]], "AMD GPUs": [[58, null]], "API Endpoint": [[88, "api-endpoint"]], "API Reference": [[22, "api-reference"]], "API related": [[21, "api-related"]], "ASCEND": [[15, "ascend"]], "Accuracy": [[53, "accuracy"]], "Accuracy Impact": [[18, "accuracy-impact"]], "Accuracy Test with aime 2025": [[30, "accuracy-test-with-aime-2025"]], "Accuracy Test with gpqa-diamond": [[30, "accuracy-test-with-gpqa-diamond"]], "Accuracy Test with gsm8k": [[30, "accuracy-test-with-gsm8k"]], "Accuracy Test with lm_eval": [[34, "accuracy-test-with-lm-eval"]], "Achieve a high token usage": [[12, "achieve-a-high-token-usage"]], "Achieving high throughput for offline batch inference": [[12, "achieving-high-throughput-for-offline-batch-inference"]], "Add Tokenizer (Async)": [[22, "add-tokenizer-async"]], "Add Worker": [[22, "add-worker"]], "Add a Runner": [[55, "add-a-runner"]], "Add new kernels": [[48, "add-new-kernels"]], "Add the Model to the Test Suite": [[98, "add-the-model-to-the-test-suite"]], "Adjust the request submission speed to control #queue-req": [[12, "adjust-the-request-submission-speed-to-control-queue-req"]], "Admin and Health Endpoints": [[22, "admin-and-health-endpoints"]], "Adoption": [[84, "adoption"]], "Advanced Configuration": [[15, "advanced-configuration"], [15, "id5"], [90, "advanced-configuration"]], "Advanced Features": [[17, "advanced-features"], [57, null], [70, "advanced-features"]], "Advanced Usage": [[37, "Advanced-Usage"]], "Advanced: Speculative Decoding (EAGLE3)": [[70, "advanced-speculative-decoding-eagle3"]], "Architecture": [[2, "architecture"], [22, "architecture"], [22, "id7"]], "Areas for Contribution": [[70, "areas-for-contribution"]], "Args for multi-item scoring": [[21, "args-for-multi-item-scoring"]], "Arguments": [[90, "arguments"]], "Arguments for LoRA Serving": [[13, "Arguments-for-LoRA-Serving"]], "Ascend NPUs": [[65, null]], "Attention Backend": [[1, null]], "Attention Backend Comparison": [[70, "attention-backend-comparison"]], "Attention Backend Selection Guide (CUDA)": [[1, "attention-backend-selection-guide-cuda"]], "Attention Backends": [[90, "attention-backends"]], "Attention backend arguments": [[3, "attention-backend-arguments"]], "Authentication": [[49, "authentication"]], "Automatic Selection Logic": [[1, "automatic-selection-logic"]], "Available Quantization Methods": [[17, "available-quantization-methods"]], "Avoid out-of-memory errors by tuning --chunked-prefill-size, --mem-fraction-static, and --max-running-requests": [[12, "avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests"]], "Backend Compatibility": [[27, "Backend-Compatibility"]], "Backend options": [[90, "backend-options"]], "Backends for All-to-All Communication": [[7, "backends-for-all-to-all-communication"]], "Backends for MoE Computation": [[7, "backends-for-moe-computation"]], "Basic Example: Qwen-7B": [[70, "basic-example-qwen-7b"]], "Basic Offline Engine API Call": [[28, "Basic-Offline-Engine-API-Call"]], "Basic Profiling": [[90, "basic-profiling"]], "Basic Usage": [[4, "basic-usage"], [40, "Basic-Usage"], [57, null], [77, "Basic-Usage"], [90, "basic-usage"]], "Basic example": [[79, "basic-example"]], "Batch Tokenize Request": [[22, "batch-tokenize-request"]], "Batching": [[77, "Batching"]], "Bench Serving Guide": [[49, null]], "Benchmark": [[50, "benchmark"], [61, "benchmark"], [61, "id4"], [61, "id6"], [61, "id8"], [61, "id10"], [61, "id12"], [61, "id14"], [61, "id16"], [61, "id18"], [61, "id20"], [61, "id22"], [61, "id24"], [61, "id26"], [61, "id28"], [61, "id30"], [61, "id32"], [61, "id34"], [61, "id36"], [61, "id38"], [61, "id40"], [61, "id42"], [61, "id44"], [61, "id46"], [61, "id48"], [61, "id50"], [61, "id52"], [61, "id54"], [61, "id56"], [61, "id58"], [61, "id60"], [98, "benchmark"]], "Benchmark and Profiling": [[50, null]], "Benchmark the speed": [[51, "benchmark-the-speed"], [59, "benchmark-the-speed"]], "Benchmarking Results": [[30, "benchmarking-results"], [34, "benchmarking-results"]], "Benchmarking with Requests": [[67, "benchmarking-with-requests"], [70, "benchmarking-with-requests"], [71, "benchmarking-with-requests"]], "Benefits of ModelOpt": [[17, "benefits-of-modelopt"]], "Best Practice for Long Context": [[16, "best-practice-for-long-context"]], "Best Practice for Pipeline Parallelism with PD Disaggregation": [[16, "best-practice-for-pipeline-parallelism-with-pd-disaggregation"]], "Best Practice on Ascend NPU": [[61, null]], "Best Practices": [[18, "best-practices"]], "Block-wise FP8": [[29, "block-wise-fp8"]], "Build From Source": [[30, "build-from-source"]], "Build from source": [[51, "build-from-source"]], "Building Modules": [[22, "building-modules"]], "Built-in Tools": [[33, "built-in-tools"]], "C++ Implementation": [[48, "c-implementation"]], "C++ Utilities": [[48, "c-utilities"]], "CANN": [[60, "cann"]], "CI rate limits": [[51, "ci-rate-limits"], [59, "ci-rate-limits"]], "CPU Servers": [[67, null]], "CPU performance power scheme": [[60, "cpu-performance-power-scheme"]], "CUDA Error: Illegal Memory Access Encountered": [[74, "cuda-error-illegal-memory-access-encountered"]], "CUDA Out of Memory": [[74, "cuda-out-of-memory"]], "Cache-Aware Policy Tuning": [[22, "cache-aware-policy-tuning"]], "Cache-DiT Acceleration": [[90, "cache-dit-acceleration"]], "Call with Precomputed Embeddings": [[28, "Call-with-Precomputed-Embeddings"], [28, "id2"]], "Call with Processor Output": [[28, "Call-with-Processor-Output"], [28, "id1"]], "Capture expert selection distribution in MoE models": [[36, "Capture-expert-selection-distribution-in-MoE-models"]], "Case Study on NVIDIA H20": [[16, "case-study-on-nvidia-h20"]], "Chat Completions": [[40, "Chat-Completions"]], "Check if the metrics are being collected": [[85, "check-if-the-metrics-are-being-collected"]], "Checkpoint Engine Integration": [[2, null]], "Checkpoint Engine Options": [[2, "checkpoint-engine-options"]], "Choices Methods in SGLang": [[75, null]], "Choosing LoRA Backend": [[13, "Choosing-LoRA-Backend"]], "Choosing model and tokenizer": [[49, "choosing-model-and-tokenizer"]], "Chunked Prefill": [[70, "chunked-prefill"]], "Chunked Prefill Size and Smoothing Factor": [[16, "chunked-prefill-size-and-smoothing-factor"]], "Circuit Breaker": [[22, "circuit-breaker"]], "Circuit Breaker Flapping": [[22, "circuit-breaker-flapping"]], "Classification API": [[22, "classification-api"], [88, null]], "Classification Models (Multi-class)": [[88, "classification-models-multi-class"]], "Classify (reward model)": [[36, "Classify-(reward-model)"]], "Client Request": [[91, "client-request"]], "Co-launch Router and Workers": [[22, "co-launch-router-and-workers"]], "Code Structure": [[48, "code-structure"]], "Code style guidance": [[51, "code-style-guidance"], [59, "code-style-guidance"]], "Collaboration": [[84, "collaboration"]], "Combined Configuration Example": [[90, "combined-configuration-example"]], "Command Example": [[3, "command-example"], [5, "command-example"]], "Command Line Usage": [[50, "command-line-usage"]], "Common Notes": [[56, "common-notes"]], "Common Pitfalls": [[96, "common-pitfalls"], [96, "id3"]], "Common launch commands": [[21, "common-launch-commands"]], "Community and Support": [[10, "community-and-support"]], "Comparison": [[22, "comparison"]], "Compatibility": [[88, "compatibility"]], "Compatibility Matrix": [[90, "compatibility-matrix"]], "Compilation Long-Time": [[70, "compilation-long-time"]], "Completions": [[40, "Completions"]], "Complex Prompts": [[77, "Complex-Prompts"]], "Component Version Mapping For SGLang": [[60, "component-version-mapping-for-sglang"]], "Comprehensive Benchmark Script": [[70, "comprehensive-benchmark-script"]], "Computation and Communication Overlap": [[7, "computation-and-communication-overlap"]], "Configuration": [[22, "configuration"], [22, "id3"]], "Configuration Files": [[85, "configuration-files"]], "Configuration Guidelines": [[10, "configuration-guidelines"]], "Configuration Options": [[2, "configuration-options"]], "Configuration Reference": [[22, "configuration-reference"]], "Configuration Tips": [[30, "configuration-tips"], [34, "configuration-tips"], [44, "configuration-tips"]], "Configuration file support": [[21, "configuration-file-support"]], "Configuration overview": [[8, "configuration-overview"]], "Connection Issues": [[70, "connection-issues"]], "Constrained Decoding": [[77, "Constrained-Decoding"]], "Constrained decoding": [[46, "constrained-decoding"]], "Continue Generation": [[23, "continue-generation"]], "Contributing": [[70, "contributing"]], "Contributing to SGLang Diffusion": [[90, "contributing-to-sglang-diffusion"]], "Contribution Guide": [[51, null], [59, null]], "Control Plane": [[22, "control-plane"]], "Control flow": [[77, "Control-flow"]], "Conversation and Response APIs": [[22, "conversation-and-response-apis"]], "Core HiCache Parameters": [[10, "core-hicache-parameters"]], "Core Settings": [[22, "core-settings"]], "Core parameters": [[46, "core-parameters"]], "Crash Dump and Replay": [[14, "crash-dump-and-replay"]], "Create Docker": [[60, "create-docker"]], "Create a video": [[90, "create-a-video"]], "Create an image": [[90, "create-an-image"]], "Create decode k8s service": [[80, "create-decode-k8s-service"]], "Create prefill k8s service": [[80, "create-prefill-k8s-service"]], "Creating Service for Prefill and Decode": [[80, "creating-service-for-prefill-and-decode"]], "Cross-Encoder Rerank (embedding runner)": [[96, "cross-encoder-rerank-embedding-runner"]], "Cuda Graph for Multi-Modal Encoder in SGLang": [[3, null]], "Currently supported parsers:": [[27, "Currently-supported-parsers:"]], "Custom Attention Backends": [[70, "custom-attention-backends"]], "Custom Chat Template": [[72, null]], "Custom SCM Bins": [[90, "custom-scm-bins"]], "Custom Storage Backend Integration": [[10, "custom-storage-backend-integration"]], "Custom logit processor": [[46, "custom-logit-processor"]], "Custom weight loader": [[21, "custom-weight-loader"]], "CustomOps": [[60, "customops"]], "DBCache Parameters": [[90, "dbcache-parameters"]], "DP for Multi-Modal Encoder in SGLang": [[5, null]], "DSA long sequence context parallel optimization(experimental)": [[30, "dsa-long-sequence-context-parallel-optimization-experimental"]], "Data Parallelism Attention": [[29, "data-parallelism-attention"]], "Data Plane": [[22, "data-plane"]], "Data Transfer Optimization": [[11, "data-transfer-optimization"]], "Data Write-back": [[11, "data-write-back"]], "Data parallelism": [[21, "data-parallelism"]], "Datasets": [[49, "datasets"]], "Debug": [[79, "debug"]], "Debug Mode": [[93, "debug-mode"]], "Debug SGLang with VSCode Debugger": [[52, "debug-sglang-with-vscode-debugger"]], "Debug tensor dumps": [[21, "debug-tensor-dumps"]], "Debugging": [[22, "debugging"]], "Decode": [[80, "decode"]], "Decode Server Configuration": [[15, "decode-server-configuration"]], "DeepEP Configuration": [[73, "deepep-configuration"]], "DeepEP-compatible Library": [[60, "deepep-compatible-library"]], "DeepGEMM Configuration (Advanced Optimization)": [[73, "deepgemm-configuration-advanced-optimization"]], "DeepSeek Multi-Node": [[15, "deepseek-multi-node"], [15, "id4"], [15, "id8"]], "DeepSeek R1 High Performance 50ms 1": [[61, "deepseek-r1-high-performance-50ms-1"]], "DeepSeek R1 High Performance 50ms 2": [[61, "deepseek-r1-high-performance-50ms-2"]], "DeepSeek R1 High Performance 50ms 3": [[61, "deepseek-r1-high-performance-50ms-3"]], "DeepSeek R1 High Performance 50ms 4": [[61, "deepseek-r1-high-performance-50ms-4"]], "DeepSeek R1 High Performance 50ms 5": [[61, "deepseek-r1-high-performance-50ms-5"]], "DeepSeek R1 Low Latency 20ms 1": [[61, "deepseek-r1-low-latency-20ms-1"]], "DeepSeek R1 Low Latency 20ms 2": [[61, "deepseek-r1-low-latency-20ms-2"]], "DeepSeek R1 Low Latency 20ms 3": [[61, "deepseek-r1-low-latency-20ms-3"]], "DeepSeek R1 Low Latency 20ms 4": [[61, "deepseek-r1-low-latency-20ms-4"]], "DeepSeek Series Models": [[61, "deepseek-series-models"]], "DeepSeek V3.2 Usage": [[30, null]], "DeepSeek V3/R1": [[81, "deepseek-v3-r1"]], "DeepSeek V3/V3.1/R1 Usage": [[29, null]], "DeepSeek examples": [[62, null]], "DeepSeek-V3.1 with 128K Input Token Length": [[16, "deepseek-v3-1-with-128k-input-token-length"]], "DeepSeekV32-Exp RBG Based PD Deploy": [[83, null]], "Deepseek V32 Low Latency 30ms": [[61, "deepseek-v32-low-latency-30ms"]], "Default Behavior": [[4, "default-behavior"]], "Define Messages": [[27, "Define-Messages"]], "Define Tools for Function Call": [[27, "Define-Tools-for-Function-Call"]], "Define a Tool Function": [[27, "Define-a-Tool-Function"]], "Denoising Stage Profiling": [[90, "denoising-stage-profiling"]], "Deploy On Kubernetes": [[79, null]], "Deploy minilb and lb service": [[80, "deploy-minilb-and-lb-service"]], "Deploying Modules": [[22, "deploying-modules"]], "Deploying Quantized Models": [[17, "deploying-quantized-models"]], "Deployment Modes": [[22, "deployment-modes"]], "Deployment with HF3FS": [[10, "deployment-with-hf3fs"]], "Deployment with Mooncake": [[10, "deployment-with-mooncake"]], "Deployment with Python": [[35, "deployment-with-python"]], "Deprecated arguments": [[21, "deprecated-arguments"]], "Design and Restrictions": [[3, "design-and-restrictions"]], "Deterministic Inference": [[4, null], [23, "deterministic-inference"]], "Deterministic Inference with Non-Greedy Sampling (Temperature > 0)": [[4, "deterministic-inference-with-non-greedy-sampling-temperature-0"]], "Detokenize Request": [[22, "detokenize-request"]], "Detokenize Response": [[22, "detokenize-response"]], "Developer Guide": [[57, null]], "Development Guide Using Docker": [[52, null]], "Development Guide for JIT Kernels": [[48, null]], "Diffusers Backend": [[90, "diffusers-backend"]], "Diffusion LLM": [[21, "diffusion-llm"]], "Diffusion Language Models": [[89, null]], "Diffusion Models": [[90, null]], "Disable NUMA Auto-Balancing": [[58, "disable-numa-auto-balancing"]], "Disable NUMA balancing": [[60, "disable-numa-balancing"]], "Distributed Computing": [[73, "distributed-computing"]], "Distributed environment warning": [[90, "distributed-environment-warning"]], "Docker": [[22, "docker"], [30, "docker"]], "Docs Workflow": [[0, "docs-workflow"]], "Documentation": [[70, "documentation"], [98, "documentation"]], "Documentation Style Guidelines": [[0, "documentation-style-guidelines"]], "Double Sparsity": [[21, "double-sparsity"]], "Download Weights": [[29, "download-weights"]], "Download image content": [[90, "download-image-content"]], "Download video content": [[90, "download-video-content"]], "Duration Buckets": [[22, "duration-buckets"]], "Dynamic Backend Loading": [[10, "dynamic-backend-loading"]], "Dynamic LoRA loading": [[13, "Dynamic-LoRA-loading"]], "Dynamic batch tokenizer": [[21, "dynamic-batch-tokenizer"]], "Dynamic inputs to fit static constraints of CUDA Graph": [[3, "dynamic-inputs-to-fit-static-constraints-of-cuda-graph"]], "EAGLE Decoding": [[24, "EAGLE-Decoding"]], "EAGLE Speculative Decoding": [[31, "eagle-speculative-decoding"], [34, "eagle-speculative-decoding"], [44, "eagle-speculative-decoding"]], "EAGLE-2 Decoding via Frequency-Ranked Speculative Sampling": [[24, "EAGLE-2-Decoding-via-Frequency-Ranked-Speculative-Sampling"]], "EAGLE-2 Decoding with torch.compile": [[24, "EAGLE-2-Decoding-with-torch.compile"]], "EAGLE-2 decoding": [[24, "EAGLE-2-decoding"]], "EAGLE-3 Decoding": [[24, "EAGLE-3-Decoding"]], "EBNF": [[25, "EBNF"], [25, "id2"], [25, "id6"], [26, "EBNF"], [26, "id2"], [26, "id6"]], "EP with Spectulative Decoding": [[7, "ep-with-spectulative-decoding"]], "EPD Disaggregation": [[6, null]], "Easy To Postpone Generation": [[23, "easy-to-postpone-generation"]], "Edit an image": [[90, "edit-an-image"]], "Embedding Models": [[66, "embedding-models"], [91, null]], "Enable Dynamic Chunking and Adjust Smoothing Factor for Ultra-long ITL": [[16, "enable-dynamic-chunking-and-adjust-smoothing-factor-for-ultra-long-itl"]], "Enabling Quantized KV Cache": [[18, "enabling-quantized-kv-cache"]], "Enabling cache for torch.compile": [[87, null]], "Encode (embedding model)": [[36, "Encode-(embedding-model)"]], "Encode prefill disaggregation": [[21, "encode-prefill-disaggregation"]], "End-to-end examples": [[49, "end-to-end-examples"]], "Endpoints": [[38, "endpoints"], [90, "endpoints"]], "Environment Setup": [[48, "environment-setup"]], "Environment Variables": [[73, null], [90, "environment-variables"]], "Environment Verification": [[70, "environment-verification"]], "Error Handling": [[88, "error-handling"]], "Evaluating New Models with SGLang": [[53, null]], "Evaluation": [[52, "evaluation"]], "Example Client Code Snippet": [[89, "example-client-code-snippet"]], "Example Client Request": [[96, "example-client-request"]], "Example Client Request (supports optional instruct, top_n, and return_documents)": [[96, "example-client-request-supports-optional-instruct-top-n-and-return-documents"]], "Example Configuration File": [[89, "example-configuration-file"]], "Example Configurations": [[4, "example-configurations"]], "Example Launch Command": [[89, "example-launch-command"]], "Example Usage": [[88, "example-usage"]], "Example Usage Commands": [[67, "example-usage-commands"]], "Example launch Command": [[92, "example-launch-command"], [95, "example-launch-command"], [97, "example-launch-command"], [99, "example-launch-command"]], "Example usage with the above optimizations:": [[32, "example-usage-with-the-above-optimizations"], [45, "example-usage-with-the-above-optimizations"]], "Example workflow": [[50, "example-workflow"]], "Example: DeepSeek-V3 Models": [[40, "Example:-DeepSeek-V3-Models"]], "Example: Implementing and Serving a Llama Wrapper Model": [[98, "example-implementing-and-serving-a-llama-wrapper-model"]], "Example: Qwen3 Models": [[40, "Example:-Qwen3-Models"]], "Example: Required Tool Choice": [[27, "Example:-Required-Tool-Choice"]], "Example: Running DeepSeek-V3.1-Terminus": [[67, "example-running-deepseek-v3-1-terminus"]], "Example: Running Llama-3.2-3B": [[67, "example-running-llama-3-2-3b"]], "Example: Running Ovis-Image-7B": [[90, "example-running-ovis-image-7b"]], "Example: Specific Function Choice": [[27, "Example:-Specific-Function-Choice"]], "Example: Switching LoRAs": [[90, "example-switching-loras"]], "Examples": [[7, "examples"], [7, "id1"], [22, "examples"], [22, "id9"], [46, "examples"], [49, "examples"], [58, "examples"]], "Examples of Offline Model Quantization": [[17, "examples-of-offline-model-quantization"]], "Execute the Tool": [[27, "Execute-the-Tool"]], "Expert Parallelism": [[7, null]], "Explicitly select devices": [[93, "explicitly-select-devices"]], "Extensible EP Framework": [[7, "extensible-ep-framework"]], "External Resources": [[70, "external-resources"]], "Extra Diffusers Arguments": [[90, "extra-diffusers-arguments"]], "FAQ": [[29, "faq"], [80, "faq"], [83, "faq"], [90, "faq"]], "FP4 Accuracy": [[18, "fp4-accuracy"]], "FP4 Format": [[18, "fp4-format"]], "FP8 (quantised) mode": [[32, "fp8-quantised-mode"], [45, "fp8-quantised-mode"]], "FP8 Accuracy": [[18, "fp8-accuracy"]], "FP8 Format": [[18, "fp8-format"]], "Feature Support Matrix": [[70, "feature-support-matrix"]], "Features": [[22, "features"]], "Fine-Grained Engine Sleep and Wake Up": [[23, "fine-grained-engine-sleep-and-wake-up"]], "Flush Cache": [[36, "Flush-Cache"]], "For Multi-Modal": [[21, "for-multi-modal"]], "For PD-Multiplexing": [[21, "for-pd-multiplexing"]], "For checkpoint decryption": [[21, "for-checkpoint-decryption"]], "Forcing Pythonic Tool Call Output Without a Chat Template": [[27, "Forcing-Pythonic-Tool-Call-Output-Without-a-Chat-Template"]], "Fork and clone the repository": [[51, "fork-and-clone-the-repository"], [59, "fork-and-clone-the-repository"]], "Format code with pre-commit": [[51, "format-code-with-pre-commit"], [59, "format-code-with-pre-commit"]], "Forward hooks": [[21, "forward-hooks"]], "Framework Overview": [[7, "framework-overview"]], "Frequently Asked Questions": [[74, "frequently-asked-questions"]], "Frontend Language": [[76, null], [76, null]], "Full Pipeline Profiling": [[90, "full-pipeline-profiling"]], "Full TLS Configuration Example": [[22, "full-tls-configuration-example"]], "Function Call Parsing": [[22, "function-call-parsing"]], "Function Calling / Tool Use": [[73, "function-calling-tool-use"]], "Function Calling and Reasoning Parser": [[30, "function-calling-and-reasoning-parser"]], "Function calling for DeepSeek Models": [[29, "function-calling-for-deepseek-models"]], "Future Works": [[13, "Future-Works"]], "GLM-4.6V / GLM-4.5V Usage": [[32, null]], "GPT OSS Usage": [[33, null]], "General Configuration": [[73, "general-configuration"]], "Generate": [[90, "generate"]], "Generate (text generation model)": [[36, "Generate-(text-generation-model)"]], "Generating Multiple Reproducible Responses": [[4, "generating-multiple-reproducible-responses"]], "Get Model Info": [[36, "Get-Model-Info"]], "Get Model Information": [[90, "get-model-information"]], "Get Server Info": [[36, "Get-Server-Info"]], "Get Started": [[57, null]], "Getting Token IDs": [[40, "Getting-Token-IDs"]], "Go Bindings": [[22, "go-bindings"]], "Greedy Token Selection": [[75, "greedy-token-selection"]], "Guidance about Dynamic Chunking": [[16, "guidance-about-dynamic-chunking"]], "HTTP API Usage": [[50, "http-api-usage"]], "HTTP server": [[21, "http-server"]], "Handle Tools": [[27, "Handle-Tools"], [27, "id1"]], "Hardware Platforms": [[57, null]], "Hardware-specific notes / recommendations": [[32, "hardware-specific-notes-recommendations"], [45, "hardware-specific-notes-recommendations"]], "Health Check": [[36, "Health-Check"]], "Health Checks": [[22, "health-checks"]], "HiCache System Design and Optimization": [[11, null]], "HiRadixTree: Metadata Organization in HiCache": [[11, "hiradixtree-metadata-organization-in-hicache"]], "Hierarchical KV Caching (HiCache)": [[9, null]], "Hierarchical cache": [[21, "hierarchical-cache"]], "Hierarchical sparse attention": [[21, "hierarchical-sparse-attention"]], "High Availability": [[22, "high-availability"]], "High Throughput": [[61, "high-throughput"], [61, "id2"]], "High-Performance Configuration: Qwen3-8B": [[70, "high-performance-configuration-qwen3-8b"]], "History and Data Connectors": [[22, "history-and-data-connectors"]], "Hook lifecycle and behavior": [[8, "hook-lifecycle-and-behavior"]], "Hook spec schema": [[8, "hook-spec-schema"]], "How to Contribute": [[70, "how-to-contribute"]], "How to Extend the Tracing Framework to Support Complex Tracing Scenarios": [[86, "how-to-extend-the-tracing-framework-to-support-complex-tracing-scenarios"]], "How to Generate a Report": [[90, "how-to-generate-a-report"]], "How to Support New Diffusion Models": [[90, "how-to-support-new-diffusion-models"]], "How to Support New Models": [[98, null]], "How to Support a New Language Model": [[98, "how-to-support-a-new-language-model"]], "How to Support a New Multimodal Large Language Model": [[98, "how-to-support-a-new-multimodal-large-language-model"]], "How to Trigger CI Tests": [[51, "how-to-trigger-ci-tests"], [59, "how-to-trigger-ci-tests"]], "How to add Tracing for slices you\u2019re interested in?": [[86, "how-to-add-tracing-for-slices-you-re-interested-in"]], "How to enable": [[27, "How-to-enable"]], "How to support a new model?": [[27, "How-to-support-a-new-model?"]], "How to update sgl-kernel": [[51, "how-to-update-sgl-kernel"], [59, "how-to-update-sgl-kernel"]], "How to update sgl-kernel-npu": [[59, "how-to-update-sgl-kernel-npu"]], "Hybrid attention (different backends for prefill vs decode) (Experimental)": [[1, "hybrid-attention-different-backends-for-prefill-vs-decode-experimental"]], "Hyperparameter Tuning": [[12, null]], "Image Generation": [[90, "image-generation"]], "Image Generation Models": [[90, "image-generation-models"]], "Image Reranking (text query, image/mixed documents)": [[96, "image-reranking-text-query-image-mixed-documents"]], "Image input:": [[32, "image-input"], [45, "image-input"]], "Image/Video Configuration": [[90, "image-video-configuration"]], "Implementation Details": [[88, "implementation-details"]], "Implementation Refactoring based on Async Communication": [[16, "implementation-refactoring-based-on-async-communication"]], "Implementing New Backends": [[7, "implementing-new-backends"]], "Implementing Our Model": [[98, "implementing-our-model"]], "Important Notes": [[50, "important-notes"]], "Important Server Parameters and Flags": [[32, "important-server-parameters-and-flags"], [45, "important-server-parameters-and-flags"]], "In sequence splitting (default setting)": [[30, "in-sequence-splitting-default-setting"]], "Inference Endpoints": [[22, "inference-endpoints"]], "Initialize the Client": [[27, "Initialize-the-Client"]], "Install Dependency": [[0, "install-dependency"]], "Install From Source": [[67, "install-from-source"], [71, "install-from-source"]], "Install SGLang": [[56, null], [58, "install-sglang"], [68, "install-sglang"]], "Install SGLang from Source": [[51, "install-sglang-from-source"], [59, "install-sglang-from-source"]], "Install SGLang-diffusion": [[90, "install-sglang-diffusion"]], "Install Using Docker": [[67, "install-using-docker"], [71, "install-using-docker"]], "Install Using Docker (Recommended)": [[58, "install-using-docker-recommended"]], "Install from Source": [[58, "install-from-source"], [68, "install-from-source"]], "Installation": [[2, "installation"], [17, "installation"], [22, "installation"], [22, "id5"], [22, "id8"], [30, "installation"], [67, "installation"], [70, "installation"], [71, "installation"], [90, "installation"], [93, "installation"]], "Installing SGLang from source": [[60, "installing-sglang-from-source"]], "Installing and running SGLang with Jetson Containers": [[69, "installing-and-running-sglang-with-jetson-containers"]], "Integer Range": [[48, "integer-range"]], "Integration with PD Disaggregation": [[10, "integration-with-pd-disaggregation"]], "Integration with PD-Disaggregation Deployment Mode": [[11, "integration-with-pd-disaggregation-deployment-mode"]], "Interactive Debugging": [[98, "interactive-debugging"]], "Introduction": [[93, "introduction"]], "Issues with Unified Scheduling": [[15, "issues-with-unified-scheduling"]], "JSON": [[25, "JSON"], [25, "id1"], [25, "id5"], [26, "JSON"], [26, "id1"], [26, "id5"]], "JSON Format": [[72, "json-format"]], "JSONL output format": [[49, "jsonl-output-format"]], "Jinja Format": [[72, "jinja-format"]], "Kernel Backends (Attention, Sampling, Grammar, GEMM)": [[21, "kernel-backends-attention-sampling-grammar-gemm"]], "Kernel Launching": [[48, "kernel-launching"]], "Key Configurations with Storage Backends Enabled": [[10, "key-configurations-with-storage-backends-enabled"]], "Key Features": [[90, "key-features"]], "Key Inference Metrics (gRPC mode)": [[22, "key-inference-metrics-grpc-mode"]], "Keys to success": [[79, "keys-to-success"]], "Known supported models": [[3, "known-supported-models"], [5, "known-supported-models"]], "Ktransformers": [[21, "ktransformers"]], "Kubernetes Deployment": [[22, "kubernetes-deployment"]], "Kubernetes Discovery": [[22, "kubernetes-discovery"]], "LLMs": [[53, "llms"], [53, "id1"]], "LMCache": [[21, "lmcache"]], "LWS Based PD Deploy": [[80, null]], "Language Bindings": [[22, "language-bindings"]], "Large Language Models": [[66, "large-language-models"], [92, null]], "Latency Optimization": [[70, "latency-optimization"]], "Latency Testing": [[70, "latency-testing"]], "Launch A Server": [[36, "Launch-A-Server"], [40, "Launch-A-Server"], [41, "Launch-A-Server"], [42, "Launch-A-Server"], [47, "Launch-A-Server"], [77, "Launch-A-Server"]], "Launch Command": [[96, "launch-command"], [96, "id1"], [96, "id2"]], "Launch Command for Different Attention Backends": [[1, "launch-command-for-different-attention-backends"]], "Launch DeepSeek V3.1/V3/R1 with SGLang": [[29, "launch-deepseek-v3-1-v3-r1-with-sglang"]], "Launch DeepSeek V3.2 with SGLang": [[30, "launch-deepseek-v3-2-with-sglang"]], "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang": [[31, null]], "Launch Llama 4 with SGLang": [[34, "launch-llama-4-with-sglang"]], "Launch Qwen3-Next with SGLang": [[44, "launch-qwen3-next-with-sglang"]], "Launch Server": [[91, "launch-server"]], "Launch commands for SGLang": [[32, "launch-commands-for-sglang"], [45, "launch-commands-for-sglang"]], "Launch of the Serving Engine": [[67, "launch-of-the-serving-engine"], [70, "launch-of-the-serving-engine"], [71, "launch-of-the-serving-engine"]], "Launch with one node of 8 x H200": [[29, "launch-with-one-node-of-8-x-h200"]], "Launching the Server": [[20, "Launching-the-Server"], [27, "Launching-the-Server"]], "Layer-wise NVTX Profiling with Nsight Systems": [[50, "layer-wise-nvtx-profiling-with-nsight-systems"]], "Learn More and Join the Community": [[78, null]], "Limitations": [[90, "limitations"]], "List LoRA Adapters": [[90, "list-lora-adapters"]], "List Workers": [[22, "list-workers"]], "List videos": [[90, "list-videos"]], "Llama 3.1 405B": [[81, "llama-3-1-405b"]], "Llama 4 Basic Call": [[28, "Llama-4-Basic-Call"]], "Llama Models": [[4, "llama-models"]], "Llama Single Node": [[15, "llama-single-node"], [15, "id3"], [15, "id7"]], "Llama4 Usage": [[34, null]], "LoRA": [[21, "lora"]], "LoRA GPU Pinning": [[13, "LoRA-GPU-Pinning"]], "LoRA Management": [[90, "lora-management"]], "LoRA Overlap Loading": [[13, "LoRA-Overlap-Loading"]], "LoRA Serving": [[13, null]], "Load Balancing Policies": [[22, "load-balancing-policies"]], "Load Balancing Router": [[23, "load-balancing-router"]], "Load Imbalance / Hot Workers": [[22, "load-imbalance-hot-workers"]], "Local Match": [[11, "local-match"]], "Logging": [[14, "logging"], [21, "logging"], [22, "logging"]], "Logit Bias Support": [[40, "Logit-Bias-Support"], [40, "id1"]], "Low Latency": [[61, "low-latency"], [61, "id1"]], "Low Throughput": [[70, "low-throughput"]], "MCP Configuration File": [[22, "mcp-configuration-file"]], "MCP Integration": [[22, "mcp-integration"]], "MHA Backends": [[1, "mha-backends"]], "MLA Backends": [[1, "mla-backends"]], "Make a release in GitHub": [[54, "make-a-release-in-github"]], "Mamba Cache": [[21, "mamba-cache"]], "Mamba Radix Cache": [[44, "mamba-radix-cache"]], "Matryoshka Embedding Example": [[91, "matryoshka-embedding-example"]], "MemFabric-Hybrid": [[60, "memfabric-hybrid"]], "Memory Growth": [[22, "memory-growth"]], "Memory Layout Optimization": [[10, "memory-layout-optimization"]], "Memory Management": [[73, "memory-management"]], "Memory Optimization": [[70, "memory-optimization"]], "Memory Savings": [[18, "memory-savings"]], "Memory and scheduling": [[21, "memory-and-scheduling"]], "Merge LoRA Weights": [[90, "merge-lora-weights"]], "Method 1: Installing from source with prerequisites": [[60, "method-1-installing-from-source-with-prerequisites"]], "Method 1: Using PyPI (Recommended)": [[70, "method-1-using-pypi-recommended"]], "Method 1: With pip or uv": [[56, "method-1-with-pip-or-uv"], [90, "method-1-with-pip-or-uv"]], "Method 2: From Source": [[70, "method-2-from-source"]], "Method 2: From source": [[56, "method-2-from-source"], [90, "method-2-from-source"]], "Method 2: Using Docker Image": [[60, "method-2-using-docker-image"]], "Method 3: Using Docker": [[70, "method-3-using-docker"], [90, "method-3-using-docker"]], "Method 3: Using docker": [[56, "method-3-using-docker"]], "Method 4: Cloud TPU with SkyPilot": [[70, "method-4-cloud-tpu-with-skypilot"]], "Method 4: Using Kubernetes": [[56, "method-4-using-kubernetes"]], "Method 5: Using docker compose": [[56, "method-5-using-docker-compose"]], "Method 6: Run on Kubernetes or Clouds with SkyPilot": [[56, "method-6-run-on-kubernetes-or-clouds-with-skypilot"]], "Method 7: Run on AWS SageMaker": [[56, "method-7-run-on-aws-sagemaker"]], "Methods": [[75, "methods"]], "Metric Categories (40+ metrics)": [[22, "metric-categories-40-metrics"]], "Metrics explained": [[49, "metrics-explained"]], "MindSpore Models": [[93, null]], "MiniMax M2.1/M2 Usage": [[35, null]], "MoE": [[21, "moe"]], "Model Deployment": [[61, "model-deployment"], [61, "id3"], [61, "id5"], [61, "id7"], [61, "id9"], [61, "id11"], [61, "id13"], [61, "id15"], [61, "id17"], [61, "id19"], [61, "id21"], [61, "id23"], [61, "id25"], [61, "id27"], [61, "id29"], [61, "id31"], [61, "id33"], [61, "id35"], [61, "id37"], [61, "id39"], [61, "id41"], [61, "id43"], [61, "id45"], [61, "id47"], [61, "id49"], [61, "id51"], [61, "id53"], [61, "id55"], [61, "id57"], [61, "id59"]], "Model Hooks": [[8, null]], "Model Thinking/Reasoning Support": [[40, "Model-Thinking/Reasoning-Support"]], "Model and tokenizer": [[21, "model-and-tokenizer"]], "Model override args": [[21, "model-override-args"]], "Model-Specific Behaviors": [[20, "Model-Specific-Behaviors"]], "Model-Specific Options": [[73, "model-specific-options"]], "Models x Optimization": [[90, "models-x-optimization"]], "Monitoring with PromQL": [[22, "monitoring-with-promql"]], "Mooncake": [[15, "mooncake"]], "Moore Threads GPUs": [[68, null]], "Motivation": [[3, "motivation"]], "Multi Token Prediction": [[24, "Multi-Token-Prediction"]], "Multi-Modal Embedding Model": [[41, "Multi-Modal-Embedding-Model"]], "Multi-Model Inference Gateway": [[22, "multi-model-inference-gateway"]], "Multi-Node Deployment": [[81, null], [82, null], [82, null]], "Multi-Node Distributed Serving": [[70, "multi-node-distributed-serving"]], "Multi-Node Inference on SLURM": [[81, "multi-node-inference-on-slurm"]], "Multi-Node Profiling and Shared Storage Considerations": [[50, "multi-node-profiling-and-shared-storage-considerations"]], "Multi-Node Setup (2 Nodes)": [[2, "multi-node-setup-2-nodes"]], "Multi-Node Setup with Tensor Parallelism (TP=16)": [[2, "multi-node-setup-with-tensor-parallelism-tp-16"]], "Multi-Node Tensor Parallelism": [[29, "multi-node-tensor-parallelism"]], "Multi-Rank Synchronization": [[11, "multi-rank-synchronization"]], "Multi-head Latent Attention (MLA) Throughput Optimizations": [[29, "multi-head-latent-attention-mla-throughput-optimizations"]], "Multi-layer Eagle speculative decoding": [[21, "multi-layer-eagle-speculative-decoding"]], "Multi-modal Generation": [[77, "Multi-modal-Generation"]], "Multi-node distributed serving": [[21, "multi-node-distributed-serving"]], "Multi-token Prediction": [[29, "multi-token-prediction"], [30, "multi-token-prediction"]], "Multi-turn Dialog": [[77, "Multi-turn-Dialog"]], "Multimodal": [[46, "multimodal"]], "Multimodal Embedding Example": [[91, "multimodal-embedding-example"]], "Multimodal Inputs Limitation": [[95, "multimodal-inputs-limitation"]], "Multimodal Language Models": [[66, "multimodal-language-models"], [95, null]], "Multimodal Query Reranking (query with image)": [[96, "multimodal-query-reranking-query-with-image"]], "Multiple-Image Inputs": [[42, "Multiple-Image-Inputs"]], "NCCL as backend": [[19, "nccl-as-backend"]], "NIXL": [[15, "nixl"]], "NIXL Backend Selection": [[15, "nixl-backend-selection"]], "NSA Backend Configuration (For DeepSeek V3.2)": [[73, "nsa-backend-configuration-for-deepseek-v3-2"]], "NVIDIA Jetson Orin": [[69, null]], "NVLink Transport Configuration": [[15, "nvlink-transport-configuration"]], "Native API and SGLang Runtime (SRT)": [[25, "Native-API-and-SGLang-Runtime-(SRT)"], [26, "Native-API-and-SGLang-Runtime-(SRT)"], [27, "Native-API-and-SGLang-Runtime-(SRT)"]], "Nest Asyncio": [[37, "Nest-Asyncio"]], "Ngram speculative decoding": [[21, "ngram-speculative-decoding"]], "Non-FP8 (BF16 / full precision) mode": [[32, "non-fp8-bf16-full-precision-mode"], [45, "non-fp8-bf16-full-precision-mode"]], "Non-Streaming Request": [[20, "Non-Streaming-Request"], [27, "Non-Streaming-Request"]], "Non-streaming Asynchronous Generation": [[37, "Non-streaming-Asynchronous-Generation"]], "Non-streaming Synchronous Generation": [[37, "Non-streaming-Synchronous-Generation"]], "Normal": [[46, "normal"]], "Note on defaults": [[46, "note-on-defaults"]], "Notes": [[22, "notes"], [33, "notes"], [49, "notes"], [90, "notes"]], "Notes for ROCm / MPS": [[90, "notes-for-rocm-mps"]], "Nsight Systems": [[90, "nsight-systems"]], "OOM (Out of Memory) Errors": [[70, "oom-out-of-memory-errors"]], "Observability": [[14, null], [22, "observability"]], "Obtain CANN Image": [[60, "obtain-cann-image"]], "Obtain Image": [[60, "obtain-image"]], "Offline Batch Inference": [[37, "Offline-Batch-Inference"]], "Offline Engine API": [[20, "Offline-Engine-API"], [25, "Offline-Engine-API"], [26, "Offline-Engine-API"], [27, "Offline-Engine-API"], [37, null]], "Offline Quantization": [[17, "offline-quantization"]], "Offline infer": [[93, "offline-infer"]], "Offloading": [[21, "offloading"]], "Ollama-Compatible API": [[38, null]], "Online Quantization": [[17, "online-quantization"]], "Open-To-Use Refit Functionality": [[23, "open-to-use-refit-functionality"]], "OpenAI APIs - Completions": [[40, null]], "OpenAI APIs - Embedding": [[41, null]], "OpenAI APIs - Vision": [[42, null]], "OpenAI Backend Proxy": [[22, "openai-backend-proxy"]], "OpenAI Compatible API": [[20, "OpenAI-Compatible-API"], [25, "OpenAI-Compatible-API"], [26, "OpenAI-Compatible-API"], [27, "OpenAI-Compatible-API"]], "OpenAI-Compatible APIs": [[39, null]], "OpenAI-compatible API usage": [[13, "OpenAI-compatible-API-usage"]], "OpenTelemetry Tracing": [[22, "opentelemetry-tracing"]], "Optimal Configuration": [[61, "optimal-configuration"]], "Optimization/debug options": [[21, "optimization-debug-options"]], "Optimizations": [[29, "optimizations"]], "Optimized Model List": [[67, "optimized-model-list"], [70, "optimized-model-list"], [71, "optimized-model-list"]], "Option 1. Use the default dev container automatically from VSCode": [[52, "option-1-use-the-default-dev-container-automatically-from-vscode"]], "Option 2. Start up containers manually (advanced)": [[52, "option-2-start-up-containers-manually-advanced"]], "Oracle Configuration": [[22, "oracle-configuration"]], "Other key options": [[49, "other-key-options"]], "Other options": [[46, "other-options"]], "Other tips": [[50, "other-tips"]], "Output Files": [[50, "output-files"]], "Output Location": [[90, "output-location"]], "Output Options": [[90, "output-options"]], "Overall Architecture": [[11, "overall-architecture"]], "Overall Workflow": [[11, "overall-workflow"]], "Overview": [[2, "overview"], [22, "overview"], [22, "id4"], [88, "overview"], [90, "overview"], [90, "id3"]], "PD Disaggregation": [[15, null], [30, "pd-disaggregation"]], "PD Disaggregation with PP + CP": [[30, "pd-disaggregation-with-pp-cp"]], "PD Mixed Scene": [[60, "pd-mixed-scene"], [60, "id1"]], "PD Mode Discovery": [[22, "pd-mode-discovery"]], "PD Separation Scene": [[60, "pd-separation-scene"]], "PD disaggregation": [[21, "pd-disaggregation"]], "Parallelism": [[77, "Parallelism"]], "Parameters": [[40, "Parameters"], [40, "id3"], [88, "parameters"]], "Parser Endpoints": [[22, "parser-endpoints"]], "Pause Generation": [[23, "pause-generation"]], "Penalizers": [[46, "penalizers"]], "Performance": [[22, "performance"], [53, "performance"]], "Performance Benefits": [[2, "performance-benefits"]], "Performance Considerations": [[18, "performance-considerations"]], "Performance Highlights": [[24, "Performance-Highlights"]], "Performance Optimization": [[70, "performance-optimization"], [95, "performance-optimization"]], "Performance Tips": [[90, "performance-tips"]], "Performance Tuning": [[73, "performance-tuning"]], "Pipeline Parallel + Context Parallel (PP + CP)": [[30, "pipeline-parallel-context-parallel-pp-cp"]], "Pipeline Parallelism for Long Context": [[16, null]], "Platform support matrix": [[90, "platform-support-matrix"]], "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)": [[43, null]], "Port a Model from vLLM to SGLang": [[98, "port-a-model-from-vllm-to-sglang"]], "Possible PyTorch bugs": [[50, "possible-pytorch-bugs"]], "Post-Training Integration": [[84, null]], "PostgreSQL Configuration": [[22, "postgresql-configuration"]], "Prefetch Policies": [[10, "prefetch-policies"]], "Prefetch from L3": [[11, "prefetch-from-l3"]], "Prefill": [[80, "prefill"]], "Prefill Server Configuration": [[15, "prefill-server-configuration"]], "Prefill-Decode Disaggregation": [[22, "prefill-decode-disaggregation"]], "Prefill/Decode": [[22, "prefill-decode"]], "Prepare Environment": [[59, "prepare-environment"]], "Preparing the Running Environment": [[60, "preparing-the-running-environment"]], "Prerequisites": [[22, "prerequisites"], [38, "prerequisites"], [49, "prerequisites"], [69, "prerequisites"], [79, "prerequisites"], [85, "prerequisites"], [90, "prerequisites"]], "Prevent swapping out system memory": [[60, "prevent-swapping-out-system-memory"]], "Production Metrics": [[14, "production-metrics"], [85, null]], "Production Recommendations": [[22, "production-recommendations"]], "Production Request Tracing": [[86, null]], "Profile": [[52, "profile"]], "Profile Decode Workers": [[50, "profile-decode-workers"]], "Profile In PD Disaggregation Mode": [[50, "profile-in-pd-disaggregation-mode"]], "Profile Prefill Workers": [[50, "profile-prefill-workers"]], "Profile a server with HTTP API endpoints": [[50, "profile-a-server-with-http-api-endpoints"]], "Profile a server with sglang.bench_offline_throughput": [[50, "profile-a-server-with-sglang-bench-offline-throughput"]], "Profile a server with sglang.bench_serving": [[50, "profile-a-server-with-sglang-bench-serving"]], "Profile a server with sglang.profiler": [[50, "profile-a-server-with-sglang-profiler"]], "Profile with Nsight": [[50, "profile-with-nsight"]], "Profile with PyTorch Profiler": [[50, "profile-with-pytorch-profiler"]], "Profiler Trace Merger for Distributed Traces": [[50, "profiler-trace-merger-for-distributed-traces"]], "Profiling & Benchmarking": [[73, "profiling-benchmarking"]], "Profiling Multimodal Generation": [[90, "profiling-multimodal-generation"]], "Profiling in PD Disaggregation Mode": [[15, "profiling-in-pd-disaggregation-mode"]], "Prometheus Metrics": [[22, "prometheus-metrics"]], "PyPI Package Release Process": [[54, null]], "PyTorch Profiler": [[90, "pytorch-profiler"]], "Python API Usage": [[17, "python-api-usage"]], "Python Bindings": [[22, "python-bindings"]], "Python Interface": [[48, "python-interface"]], "Python Package": [[22, "python-package"]], "Python Tool": [[33, "python-tool"]], "Python Version": [[60, "python-version"]], "Pythonic Tool Call Format (Llama-3.2 / Llama-3.3 / Llama-4)": [[27, "Pythonic-Tool-Call-Format-(Llama-3.2-/-Llama-3.3-/-Llama-4)"]], "Pytorch and Pytorch Framework Adaptor on Ascend": [[60, "pytorch-and-pytorch-framework-adaptor-on-ascend"]], "Quantization": [[17, null], [73, "quantization"], [99, "quantization"]], "Quantization and Export Workflow": [[17, "quantization-and-export-workflow"]], "Quantization and data type": [[21, "quantization-and-data-type"]], "Quantized KV Cache": [[18, null]], "Query VLM with Offline Engine": [[28, null]], "Querying Llama 4 Vision Model": [[28, "Querying-Llama-4-Vision-Model"]], "Querying Qwen2.5-VL Model": [[28, "Querying-Qwen2.5-VL-Model"]], "Queue Overflow (429)": [[22, "queue-overflow-429"]], "Quick Demo": [[33, "quick-demo"]], "Quick Start": [[22, "quick-start"], [38, "quick-start"], [91, "quick-start"]], "Quick start": [[49, "quick-start"]], "Qwen Series Models": [[61, "qwen-series-models"]], "Qwen VL": [[6, "qwen-vl"]], "Qwen3 235B High Throughput 50ms 1": [[61, "qwen3-235b-high-throughput-50ms-1"]], "Qwen3 235B High Throughput 50ms 2": [[61, "qwen3-235b-high-throughput-50ms-2"]], "Qwen3 235B High Throughput 50ms 3": [[61, "qwen3-235b-high-throughput-50ms-3"]], "Qwen3 235B High Throughput 50ms 4": [[61, "qwen3-235b-high-throughput-50ms-4"]], "Qwen3 235B Low Latency 10ms": [[61, "qwen3-235b-low-latency-10ms"]], "Qwen3 32B A2 High Throughput 50ms 1": [[61, "qwen3-32b-a2-high-throughput-50ms-1"]], "Qwen3 32B A2 High Throughput 50ms 2": [[61, "qwen3-32b-a2-high-throughput-50ms-2"]], "Qwen3 32B A2 Low Latency 11ms": [[61, "qwen3-32b-a2-low-latency-11ms"]], "Qwen3 32B A2 Low Latency 18ms": [[61, "qwen3-32b-a2-low-latency-18ms"]], "Qwen3 32B High Throughput 50ms 1": [[61, "qwen3-32b-high-throughput-50ms-1"]], "Qwen3 32B High Throughput 50ms 2": [[61, "qwen3-32b-high-throughput-50ms-2"]], "Qwen3 32B High Throughput 50ms 3": [[61, "qwen3-32b-high-throughput-50ms-3"]], "Qwen3 32B Low Latency 11ms": [[61, "qwen3-32b-low-latency-11ms"]], "Qwen3 32B Low Latency 12ms": [[61, "qwen3-32b-low-latency-12ms"]], "Qwen3 32B Low Latency 18ms": [[61, "qwen3-32b-low-latency-18ms"]], "Qwen3 480B High Throughput 50ms 1": [[61, "qwen3-480b-high-throughput-50ms-1"]], "Qwen3 480B High Throughput 50ms 2": [[61, "qwen3-480b-high-throughput-50ms-2"]], "Qwen3 480B High Throughput 50ms 3": [[61, "qwen3-480b-high-throughput-50ms-3"]], "Qwen3 Next High Throughput 50ms": [[61, "qwen3-next-high-throughput-50ms"]], "Qwen3 examples": [[64, null]], "Qwen3-235B Atlas 800I A3-8Card PD Mixed 2K-2K 100ms": [[61, "qwen3-235b-atlas-800i-a3-8card-pd-mixed-2k-2k-100ms"]], "Qwen3-235B-A22B-FP8 with 128K Input Token Length": [[16, "qwen3-235b-a22b-fp8-with-128k-input-token-length"]], "Qwen3-30B-A3B (MoE Model)": [[4, "qwen3-30b-a3b-moe-model"]], "Qwen3-8B": [[4, "qwen3-8b"]], "Qwen3-Next Usage": [[44, null]], "Qwen3-Reranker (decoder-only yes/no rerank)": [[96, "qwen3-reranker-decoder-only-yes-no-rerank"]], "Qwen3-VL Usage": [[45, null]], "Qwen3-VL-Reranker (multimodal decoder-only rerank)": [[96, "qwen3-vl-reranker-multimodal-decoder-only-rerank"]], "R-Fork": [[19, null]], "RDMA RoCE case": [[79, "rdma-roce-case"]], "ROCm quickstart for sgl-diffusion": [[90, "rocm-quickstart-for-sgl-diffusion"]], "Rate Limiting and Queuing": [[22, "rate-limiting-and-queuing"]], "Rate, concurrency, and streaming": [[49, "rate-concurrency-and-streaming"]], "Reasoning Content for DeepSeek R1 & V3.1": [[29, "reasoning-content-for-deepseek-r1-v3-1"]], "Reasoning Parser": [[20, null]], "Reasoning Parser Integration": [[22, "reasoning-parser-integration"]], "Redis Configuration": [[22, "redis-configuration"]], "Reference": [[17, "reference"]], "References": [[2, "references"], [24, "References"], [57, null], [69, "references"], [70, "references"], [90, "references"], [90, "id5"]], "Registering an External Model Implementation": [[98, "registering-an-external-model-implementation"]], "Regular HTTP Routing": [[22, "regular-http-routing"]], "Regular expression": [[25, "Regular-expression"], [25, "id3"], [25, "id7"], [26, "Regular-expression"], [26, "id3"], [26, "id7"]], "Related Parameters": [[11, "related-parameters"]], "Release Memory": [[23, "release-memory"]], "Reliability and Flow Control": [[22, "reliability-and-flow-control"]], "Remaining issues": [[79, "remaining-issues"]], "Remote code": [[99, "remote-code"]], "Reporting Results": [[53, "reporting-results"]], "Request": [[22, "request"]], "Request Dump and Replay": [[14, "request-dump-and-replay"]], "Request Format": [[88, "request-format"]], "Request ID Propagation": [[22, "request-id-propagation"]], "Request Parameters (Multimodal)": [[96, "request-parameters-multimodal"]], "RequestMetricsExporter configuration": [[21, "requestmetricsexporter-configuration"]], "Requesting a review for merge": [[51, "requesting-a-review-for-merge"], [59, "requesting-a-review-for-merge"]], "Requirements": [[15, "requirements"], [15, "id1"], [93, "requirements"]], "Rerank Models": [[66, "rerank-models"], [96, null]], "Response": [[22, "response"], [22, "id1"]], "Response Fields": [[22, "response-fields"], [88, "response-fields"]], "Response Format": [[88, "response-format"], [96, "response-format"]], "Responses API": [[33, "responses-api"]], "Responses API & Built-in Tools": [[33, "responses-api-built-in-tools"]], "Resume Memory": [[23, "resume-memory"]], "Retries": [[22, "retries"]], "Returning Routed Experts (MoE Models)": [[40, "Returning-Routed-Experts-(MoE-Models)"], [40, "id4"]], "Reward Models": [[66, "reward-models"], [97, null]], "Reward Models (Single score)": [[88, "reward-models-single-score"]], "RoCE scenario": [[79, "roce-scenario"]], "Rotary buffer management": [[3, "rotary-buffer-management"]], "Round robin splitting": [[30, "round-robin-splitting"]], "Router API Key": [[22, "router-api-key"]], "Router Integration": [[15, "router-integration"]], "Run Model": [[93, "run-model"]], "Run and add unit tests": [[51, "run-and-add-unit-tests"], [59, "run-and-add-unit-tests"]], "Running DeepSeek in PD mixed mode on 1 x Atlas 800I A3.": [[62, "running-deepseek-in-pd-mixed-mode-on-1-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation mode on 2 x Atlas 800I A3.": [[62, "running-deepseek-with-pd-disaggregation-mode-on-2-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3.": [[62, "running-deepseek-with-pd-disaggregation-on-4-x-atlas-800i-a3"]], "Running DeepSeek-V3": [[58, "running-deepseek-v3"], [62, "running-deepseek-v3"]], "Running Inference": [[69, "running-inference"]], "Running Llama3.1": [[58, "running-llama3-1"]], "Running Qwen3": [[64, "running-qwen3"]], "Running Qwen3-235B-A22B-Instruct-2507 MOE on 1 x Atlas 800I A3.": [[64, "running-qwen3-235b-a22b-instruct-2507-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-30B-A3B MOE on 1 x Atlas 800I A3.": [[64, "running-qwen3-30b-a3b-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-32B on 1 x Atlas 800I A3 with Qwen3-32B-Eagle3.": [[64, "running-qwen3-32b-on-1-x-atlas-800i-a3-with-qwen3-32b-eagle3"]], "Running Qwen3-32B on 1 x Atlas 800I A3.": [[64, "running-qwen3-32b-on-1-x-atlas-800i-a3"]], "Running Qwen3-VL-8B-Instruct on 1 x Atlas 800I A3.": [[64, "running-qwen3-vl-8b-instruct-on-1-x-atlas-800i-a3"]], "Running SGLang Service": [[60, "running-sglang-service"]], "Running Service For Large Language Models": [[60, "running-service-for-large-language-models"]], "Running Service For Multimodal Language Models": [[60, "running-service-for-multimodal-language-models"]], "Running examples on Multi-Node": [[29, "running-examples-on-multi-node"]], "Running quantization with TorchAO": [[69, "running-quantization-with-torchao"]], "Runtime Checking": [[48, "runtime-checking"]], "Runtime Configuration": [[22, "runtime-configuration"]], "Runtime options": [[21, "runtime-options"]], "Rust Binary": [[22, "rust-binary"]], "SCM (Step Computation Masking)": [[90, "scm-step-computation-masking"]], "SCM Policy": [[90, "scm-policy"]], "SCM Presets": [[90, "scm-presets"]], "SCM disabled for low step count": [[90, "scm-disabled-for-low-step-count"]], "SGLang Diffusion OpenAI API": [[90, "sglang-diffusion-openai-api"]], "SGLang Documentation": [[0, null], [57, null]], "SGLang Frontend Language": [[77, null]], "SGLang HiCache Best Practices": [[10, null]], "SGLang Kernels NPU": [[60, "sglang-kernels-npu"]], "SGLang Model Gateway": [[22, null]], "SGLang Native API": [[20, "SGLang-Native-API"]], "SGLang Native APIs": [[36, null]], "SGLang Server Options": [[2, "sglang-server-options"]], "SGLang diffusion CLI Inference": [[90, "sglang-diffusion-cli-inference"]], "SGLang for RL Systems": [[23, null]], "SGLang installation with NPUs support": [[60, null]], "SGLang\u2019s Solution": [[4, "sglang-s-solution"]], "STEP 1: Write the C++ kernel": [[48, "step-1-write-the-c-kernel"]], "STEP 2: Create Python Interfaces": [[48, "step-2-create-python-interfaces"]], "STEP 3: Use your kernel": [[48, "step-3-use-your-kernel"]], "Sampling Parameters": [[46, null], [90, "sampling-parameters"]], "Sampling parameters": [[46, "id1"]], "Scaling Factors": [[18, "scaling-factors"]], "Security Best Practices": [[22, "security-best-practices"]], "Security Configurations": [[22, "security-configurations"]], "Security and Authentication": [[22, "security-and-authentication"]], "Select a backend via CLI": [[90, "select-a-backend-via-cli"]], "Selection priority": [[90, "selection-priority"]], "Send Results Back to Model": [[27, "Send-Results-Back-to-Model"]], "Sending Image/Video Requests": [[32, "sending-image-video-requests"], [45, "sending-image-video-requests"]], "Sending Requests": [[47, null]], "Separate Launch (HTTP)": [[22, "separate-launch-http"]], "Separate Reasoning Request": [[22, "separate-reasoning-request"]], "Serve": [[90, "serve"], [90, "id1"]], "Server Arguments": [[4, "server-arguments"], [21, null], [90, "server-arguments"]], "Server flag": [[23, "server-flag"]], "Service Discovery (Kubernetes)": [[22, "service-discovery-kubernetes"]], "Serving Multiple Adaptors": [[13, "Serving-Multiple-Adaptors"]], "Serving Our Model Via SGLang\u2019s Offline Engine": [[98, "serving-our-model-via-sglang-s-offline-engine"]], "Serving Single Adaptor": [[13, "Serving-Single-Adaptor"]], "Set LoRA Adapter": [[90, "set-lora-adapter"]], "Set Up Self-Hosted Runners for GitHub Action": [[55, null]], "Setup Docker Container": [[52, "setup-docker-container"]], "Setup Guide": [[85, "setup-guide"], [86, "setup-guide"]], "Setup VSCode on a Remote Host": [[52, "setup-vscode-on-a-remote-host"]], "Single Node Setup": [[2, "single-node-setup"]], "Single-Batch Overlap (SBO)": [[7, "single-batch-overlap-sbo"]], "Smart Router": [[38, "smart-router"]], "Software Requirements": [[70, "software-requirements"]], "Some communication environment issues": [[93, "some-communication-environment-issues"]], "Some dependencies of protobuf": [[93, "some-dependencies-of-protobuf"]], "Special Requirements": [[90, "special-requirements"]], "Speculative Decoding": [[24, null], [33, "speculative-decoding"], [70, "speculative-decoding"]], "Speculative decoding": [[21, "speculative-decoding"]], "Speculative decoding with hybrid attention": [[1, "speculative-decoding-with-hybrid-attention"]], "Stable addresses": [[3, "stable-addresses"]], "Standard Usage": [[30, "standard-usage"]], "Start server": [[93, "start-server"]], "Start the server": [[90, "start-the-server"], [90, "id2"]], "Step 1: Start a docker container.": [[55, "step-1-start-a-docker-container"]], "Step 2: Configure the runner by config.sh": [[55, "step-2-configure-the-runner-by-config-sh"]], "Step 3: Run the runner by run.sh": [[55, "step-3-run-the-runner-by-run-sh"]], "Steps to add a new attention backend": [[1, "steps-to-add-a-new-attention-backend"]], "Storage & Caching": [[73, "storage-caching"]], "Storage and Privacy": [[22, "storage-and-privacy"]], "Streaming": [[46, "streaming"], [47, "Streaming"], [47, "id1"], [77, "Streaming"]], "Streaming Asynchronous Generation": [[37, "Streaming-Asynchronous-Generation"]], "Streaming Request": [[20, "Streaming-Request"], [27, "Streaming-Request"]], "Streaming Synchronous Generation": [[37, "Streaming-Synchronous-Generation"]], "Structural Tag": [[25, "Structural-Tag"], [25, "id4"], [25, "id8"], [26, "Structural-Tag"], [26, "id4"]], "Structured Outputs": [[25, null]], "Structured Outputs (JSON, Regex, EBNF)": [[40, "Structured-Outputs-(JSON,-Regex,-EBNF)"], [46, "structured-outputs-json-regex-ebnf"]], "Structured Outputs For Reasoning Models": [[26, null]], "Structured output with XGrammar": [[69, "structured-output-with-xgrammar"]], "Summary": [[8, "summary"], [38, "summary"]], "Support": [[93, "support"]], "Support Matrix": [[1, "support-matrix"]], "Support Models on Ascend NPU": [[66, null]], "Supported Arguments": [[90, "supported-arguments"]], "Supported Backends": [[4, "supported-backends"]], "Supported Backends and Selection Guidance": [[7, "supported-backends-and-selection-guidance"]], "Supported Formats": [[18, "supported-formats"], [22, "supported-formats"]], "Supported Models": [[26, "Supported-Models"], [35, "supported-models"], [57, null], [88, "supported-models"], [89, "supported-models"], [90, "supported-models"], [91, "supported-models"], [93, "supported-models"]], "Supported Models & Parsers": [[20, "Supported-Models-&-Parsers"]], "Supported Models and Configuration": [[40, "Supported-Models-and-Configuration"]], "Supported Parsers": [[22, "supported-parsers"]], "Supported TPU Hardware": [[70, "supported-tpu-hardware"]], "Supported Tool Choice Options": [[27, "Supported-Tool-Choice-Options"]], "Supported Transports": [[22, "supported-transports"]], "Supported backends and endpoints": [[49, "supported-backends-and-endpoints"]], "Supported features": [[99, "supported-features"]], "Supported models": [[92, "supported-models"], [95, "supported-models"], [97, "supported-models"]], "Supported rerank models": [[96, "supported-rerank-models"]], "Supporting New Reasoning Model Schemas": [[20, "Supporting-New-Reasoning-Model-Schemas"]], "System Configuration": [[58, "system-configuration"]], "System Design": [[11, "system-design"]], "System Requirements": [[35, "system-requirements"], [70, "system-requirements"]], "System Settings": [[60, "system-settings"]], "TLS (HTTPS) for Gateway Server": [[22, "tls-https-for-gateway-server"]], "TLS Configuration": [[22, "tls-configuration"]], "TODO": [[79, "todo"]], "TPU": [[70, null]], "TPU-Specific Optimizations": [[70, "tpu-specific-optimizations"]], "Table of Contents": [[22, "table-of-contents"]], "Targeted Stage Profiling": [[90, "targeted-stage-profiling"]], "TaylorSeer Configuration": [[90, "taylorseer-configuration"]], "Tensor Checking": [[48, "tensor-checking"]], "Test the accuracy": [[51, "test-the-accuracy"], [59, "test-the-accuracy"]], "Testing": [[22, "testing"], [88, "testing"]], "Testing & Debugging (Internal/CI)": [[73, "testing-debugging-internal-ci"]], "Testing Deployment": [[35, "testing-deployment"]], "Testing and Debugging": [[98, "testing-and-debugging"]], "Testing on TPU": [[70, "testing-on-tpu"]], "Text-Only Reranking (backward compatible)": [[96, "text-only-reranking-backward-compatible"]], "The Root Cause of Non-Determinism": [[4, "the-root-cause-of-non-determinism"]], "The results are not deterministic, even with a temperature of 0": [[74, "the-results-are-not-deterministic-even-with-a-temperature-of-0"]], "The server hangs": [[74, "the-server-hangs"]], "Thinking Budget for DeepSeek R1": [[29, "thinking-budget-for-deepseek-r1"]], "Thinking Budget for GLM-4.5 / GLM-4.6": [[31, "thinking-budget-for-glm-4-5-glm-4-6"]], "Thinking Budget for GLM-4.5V / GLM-4.6V": [[32, "thinking-budget-for-glm-4-5v-glm-4-6v"]], "Throughput Optimization": [[70, "throughput-optimization"]], "Throughput Testing": [[70, "throughput-testing"]], "Tips for newcomers": [[51, "tips-for-newcomers"], [59, "tips-for-newcomers"]], "Token Length Normalized": [[75, "token-length-normalized"]], "Tokenization Endpoints": [[22, "tokenization-endpoints"]], "Tokenize Request": [[22, "tokenize-request"]], "Tokenize Response": [[22, "tokenize-response"]], "Tokenize/Detokenize Example (Round Trip)": [[36, "Tokenize/Detokenize-Example-(Round-Trip)"]], "Tokenizer Caching": [[22, "tokenizer-caching"]], "Tokenizer Loading Failures": [[22, "tokenizer-loading-failures"]], "Tokenizer Management": [[22, "tokenizer-management"]], "Tokenizer Sources": [[22, "tokenizer-sources"]], "Tool & Reasoning Parser": [[33, "tool-reasoning-parser"]], "Tool Call Parsing": [[22, "tool-call-parsing"]], "Tool Choice Mode": [[27, "Tool-Choice-Mode"]], "Tool Parser": [[27, null]], "Top-level fields": [[8, "top-level-fields"]], "TransferEngine as backend": [[19, "transferengine-as-backend"]], "Transformers fallback in SGLang": [[99, null]], "Triton on Ascend": [[60, "triton-on-ascend"]], "Troubleshooting": [[2, "troubleshooting"], [22, "troubleshooting"], [49, "troubleshooting"], [70, "troubleshooting"], [74, "troubleshooting"], [85, "troubleshooting"], [90, "troubleshooting"], [93, "troubleshooting"]], "Troubleshooting and Frequently Asked Questions": [[74, null]], "Try other options": [[12, "try-other-options"]], "Tune --cuda-graph-max-bs": [[12, "tune-cuda-graph-max-bs"]], "Tune --dp-size and --tp-size": [[12, "tune-dp-size-and-tp-size"]], "Tune --mem-fraction-static to increase KV cache pool capacity": [[12, "tune-mem-fraction-static-to-increase-kv-cache-pool-capacity"]], "Tuning the Chunked Prefill Size": [[16, "tuning-the-chunked-prefill-size"]], "Two-Batch Overlap (TBO)": [[7, "two-batch-overlap-tbo"]], "Unconditional Likelihood Normalized": [[75, "unconditional-likelihood-normalized"]], "Understanding the Three Input Formats": [[28, "Understanding-the-Three-Input-Formats"]], "Unified Interfaces and Rich L3 Storage Backends": [[11, "unified-interfaces-and-rich-l3-storage-backends"]], "Unmerge LoRA Weights": [[90, "unmerge-lora-weights"]], "Update Documentation": [[0, "update-documentation"]], "Update GRUB Settings": [[58, "update-grub-settings"]], "Update Weights From Disk": [[36, "Update-Weights-From-Disk"]], "Update Weights from Disk": [[23, "update-weights-from-disk"]], "Update Weights from Distributed Group": [[23, "update-weights-from-distributed-group"]], "Update Weights from Tensor": [[23, "update-weights-from-tensor"]], "Update the version in code": [[54, "update-the-version-in-code"]], "Upload the PyPI package": [[54, "upload-the-pypi-package"]], "Usage": [[4, "usage"], [6, "usage"], [13, "Usage"], [15, "usage"], [15, "id2"], [15, "id6"], [18, "usage"], [19, "usage"], [20, "Usage"], [22, "usage"], [22, "id2"], [22, "id6"], [26, "Usage"], [40, "Usage"], [40, "id2"], [85, "usage"], [90, "usage"], [90, "id4"]], "Usage Examples": [[2, "usage-examples"]], "Usage Notes": [[95, "usage-notes"]], "Use Models From ModelScope": [[94, null]], "User Guide": [[1, "user-guide"]], "Using --enable-layerwise-nvtx-marker with Nsight Systems and /start_profile": [[50, "using-enable-layerwise-nvtx-marker-with-nsight-systems-and-start-profile"]], "Using /end_profile endpoint": [[50, "using-end-profile-endpoint"]], "Using /start_profile endpoint": [[50, "using-start-profile-endpoint"]], "Using Configuration Files": [[90, "using-configuration-files"]], "Using GPTQModel": [[17, "using-gptqmodel"]], "Using Input IDs": [[41, "Using-Input-IDs"]], "Using LLM Compressor": [[17, "using-llm-compressor"]], "Using LoRA Adapters": [[40, "Using-LoRA-Adapters"]], "Using NVIDIA ModelOpt": [[17, "using-nvidia-modelopt"]], "Using Native Generation APIs": [[47, "Using-Native-Generation-APIs"]], "Using OpenAI Python Client": [[41, "Using-OpenAI-Python-Client"], [42, "Using-OpenAI-Python-Client"], [47, "Using-OpenAI-Python-Client"]], "Using Python": [[88, "using-python"]], "Using Python Requests": [[41, "Using-Python-Requests"], [42, "Using-Python-Requests"], [47, "Using-Python-Requests"]], "Using Sliding Tile Attention (STA)": [[90, "using-sliding-tile-attention-sta"]], "Using Unsloth": [[17, "using-unsloth"]], "Using auto-round": [[17, "using-auto-round"]], "Using cURL": [[41, "Using-cURL"], [42, "Using-cURL"], [47, "Using-cURL"]], "Using curl": [[88, "using-curl"]], "VLMs": [[53, "vlms"]], "Verification": [[4, "verification"]], "Verified LoRA Examples": [[90, "verified-lora-examples"]], "Verified LoRAs by Base Model": [[90, "verified-loras-by-base-model"]], "Video Generation": [[90, "video-generation"]], "Video Generation Models": [[90, "video-generation-models"]], "Video Input Support": [[95, "video-input-support"]], "Video Input:": [[32, "video-input"], [45, "video-input"]], "View Traces": [[90, "view-traces"]], "View traces": [[50, "view-traces"]], "WASM Middleware": [[22, "wasm-middleware"]], "Warmup Step": [[58, "warmup-step"]], "Web Search Tool": [[33, "web-search-tool"]], "What it does": [[49, "what-it-does"]], "Why Deterministic Inference Matters": [[4, "why-deterministic-inference-matters"]], "Why Dynamic Chunking": [[16, "why-dynamic-chunking"]], "Why HiCache Matters": [[10, "why-hicache-matters"]], "Why Pipeline Parallelism?": [[16, "why-pipeline-parallelism"]], "Why SGLang for RL Lifecycle?": [[23, "why-sglang-for-rl-lifecycle"]], "Why and What is EPD Disaggregation?": [[6, "why-and-what-is-epd-disaggregation"]], "Why and What is HiCache?": [[11, "why-and-what-is-hicache"]], "Why and What is PD Disaggregation?": [[15, "why-and-what-is-pd-disaggregation"]], "Worker API Keys": [[22, "worker-api-keys"]], "Worker Management APIs": [[22, "worker-management-apis"]], "Workers Never Ready": [[22, "workers-never-ready"]], "Workload Balancer": [[7, "workload-balancer"]], "Write documentations": [[51, "write-documentations"], [59, "write-documentations"]], "Writing a hook factory": [[8, "writing-a-hook-factory"]], "XPU": [[71, null]], "config (optional)": [[8, "config-optional"]], "gRPC Connection Issues": [[22, "grpc-connection-issues"]], "gRPC Launch": [[22, "grpc-launch"]], "gRPC Routing": [[22, "grpc-routing"]], "hook_factory (required)": [[8, "hook-factory-required"]], "mTLS for Worker Communication": [[22, "mtls-for-worker-communication"]], "name (optional)": [[8, "name-optional"]], "quark_int4fp8_moe online quantization method": [[17, "quark-int4fp8-moe-online-quantization-method"]], "target_modules (required)": [[8, "target-modules-required"]], "test gsm8k": [[62, "test-gsm8k"]], "torchao online quantization method": [[17, "torchao-online-quantization-method"]], "v1/rerank (cross encoder rerank model)": [[36, "v1/rerank-(cross-encoder-rerank-model)"]], "v1/score (decoder-only scoring)": [[36, "v1/score-(decoder-only-scoring)"]]}, "docnames": ["README", "advanced_features/attention_backend", "advanced_features/checkpoint_engine", "advanced_features/cuda_graph_for_multi_modal_encoder", "advanced_features/deterministic_inference", "advanced_features/dp_for_multi_modal_encoder", "advanced_features/epd_disaggregation", "advanced_features/expert_parallelism", "advanced_features/forward_hooks", "advanced_features/hicache", "advanced_features/hicache_best_practices", "advanced_features/hicache_design", "advanced_features/hyperparameter_tuning", "advanced_features/lora", "advanced_features/observability", "advanced_features/pd_disaggregation", "advanced_features/pipeline_parallelism", "advanced_features/quantization", "advanced_features/quantized_kv_cache", "advanced_features/rfork", "advanced_features/separate_reasoning", "advanced_features/server_arguments", "advanced_features/sgl_model_gateway", "advanced_features/sglang_for_rl", "advanced_features/speculative_decoding", "advanced_features/structured_outputs", "advanced_features/structured_outputs_for_reasoning_models", "advanced_features/tool_parser", "advanced_features/vlm_query", "basic_usage/deepseek_v3", "basic_usage/deepseek_v32", "basic_usage/glm45", "basic_usage/glmv", "basic_usage/gpt_oss", "basic_usage/llama4", "basic_usage/minimax_m2", "basic_usage/native_api", "basic_usage/offline_engine_api", "basic_usage/ollama_api", "basic_usage/openai_api", "basic_usage/openai_api_completions", "basic_usage/openai_api_embeddings", "basic_usage/openai_api_vision", "basic_usage/popular_model_usage", "basic_usage/qwen3", "basic_usage/qwen3_vl", "basic_usage/sampling_params", "basic_usage/send_request", "developer_guide/JIT_kernels", "developer_guide/bench_serving", "developer_guide/benchmark_and_profiling", "developer_guide/contribution_guide", "developer_guide/development_guide_using_docker", "developer_guide/evaluating_new_models", "developer_guide/release_process", "developer_guide/setup_github_runner", "get_started/install", "index", "platforms/amd_gpu", "platforms/ascend_contribution_guide", "platforms/ascend_npu", "platforms/ascend_npu_best_practice", "platforms/ascend_npu_deepseek_example", "platforms/ascend_npu_quantization", "platforms/ascend_npu_qwen3_examples", "platforms/ascend_npu_support", "platforms/ascend_npu_support_models", "platforms/cpu_server", "platforms/mthreads_gpu", "platforms/nvidia_jetson", "platforms/tpu", "platforms/xpu", "references/custom_chat_template", "references/environment_variables", "references/faq", "references/frontend/choices_methods", "references/frontend/frontend_index", "references/frontend/frontend_tutorial", "references/learn_more", "references/multi_node_deployment/deploy_on_k8s", "references/multi_node_deployment/lws_pd/lws_pd_deploy", "references/multi_node_deployment/multi_node", "references/multi_node_deployment/multi_node_index", "references/multi_node_deployment/rbg_pd/deepseekv32_pd", "references/post_training_integration", "references/production_metrics", "references/production_request_trace", "references/torch_compile_cache", "supported_models/classify_models", "supported_models/diffusion_language_models", "supported_models/diffusion_models", "supported_models/embedding_models", "supported_models/generative_models", "supported_models/mindspore_models", "supported_models/modelscope", "supported_models/multimodal_language_models", "supported_models/rerank_models", "supported_models/reward_models", "supported_models/support_new_models", "supported_models/transformers_fallback"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["README.md", "advanced_features/attention_backend.md", "advanced_features/checkpoint_engine.md", "advanced_features/cuda_graph_for_multi_modal_encoder.md", "advanced_features/deterministic_inference.md", "advanced_features/dp_for_multi_modal_encoder.md", "advanced_features/epd_disaggregation.md", "advanced_features/expert_parallelism.md", "advanced_features/forward_hooks.md", "advanced_features/hicache.rst", "advanced_features/hicache_best_practices.md", "advanced_features/hicache_design.md", "advanced_features/hyperparameter_tuning.md", "advanced_features/lora.ipynb", "advanced_features/observability.md", "advanced_features/pd_disaggregation.md", "advanced_features/pipeline_parallelism.md", "advanced_features/quantization.md", "advanced_features/quantized_kv_cache.md", "advanced_features/rfork.md", "advanced_features/separate_reasoning.ipynb", "advanced_features/server_arguments.md", "advanced_features/sgl_model_gateway.md", "advanced_features/sglang_for_rl.md", "advanced_features/speculative_decoding.ipynb", "advanced_features/structured_outputs.ipynb", "advanced_features/structured_outputs_for_reasoning_models.ipynb", "advanced_features/tool_parser.ipynb", "advanced_features/vlm_query.ipynb", "basic_usage/deepseek_v3.md", "basic_usage/deepseek_v32.md", "basic_usage/glm45.md", "basic_usage/glmv.md", "basic_usage/gpt_oss.md", "basic_usage/llama4.md", "basic_usage/minimax_m2.md", "basic_usage/native_api.ipynb", "basic_usage/offline_engine_api.ipynb", "basic_usage/ollama_api.md", "basic_usage/openai_api.rst", "basic_usage/openai_api_completions.ipynb", "basic_usage/openai_api_embeddings.ipynb", "basic_usage/openai_api_vision.ipynb", "basic_usage/popular_model_usage.rst", "basic_usage/qwen3.md", "basic_usage/qwen3_vl.md", "basic_usage/sampling_params.md", "basic_usage/send_request.ipynb", "developer_guide/JIT_kernels.md", "developer_guide/bench_serving.md", "developer_guide/benchmark_and_profiling.md", "developer_guide/contribution_guide.md", "developer_guide/development_guide_using_docker.md", "developer_guide/evaluating_new_models.md", "developer_guide/release_process.md", "developer_guide/setup_github_runner.md", "get_started/install.md", "index.rst", "platforms/amd_gpu.md", "platforms/ascend_contribution_guide.md", "platforms/ascend_npu.md", "platforms/ascend_npu_best_practice.md", "platforms/ascend_npu_deepseek_example.md", "platforms/ascend_npu_quantization.md", "platforms/ascend_npu_qwen3_examples.md", "platforms/ascend_npu_support.rst", "platforms/ascend_npu_support_models.md", "platforms/cpu_server.md", "platforms/mthreads_gpu.md", "platforms/nvidia_jetson.md", "platforms/tpu.md", "platforms/xpu.md", "references/custom_chat_template.md", "references/environment_variables.md", "references/faq.md", "references/frontend/choices_methods.md", "references/frontend/frontend_index.rst", "references/frontend/frontend_tutorial.ipynb", "references/learn_more.md", "references/multi_node_deployment/deploy_on_k8s.md", "references/multi_node_deployment/lws_pd/lws_pd_deploy.md", "references/multi_node_deployment/multi_node.md", "references/multi_node_deployment/multi_node_index.rst", "references/multi_node_deployment/rbg_pd/deepseekv32_pd.md", "references/post_training_integration.md", "references/production_metrics.md", "references/production_request_trace.md", "references/torch_compile_cache.md", "supported_models/classify_models.md", "supported_models/diffusion_language_models.md", "supported_models/diffusion_models.md", "supported_models/embedding_models.md", "supported_models/generative_models.md", "supported_models/mindspore_models.md", "supported_models/modelscope.md", "supported_models/multimodal_language_models.md", "supported_models/rerank_models.md", "supported_models/reward_models.md", "supported_models/support_new_models.md", "supported_models/transformers_fallback.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [3, 6, 7, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 49, 51, 52, 53, 56, 58, 59, 60, 63, 69, 73, 75, 77, 79, 84, 85, 86, 88, 89, 90, 91, 92, 95, 96, 99], "0": [0, 2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 77, 79, 81, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], "00": [13, 20, 24, 25, 26, 27, 28, 30, 36, 37, 40, 41, 42, 47, 77, 79, 81, 96], "000": [26, 30, 51, 57, 59], "0000": [12, 79], "00001": 17, "00002962350845336914": 41, "00004738569259643555": 41, "00005257129669189453": 41, "00006532669067382812": 41, "00008237361907958984": 41, "0000928044319152832": 41, "0000998377799987793": 41, "0001": 79, "00010514259338378906": 41, "0001322031021118164": 41, "00013875961303710938": 41, "00014603137969970703": 41, "0001493692398071289": 41, "0001697540283203125": 41, "00017774105072021484": 41, "00018644332885742188": 41, "0001951456069946289": 41, "0002": 24, "0002028942108154297": 41, "0002053976058959961": 41, "00021159648895263672": 41, "00021409988403320312": 41, "00023102760314941406": [36, 41], "0002351999282836914": 41, "00025582313537597656": 41, "0002701282501220703": 41, "00027441978454589844": 41, "00029540061950683594": 41, "0003": 24, "00031065940856933594": 41, "00032067298889160156": 41, "0003418922424316406": 41, "0003495216369628906": 41, "00035071372985839844": 41, "0003693103790283203": 41, "0003848075866699219": 41, "00039005279541015625": 41, "0003972053527832031": 41, "0004031658172607422": 41, "00040984153747558594": 41, "0004382133483886719": 41, "0004413127899169922": 41, "00044417381286621094": 41, "0004513263702392578": 41, "0004620552062988281": 41, "0005130767822265625": 41, "0005335807800292969": 41, "0005621910095214844": 41, "0005698204040527344": 41, "0005784034729003906": 41, "0006489753723144531": 41, "0006608963012695312": 41, "0006771087646484375": 41, "0006952285766601562": 41, "0007076263427734375": 41, "0007262229919433594": 41, "000728607177734375": 41, "0007519721984863281": 41, "0007572174072265625": 41, "0007658004760742188": 41, "0007991790771484375": 41, "0008139610290527344": 41, "0008296966552734375": 41, "0008397102355957031": 41, "0008406639099121094": 41, "0008764266967773438": 41, "0009050369262695312": 41, "0009250640869140625": 41, "0009288787841796875": 41, "0009407997131347656": 41, "0009546279907226562": 41, "0009584426879882812": 41, "0009703636169433594": 41, "000988006591796875": 41, "0009918212890625": 41, "001": [80, 83, 85], "0010013580322265625": 41, "0010061264038085938": 41, "0010251998901367188": 41, "0010318756103515625": 41, "0010385513305664062": 41, "0010423660278320312": 41, "001056671142578125": 41, "0010623931884765625": 41, "0010852813720703125": 41, "0010995864868164062": 41, "0011196136474609375": 41, "0011234283447265625": 41, "0011415481567382812": 41, "0011529922485351562": 41, "0011587142944335938": 41, "001186370849609375": 41, "0011911392211914062": 41, "0011949539184570312": 41, "00119781494140625": 41, "0012035369873046875": 41, "00121307373046875": 41, "0012311935424804688": 41, "0012607574462890625": 41, "0012693405151367188": 41, "0012760162353515625": 41, "0012845993041992188": 41, "0012979507446289062": 41, "0013246536254882812": 41, "001338958740234375": 41, "0013513565063476562": 41, "001354217529296875": 41, "0013570785522460938": 41, "0013742446899414062": 41, "001377105712890625": 41, "0013799667358398438": 41, "0013914108276367188": 41, "0014181137084960938": 41, "001422882080078125": 41, "0014295578002929688": 41, "0014467239379882812": 41, "0014743804931640625": 41, "0014867782592773438": 41, "0014982223510742188": 41, "0015039443969726562": 41, "0015106201171875": 41, "001552581787109375": 41, "0015573501586914062": 41, "0015630722045898438": 41, "0015840530395507812": 41, "00159454345703125": 41, "0016031265258789062": 41, "0016222000122070312": 41, "0016231536865234375": 41, "0016326904296875": 41, "0016994476318359375": 41, "0017156600952148438": 41, "0017194747924804688": 41, "001720428466796875": 41, "0017271041870117188": 41, "0017423629760742188": 41, "0017652511596679688": 41, "0017824172973632812": 41, "00179290771484375": 41, "001811981201171875": 41, "0018157958984375": 41, "0018186569213867188": 41, "0018243789672851562": 41, "0018367767333984375": 41, "0018520355224609375": 41, "0018749237060546875": 41, "0018901824951171875": 41, "0019025802612304688": 41, "0019130706787109375": 41, "0019359588623046875": 41, "0019464492797851562": 41, "001983642578125": 41, "0019989013671875": 41, "002": [13, 20, 21, 25, 26, 27, 28, 36, 37], "00201416015625": 41, "002033233642578125": 41, "0020389556884765625": 41, "0020427703857421875": 41, "002044677734375": 41, "0020751953125": 41, "0020847320556640625": 41, "0021038055419921875": 41, "0021190643310546875": 41, "002124786376953125": 41, "00214385986328125": 41, "0021457672119140625": 41, "00217437744140625": 41, "002193450927734375": 41, "0021953582763671875": 41, "0022068023681640625": 41, "0022106170654296875": 41, "0022411346435546875": 41, "0022487640380859375": 41, "0022735595703125": 41, "002288818359375": 41, "0023021697998046875": 41, "0023040771484375": 41, "002338409423828125": 41, "002349853515625": 41, "0023708343505859375": 41, "0023746490478515625": 41, "00238800048828125": 41, "0024089813232421875": 41, "002460479736328125": 41, "0024623870849609375": 41, "0024738311767578125": 41, "002513885498046875": 41, "0025234222412109375": 41, "0025348663330078125": 41, "0025424957275390625": 41, "0025730133056640625": 41, "0025844573974609375": 41, "0025882720947265625": 41, "00261688232421875": 41, "0026378631591796875": 41, "0026416778564453125": 41, "00264739990234375": 41, "0026536": 36, "0026607513427734375": 41, "00270843505859375": 41, "002750396728515625": 41, "002765655517578125": 41, "00276947021484375": 41, "0027828216552734375": 41, "0027980804443359375": 41, "002826690673828125": 41, "002838134765625": 41, "0028438568115234375": 41, "002849578857421875": 41, "0028591156005859375": 41, "002864837646484375": 41, "00286865234375": 41, "002918243408203125": 41, "0029296875": 41, "0029582977294921875": 41, "0029697418212890625": 41, "00298309326171875": 41, "0029964447021484375": 41, "0030002593994140625": 41, "00301361083984375": 41, "0030498504638671875": 41, "0030574798583984375": 41, "0030612945556640625": 41, "003070831298828125": 41, "00307464599609375": 41, "0030803680419921875": 41, "003086090087890625": 41, "00308990478515625": 41, "0030918121337890625": 41, "003139495849609375": 41, "0031452178955078125": 41, "0031528472900390625": 41, "003154754638671875": 41, "0031948089599609375": 41, "003215789794921875": 41, "00322723388671875": 41, "0032444000244140625": 41, "0032711029052734375": [36, 41], "00328826904296875": 41, "003307342529296875": 41, "0033359527587890625": 41, "0033473968505859375": 41, "003353118896484375": 41, "00336456298828125": 41, "0033740997314453125": 41, "0033931732177734375": 41, "0034122467041015625": 41, "00342559814453125": 41, "0034503936767578125": 41, "0034637451171875": 41, "00347137451171875": 41, "003475189208984375": 41, "00350189208984375": 41, "0035037994384765625": 41, "003520965576171875": 41, "003574371337890625": 41, "003582000732421875": 41, "0036029815673828125": 41, "0036106109619140625": 41, "003631591796875": 41, "0036411285400390625": 41, "0036945343017578125": 41, "003711700439453125": 41, "0037212371826171875": 41, "0037288665771484375": 41, "0037326812744140625": 41, "003742218017578125": 41, "003753662109375": 41, "0037593841552734375": 41, "0037841796875": 41, "0037975311279296875": 41, "0038051605224609375": 41, "0038089752197265625": 41, "00382232666015625": 41, "003833770751953125": 41, "003917694091796875": 41, "00394439697265625": 41, "003948211669921875": 41, "003963470458984375": 41, "003971099853515625": 41, "003978729248046875": 41, "0039825439453125": 41, "003986358642578125": 41, "003993988037109375": 41, "00400543212890625": 41, "004016876220703125": 41, "004024505615234375": 41, "0040435791015625": 41, "00405120849609375": 41, "0040740966796875": 41, "004100799560546875": 41, "004123687744140625": 41, "004150390625": 41, "00415802001953125": 41, "004161834716796875": 41, "00417327880859375": 41, "004184722900390625": 41, "0041961669921875": 41, "004207611083984375": 41, "00424957275390625": 41, "004276275634765625": 41, "004283905029296875": 41, "0042877197265625": 41, "004390716552734375": 41, "00440216064453125": 41, "004413604736328125": 41, "004497528076171875": 41, "004512786865234375": 41, "0045318603515625": 41, "0045623779296875": 41, "00457000732421875": 41, "0045928955078125": 41, "00463104248046875": 41, "004642486572265625": 41, "00466156005859375": 41, "004665374755859375": 41, "004680633544921875": 41, "004688262939453125": 41, "00469207763671875": 41, "004695892333984375": 41, "00469970703125": 41, "0047149658203125": 41, "004726409912109375": 41, "0047607421875": 41, "004810333251953125": 41, "0048370361328125": 41, "00484466552734375": 41, "00487518310546875": 41, "004878997802734375": 41, "00493621826171875": 41, "0049591064453125": 41, "00496673583984375": 41, "004970550537109375": 41, "004974365234375": 41, "004985809326171875": 41, "005": 85, "0050048828125": 41, "005008697509765625": 41, "005023956298828125": 41, "005035400390625": 41, "005039215087890625": 41, "0050811767578125": 41, "005096435546875": 41, "005107879638671875": 41, "00513458251953125": 41, "005161285400390625": 41, "00521087646484375": 41, "005222320556640625": 41, "005237579345703125": 41, "00524139404296875": 41, "00525665283203125": 41, "005260467529296875": 41, "00527191162109375": 41, "00531005859375": 41, "005397796630859375": 41, "005405426025390625": 41, "00540924072265625": 41, "0054168701171875": 41, "00543975830078125": 41, "0054473876953125": 41, "00545501708984375": 41, "0054779052734375": 41, "00551605224609375": 41, "005519866943359375": 41, "005527496337890625": 41, "0055389404296875": 41, "005588531494140625": 41, "0055999755859375": 41, "00560760498046875": 41, "005626678466796875": 41, "005634307861328125": 41, "005657196044921875": 41, "00566864013671875": 41, "00569915771484375": 41, "0057220458984375": 41, "005725860595703125": 41, "005767822265625": 41, "0057830810546875": 41, "005794525146484375": 41, "00579833984375": 41, "00580596923828125": 41, "00583648681640625": 41, "005840301513671875": 41, "005847930908203125": 41, "005855560302734375": 41, "005859375": 41, "005878448486328125": 41, "005886077880859375": 41, "005893707275390625": 41, "0059051513671875": [36, 41], "00594329833984375": 41, "005962371826171875": 41, "005970001220703125": 41, "005992889404296875": 41, "00600433349609375": 41, "0060272216796875": 41, "00604248046875": 41, "00605010986328125": 41, "0060577392578125": 41, "006076812744140625": 41, "00611114501953125": 41, "006134033203125": 41, "006137847900390625": 41, "006145477294921875": 41, "0061492919921875": 41, "006160736083984375": 41, "00616455078125": 41, "006168365478515625": 41, "006175994873046875": 41, "00620269775390625": 41, "0062255859375": 41, "006229400634765625": 41, "0062408447265625": 41, "006256103515625": 41, "006259918212890625": 41, "006275177001953125": 41, "0063323974609375": 41, "00637054443359375": 41, "006374359130859375": 41, "00640106201171875": 41, "006420135498046875": 41, "006435394287109375": 41, "006450653076171875": 41, "0064544677734375": 41, "006465911865234375": 41, "006504058837890625": 41, "0065155029296875": 41, "006534576416015625": 41, "006542205810546875": 41, "0065765380859375": 41, "006580352783203125": 41, "00658416748046875": 41, "006587982177734375": 41, "006595611572265625": 41, "006618499755859375": 41, "006626129150390625": 41, "006633758544921875": 41, "006664276123046875": 41, "006687164306640625": 41, "00669097900390625": 41, "0066986083984375": 41, "006710052490234375": 41, "006717681884765625": 41, "00673675537109375": 41, "006755828857421875": 41, "00676727294921875": 41, "00679779052734375": 41, "006816864013671875": 41, "006908416748046875": 41, "006916046142578125": 41, "006923675537109375": 41, "006969451904296875": 41, "00698089599609375": 41, "006999969482421875": 41, "007007598876953125": 41, "007022857666015625": 41, "0070343017578125": 41, "00704193115234375": 41, "007106781005859375": 41, "007110595703125": 41, "007137298583984375": 41, "00717926025390625": 41, "007228851318359375": 41, "0072479248046875": 41, "00725555419921875": 41, "007289886474609375": 41, "007305145263671875": 41, "0073089599609375": 41, "00731658935546875": 41, "00733184814453125": 41, "00734710693359375": 41, "007373809814453125": 41, "00739288330078125": 41, "0074005126953125": 41, "00740814208984375": 41, "0074310302734375": 41, "007457733154296875": 41, "007465362548828125": 41, "00748443603515625": 41, "0074920654296875": 41, "00749969482421875": 41, "007507552643049313": 85, "007518768310546875": 41, "007534027099609375": 41, "0075531005859375": 41, "00759124755859375": 41, "00763702392578125": 41, "007678985595703125": 41, "007709503173828125": 41, "007720947265625": 41, "0077362060546875": 41, "00775146484375": 41, "007755279541015625": 41, "007778167724609375": 41, "007793426513671875": 41, "0077972412109375": 41, "00782012939453125": 41, "0078277587890625": 41, "00783538818359375": 41, "007843017578125": 41, "0078582763671875": 41, "007904052734375": 41, "0079193115234375": 41, "00794219970703125": 41, "007965087890625": 41, "00799560546875": 41, "00803375244140625": 41, "00807952880859375": 41, "00809478759765625": 41, "00811767578125": 41, "0081329345703125": 41, "0081634521484375": 41, "0081787109375": 41, "00820159912109375": 41, "00821685791015625": 41, "00824737548828125": 41, "0082550048828125": 41, "00826263427734375": 41, "0082855224609375": 41, "00829315185546875": 41, "00833892822265625": 41, "0083465576171875": 41, "00835418701171875": 41, "00836944580078125": 41, "0083770751953125": 41, "00838470458984375": 41, "0084228515625": 41, "00843048095703125": 41, "0084381103515625": 41, "00844573974609375": 41, "008453369140625": 41, "00847625732421875": 41, "008514404296875": 41, "0085296630859375": 41, "008544921875": 41, "00855255126953125": 41, "0085601806640625": 41, "00856781005859375": 41, "008575439453125": 41, "00860595703125": 41, "0086212158203125": 41, "0086669921875": 41, "0086822509765625": 41, "00868988037109375": 41, "008697509765625": 41, "00872039794921875": 41, "00872802734375": 41, "00873565673828125": 41, "0087432861328125": 41, "00878143310546875": 41, "00879669189453125": 41, "00881195068359375": 41, "008819580078125": 41, "00882720947265625": 41, "00884246826171875": 41, "00885772705078125": 41, "0088958740234375": 41, "0089111328125": 41, "0089263916015625": 41, "00893402099609375": 41, "00896453857421875": 41, "00897979736328125": 41, "009002685546875": 41, "0090179443359375": 41, "00902557373046875": 41, "00905609130859375": 41, "009063720703125": 41, "00907135009765625": 41, "0091094970703125": 41, "00911712646484375": 41, "00913238525390625": 41, "00914764404296875": 41, "00916290283203125": 41, "0091705322265625": 41, "00919342041015625": 41, "0092010498046875": 41, "00923919677734375": 41, "009246826171875": 41, "00925445556640625": 41, "00930023193359375": 41, "0093536376953125": 41, "00936126708984375": 41, "00939178466796875": 41, "0093994140625": 41, "00945281982421875": 41, "00946044921875": 41, "00948333740234375": 41, "009490966796875": 41, "00952911376953125": 41, "0095367431640625": 41, "00954437255859375": 41, "0095672607421875": 41, "00958251953125": 41, "00960540771484375": 41, "009613037109375": 41, "009674072265625": 41, "00968170166015625": 41, "0096893310546875": 41, "00970458984375": 41, "00975799560546875": 41, "00978851318359375": 41, "00980377197265625": 41, "00981903076171875": 41, "00982666015625": 41, "00983428955078125": 41, "009857177734375": 41, "00986480712890625": 41, "00988006591796875": 41, "00994110107421875": 41, "00995635986328125": 41, "00it": 13, "01": [12, 13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77, 79, 85, 96], "0100250244140625": 41, "010040283203125": 41, "010101318359375": 41, "01010894775390625": 41, "0101165771484375": 41, "0101318359375": 41, "01013946533203125": 41, "01015472412109375": 41, "010162353515625": 41, "01018524169921875": 41, "01019287109375": 41, "0102081298828125": 41, "010223388671875": 41, "0102386474609375": 41, "01024": 17, "01025390625": 41, "01026153564453125": 41, "0102691650390625": 41, "01031494140625": 41, "0103302001953125": 41, "010345458984375": 41, "01035308837890625": 41, "01038360595703125": 41, "0104522705078125": 41, "010467529296875": 41, "01052093505859375": 41, "01053619384765625": 41, "0105438232421875": 41, "0105743408203125": 41, "01058197021484375": 41, "01064300537109375": 41, "01065826416015625": 41, "0106658935546875": 41, "01068115234375": 41, "01068878173828125": 41, "010711669921875": 41, "0107269287109375": 41, "0107421875": 41, "01074981689453125": 41, "010772705078125": 41, "01078033447265625": 41, "01079559326171875": 41, "01080322265625": 41, "0108184814453125": 41, "01084136962890625": 41, "0108489990234375": 41, "0108795166015625": 41, "010894775390625": 41, "01097869873046875": 41, "01099395751953125": 41, "01100921630859375": 41, "011016845703125": 41, "0110321044921875": 41, "0110626220703125": 41, "011077880859375": [36, 41], "01110076904296875": 41, "0111083984375": 41, "01113128662109375": 41, "01114654541015625": 41, "0111846923828125": 41, "01119232177734375": 41, "01123046875": 41, "01123809814453125": 41, "0112457275390625": 41, "0112762451171875": 41, "01129913330078125": 41, "01131439208984375": 41, "01132965087890625": 41, "0113372802734375": 41, "0113525390625": 41, "01136016845703125": 41, "0113677978515625": 41, "01137542724609375": 41, "011383056640625": 41, "0113983154296875": 41, "01141357421875": 41, "01143646240234375": 41, "011444091796875": 41, "01145172119140625": 41, "011474609375": 41, "0114898681640625": 41, "011505126953125": 41, "01151275634765625": 41, "0115203857421875": 41, "01152801513671875": 41, "01153564453125": 41, "0115814208984375": 41, "01158905029296875": 41, "0115966796875": 41, "0116119384765625": 41, "011627197265625": 41, "01171875": 41, "01175689697265625": 41, "01177978515625": 41, "01178741455078125": 41, "01180267333984375": 41, "01184844970703125": 41, "0118560791015625": 41, "01189422607421875": 41, "01190948486328125": 41, "0119476318359375": 41, "01195526123046875": 41, "011962890625": 41, "01198577880859375": 41, "01200103759765625": 41, "0120391845703125": 41, "01207733154296875": 41, "0120849609375": 41, "01210784912109375": 41, "01212310791015625": 41, "01213836669921875": 41, "01214599609375": 41, "0121612548828125": 41, "01218414306640625": 41, "0121917724609375": 41, "01219940185546875": 41, "01220703125": 41, "01224517822265625": 41, "01226806640625": 41, "012298583984375": 41, "0123291015625": 41, "012359619140625": 41, "0123748779296875": 41, "01241302490234375": 41, "012420654296875": 41, "012451171875": 41, "01247406005859375": 41, "01248931884765625": 41, "0125274658203125": 41, "01253509521484375": 41, "012542724609375": 41, "0125579833984375": 41, "01256561279296875": 41, "01259613037109375": 41, "012603759765625": 41, "01262664794921875": 41, "01263427734375": 41, "01264190673828125": 41, "01276397705078125": 41, "012786865234375": 41, "01280975341796875": 41, "0128326416015625": 41, "01285552978515625": 41, "01287078857421875": 41, "01287841796875": 41, "0128936767578125": 41, "012908935546875": 41, "01300811767578125": 41, "0130157470703125": 41, "01302337646484375": 41, "01303863525390625": 41, "0130462646484375": 41, "01305389404296875": 41, "01308441162109375": 41, "01312255859375": 41, "01317596435546875": 41, "01320648193359375": 41, "01325225830078125": 41, "01326751708984375": 41, "01328277587890625": 41, "0132904052734375": 41, "0133056640625": 41, "01332855224609375": 41, "0133514404296875": 41, "01335906982421875": 41, "01336669921875": 41, "01340484619140625": 41, "01346588134765625": 41, "01348114013671875": 41, "01349639892578125": 41, "0135040283203125": 41, "01355743408203125": 41, "01360321044921875": 41, "01361083984375": 41, "0136260986328125": 41, "01364898681640625": 41, "01367950439453125": 41, "01371002197265625": 41, "0137176513671875": 41, "01372528076171875": 41, "01373291015625": 41, "01374053955078125": 41, "013763427734375": 41, "0137786865234375": 41, "0138092041015625": 41, "01381683349609375": 41, "01384735107421875": 41, "01386260986328125": 41, "01389312744140625": 41, "01392364501953125": 41, "0139312744140625": 41, "013946533203125": 41, "01397705078125": 41, "0140228271484375": 41, "0140533447265625": [36, 41], "0140838623046875": 41, "01409912109375": 41, "01412200927734375": 41, "014129638671875": 41, "0141448974609375": 41, "01415252685546875": 41, "01418304443359375": 41, "0142059326171875": 41, "0142364501953125": 41, "01427459716796875": 41, "014312744140625": 41, "0143280029296875": 41, "0143585205078125": 41, "014373779296875": 41, "01441192626953125": [36, 41], "01442718505859375": 41, "01445770263671875": 41, "0144805908203125": 41, "014495849609375": 41, "0145111083984375": 41, "0145263671875": 41, "01454925537109375": 41, "01456451416015625": 41, "01457977294921875": 41, "014617919921875": 41, "0146484375": 41, "0146636962890625": 41, "014678955078125": 41, "0146942138671875": 41, "01470184326171875": 41, "01471710205078125": 41, "01473236083984375": 41, "0147857666015625": 41, "0148162841796875": 41, "01483154296875": 41, "0148468017578125": 41, "01488494873046875": 41, "01490020751953125": 41, "01491546630859375": 41, "01495361328125": 41, "0149993896484375": 41, "015": 85, "0150146484375": 41, "01505279541015625": 41, "01506805419921875": 41, "01509857177734375": 41, "01513671875": 41, "0151519775390625": 41, "01519012451171875": 41, "01520538330078125": 41, "01522064208984375": 41, "01523590087890625": 41, "01525115966796875": 41, "0152740478515625": 41, "01531982421875": 41, "01535797119140625": 41, "01540374755859375": 41, "01541900634765625": 41, "0154266357421875": 41, "01544189453125": 41, "015472412109375": 41, "0154876708984375": 41, "01551055908203125": 41, "01557159423828125": 41, "01558685302734375": 41, "0156097412109375": 41, "0156707763671875": 41, "01568603515625": 41, "015716552734375": 41, "0157318115234375": 41, "0157470703125": 41, "015777587890625": 41, "0157928466796875": 41, "015838623046875": 41, "0158538818359375": 41, "015869140625": 41, "0158843994140625": 41, "015899658203125": 41, "0159149169921875": 41, "015960693359375": 41, "0159759521484375": 41, "0159912109375": [36, 41], "0160064697265625": 41, "016021728515625": 41, "0160675048828125": 41, "0160980224609375": 41, "016143798828125": 41, "01617431640625": 41, "0161895751953125": 41, "016265869140625": 41, "016326904296875": 41, "016357421875": 41, "016448974609375": 41, "016510009765625": 41, "0165252685546875": 41, "0166015625": 41, "0166168212890625": 41, "016632080078125": 41, "0166778564453125": 41, "016693115234375": 41, "0167236328125": 41, "0167388916015625": 41, "0167694091796875": 41, "01678466796875": 41, "016815185546875": 41, "0168304443359375": 41, "016845703125": 41, "0168609619140625": 41, "016876220703125": 41, "016937255859375": 41, "0169677734375": 41, "016998291015625": 41, "0170745849609375": 41, "01708984375": 41, "0171966552734375": 41, "0172119140625": 41, "0172271728515625": 41, "017242431640625": 41, "0172882080078125": 41, "017333984375": 41, "017364501953125": 41, "0173797607421875": 41, "0174102783203125": 41, "0174560546875": 41, "017486572265625": 41, "0175018310546875": 41, "01751708984375": 41, "0175323486328125": 41, "0175628662109375": 41, "017578125": 41, "0176239013671875": 41, "01763916015625": 41, "0176849365234375": 41, "0177001953125": 41, "017730712890625": 41, "0177764892578125": 41, "0178070068359375": 41, "0178375244140625": 41, "017852783203125": 41, "01788330078125": 41, "0178985595703125": 41, "017913818359375": 41, "0179290771484375": 41, "0180816650390625": 41, "01812744140625": 41, "018157958984375": 41, "0181732177734375": 41, "018218994140625": 41, "0182342529296875": 41, "01824951171875": 41, "018280029296875": 41, "0183258056640625": 41, "01837158203125": 41, "018402099609375": 41, "0184173583984375": 41, "0184326171875": 41, "018463134765625": 41, "0185394287109375": 41, "0185546875": 41, "018585205078125": 41, "0186004638671875": 41, "018707275390625": 41, "01873779296875": 41, "0187530517578125": 41, "018768310546875": 41, "0188446044921875": 41, "018890380859375": 41, "0189208984375": 41, "0189361572265625": 41, "018951416015625": 41, "0189666748046875": 41, "01898193359375": 41, "019012451171875": 41, "01904296875": 41, "019073486328125": 41, "01910400390625": 41, "019134521484375": 41, "0192413330078125": 41, "01934814453125": 41, "0193634033203125": 41, "0193939208984375": 41, "0194854736328125": 41, "01953125": 41, "0196075439453125": 41, "019622802734375": 41, "0196533203125": 41, "019683837890625": 41, "0196990966796875": 41, "01971435546875": 41, "019775390625": 41, "0198211669921875": 41, "0198516845703125": 41, "019927978515625": 41, "019989013671875": 41, "01it": [13, 24, 36], "02": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77, 79, 85], "0200": 79, "0200042724609375": 41, "020050048828125": 41, "0200653076171875": 41, "020111083984375": 41, "020172119140625": 41, "0202178955078125": 41, "020233154296875": 41, "02032470703125": 41, "0203399658203125": 41, "0204315185546875": 41, "02044677734375": 41, "020477294921875": 41, "0205535888671875": 41, "02056884765625": 41, "0206298828125": 41, "0207061767578125": 41, "020721435546875": 41, "0207977294921875": 41, "02081298828125": 41, "0208282470703125": 41, "020843505859375": 41, "0208587646484375": 41, "0208740234375": 41, "0208892822265625": 41, "0209503173828125": 41, "0210418701171875": 41, "02117919921875": 41, "0211944580078125": 41, "021209716796875": 41, "0212249755859375": 41, "0212860107421875": 41, "0213470458984375": 41, "021392822265625": 41, "02142333984375": 41, "0214385986328125": 41, "021453857421875": 41, "021484375": 41, "021514892578125": 41, "0215301513671875": 41, "0215911865234375": 41, "0216522216796875": 41, "02166748046875": 41, "0216827392578125": 41, "0217": 24, "0217132568359375": 41, "021727999672293663": 24, "0217742919921875": 41, "0218353271484375": 41, "0218658447265625": 41, "021881103515625": 41, "0219573974609375": 41, "0219879150390625": 41, "02203369140625": 41, "0222": 24, "0222015380859375": 41, "022207999601960182": 24, "022216796875": 41, "0222625732421875": 41, "0222930908203125": 41, "0223": 24, "0223236083984375": 41, "022336000576615334": 24, "0224456787109375": 41, "0224761962890625": 41, "022491455078125": 41, "0225": 79, "02264404296875": 41, "022735595703125": 41, "0228424072265625": [36, 41], "022857666015625": 41, "022918701171875": 41, "0229949951171875": 41, "023": 91, "023040771484375": 41, "0230712890625": 41, "0231170654296875": 41, "02313232421875": 41, "0231475830078125": 41, "023162841796875": 41, "0232391357421875": 41, "0232696533203125": 41, "0233": 24, "0233306884765625": 41, "0233612060546875": 41, "0235137939453125": 41, "0235748291015625": 41, "02362060546875": 41, "0237": [24, 36], "023744000121951103": 24, "0238494873046875": 41, "02386474609375": 41, "0238800048828125": 41, "023956298828125": 41, "02398681640625": 41, "024017333984375": 41, "02410888671875": 41, "0241546630859375": 41, "02423095703125": 41, "0242462158203125": 41, "024322509765625": 41, "0243988037109375": 41, "024505615234375": 41, "02471923828125": 41, "024749755859375": 41, "0247650146484375": 41, "0247802734375": 41, "0247955322265625": 41, "0248565673828125": 41, "0248870849609375": 41, "0249176025390625": 41, "025": 85, "0251617431640625": 41, "02520751953125": 41, "025238037109375": 41, "0252838134765625": 41, "025299072265625": 41, "0254058837890625": 41, "0255279541015625": 41, "025543212890625": 41, "0255584716796875": 41, "0255889892578125": 41, "0256500244140625": 41, "0256805419921875": 41, "025848388671875": 41, "025970458984375": 41, "0260009765625": 41, "026031494140625": 41, "026092529296875": 41, "0261688232421875": 41, "02618408203125": 41, "026214599609375": 41, "0262451171875": 41, "0262603759765625": 41, "026274681091308594": 25, "0262908935546875": 41, "0263": 24, "02642822265625": 41, "0264739990234375": 41, "0266265869140625": 41, "0266876220703125": 41, "0267181396484375": 41, "0268402099609375": 41, "0269775390625": 41, "0269927978515625": 41, "0270": 24, "02716064453125": 41, "0272064208984375": 41, "0272369384765625": 41, "02728271484375": 41, "0272979736328125": [36, 41], "0273284912109375": 41, "0274200439453125": 41, "0275421142578125": 41, "027618408203125": 41, "027923583984375": 41, "0279693603515625": 41, "028045654296875": 41, "028076171875": 41, "0280914306640625": 41, "0281524658203125": 41, "0282135009765625": 41, "028228759765625": 41, "0282745361328125": 41, "028289794921875": 41, "0283050537109375": 41, "0284": 36, "0284271240234375": 41, "0284423828125": 41, "028472900390625": 41, "0285491943359375": 41, "028656005859375": 41, "0286865234375": 41, "02874755859375": 41, "0288848876953125": 41, "0289154052734375": 41, "0289306640625": 41, "029052734375": 41, "0291595458984375": 41, "0291900634765625": 41, "029296875": 41, "02935791015625": 41, "0294036865234375": 41, "0294342041015625": 41, "0294952392578125": 41, "0295562744140625": 41, "029571533203125": 41, "029632568359375": 41, "0298004150390625": 41, "0298309326171875": 41, "0299": 24, "029937744140625": 41, "02it": [13, 25, 36, 41], "03": [12, 13, 20, 24, 25, 26, 27, 36, 42, 47, 77, 85, 92], "030029296875": 41, "0300445556640625": 41, "0301055908203125": 41, "0301361083984375": 41, "0301666259765625": 41, "030242919921875": 41, "0303": 24, "030364990234375": 41, "0305023193359375": 41, "030670166015625": 41, "0307769775390625": 41, "030975341796875": 41, "0310211181640625": 41, "0311431884765625": 41, "0311737060546875": 41, "03143310546875": 41, "03155517578125": 41, "031646728515625": 41, "032012939453125": 41, "032135009765625": 41, "032318115234375": 41, "0324": [15, 24, 27, 29], "032440185546875": 41, "032470703125": 41, "032501220703125": 41, "03271484375": 41, "032806396484375": 41, "03289794921875": 41, "03314208984375": 41, "03326416015625": 41, "0333251953125": 41, "033447265625": 41, "03375244140625": 41, "0338134765625": 41, "033935546875": 41, "0340576171875": 41, "03411865234375": 41, "03424072265625": 41, "0343017578125": 41, "034454345703125": 41, "03448486328125": 41, "0345458984375": 41, "034637451171875": 41, "03466796875": 41, "034759521484375": 41, "03509521484375": 41, "035247802734375": 41, "035308837890625": 41, "03570556640625": 41, "035888671875": 41, "03607177734375": 41, "03619384765625": 41, "0362548828125": 41, "036346435546875": 41, "036376953125": 41, "036468505859375": 41, "036529541015625": 41, "03668212890625": 41, "03692626953125": 41, "0369873046875": 41, "037078857421875": 41, "0372314453125": 41, "037506103515625": 41, "037841796875": 41, "0380859375": 41, "038116455078125": 41, "03826904296875": 41, "0385": 24, "038604736328125": 41, "038787841796875": 41, "038818359375": 41, "038848876953125": 41, "03924560546875": 41, "039276123046875": 41, "0393": 24, "039435e": 85, "039459228515625": 41, "039703369140625": 41, "03it": 13, "04": [13, 24, 27, 36, 37, 55, 60, 79, 85], "0400": 24, "0402": 24, "040252685546875": 41, "0403": 24, "0404052734375": 41, "040618896484375": 41, "0406494140625": 41, "040802001953125": 41, "0412": 24, "041412353515625": 41, "041717529296875": 41, "041961669921875": 41, "0421": 24, "0423": 24, "04248046875": 41, "0427": 24, "042938232421875": 41, "0435": 24, "044219970703125": 41, "045166015625": 41, "045257568359375": 41, "04534912109375": 41, "0458984375": 41, "0467529296875": 41, "0472": 24, "047231998294591904": 24, "047698974609375": 41, "048248291015625": 41, "048370361328125": 41, "0484": 24, "04840087890625": 41, "04841599985957146": 24, "048448000103235245": 24, "04848000034689903": 24, "048492431640625": 41, "0485": 24, "0486": 24, "0493": 24, "0494": 24, "04940799996256828": 24, "049652099609375": 41, "0498": 24, "04986572265625": [36, 41], "049957275390625": 41, "05": [13, 22, 24, 36, 47, 79, 85], "05078125": 41, "0510": 24, "05100800096988678": 24, "0516d8d82927490fb1329ebbd6be0296": 42, "0526": 24, "0528": [7, 18, 20, 40, 66, 80], "052978515625": 41, "0530879981815815": 24, "0531": 24, "053497314453125": 41, "05401611328125": 41, "0546875": 36, "0547": 24, "05478215217590332": 47, "0549": 24, "0551": 24, "0561": 24, "0563": 24, "0564": 24, "056488037109375": 41, "0567": 24, "057037353515625": 41, "057373046875": 41, "05792236328125": 41, "0586": 24, "0587": 24, "059112548828125": 41, "05987548828125": 41, "05it": 13, "06": [13, 20, 24, 26, 36, 77, 85], "06072998046875": 41, "0611572265625": 41, "0620": 24, "0625": 41, "062744140625": 41, "0631103515625": 41, "0633544921875": 41, "0637": 36, "0643310546875": 41, "0647": 24, "0654": 24, "0670": 24, "06707763671875": 41, "0678": 24, "068603515625": 41, "0690": 24, "06927490234375": 41, "06it": [13, 25], "07": [24, 26, 36, 42, 79], "0712": 24, "07232666015625": 41, "0727": 24, "073486328125": 41, "07478400319814682": 24, "0748": 24, "0749": 24, "075": 85, "07500000000000001": 85, "0751": 24, "0755": 24, "07552000135183334": 24, "0761": 24, "0767": 24, "0773": 24, "0775146484375": 41, "0784": 24, "07958984375": 41, "07977294921875": 41, "07it": [13, 36, 77], "08": [12, 13, 24, 79, 85], "0800": 24, "0804": 24, "08087158203125": 41, "0831": 24, "0837": 24, "0865": 24, "0892": 24, "089599609375": 41, "08it": 13, "09": [13, 24, 36, 74], "0911": 24, "09149503707885742": 25, "0916": 24, "09197998046875": 41, "0924": [66, 92], "0932": 24, "0936": 24, "0937": 24, "0940": 24, "0943603515625": 41, "0945": 24, "0946044921875": 41, "0947": 24, "09521484375": 41, "0957": 24, "09625244140625": 41, "0964": 24, "0979": 24, "0995": 24, "09it": [13, 36, 77], "0cf437542ed0438fb0423ed7fc38b92c": 24, "0dd7": 79, "0e9e39f249a16976918f6564b8830bc894c89659": 13, "0rc1": 55, "0x0": 79, "1": [0, 1, 2, 3, 4, 6, 8, 10, 11, 12, 13, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 59, 66, 69, 71, 73, 77, 79, 85, 86, 87, 88, 89, 92, 93, 95, 96, 97, 98], "10": [0, 12, 13, 15, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 35, 36, 37, 40, 41, 42, 47, 50, 53, 60, 61, 62, 77, 79, 83, 84, 85, 88, 90, 92], "100": [10, 12, 13, 14, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 36, 37, 40, 41, 42, 47, 48, 49, 50, 53, 70, 77, 84, 85, 90], "1000": [7, 13, 20, 21, 22, 25, 26, 27, 28, 36, 37, 49, 50, 53, 61, 73], "10000": [10, 22, 61], "1000000": 34, "10000000": [13, 20, 21, 25, 26, 27, 28, 36, 37], "100000000": 83, "1000000000": 83, "10001": 22, "10011": 70, "1002": [13, 21], "10025600343942642": 24, "1003": 24, "1003566476": 36, "1004": 21, "10040": 26, "10078": 18, "1008": [21, 24, 36], "100b": [89, 92], "100m": 22, "100mb": 50, "1012": 24, "1014": 24, "1016": 21, "10161": 26, "1018": 24, "10227": 36, "10236799716949463": 24, "1024": [11, 13, 17, 20, 22, 24, 25, 26, 27, 28, 29, 31, 36, 37, 49, 50, 53, 61, 67, 70, 71, 73, 80, 83, 85, 89, 90, 91], "1024x1024": 90, "1025": 24, "10277": 26, "1030": 36, "1031": 24, "1032": 24, "1033": 36, "1035": 85, "104": [20, 25, 26, 27, 28, 37], "1041": 24, "1042": 26, "1047": 24, "1048576": 95, "105": 36, "1052": 26, "10542": 26, "10689": 26, "10696": 26, "106b": [66, 95], "107": 13, "1075": 26, "1077": 26, "108": 61, "1080p": 49, "1080x1920": 49, "1081": 36, "1083": 26, "1084": 47, "1088": 61, "109": 30, "1091": [26, 36, 41], "10912": 83, "1095": 24, "1096": 24, "10991": 36, "10997": 26, "109b": 34, "10b": 67, "10it": [28, 42, 77], "10m": [22, 34], "11": [12, 13, 21, 22, 24, 25, 26, 27, 33, 36, 47, 50, 60, 77, 79, 85, 90], "11000": 61, "11008": [24, 85], "11008x4096": 24, "1101": 26, "1103": 36, "1105": 26, "11050": 36, "1107": 36, "111": 13, "1111": 24, "11111": 40, "11136": 26, "11141": 26, "1119": 26, "112": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "11228": 85, "1124": [26, 36, 92], "11245": 26, "1125": [85, 92], "1128": 26, "113": 13, "114": 61, "114688": 61, "11477": 36, "115": 13, "1152": 61, "1154": 24, "11584": 25, "116": [29, 33], "1160": 36, "116093850019932e": 85, "11649": 26, "11685": 85, "1175": 24, "1181": 26, "1184": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "11852": 16, "11876": 36, "1189": 26, "1190": 24, "1196": [26, 36], "11b": [66, 95], "11it": 24, "11k": 61, "11k1k": 61, "12": [1, 13, 15, 20, 21, 22, 24, 25, 26, 27, 28, 33, 36, 37, 42, 47, 50, 55, 56, 61, 62, 67, 70, 71, 77, 81, 90, 92], "120": [20, 22, 25, 26, 27, 28, 37, 51, 59, 61, 73], "1200": [61, 83], "120000": [30, 53], "12065": 30, "12095": [26, 36, 47], "120b": [18, 27, 33, 66, 92], "12159": 26, "1228": 24, "12288": 16, "123": [40, 86], "1231": 36, "12313": 26, "12345": 40, "123456": 33, "1234567890": 90, "1234567890ab": 22, "123859": 85, "12396": 26, "125": 67, "12577": 26, "12612": 18, "1265": 26, "127": [6, 10, 13, 15, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 40, 41, 46, 47, 49, 50, 53, 60, 61, 62, 70, 79, 88, 89, 91, 93, 96], "1273": 26, "12730": 26, "1275": 24, "12752": 36, "128": [1, 4, 13, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 34, 36, 37, 40, 46, 49, 52, 58, 61, 62, 67, 69, 70, 71, 73, 82, 85, 89, 91, 95], "1280": [13, 20, 25, 26, 27, 28, 36, 37, 90], "128000": 30, "128009": [24, 25], "1280x720": 90, "1281": [26, 36], "1283": [24, 36], "128902e": 85, "128e": 34, "128g": 55, "128k": [92, 95], "128x11008": 24, "128x128": 29, "128x4096": 24, "1290": 26, "12966": 26, "12b": 95, "12it": [25, 77], "12k": 16, "12t": 92, "13": [12, 13, 20, 21, 22, 24, 25, 26, 27, 28, 33, 36, 40, 47, 56, 61, 67, 77], "130859375": 41, "130b": 92, "131072": [13, 24, 30, 36, 61, 83], "13126": 5, "13187": 26, "1319": 30, "132": 61, "13289": 26, "132b": 92, "133": 61, "1330": 85, "13327": 7, "1335": [24, 26], "13382": 26, "13390": 36, "13425779342651367": 25, "1349": 26, "13530": 26, "1355": 24, "13550": 30, "13580": 26, "135m": 92, "136": [20, 25, 26, 27, 28, 37, 80, 83], "1366": 36, "13700": 36, "1372": 26, "13724": 5, "1376": 26, "138": [29, 33], "13837": 26, "139": 27, "13925": 5, "13959": [30, 47], "13b": [66, 92, 95], "13it": [36, 42], "14": [13, 24, 25, 26, 27, 33, 36, 42, 61, 62, 67, 77, 80, 83, 85], "140": 85, "14006": 85, "14007": 85, "1401": 26, "1408": 36, "14097": 5, "141": 61, "1410": 26, "1414": [26, 36], "1416": 36, "14190": 26, "141fc3a09386a8baf0d7495c247ae2d1a565f69f": 13, "14243245124816895": 25, "1424422264099121": 25, "14244627952575684": 25, "1429": 26, "1431": 26, "1438": 26, "1439": 24, "144": [13, 20, 25, 26, 27, 28, 36, 37, 61], "14422": 3, "1447": 26, "144gb": 35, "1459": 26, "14647": 36, "1465": [24, 26], "1477": 26, "148": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "1482": 26, "14927": 36, "1495": 26, "1498896": 13, "14b": [1, 90, 92], "14it": 77, "15": [13, 16, 20, 21, 22, 24, 25, 26, 27, 33, 36, 61, 77, 79, 85], "150": [40, 77], "1500": 61, "15040": 30, "151": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "1513": 85, "1513243": 36, "1513671875": 41, "151643": [26, 36], "151645": [24, 40, 42, 47], "151649": 26, "152": [20, 25, 26, 27, 28, 37], "1522": 22, "15320": 3, "15339": 22, "15358": 30, "1536": [13, 20, 25, 26, 27, 28, 36, 37, 61, 62, 64, 91], "154": [20, 25, 26, 27, 28, 37], "15423": 26, "155113935470581": 26, "1558": 26, "156": 61, "1573": 36, "1576": 26, "158": 24, "15934": 26, "15b": [92, 95], "15b3": 79, "15it": [13, 36], "16": [1, 13, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 36, 37, 40, 41, 42, 47, 49, 53, 61, 62, 64, 67, 70, 77, 79, 80, 81, 83, 92], "160": [12, 13, 20, 25, 26, 27, 28, 36, 37, 61], "1600": [61, 62], "16045": 26, "1616": 26, "162": [13, 85], "162102222442627": 26, "1632": 30, "1633": 26, "16380": 30, "16384": [12, 13, 20, 21, 25, 26, 27, 28, 30, 36, 37, 61, 62, 70, 79], "163840": 79, "164": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "1640": 61, "16408": 26, "1650390625": 41, "1657": 36, "1661": 26, "16686": 86, "167": 67, "1673": 30, "168": [20, 21, 25, 26, 27, 28, 37], "1681": 26, "16875": 85, "169": [80, 83], "1692": 24, "1697": 24, "16card": 61, "16e": [27, 28, 34, 66, 92], "16g": [58, 60], "16it": [13, 24, 42], "16k": [16, 92], "16x": 21, "17": [12, 13, 24, 25, 26, 27, 28, 36, 42, 61, 77, 79], "17064": 36, "171": 67, "171662e": 85, "172": [13, 61, 80, 81, 83], "1739": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "17408": 36, "1741": 36, "17417": 26, "1741943359375": 41, "1744": 26, "1745383213": 88, "1745993638": 29, "175": 33, "1750252498": [80, 83], "176": [13, 20, 25, 26, 27, 28, 36, 37], "1767034308": 22, "1769479998": 24, "1769480050": 25, "1769480051": 25, "1769480085": 24, "1769480136": 26, "1769480141": 26, "1769480145": 24, "1769480160": 26, "1769480163": 26, "1769480201": 24, "1769480240": 24, "1769480280": 36, "1769480351": 40, "1769480352": 40, "1769480443": 42, "1769480444": 42, "1769480445": 42, "1769480454": 36, "1769480486": 47, "1769480487": 47, "1769480869": 27, "1769480871": 27, "1769480953": 27, "17724609375": 41, "17729806900024414": 25, "17767": 26, "1779": 26, "178": 61, "1792": [13, 20, 25, 26, 27, 28, 36, 37], "17b": [27, 28, 34, 66, 92], "17it": [13, 24, 25], "18": [13, 20, 21, 24, 25, 26, 27, 28, 33, 36, 37, 40, 47, 61, 62, 77, 79, 81], "180": 22, "1800": 61, "18000": 61, "18006": 24, "1815": 85, "1828": 36, "184": [20, 25, 26, 27, 28, 37], "18413": 26, "18432": 16, "1855": 26, "18647": 36, "1865": 36, "1868896484375": 41, "187": 33, "1879": 47, "18k": [16, 61], "18k4k": 61, "19": [13, 20, 24, 25, 26, 27, 36, 40, 41], "19083": 26, "19091": 26, "1917": 22, "192": [13, 20, 21, 25, 26, 27, 28, 36, 37, 61], "19473767280578613": 25, "19482": 26, "1970": 85, "19730": 2, "198": [26, 30, 53], "1990": 26, "1995": 26, "19it": [13, 25, 28], "1_6b": 66, "1a423dce085d4b349451ec6f090208b3": 13, "1b": [17, 27, 52, 66, 92, 95, 99], "1b7d4c3a6e1f": 22, "1card": 61, "1d": 48, "1e5caf694c214544ba3cec8240e136e0": 47, "1e9": 11, "1gb": 11, "1k": 61, "1m": [1, 22, 34, 92], "1mb": 22, "1p1d": 80, "1t": 92, "1v": 95, "1x": 24, "2": [0, 1, 5, 8, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 29, 32, 33, 34, 36, 37, 40, 41, 42, 43, 46, 47, 49, 50, 51, 59, 64, 66, 71, 72, 77, 79, 81, 84, 85, 88, 92, 93, 95, 96, 97, 98, 99], "20": [2, 12, 13, 20, 22, 24, 25, 26, 27, 28, 29, 30, 33, 36, 37, 40, 42, 47, 53, 61, 62, 70, 73, 77, 79, 83, 85], "200": [13, 20, 25, 26, 27, 28, 33, 36, 37, 49, 51, 53, 59, 62, 79, 92], "2000": [12, 49, 52, 61], "20000": [22, 79, 81], "200b": 18, "200k": 92, "20102": [30, 80, 83], "2014": 36, "202": [13, 22], "2020": 35, "2021": 26, "2022": [26, 36], "2023": 26, "2023todai": 25, "2024": 92, "2024userpari": 25, "2025": [12, 33, 74, 79, 92], "20251121": 60, "2026": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "20474": 36, "2048": [12, 13, 20, 24, 25, 26, 27, 28, 30, 34, 36, 37, 49, 61, 70, 74, 80, 83], "20480": [13, 20, 24, 25, 26, 27, 36, 37], "2055": 26, "206": 33, "208": [13, 20, 25, 26, 27, 28, 36, 37, 77], "2082577": 25, "2086": 47, "2097": [26, 36], "20b": [27, 67, 92], "20it": [13, 24, 28], "20m": 13, "21": [13, 24, 25, 26, 27, 36, 41, 47, 77, 85], "210": [33, 67], "2100": 61, "21286": 36, "21340": 36, "214": 67, "2141000": 25, "2147000": 25, "2147483648": 83, "21500000": 25, "2154000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 26, "216": [20, 25, 26, 27, 28, 37], "21600000": 26, "2163": 26, "216608": 25, "21892": 36, "21b": [66, 92], "21it": [13, 77], "22": [13, 24, 25, 26, 29, 36, 61, 62, 74, 77, 83], "220": [25, 26, 36], "221": [80, 83], "2218": 24, "222": 77, "2236": 26, "224": [13, 20, 25, 26, 27, 28, 36, 37], "2241170": 26, "224gb": 81, "2253": 36, "22570": 26, "2293": 26, "2297": 26, "2299": 26, "22it": [13, 26, 36], "22m": [80, 83], "23": [13, 24, 26, 27, 36, 41, 60, 79], "230": 35, "2304": [13, 20, 25, 26, 27, 28, 36, 37], "2308": 26, "2309": 24, "23126": 26, "232": [20, 25, 26, 27, 28, 37], "2321928": 36, "2326": 85, "233": 12, "2340147": 47, "235": [30, 80, 83], "23560": 26, "235b": [10, 18, 20, 45, 66, 67, 95], "2371361255645752": 26, "23714399337768555": 26, "23714780807495117": 26, "2390": 26, "24": [13, 20, 22, 24, 25, 26, 27, 28, 36, 37, 61, 62, 67, 77, 79, 80, 90], "240": [13, 18, 20, 22, 25, 26, 27, 28, 36, 37], "2400": [26, 40], "2407": 27, "240gb": 11, "24155": 30, "2417": 85, "242": [13, 80, 83], "244": 24, "24576": 61, "2464": 26, "24667": 61, "24669": [61, 62], "247": 85, "2474": 26, "248": [20, 25, 26, 27, 28, 37], "2486572265625": 41, "2494": 26, "24b": [66, 95], "24card": 61, "24it": 36, "25": [11, 13, 24, 25, 26, 27, 28, 30, 36, 40, 60, 77, 79, 85, 90], "25000": 21, "2503": [66, 95], "2506": 26, "2507": [10, 20, 66], "250m": 22, "2511": 90, "2512": 90, "2513": 85, "253": 67, "2530": 26, "253125": 85, "25361": 36, "253b": 92, "25477": 36, "25503": 36, "255b": 92, "256": [11, 12, 13, 17, 20, 21, 22, 25, 26, 27, 28, 36, 37, 48, 49, 50, 52, 61, 70, 77, 90, 91, 95], "2560": [13, 20, 25, 26, 27, 28, 36, 37], "256k": 92, "256mb": 22, "2578": 26, "2598": 26, "25it": 27, "25m": 22, "26": [13, 20, 24, 25, 27, 36, 61, 62, 80, 83], "262144": [61, 80, 83], "2623": 26, "263": 36, "26306266784668": 85, "264": [26, 36], "264404296875": 41, "2647": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "26553": 26, "265937449": 36, "266055e": 85, "26789": 36, "2697": 26, "26it": [13, 27], "27": [13, 20, 24, 25, 26, 27, 28, 33, 36, 37, 40, 41, 42, 47, 77, 79, 85], "2704": [26, 36], "271": [26, 36], "2718": 36, "27190": 26, "272": 61, "2750": 26, "2753": 36, "277": 33, "27748": 26, "2776": 26, "279": [25, 26, 36, 47], "2797": 26, "27b": [66, 92, 95, 97], "27it": [24, 77], "28": [13, 20, 24, 25, 26, 27, 28, 36, 37, 61, 62, 85, 92], "281": 27, "2814453125": 85, "2816": [13, 20, 25, 26, 27, 28, 36, 37], "282": 13, "2826": 85, "2828": 24, "2844": 24, "285": 36, "28672": 61, "2868": 24, "28680": [61, 62], "2878": 26, "288": [13, 20, 25, 26, 27, 28, 36, 37, 61], "2894": 26, "28b": 95, "28it": [24, 26], "28m": 13, "29": [13, 20, 24, 27, 30, 33, 36, 83], "29000": 22, "2908": 36, "290b": 92, "29138749187": 33, "2922980785369873": 36, "2924": 26, "29257": 36, "2937": 24, "2938": 26, "29500": [2, 93], "296": 26, "296752e": 85, "2974": 24, "29it": [13, 27, 36, 77], "2_6": [66, 95], "2a": [0, 21], "2b": [17, 21, 66, 91, 92, 95, 96], "2card": 61, "2f": [36, 96], "2f3a0c3": 22, "2k": 16, "2k2k": 61, "2m": [13, 22], "2t": 92, "2x": [7, 10, 21, 22, 79, 84, 90], "3": [0, 1, 4, 12, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 49, 50, 52, 58, 60, 62, 66, 69, 71, 72, 77, 79, 80, 83, 85, 87, 92, 93, 95, 96, 97, 98, 99], "30": [11, 13, 20, 21, 22, 25, 26, 27, 28, 30, 36, 37, 41, 42, 51, 59, 61, 80, 83, 85, 90], "300": [13, 15, 20, 21, 22, 25, 26, 27, 28, 32, 36, 37, 42, 45, 83, 92, 95], "3000": [49, 61, 83, 85], "30000": [4, 6, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 40, 45, 46, 47, 49, 50, 52, 53, 56, 58, 67, 70, 72, 80, 81, 83, 85, 89, 90, 91, 92, 94, 95, 96, 97, 99], "300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 26, "30001": [6, 15, 22, 38, 50, 80], "30002": [6, 50], "30003": [6, 50], "3001": 61, "30010": 90, "30011": 22, "30080": 83, "301": 36, "30339": 26, "304": [26, 36, 47], "3042": 26, "307": 42, "3072": [13, 20, 25, 26, 27, 28, 36, 37, 61], "30789": 36, "308": 26, "3080": 36, "30800": [80, 83], "3090": 85, "30b": [27, 45, 60, 61, 66, 92, 95], "30gb": 11, "30it": [13, 25, 27, 42, 77], "31": [13, 25, 30, 56, 73, 77], "31000": 22, "31028": 77, "311": [26, 36], "3118": 26, "312": 61, "312226e": 85, "31378": 22, "3138": 24, "314": 85, "3146": [26, 36], "314b": 92, "315": [25, 26, 36, 47], "3151": 26, "316000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 26, "317": 12, "31it": [13, 24, 27], "32": [1, 13, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 36, 37, 46, 47, 48, 50, 61, 62, 64, 70, 71, 73, 79, 80, 83, 85, 89], "320": [13, 20, 25, 26, 27, 28, 36, 37, 61], "3200": 61, "3202": 18, "3207": 26, "3213": 26, "322": 13, "323": [26, 36, 47], "32313": 26, "3238": 26, "32469": 36, "3248779296875": 85, "3259": 26, "326": 26, "3270": 24, "32768": [36, 61, 80, 83], "3278": 26, "3283": [26, 36, 47], "32832": 36, "32b": [66, 67, 70, 92], "32b_eagle3": 70, "32card": 61, "32exp": 83, "32g": [52, 56, 90], "32it": [25, 27], "33": [13, 24, 27, 36, 77], "330": [25, 26], "3328": [13, 20, 25, 26, 27, 28, 36, 37], "3330": 26, "336": [66, 91], "3363": 36, "339675e": 85, "33it": [13, 27, 77], "34": [13, 20, 24, 25, 26, 27, 28, 33, 36, 37, 40, 41, 42, 47, 77], "3405": 36, "3409": 36, "3410": [26, 36], "34277": 40, "3430": 26, "3440": 61, "34411": 77, "345": 26, "3460": 26, "34b": 66, "34it": [13, 20, 24], "35": [13, 24, 25, 36, 77, 90], "3500": 61, "3500000": 26, "350x": 29, "3518979474117756e": 85, "352": [13, 20, 25, 26, 27, 28, 36, 37, 62], "3526": 26, "3533": 18, "3545": 26, "3555": 36, "3561": 26, "357747e": 85, "358": [26, 36], "3583": 30, "3584": [13, 20, 25, 26, 27, 28, 36, 37, 61], "3595688": 25, "3598": 26, "35it": 13, "36": [13, 24, 28, 33, 36, 41, 47, 61], "3600": [16, 29, 30, 61], "360p": 49, "361773588": 20, "362": 13, "36342": 36, "36386": 36, "364": 26, "369": [26, 36], "369873046875": 41, "36b": 92, "36it": 13, "37": [13, 27, 40, 47], "37085": 13, "370959": 12, "371": 42, "373": 24, "3730": 26, "3735": 26, "374": [25, 26, 33, 36, 47], "377": 42, "3786": 26, "3796875": 85, "37it": [27, 36, 40], "38": [13, 24, 36], "380": 28, "382": [26, 36, 85], "3825": 36, "384": [13, 20, 25, 26, 27, 28, 36, 37, 61], "3840": [13, 20, 25, 26, 27, 28, 36, 37], "387": 26, "3880": 26, "3881": [26, 36], "389": [26, 47], "38916": 13, "38926": 13, "38936": 13, "389414e": 85, "38944": 13, "39": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 67, 77], "3900": 61, "392855cc896248e1ac36615c082206bb": 27, "3946": 36, "3950": 36, "39529": 26, "3953": 26, "3956175": 25, "39735": 26, "39it": 36, "3_1": 92, "3_3": 92, "3a7b": 22, "3b": [27, 28, 49, 66, 71, 90, 92], "3e": 2, "3f": 11, "3k": 61, "3m": 35, "3moe": 92, "3next": 92, "3rd": 40, "3x": [11, 90], "4": [0, 1, 5, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 35, 36, 37, 40, 41, 42, 43, 44, 47, 50, 51, 59, 60, 64, 66, 67, 73, 77, 79, 80, 81, 83, 84, 85, 90, 92, 93, 95, 97], "40": [13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 42, 56, 67, 70, 77, 85, 92], "400": [57, 61, 88, 90], "4000": [18, 58, 61], "40000": 79, "400757e": 85, "4008": 36, "400b": [34, 92], "400k": 35, "401": 49, "402": 13, "403": 49, "4030": 24, "405": 26, "407": 27, "408": 22, "4085": 24, "4090": 90, "4096": [3, 12, 13, 16, 20, 21, 24, 25, 26, 27, 28, 30, 36, 37, 53, 61, 70, 73, 74, 83], "4096x12288": 24, "4096x22016": 24, "4096x32000": 24, "4096x4096": 24, "41": [13, 25], "410": 61, "4126": 36, "4135": 26, "416": [13, 20, 25, 26, 27, 28, 36, 37], "418": 24, "419": [26, 36], "41d4": 22, "42": [4, 13, 22, 24, 40, 61, 67, 77], "420": 27, "4226": 36, "4229": 36, "424b": [92, 95], "4257": 26, "4258": 24, "427": 27, "429": [26, 36], "42it": 77, "43": [4, 13, 24, 25, 36, 67], "4300": 61, "4317": [13, 20, 21, 22, 25, 26, 27, 28, 36, 37, 86], "4318": 86, "432": [26, 36], "4324": 24, "433413": 85, "43399": 36, "4340292513370514": 88, "4348a1b76eff48f4ade43d83bdb77566": 25, "4378": 26, "438": [26, 36], "4396": 26, "43it": [24, 27], "44": [4, 13, 24, 36, 47], "4411": 26, "4418": 30, "442": 13, "44292": 26, "444": 24, "44441": 26, "44519": 36, "446655440000": 22, "448": [13, 20, 25, 26, 27, 28, 36, 37], "4491": 24, "44it": [13, 27, 42, 77], "45": [4, 13, 22, 24, 25, 26, 36, 90], "4505": 47, "450560": 61, "451": 36, "4512": 24, "45541": 25, "458": 26, "4580": 24, "458322930": 13, "4586": 26, "4588": 26, "458880": 61, "459": 26, "4594": 12, "45it": 13, "46": [4, 13, 20, 24, 25, 26], "4608": [13, 20, 25, 26, 27, 28, 36, 37], "4650": 36, "4658": 26, "466": 27, "4686": 26, "4695": 26, "47": [13, 24, 40, 41], "4710": 26, "4718": 26, "4734": 26, "476": [26, 36], "47b": 92, "47it": [27, 36], "48": [13, 20, 21, 24, 25, 26, 27, 28, 29, 30, 36, 37, 61, 77], "480": [13, 20, 25, 26, 27, 28, 36, 37, 61], "48027729988098145": 36, "480b": 66, "480p": 90, "482": [13, 36], "48206": 26, "483698": 26, "48506": 36, "486": 85, "487316894531251": 85, "48908": 79, "48924": 79, "48b": 92, "48it": [13, 36], "49": [13, 24, 25, 85], "49000": 26, "49152": 61, "4934": 18, "493d36bedbcb4904ad15b19b5e4b54da": 26, "4948": 36, "497": 26, "498": [25, 33], "498147920": 25, "49b": 92, "4a": 49, "4b": [40, 49, 66, 90, 91, 92, 95], "4b05be832b5b48118160efe9a79034ec": 26, "4bit": 17, "4c3f": 22, "4c81eb8bf0394911a76b340d0dfcebdc": 13, "4card": 61, "4f": [36, 96], "4k": [16, 49, 61], "4k1": 61, "4so": 77, "4th": 67, "4v": [92, 95], "4x": [22, 35, 90], "4xh100": 44, "5": [0, 1, 3, 5, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 34, 36, 37, 38, 40, 41, 42, 43, 46, 47, 49, 50, 51, 53, 55, 58, 59, 60, 62, 66, 67, 70, 71, 77, 79, 80, 83, 85, 88, 90, 91, 92, 93, 94, 95, 97, 98], "50": [4, 12, 13, 20, 21, 22, 24, 25, 26, 27, 28, 30, 36, 40, 41, 77, 79, 85, 90], "500": [21, 22, 26, 37, 49, 51, 53, 59, 73, 86, 88], "5000": [15, 22, 61, 62], "50000": [21, 61, 62], "500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 26, "50051": 10, "5008": 26, "500m": 22, "50100": 25, "5018": 25, "502": 22, "5020": 26, "503": 22, "504": [22, 36], "5043": 26, "506": 36, "5067": 18, "5081": 18, "50814177726902": 85, "50it": 37, "50m": 22, "50mb": 22, "51": [13, 20, 24, 26, 27, 36, 40], "512": [11, 12, 13, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 36, 37, 49, 50, 61, 62, 70, 77, 91, 95], "5120": [13, 20, 25, 26, 27, 28, 36, 37], "512x768": 49, "514771912145079": 85, "515": 26, "5168": 24, "51it": [24, 36], "52": [13, 24, 36, 81, 92], "522": 13, "5226": 30, "524": 36, "524288": 80, "52428800": 22, "525": [26, 36], "527617": 25, "52844": 26, "52b": 92, "52it": 13, "53": [13, 24, 26, 27], "53116": 36, "532": 26, "53371": 26, "537": 26, "538116216659546": 26, "53814": 36, "53818": 36, "53828": 36, "53838": 36, "53854": 36, "5397475": 26, "53it": 27, "54": [13, 20, 24, 26, 61, 77], "54231": 26, "5432": 22, "5434": 18, "544": 90, "545": 30, "5452638": 25, "5452707": 25, "5452733": 25, "55": [13, 24, 25, 27], "550e8400": 22, "5512": 26, "55121": 26, "5527": 26, "553": 36, "5542": 36, "557572e": 85, "55d8b842ecf84e5b852f73e1bd015d5": 24, "56": [13, 18, 20, 24, 25, 26, 27, 28, 37, 40, 61], "562": 13, "5632": [13, 20, 25, 26, 27, 28, 36, 37], "5648": 26, "565": 27, "565970778465271": 88, "5678": 22, "56953125": 85, "56it": 13, "57": [13, 24, 36, 47], "570": 28, "5707": 36, "5711": 26, "572": [26, 36], "5724": 16, "57344": 18, "576": [26, 36, 61], "5768368": 26, "57696958": 27, "5791104": 25, "5791549598": 85, "57it": 24, "58": [20, 26, 27, 33, 36], "5821": 26, "5847": 26, "5871": 26, "58f3c87c8811471792a70f1fc492c83a": 25, "58it": [27, 47], "59": [13, 20, 24, 27], "593": 85, "594": 26, "5944": 26, "595": 26, "59604": 26, "596463012695313": 85, "5975": 26, "5978": 26, "59it": 47, "5_step": 90, "5b": [0, 13, 22, 36, 37, 38, 40, 41, 47, 66, 71, 88, 90, 92, 97, 98], "5k": 61, "5k1": 61, "5k1k": 61, "5m": [22, 34], "5moe": [66, 92], "5t": 92, "5v": [5, 43, 66, 95], "5x": 29, "6": [13, 16, 20, 21, 22, 24, 25, 26, 27, 28, 32, 36, 37, 40, 41, 42, 43, 47, 49, 50, 58, 60, 61, 62, 66, 67, 69, 77, 79, 84, 85, 90, 92, 93, 95], "60": [22, 24, 36, 40, 42, 50, 61, 77, 79, 83, 85, 95, 96], "600": [15, 22, 61], "6000": [18, 61], "6017": 80, "602": 13, "602112": 95, "60392": 36, "606": 26, "60704": 25, "609": 25, "6099": 26, "60it": 36, "61": [13, 20, 26, 33, 42, 61, 77], "6144": [13, 16, 20, 25, 26, 27, 28, 36, 37], "6169": 26, "617": 30, "61it": [27, 37, 40], "62": [26, 27, 36, 77], "62001": 30, "624": [26, 61], "62it": 25, "6364": 26, "6379": 22, "63it": [36, 37], "64": [1, 10, 13, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 53, 61, 70, 71, 73, 77, 80, 83, 86], "640": [13, 20, 25, 26, 27, 28, 36, 37], "64000": [30, 61], "642": 13, "646": 26, "647": 36, "64cc9dc649f448a0b5168351f0ae7880": 27, "64k": 61, "64k3k": 61, "64mb": 22, "64x11008": 24, "64x4096": 24, "65": [1, 16, 24, 32, 45], "650": [61, 62], "6501ef8e2d874006bf555bc80cddc7c5": 29, "6509": 36, "6540": 26, "65536": [12, 28, 34, 61], "65it": 36, "66": [13, 61], "6656": [13, 20, 25, 26, 27, 28, 36, 37], "665690": 12, "6688": [60, 61, 62], "6699": 61, "67": [13, 24, 30, 77], "67108864": 22, "671b": 92, "6722": [26, 36], "675": 26, "67706": 36, "6771": 26, "6778": 18, "678": 26, "67890": 40, "68": [24, 36, 61, 62], "68000": 61, "6801": 26, "682": [13, 36], "685": 61, "686": 36, "6864": 25, "6894": 26, "6896": 26, "6899": 18, "69": [13, 24], "6980p": [29, 67], "6b": [56, 66, 91, 92, 96], "6k": [16, 61], "6k1": 61, "6lcbd": 80, "6th": 67, "6v": [5, 43], "7": [12, 13, 20, 21, 22, 24, 25, 26, 27, 28, 34, 36, 40, 43, 47, 50, 60, 61, 66, 74, 77, 79, 80, 85, 88, 90, 92, 93, 95], "70": [13, 20, 24, 42, 50], "700": 26, "7007": 25, "7010": 18, "7039": 26, "704": [13, 20, 25, 26, 27, 28, 36, 37], "7042": 26, "705": 26, "7071": 26, "70b": [27, 67], "70it": 20, "71": [20, 24, 30, 61], "712400": 79, "714": 26, "71486": 26, "7168": [13, 20, 25, 26, 27, 28, 36, 37], "7196": 26, "71it": [13, 24], "72": [20, 24, 25, 26, 27, 28, 36, 37, 40, 61], "720": [61, 62, 90], "7207887956956": 36, "720p": [49, 90], "722": 13, "7239": 61, "7273": 18, "728": 26, "7281": 26, "7282ed30580a4dfebfefcad25a2ac3cf": 24, "72b": [66, 95, 97], "72it": [13, 77], "73": [24, 27, 40, 61, 77, 85], "730975341796876": 85, "7333": 18, "7339": 61, "73594": 26, "73it": 28, "74": [13, 24, 34, 37, 47, 61], "74059": 36, "7407": 47, "742": 26, "7439": 61, "7460823": 26, "7482": 26, "7486296874999999": 28, "749": 33, "74m": [80, 83], "75": [13, 15, 16, 24, 25, 27, 34, 36, 40, 61, 77, 85, 90, 92], "752": 26, "7533": 18, "7546": 26, "756": 26, "758": 36, "75b": 92, "76": [13, 24, 36, 37, 40, 47], "762": 13, "76602": 26, "7667": 18, "768": [12, 13, 20, 25, 26, 27, 28, 36, 37, 61], "7680": [13, 20, 25, 26, 27, 28, 36, 37], "768422430": 26, "7697": 18, "77": [13, 24, 26, 36], "7707": 18, "773": 26, "7733": 18, "7735": 26, "7772": 47, "77it": 36, "77x": 84, "78": [13, 18, 24, 36, 47, 61, 62], "783": 30, "788": [26, 30], "78it": 36, "79": [24, 26, 61], "793": 30, "794": 25, "797": 30, "7979": 16, "798": 30, "799": 30, "7ae557604adf67be50417f59c2c2f167def9a775": 36, "7b": [5, 17, 20, 24, 26, 27, 36, 42, 46, 51, 59, 66, 72, 77, 91, 92, 94, 95, 97], "7f": 79, "7fa2af80": 50, "7x": 29, "8": [1, 2, 4, 7, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 40, 45, 46, 47, 49, 50, 52, 53, 58, 60, 61, 62, 64, 69, 70, 74, 77, 79, 80, 81, 83, 85, 90, 93], "80": [13, 20, 22, 24, 25, 26, 27, 28, 34, 36, 37, 42, 53, 61, 70, 77], "800": 29, "8000": [6, 15, 22, 30, 35, 49, 50, 60, 61, 62, 80, 81, 83, 88], "8001": [22, 60, 61, 62, 96], "80022": 26, "800i": [29, 60], "802": 13, "803": [26, 30], "806": 36, "807": [26, 36], "808": 30, "8080": [0, 10, 22, 56, 83], "80b": [27, 44, 61, 66, 92], "80it": 13, "81": [24, 26, 61, 62], "8127": 36, "813": [27, 30], "814de8ed089c482fa19dc38dd83f5a07": 47, "815": [61, 62], "816043786240": 10, "8188": [61, 62], "8192": [12, 13, 20, 24, 25, 26, 27, 28, 32, 36, 37, 45, 53, 61, 62, 69, 70, 73, 79], "81adccc0b64a4e79928437a8faabe7eb": 25, "81it": 24, "82": [12, 24, 36, 67], "821": 26, "823": 36, "8232": 36, "824": 30, "8253": 26, "829": 26, "82m": 13, "83": [30, 61], "830": 36, "832": [13, 20, 25, 26, 27, 28, 36, 37, 61, 62], "835": [20, 25, 26, 27, 37], "836": 36, "8365": 26, "838": 30, "83it": 13, "84": [13, 24, 61, 79], "840": 30, "841": [13, 36], "842": 13, "8420": 26, "84204177856446": 85, "8443": 22, "845": 85, "8450": 36, "847": 26, "848": 30, "849": [80, 83], "84it": 47, "85": [10, 13, 16, 24, 27, 35], "8542968750000001": 85, "855": 85, "8585": 36, "85it": 24, "86": [24, 61, 67, 85], "860": 61, "862": [26, 36], "866964": 85, "86it": [13, 24], "87": [13, 24, 30], "879": 30, "88": [13, 20, 22, 24, 25, 26, 27, 28, 36, 37, 61, 62], "882": [13, 26], "8832519531250003": 85, "8833": 33, "8846": 16, "887471773": 28, "8884": [51, 59], "88it": 13, "89": [13, 24, 79], "892": 36, "8926": 26, "894": 36, "89469451904297": 85, "896": [13, 20, 25, 26, 27, 28, 36, 37], "8965": 86, "897": 26, "8995": [60, 61], "8996": 62, "8998": [13, 20, 21, 25, 26, 27, 28, 30, 36, 37, 61, 62], "8999": [61, 62], "8b": [1, 2, 3, 6, 13, 15, 17, 21, 22, 24, 25, 27, 36, 46, 49, 50, 56, 58, 60, 66, 67, 69, 71, 85, 87, 92, 93, 95, 96, 97, 98], "8b647c9d92cf45b0947e36fd8939abb": 24, "8c70": 22, "8t": 92, "8th": 40, "8x": [29, 35], "8xh100": [31, 34], "8xh200": 30, "9": [12, 13, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 40, 44, 49, 50, 55, 56, 67, 70, 71, 77, 79, 85, 90, 93], "90": [13, 22, 24, 27, 30, 61], "9000": [61, 62, 64], "9001": 22, "900469973": 37, "902": 26, "906": 26, "9090": 85, "90ab": 22, "90it": 13, "91": 13, "910": 36, "910b": 60, "911": 26, "912": 26, "9120": 2, "9124": 18, "914": 26, "91494": 26, "9152": 18, "9154": 18, "9157": 18, "916": 26, "9161": 18, "9163": 18, "9168": 18, "9181": 18, "9186": 18, "92": [24, 25, 26, 30, 36], "922": 13, "9220": [51, 59], "9221679687500002": 85, "92999": [26, 36], "92it": 36, "93": [24, 79], "9310812950134277": 26, "9363": 36, "94": [24, 30], "941": 85, "944": 26, "9454": 36, "95": [17, 20, 22, 24, 25, 26, 27, 30, 37, 40, 74, 89], "950195e": 85, "956": 30, "96": [13, 20, 24, 25, 26, 27, 28, 29, 30, 36, 37, 61, 70, 82], "960": [13, 20, 25, 26, 27, 28, 36, 37, 90], "9603": 36, "962": 13, "9625": [26, 36, 47], "9658": 26, "966": 26, "9693": 26, "96g": 30, "96gb": 35, "96it": [24, 36], "97": 24, "9716": 36, "9720": 36, "9729": 36, "9733": 26, "97528": 36, "97593": 26, "9763": 36, "979": 26, "97904": 26, "97m": [80, 83], "98": [24, 36], "9806": 47, "9814": 36, "9822": 25, "983": 50, "984": 21, "985": 36, "99": [22, 24, 27, 96], "990": 26, "992": 21, "993251": 26, "9932568": 26, "9932597": 26, "996": 21, "998": 21, "9998": 12, "999999": 34, "99it": 25, "9b": [66, 92, 95], "9b18419a785f46c6a6a7544bdca4cc6a": 40, "9bf17f2847b046c7b2d5495f4b4f9682": 88, "9c5dbfc57": [80, 83], "9dff": 79, "9k": 61, "9k1k": 61, "9th": 40, "9x": 29, "A": [5, 8, 11, 12, 13, 15, 16, 20, 21, 22, 23, 28, 29, 30, 37, 46, 48, 50, 51, 56, 59, 67, 69, 71, 79, 86, 90, 91, 92, 95, 96, 97, 99], "And": [16, 33, 84], "As": [11, 12, 13, 16, 37, 42, 50], "At": [11, 30, 79, 80, 83], "Be": 23, "But": [13, 24, 26, 30, 40], "By": [4, 7, 10, 11, 12, 13, 14, 15, 16, 21, 23, 24, 29, 33, 46, 56, 72, 77, 85, 90, 95, 98, 99], "For": [0, 1, 3, 7, 8, 10, 11, 13, 15, 16, 17, 20, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 59, 67, 70, 75, 79, 83, 85, 86, 90, 91, 92, 93, 95, 96, 98], "If": [0, 1, 3, 8, 11, 12, 13, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 29, 30, 32, 36, 38, 45, 46, 48, 49, 50, 51, 52, 56, 58, 59, 60, 61, 67, 68, 70, 72, 74, 79, 84, 85, 86, 87, 88, 90, 91, 92, 95, 96, 98], "In": [3, 5, 6, 8, 11, 13, 15, 16, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 36, 37, 40, 41, 42, 47, 51, 52, 56, 58, 59, 67, 70, 73, 74, 77, 79, 80, 86, 90, 93, 98], "It": [1, 3, 5, 7, 11, 12, 13, 16, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 35, 36, 37, 40, 44, 45, 46, 47, 48, 49, 50, 51, 56, 57, 59, 67, 72, 75, 90, 91, 92, 95, 98], "Its": [29, 57], "NOT": [27, 72, 96], "No": [4, 8, 13, 18, 20, 22, 24, 26, 33, 36, 40, 73, 85, 90], "Not": [1, 18, 21, 49, 73], "OFED": 79, "Of": 77, "On": [5, 11, 12, 16, 18, 23, 30, 32, 45, 56, 67, 82, 86], "One": [13, 21, 23, 40, 46, 90], "Or": [3, 15, 17, 22, 24, 27, 49, 69, 90, 94], "THE": 40, "That": [26, 98, 99], "The": [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 58, 60, 63, 67, 69, 70, 71, 73, 75, 77, 78, 79, 80, 83, 85, 86, 87, 88, 90, 92, 93, 95, 96, 98, 99], "Their": 86, "Then": [13, 17, 22, 30, 38, 51, 55, 59, 79, 81, 85, 98], "There": [13, 44, 52, 72], "These": [7, 17, 21, 24, 33, 37, 40, 51, 59, 73, 84, 86, 92, 95, 97, 98], "To": [1, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 29, 30, 31, 33, 34, 36, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 63, 67, 70, 74, 77, 80, 84, 85, 86, 90, 94, 95, 98], "Will": 1, "With": [0, 1, 13, 16, 22, 23, 29, 30, 35, 37, 49, 50, 58, 70, 95], "_": [8, 30, 77], "____": 37, "__call__": [46, 98], "__future__": 48, "__global__": 48, "__init__": [13, 20, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 54, 77, 98], "__main__": [62, 89, 98], "__name__": [8, 62, 89, 98], "__post_init__": 90, "_attn_implement": 99, "_bootstrap_extern": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "_dynamo": 24, "_flash_3_hub": 90, "_forward_attn": 7, "_forward_combin": 7, "_forward_dispatch": 7, "_forward_mlp": 7, "_jit_add_constant_modul": 48, "_output_": 30, "_pp_commit_comm_work": 16, "_pp_launch_batch": 16, "_pp_process_batch_result": 16, "_pp_send_pyobj_to_next_stag": 16, "_supports_attention_backend": 99, "_work": 36, "a10": 56, "a100": [1, 29, 32, 45, 56, 57, 90], "a14b": 90, "a1b2c3d4": 22, "a2": [30, 36, 60, 66, 79], "a22b": [10, 18, 20, 45, 66, 67, 95], "a2a": [7, 15, 21, 61, 62, 73, 80, 83], "a2b27aa70a66dc36ce71116f6c6a259dd1b23c17": 13, "a2dc": 79, "a2fcadb61a0a4c508d53782d10955d71": 42, "a3": [29, 30, 60, 66], "a35b": 66, "a36b": [66, 92], "a3b": [27, 44, 45, 60, 61, 66, 92, 95], "a40": 1, "a716": 22, "a800": 29, "a800m": [66, 92], "a98401f3062441c5902ea5591a4c0b23": 26, "aarch64": [56, 60], "ab": [22, 90], "abbrevi": [25, 26, 27], "abc": 11, "abi3": 56, "abil": [13, 92], "abl": [13, 37, 85, 98], "abnorm": [17, 90], "abort": [21, 23], "abort_al": 23, "abort_all_request": 23, "abort_on_priority_when_dis": [13, 20, 25, 26, 27, 28, 36, 37], "about": [8, 11, 12, 13, 19, 21, 25, 26, 33, 37, 40, 52, 71, 72, 74, 77, 78, 90, 95, 98, 99], "abov": [10, 21, 24, 27, 29, 38, 40, 46, 49, 50, 51, 56, 59, 67, 71, 74, 75, 77, 79, 86, 98], "absolut": [0, 22], "absorpt": 29, "abstract": 7, "abus": [51, 59], "aca85a5b9e694de488f929cbcd6bb309": 25, "acc": 21, "acc_typ": 24, "acceler": [2, 7, 12, 21, 24, 29, 56, 57, 62, 70], "accelerator_arg": 70, "accept": [15, 18, 21, 22, 24, 40, 46, 48, 49, 81, 89, 90, 92, 95, 98], "accept_length": 49, "access": [6, 11, 21, 22, 23, 25, 26, 29, 37, 40, 50, 56, 67, 70, 73, 79, 80, 83, 85, 86, 90, 98], "accommod": 86, "accord": [1, 15, 16, 17, 27, 33, 44, 50, 67, 79, 80, 83], "accordingli": [0, 20, 27, 36], "account": [3, 18, 51, 59, 74], "accumul": [18, 73, 74], "accur": [21, 26, 28, 36, 37, 44, 91], "accuraci": [13, 17, 21, 23, 24, 26, 62, 90, 92, 95, 96, 98], "achiev": [4, 7, 11, 13, 16, 23, 24, 29, 30, 40, 70, 74, 79, 84, 90, 92, 95], "across": [2, 4, 5, 7, 10, 11, 13, 16, 18, 21, 22, 23, 29, 30, 48, 50, 57, 70, 73, 74, 75, 81, 84, 86, 90, 92], "act": [13, 27, 33, 37, 38], "action": [17, 22], "activ": [7, 8, 12, 17, 21, 22, 23, 29, 35, 37, 50, 57, 60, 63, 67, 70, 71, 73, 77, 79, 81, 90, 92], "actual": [8, 11, 13, 16, 20, 24, 25, 26, 27, 35, 36, 40, 41, 42, 47, 77, 80, 83, 85, 86, 88], "ad": [0, 4, 13, 14, 16, 20, 21, 22, 27, 33, 40, 48, 51, 56, 57, 59, 85, 86, 90], "ada": 1, "adapt": [7, 13, 21, 30, 37, 60, 70, 79, 98], "adapter_a": [13, 40], "adapter_b": 40, "adb": 22, "add": [0, 2, 7, 10, 17, 20, 21, 23, 25, 26, 27, 29, 31, 33, 34, 37, 41, 44, 46, 49, 50, 52, 53, 56, 58, 60, 63, 67, 74, 80, 83, 85, 90, 95], "add_const": 48, "add_constant_kernel": 48, "add_generation_prompt": [20, 25, 26, 27], "add_link": 86, "add_special_token": 36, "addit": [2, 4, 13, 16, 18, 20, 21, 23, 27, 37, 40, 51, 56, 59, 60, 70, 75, 86, 88, 90, 98], "addition": [6, 24, 29, 30, 37, 50, 67, 71, 79], "addr": [2, 15, 16, 21, 30, 61, 62, 70, 79, 80, 81, 83, 93], "address": [2, 6, 7, 10, 11, 15, 16, 19, 21, 22, 23, 67, 71, 73, 74, 77, 79, 81], "adept": 92, "adjust": [21, 24, 29, 34, 35, 36, 44, 49, 67, 70, 74, 80, 83, 85, 95], "admin": [21, 85], "admin_api_kei": [13, 20, 21, 25, 26, 27, 28, 36, 37], "administr": [21, 24, 26, 37], "admir": 40, "adopt": [21, 22, 57], "adv": 50, "advanc": [7, 13, 30, 33, 35, 40, 46, 48, 50, 86, 92, 95], "advantag": 37, "adversari": 13, "advertis": [28, 77], "advic": 37, "advis": [25, 37], "aerob": 77, "affect": [11, 13, 15, 17, 21, 37, 60, 70], "affin": [16, 22, 60, 73], "aflah02": 81, "afm": [66, 92], "aforement": [16, 30], "after": [0, 3, 5, 7, 11, 13, 15, 17, 20, 21, 22, 23, 24, 29, 32, 35, 36, 37, 45, 47, 48, 49, 50, 56, 69, 74, 80, 86, 90, 95, 98], "afterward": [3, 24, 58], "ag": [24, 37, 79], "again": [11, 13, 17, 24, 27, 40, 51, 58, 59, 63, 90, 98], "against": [0, 11, 13, 17, 21, 49, 75, 96], "agenc": [26, 92], "agent": [20, 22, 35, 47, 49, 92], "aggreg": [11, 49, 86], "aggress": [16, 22, 89], "agnost": 7, "ago": 37, "agx": 69, "ahead": [13, 48], "ai": [1, 7, 15, 16, 18, 20, 22, 25, 26, 27, 29, 30, 33, 37, 40, 47, 52, 58, 60, 66, 67, 69, 79, 80, 83, 90, 92, 93, 95, 98], "aibrix": [11, 21], "aid": 48, "aidc": 90, "aig": 80, "ailuropoda": [36, 96], "aim": [24, 29, 37, 73, 77, 79], "aime25": [18, 30], "aiohttp": 49, "aiter": [1, 21, 30, 34, 73, 90], "aiter_attn": 21, "aiv": [61, 64], "ai\u52a9\u624b": [80, 83], "alert": 22, "algo": 44, "algoprog": 13, "algorithm": [11, 16, 17, 21, 24, 29, 30, 31, 33, 34, 37, 44, 61, 62, 64, 70, 80, 83, 89], "alia": [22, 58, 60], "alias": 90, "alibaba": [36, 41, 45, 66, 91, 92, 95], "align": [16, 17, 21, 22, 23, 84, 92, 95, 97], "aliv": [23, 77], "all": [0, 1, 2, 4, 5, 8, 10, 11, 13, 14, 16, 18, 20, 21, 22, 23, 26, 27, 28, 29, 30, 35, 40, 42, 46, 48, 49, 50, 51, 52, 53, 55, 56, 59, 60, 70, 73, 75, 80, 86, 88, 90, 94, 96, 98], "all_attention_funct": 99, "all_hip": 58, "all_musa": 68, "all_npu": 60, "all_other_model": 98, "all_reduc": 11, "allen": 92, "allenai": [17, 66, 92], "allevi": 11, "allgath": 21, "alloc": [3, 11, 12, 13, 21, 36, 50, 70, 85], "allocator_ascend": [51, 59], "allow": [2, 3, 7, 10, 11, 14, 16, 18, 21, 22, 24, 26, 29, 32, 38, 40, 45, 48, 50, 52, 56, 70, 73, 80, 86, 88, 90, 91, 95, 96, 98], "allow_auto_trunc": [13, 20, 25, 26, 27, 28, 36, 37], "allow_tf32": 24, "allreduc": 21, "almost": [90, 98], "alon": [13, 90], "along": [13, 33, 56, 58, 77, 92, 95], "alongsid": [22, 50, 56, 95], "alpha": [70, 92], "alreadi": [11, 13, 15, 16, 17, 29, 33, 37, 38, 59, 63, 67, 85, 86, 91], "alright": 26, "also": [1, 3, 11, 12, 13, 16, 17, 20, 21, 23, 24, 26, 27, 29, 30, 33, 36, 37, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 56, 58, 59, 69, 72, 74, 77, 79, 80, 81, 84, 86, 90, 95, 96, 98, 99], "altern": [0, 10, 11, 16, 17, 21, 24, 42, 48, 73, 75, 97], "although": 16, "altogeth": 26, "alwai": [0, 1, 4, 12, 13, 18, 20, 21, 22, 25, 26, 27, 37, 40, 46, 51, 59, 70, 88, 90, 96], "am": 37, "amazon": [11, 56], "amazonaw": 56, "amd": [17, 30, 34, 55, 56, 57, 73, 90], "america": [25, 26], "among": [10, 11, 24, 29, 37, 40, 73, 84, 86], "amount": [13, 16, 40, 67], "amper": [1, 7], "amplifi": 90, "amx": [1, 21, 67], "amxint4": [13, 21, 36], "an": [1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 36, 37, 38, 40, 42, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 67, 68, 73, 74, 75, 77, 79, 84, 85, 86, 92, 93, 94, 95, 97], "analysi": [16, 20, 21, 27, 52, 70, 90], "analyst": 33, "analyz": [7, 16, 22, 36, 50, 95], "ancient": [13, 40], "angelslim": 70, "angevin": 36, "angl": 24, "ani": [1, 8, 11, 13, 14, 15, 16, 17, 21, 22, 23, 24, 26, 27, 29, 36, 40, 46, 48, 50, 51, 53, 56, 59, 60, 61, 77, 79, 88, 90, 91, 98, 99], "anim": [13, 37], "annot": [21, 22, 24, 27, 40, 47, 48, 50], "anonym": 86, "anoth": [1, 12, 13, 15, 16, 21, 26, 42, 50, 58, 67, 71, 74, 77, 86], "answ": 37, "answer": [20, 22, 24, 25, 26, 27, 36, 37, 40, 75, 77, 95, 96], "antidisestablishmentarian": 75, "anyth": 40, "aot": 48, "apach": 92, "apart": 36, "apeach": [22, 66, 88, 97], "api": [8, 11, 23, 35, 46, 56, 57, 67, 70, 71, 72, 75, 77, 79, 80, 86, 89, 95], "api_kei": [13, 20, 22, 24, 25, 26, 27, 28, 29, 31, 33, 36, 37, 40, 41, 42, 46, 47, 90], "apigroup": 22, "apivers": [22, 79, 80, 83], "app": [21, 22, 26, 80, 83], "appear": [21, 28, 40, 42, 46, 50, 51, 59, 77], "append": [4, 8, 27, 29, 35, 49, 58], "append_messag": 28, "appli": [0, 6, 7, 13, 17, 21, 22, 28, 29, 35, 36, 37, 40, 49, 51, 52, 56, 59, 60, 67, 73, 79, 80, 90], "applic": [13, 22, 26, 28, 29, 35, 36, 41, 42, 47, 50, 67, 79, 80, 83, 88, 89, 90, 96], "apply_chat_templ": [20, 25, 26, 27, 34, 36], "apply_softmax": 36, "appreci": [51, 59], "approach": [4, 11, 12, 13, 16, 29, 50, 56, 77, 80], "appropri": [0, 11, 16, 17, 24, 26, 27, 40, 49, 88], "approv": [51, 59], "approxim": [18, 26, 67], "april": 23, "apt": [0, 48, 50, 55], "aqueduct": 40, "ar": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 58, 59, 60, 66, 67, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 83, 84, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99], "arbitrari": 8, "arc": 71, "arcane_jinx": 90, "arce": [66, 92], "arch": 55, "archer": 13, "architectur": [1, 5, 6, 7, 16, 17, 18, 23, 29, 33, 36, 37, 40, 50, 70, 89, 90, 91, 92, 95, 98], "area": [26, 77], "areal": [57, 84], "arg": [15, 19, 22, 36, 48, 50, 52, 62, 73, 75, 91, 95], "argument": [1, 7, 17, 18, 19, 22, 25, 26, 27, 29, 30, 31, 32, 34, 36, 40, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59, 63, 69, 86, 93, 98], "arguments_non_stream": 27, "aris": [36, 74], "arithmet": 77, "arm64": 22, "armi": 36, "around": [22, 26, 27, 29, 90, 98], "arrai": [40, 46, 49, 88, 90], "arrang": 7, "arriv": [20, 21, 36, 49], "art": [37, 40, 51, 59, 84, 92], "articl": 33, "artifact": 13, "artifici": [37, 96, 98], "artist": 37, "ascend": [1, 7, 21, 56, 57, 59, 62, 63, 64, 93], "ascend_attn": [21, 60, 64], "ascend_fuseep": [7, 21, 61], "ascend_home_path": 61, "ascend_instal": 60, "ascend_launch_block": [61, 62], "ascend_mf_store_url": [15, 60, 61, 62], "ascend_mf_transfer_protocol": 60, "ascend_npu_phy_id": 15, "ascend_rt_visible_devic": 93, "ask": [13, 20, 24, 26, 27, 36, 40, 51, 57, 59, 77], "aspect": [2, 21, 23], "aspect_ratio_id": 28, "aspect_ratio_mask": 28, "assert": [23, 36, 46, 50], "asset": [28, 32, 42, 45, 46, 77], "assign": [13, 46], "assist": [11, 24, 25, 26, 27, 28, 29, 33, 35, 36, 37, 40, 42, 46, 47, 72, 75, 77, 80, 83, 89], "assistant_begin": 77, "assistant_end": 77, "associ": [4, 22, 29], "assum": [20, 22, 26, 27], "assumpt": 23, "astral": 67, "astronaut": 40, "async": [10, 21, 23, 37, 98], "async_gener": [37, 98], "async_send": 16, "async_stream_and_merg": 37, "asynchron": [13, 16, 21, 23, 32, 45, 84, 98], "asyncio": 98, "at_least_on": 25, "atb": [61, 62], "atla": [29, 60], "atp": 22, "atp_dsn": 22, "atp_password": 22, "atp_pool_max": 22, "atp_pool_min": 22, "atp_tns_alia": 22, "atp_us": 22, "atp_wallet_path": 22, "attach": [8, 22, 28, 95], "attach_point": 22, "attachment_ep_statist": 80, "attact": 27, "attain": 12, "attempt": [11, 22, 49], "atten_tp_s": 30, "attent": [4, 7, 11, 12, 13, 15, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 30, 32, 34, 36, 37, 40, 41, 42, 45, 47, 56, 57, 60, 61, 62, 64, 69, 71, 73, 77, 79, 80, 83, 91, 92, 93, 96, 98, 99], "attention_backend": [13, 20, 25, 26, 27, 28, 36, 37, 90, 93], "attention_interfac": 99, "attentionbackendenum": 90, "attir": 77, "attn": [21, 61, 62, 90], "attn_output": 99, "attn_weight": 99, "attract": [26, 27, 37, 75], "attribut": [8, 86], "attributeerror": 8, "audio": [21, 24, 27, 36, 40, 46, 47, 95], "audio_data": 46, "audiodataitem": 46, "aug": 33, "augment": [92, 95], "august": 33, "aura": 13, "auror": 77, "australia": [13, 24, 40, 47, 77], "auth": [22, 49], "author": [21, 22, 49, 51, 59, 80, 83, 90], "auto": [0, 7, 13, 20, 21, 22, 24, 25, 26, 27, 28, 34, 36, 37, 48, 49, 61, 62, 73, 85, 87, 89, 90], "auto_awq": 17, "auto_gptq": 17, "auto_map": 99, "auto_next_anon": 86, "auto_round": 17, "autoencod": 90, "autograd": 50, "autom": 58, "automat": [0, 7, 10, 11, 13, 16, 17, 18, 21, 22, 23, 27, 28, 30, 32, 34, 36, 40, 44, 45, 46, 48, 49, 50, 51, 56, 59, 63, 67, 73, 85, 86, 88, 90], "autonom": 22, "autoprocessor": 28, "autoregress": [6, 18, 24, 89], "autoround": 17, "autoroundmllm": 17, "autosc": 56, "autotag": 69, "autotoken": [17, 20, 25, 26, 27, 36, 41], "autotun": [21, 24, 87], "auxiliari": 15, "avail": [1, 11, 13, 15, 16, 19, 21, 23, 25, 26, 29, 33, 36, 38, 40, 41, 42, 47, 48, 49, 56, 58, 67, 70, 73, 74, 79, 85, 88, 90, 92, 99], "avail_mem": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 42, 47, 77], "available_gpu_mem": [12, 13, 36], "available_tool": 27, "averag": [21, 26, 75], "avg": 30, "avg_token": 30, "avoid": [10, 11, 13, 16, 17, 18, 21, 23, 26, 28, 30, 32, 34, 40, 45, 50, 51, 52, 59, 67, 70, 71, 74, 79, 90, 93, 94, 95, 96], "awai": 90, "await": [37, 98], "awar": [15, 23, 37, 84], "awk": [61, 62], "awq": [17, 21, 29, 57, 63], "awq_marlin": [17, 21], "aws_account": 56, "aws_region": 56, "a\u043a\u0430\u0437\u0430\u043bli": 28, "b": [4, 13, 20, 21, 24, 25, 26, 27, 28, 29, 30, 36, 37, 40, 41, 42, 47, 56, 58, 61, 62, 67, 71, 74, 77, 79, 80, 83, 86, 90], "b09d89bc2cd4461f8bc01277b6172a99": 26, "b16e8c6ae28c46fbb5303778dfdb3d43": 25, "b200": [1, 29, 30, 32, 34, 45, 90], "b300": [56, 57], "b4233610175f488da714b60438c94e03": 26, "b4c2c494cc25436091a190e2418aa95c": 27, "b580": 71, "b64_json": 90, "b64decod": 90, "baai": [36, 66, 91, 92, 96], "back": [1, 7, 21, 22, 23, 30, 37, 42, 73, 77, 88, 90, 99], "backbon": [57, 84, 95], "backend": [6, 16, 18, 20, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 64, 67, 69, 71, 75, 77, 80, 81, 83, 84, 85, 91, 93, 96, 98, 99], "backend_nam": [10, 11, 21], "backendfactori": 10, "background": [13, 22, 28, 42, 85, 99], "backoff": 22, "backtrac": 50, "backu": 27, "backup": 21, "backward": [13, 21, 28, 40, 90], "bad": [8, 75, 88], "baichuan": [66, 92], "baichuan2": [66, 92], "baichuanai": 92, "baidu": [66, 92, 95], "bail": 70, "balanc": [6, 10, 11, 15, 16, 21, 29, 33, 40, 42, 61, 62, 70, 77, 80, 84, 90], "balanced": [7, 21], "bandwidth": [2, 5, 6, 11, 15], "bank": [26, 47], "bar": [52, 92, 95], "bare": 67, "base": [1, 5, 6, 7, 10, 11, 13, 15, 17, 18, 21, 22, 24, 26, 29, 30, 32, 33, 34, 35, 40, 45, 46, 49, 50, 60, 61, 66, 67, 70, 73, 75, 79, 81, 82, 86, 87, 91, 92, 95, 96, 97], "base64": [23, 28, 40, 46, 90], "base_config": 98, "base_gpu_id": [13, 20, 25, 26, 27, 28, 36, 37], "base_url": [20, 24, 25, 26, 27, 29, 31, 33, 34, 36, 40, 41, 42, 46, 47, 50, 90], "basedispatch": 7, "baseformatdetector": 27, "baselin": [11, 13, 16, 90, 98], "basemodel": [25, 26], "basemultimodalprocessor": 98, "basereasoningformatdetector": 20, "bash": [0, 30, 50, 54, 55, 56, 61, 67, 69, 70, 81], "bashrc": [50, 67], "basi": 30, "basic": [13, 49, 50, 92, 93], "basic_qa": 77, "batch": [3, 4, 5, 11, 13, 15, 16, 20, 23, 24, 25, 26, 27, 28, 29, 30, 33, 36, 40, 42, 46, 47, 49, 50, 51, 52, 53, 57, 59, 67, 70, 73, 74, 79, 80, 90, 95], "batch_get_v1": 10, "batch_set_v1": 10, "batch_siz": [17, 34], "batchspanprocessor": 73, "battl": 13, "bb14ddf6627e4534b64993d3b21ba338": 40, "bca28cd6d4b742478a41454384e70c8f": 47, "beach": 96, "beach_dog": 96, "bear": [36, 96], "bearer": [21, 22, 49, 80, 83, 90], "beast": 13, "beauti": [13, 40, 90], "becam": 37, "becaus": [5, 11, 13, 23, 26, 27, 49, 62, 77, 98], "becom": [2, 3, 5, 13, 16, 18, 21, 37, 84], "been": [11, 16, 17, 23, 24, 26, 30, 37, 40, 50, 63, 67, 70, 71, 79, 90], "befallen": 13, "befor": [0, 1, 2, 7, 11, 12, 13, 14, 15, 18, 21, 22, 23, 24, 26, 27, 29, 36, 48, 49, 50, 51, 53, 59, 69, 70, 86, 90, 95, 98], "beforehand": [29, 67], "befriend": 13, "began": 40, "begin": [13, 25, 26, 36, 50, 77, 86], "behav": 1, "behavior": [7, 15, 21, 22, 23, 27, 32, 45, 46, 49, 73, 90, 95, 96, 97], "behind": [7, 13, 16, 21, 22, 38], "beij": [25, 26, 29], "being": [1, 5, 12, 15, 16, 21, 37, 40, 77, 86], "believ": 26, "belong": [11, 13], "below": [1, 13, 21, 24, 27, 28, 32, 36, 45, 46, 52, 55, 56, 58, 60, 67, 68, 77, 86, 89, 90, 91, 92, 95, 98], "bench": [24, 50, 57, 91], "bench_one_batch": [50, 52, 98], "bench_one_batch_serv": [50, 53, 70], "bench_serv": [49, 53, 58, 61, 67, 70, 71, 85], "bench_sglang": [30, 52, 53], "bench_specul": [24, 29, 30], "benchmark": [11, 13, 14, 15, 16, 17, 24, 36, 49, 52, 53, 57, 58, 85, 90, 95], "benchmark_and_profil": 98, "benefici": 12, "benefit": [11, 18, 22, 23, 28, 37, 50, 73, 77], "berlin": [24, 25, 26, 36, 40, 75], "bertforsequenceclassif": [22, 88], "besid": [77, 90], "bespok": 75, "best": [1, 6, 9, 11, 23, 24, 26, 28, 29, 30, 32, 37, 40, 45, 65, 70, 90, 96], "best_effort": [10, 11, 13, 20, 21, 25, 26, 27, 28, 36, 37], "best_kernel": 24, "best_kernel_desc": 24, "best_tim": 24, "best_triton_kernel": 24, "best_triton_kernel_desc": 24, "best_triton_po": 24, "best_triton_tim": 24, "better": [11, 12, 13, 16, 17, 18, 21, 22, 25, 29, 30, 36, 37, 40, 46, 48, 56, 70, 89, 90, 91, 95], "between": [1, 2, 7, 10, 11, 12, 15, 16, 18, 19, 21, 29, 30, 31, 33, 36, 37, 38, 46, 49, 50, 70, 77, 80, 84, 91, 92], "bewar": 67, "beyond": [11, 22, 29, 30], "bf": [13, 20, 21, 25, 26, 27, 28, 36, 37], "bf16": [7, 18, 21, 27, 29, 30, 33, 61, 67, 71, 73, 90, 95], "bfloat16": [13, 17, 21, 24, 36, 44, 61, 62, 69, 70, 73], "bge": [36, 66, 91, 96], "bgererankmodel": 96, "bia": 98, "bias": 98, "bid": 13, "bidirect": 22, "big": [26, 37], "bigcod": 92, "biggest": 3, "bilingu": 92, "bill": 22, "billboard": 28, "billion": [35, 67, 92], "bin": [21, 30, 52, 55, 56, 61, 62, 67, 70, 81], "binari": [48, 93], "bind": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 48, 77], "bisheng": 60, "bisheng_nam": 60, "bisheng_toolkit": 61, "bisheng_url": 60, "bishengir": [61, 62], "bit": [17, 18, 26], "bitsandbyt": [17, 21], "black": [13, 20, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 77, 90], "blackwel": [1, 7, 17, 21, 27, 29, 30, 34, 73], "blank": 49, "blinker": 30, "blob": [28, 32, 42, 45, 46, 77, 90], "block": [1, 3, 7, 11, 13, 16, 18, 22, 23, 51, 59, 73, 77, 90], "block_input": 3, "block_k": 24, "block_m": 24, "block_n": 24, "block_output": 3, "block_siz": 89, "block_w": 3, "blockadapterregist": 90, "blockdim": 48, "blockidx": 48, "blockwis": [21, 73], "blog": [7, 11, 16, 19, 23, 29, 74, 78, 81], "blogpost": 75, "blood": 77, "blossom": 90, "blue": [13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77], "bluefield": 79, "bmm": [29, 73], "bn": 90, "bnf": [25, 46], "board": 77, "bodi": [13, 22, 23, 49, 53], "bogart": 77, "bogor": 13, "bold": 90, "bond0": 83, "book": 42, "bookkeep": 23, "bool": [13, 21, 23, 46, 73, 98], "boolean": [51, 59], "boost": [5, 7, 32, 77], "boot": 19, "bootstrap": [15, 21, 22, 30, 60, 61, 62, 86], "bootstrap_host": 21, "bootstrap_room": [21, 86], "bootstrap_room_list": 86, "bootstrap_room_span": 86, "bordeaux": 37, "born": 77, "boston": 27, "bot": [25, 26], "both": [1, 2, 3, 11, 12, 13, 20, 21, 22, 23, 26, 27, 28, 29, 30, 33, 34, 40, 46, 49, 50, 51, 52, 59, 73, 74, 85, 90, 91, 95, 98], "bottleneck": [7, 10, 13, 16, 21, 50, 90], "bottom": [33, 52], "bound": [21, 36], "boundari": [11, 16, 22, 27], "box": [20, 32, 45], "bracket": 26, "branch": [0, 1, 21, 24, 44, 51, 56, 58, 59, 60, 68, 90, 96], "brasilia": 13, "bras\u00edlia": [13, 24, 77], "brave": 13, "brave_search": [25, 26], "brazil": [13, 24, 26, 77], "breadth": 21, "break": [23, 26, 40, 46, 47, 60, 61, 62, 90], "breakdown": [40, 49, 90], "breakpoint": 52, "brief": [36, 89], "brittl": 23, "broad": [57, 90, 92], "broadcast": [2, 21, 23], "broader": 26, "brought": 16, "brows": 85, "browser": [0, 33, 50, 85, 86], "browser_serv": 33, "bubbl": 16, "bucket": 21, "bucket_e2e_request_lat": [13, 20, 25, 26, 27, 28, 36, 37], "bucket_inter_token_lat": [13, 20, 25, 26, 27, 28, 36, 37], "bucket_time_to_first_token": [13, 20, 25, 26, 27, 28, 36, 37], "budget": [11, 18], "buffer": [1, 12, 20, 21, 22, 44, 73], "bug": [10, 17, 51, 59, 70, 74], "build": [0, 3, 4, 11, 15, 17, 19, 26, 28, 37, 42, 52, 54, 56, 58, 59, 60, 67, 69, 71, 73, 86, 90, 95], "built": [3, 11, 13, 21, 22, 35, 40, 50, 51, 53, 56, 58, 59, 90, 93, 95], "buliltin": 21, "bump": [51, 59], "bumper": 42, "burst": [22, 49], "busi": [66, 77, 92, 96], "bypass": 7, "byte": 11, "bytesio": 28, "c": [4, 13, 27, 36, 37, 40, 47, 56, 58, 70, 79, 83, 86], "c1a7159683654dd9b72775945d451141": 42, "c3ec": 79, "c4": 17, "c4ai": [66, 92], "c501111f5103436ca639efdd888bb86": 25, "c7": 79, "c79a": 79, "ca": [22, 25, 26, 27], "cab": 28, "cach": [1, 3, 4, 6, 10, 11, 13, 15, 16, 23, 24, 28, 29, 30, 32, 34, 45, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 67, 70, 74, 79, 80, 83, 84, 85, 92, 94, 95, 96], "cache_awar": [22, 60, 61, 62], "cache_hit_r": 85, "cached_token": [25, 26, 36, 47], "cadenc": 22, "caf\u00e9": 88, "calcul": [15, 17, 18, 20, 21, 28, 33, 46, 77], "calibr": [17, 90], "calibration_dataset": 17, "calico": 90, "california": [25, 26, 27], "call": [1, 8, 16, 20, 21, 23, 24, 25, 26, 31, 32, 33, 35, 36, 37, 40, 45, 48, 49, 50, 75, 77, 80, 86, 90, 92, 95, 96, 98], "call_195cd8c7896b407dad74d73c": 27, "call_42e41fdd2c644181bb6fe4f9": 27, "call_49d2b66906a74dc0b27dad3b": 27, "call_7654ff10cabf428ab15bf71a": 27, "call_952da03f2b0a46c69eed1545": 27, "call_96921416015544edb4f8c8b5": 27, "call_9beeb6dbb85a4f0f922cc336": 27, "call_a82e0a54bd1d4ff1a4bfb3e2": 27, "call_ba31d201b4d94acebde27dba": 27, "call_f2fb7531371845039490e4ba": 27, "callabl": 8, "caller": [23, 51, 59], "came": 13, "can": [0, 1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 83, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99], "canada": [40, 47, 77], "canal": 40, "canberra": [13, 24, 40, 47, 77], "cancel": 22, "candid": 24, "cann": 93, "cann8": 60, "cann_path": 61, "cannot": [1, 8, 13, 16, 20, 24, 25, 26, 27, 28, 30, 36, 40, 41, 42, 47, 48, 50, 67, 70, 77, 79, 84, 96], "cano": 69, "cap": [49, 58], "capabl": [22, 34, 36, 37, 44, 45, 53, 58, 80, 83, 84, 89, 90, 95], "capac": [10, 11, 16, 18, 21, 22, 24, 29, 30], "capit": [13, 17, 24, 25, 26, 27, 29, 31, 36, 37, 40, 46, 47, 75, 77, 91, 93, 98], "capital_info": 25, "capitalinfo": [25, 26], "caption": 95, "captur": [1, 2, 3, 8, 13, 17, 20, 21, 24, 25, 26, 27, 28, 29, 37, 40, 42, 47, 50, 73, 77, 79, 90], "capture_out": 8, "car": 96, "cardiovascular": 77, "cardnum": 61, "care": [13, 33, 37], "cargo": 22, "cart": 28, "carv": 13, "cascad": [13, 22, 24], "case": [0, 1, 7, 11, 12, 13, 17, 21, 22, 29, 30, 35, 37, 49, 50, 51, 56, 59, 70, 74, 92, 93, 95], "cast": [13, 21, 24, 29], "castl": 13, "cat": [21, 60, 90, 96], "categori": 96, "cathedr": 37, "caus": [8, 14, 15, 16, 18, 21, 23, 27, 50, 74], "causallm": 21, "cave": 13, "caveat": [13, 50], "cb": 22, "cbm": [80, 83], "ccccdd": [80, 83], "cd": [15, 22, 30, 54, 56, 58, 59, 60, 67, 68, 70, 71, 85, 90, 93], "cd430cab1e804dca884c4b8318122043": 24, "cdef": 22, "cdna3": 17, "cdna4": 17, "celsiu": [25, 26, 27], "censu": 26, "center": [7, 13, 24, 26, 36, 37, 40], "central": 22, "cert": 22, "certain": [16, 24, 26, 58, 86, 90], "certainli": 77, "certif": 22, "cf": 80, "chain": [22, 48, 90], "challeng": [6, 13, 15, 18, 28, 51, 59, 74], "champ": [24, 36], "chanc": 27, "chang": [0, 7, 16, 23, 26, 30, 33, 36, 37, 46, 50, 51, 52, 55, 58, 59, 60, 67, 74, 79, 83, 85, 91, 95, 98], "channel": [10, 17, 20, 21, 22, 27, 29, 51, 59, 67, 71], "char": 27, "char_count": 22, "charact": [37, 77, 90, 95, 98], "character": 37, "character_gen": 77, "character_lora": 90, "character_regex": 77, "characterist": [3, 11, 16, 28], "charg": 13, "charl": 36, "chart": 80, "chat": [13, 17, 20, 21, 22, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 38, 42, 45, 46, 47, 49, 57, 66, 69, 70, 80, 83, 91, 92, 95, 96, 98], "chat_exampl": 77, "chat_templ": [13, 20, 25, 26, 27, 28, 29, 30, 36, 37, 72, 96], "chat_template_kwarg": [30, 40], "chatcomplet": [24, 27, 40, 47], "chatcompletionmessag": [24, 27, 40, 47], "chatcompletionmessagefunctiontoolcal": 27, "chatglm": [66, 92], "chatglm2": [66, 92], "chatml": [72, 95], "cheaper": 95, "check": [0, 2, 10, 12, 13, 15, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 37, 38, 40, 41, 42, 46, 47, 49, 51, 56, 59, 60, 67, 70, 73, 77, 79, 99], "check_env": 70, "check_output": [41, 42, 47], "checker": 22, "checklist": 22, "checkout": [24, 67, 71], "checkpoint": [13, 17, 18, 20, 23, 24, 25, 26, 27, 28, 32, 36, 37, 40, 41, 42, 45, 47, 50, 57, 73, 77, 98], "checkpoint_engin": 2, "checkpoint_engine_wait_weights_before_readi": [13, 20, 25, 26, 27, 28, 36, 37], "checksum": 21, "cherri": 90, "child": 11, "children": [8, 73], "china": [25, 26, 36, 84, 96], "chines": 92, "chmod": 60, "choic": [20, 21, 24, 25, 26, 29, 30, 40, 42, 44, 47, 76, 77, 80, 83, 84], "choicedeltatoolcal": 27, "choicedeltatoolcallfunct": 27, "choices_method": 75, "choos": [1, 4, 10, 11, 18, 21, 23, 24, 25, 26, 52], "chosen": [1, 13, 18, 21, 40], "chrome": [50, 90], "chronic": 77, "chunk": [1, 4, 13, 20, 21, 27, 29, 30, 32, 36, 38, 40, 45, 46, 47, 57, 61, 62, 73, 74, 80, 83, 96], "chunked_prefill_s": [12, 13, 20, 25, 26, 27, 28, 36, 37, 79], "chunked_s": 61, "chunkedsgmv": [13, 21], "churn": 13, "ci": [0, 13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "ci_permiss": [51, 59], "circuitbreakeropen": 22, "circular": 21, "circumv": 16, "citi": [13, 22, 24, 25, 26, 27, 28, 29, 36, 37, 42, 47, 77, 96, 98], "cityscap": 90, "civil": 40, "ckpt": 21, "clangd": 48, "clariti": [13, 20, 24, 25, 26, 27, 29, 36, 40, 41, 42, 47, 77], "class": [1, 8, 10, 11, 21, 22, 25, 26, 27, 46, 90, 98, 99], "class_0": 88, "class_1": 88, "class_nam": [10, 11, 21], "classic": [1, 11], "classif": [36, 57, 97], "classifi": [22, 47, 88, 97], "clean": [0, 15, 28, 90], "cleaned_chunk": 37, "cleanup": 21, "clear": [8, 22, 23, 26, 90], "cli": [21, 22, 36, 50, 56, 57], "client": [12, 13, 19, 20, 22, 24, 25, 26, 29, 31, 33, 38, 40, 46, 50, 70, 73, 79, 90], "client_tool_choic": 27, "cliff": 13, "climb": [13, 33], "clip": [63, 66, 73, 91, 95], "clone": [15, 30, 56, 58, 60, 67, 68, 69, 70, 71, 90, 93], "close": [17, 18, 22, 26, 30, 33, 44], "cloth": [42, 77], "cloudi": 27, "cloudli": 27, "cluster": [11, 21, 56, 57, 60, 67, 70, 79, 80, 81], "clusterfirstwithhostnet": [79, 80, 83], "clusterip": [80, 83], "cm1": 79, "cn": 60, "cnbc": 33, "co": [23, 24, 91], "code": [0, 1, 10, 12, 13, 15, 16, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 50, 52, 58, 60, 61, 62, 64, 67, 70, 71, 74, 77, 79, 80, 83, 86, 88, 90, 91, 92, 95, 96, 97, 98], "code_interpret": 33, "codebas": [0, 51, 59], "codeown": [51, 59], "coder": [27, 66], "coerc": 96, "cofeai": 92, "coffe": 88, "coher": [24, 92], "cohereforai": 66, "coherelab": 92, "collabor": 92, "collect": [5, 17, 21, 23, 30, 73], "collect_tokens_histogram": [13, 20, 25, 26, 27, 28, 36, 37], "collector": [21, 86], "coloc": [6, 84], "colon": 40, "color": [5, 13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 50, 77], "colosseum": 40, "column": [1, 27], "com": [0, 3, 15, 22, 28, 30, 32, 36, 42, 45, 46, 50, 51, 52, 54, 55, 56, 58, 59, 60, 67, 68, 69, 70, 71, 77, 78, 79, 80, 83, 86, 90, 93, 95, 96], "combin": [1, 2, 7, 13, 15, 20, 21, 22, 24, 25, 26, 27, 29, 30, 36, 40, 41, 42, 47, 50, 70, 73, 77, 84, 95], "combineinput": 7, "come": [13, 21, 22, 36, 37, 93, 95, 99], "comma": [21, 26], "command": [7, 13, 14, 15, 17, 22, 27, 29, 30, 34, 35, 41, 47, 51, 52, 53, 55, 56, 58, 59, 60, 66, 69, 70, 71, 79, 80, 83, 85, 90, 98], "comment": [51, 59], "commerci": 92, "commit": [0, 21, 53], "common": [0, 1, 3, 11, 18, 49, 51, 53, 59, 67, 74, 79, 90], "commonli": [24, 27], "commun": [2, 5, 13, 19, 21, 23, 30, 37, 50, 57, 62, 70, 79, 80, 90], "compact": [3, 21, 35, 92, 95], "compani": [37, 78, 80, 84], "companion": 13, "compar": [5, 11, 13, 16, 18, 23, 29, 30, 90, 92, 98], "compare_perf": 90, "comparison": [26, 75, 90, 98], "compat": [4, 7, 10, 11, 16, 17, 18, 21, 22, 29, 33, 35, 36, 40, 41, 42, 44, 46, 49, 57, 70, 72, 79, 80, 83, 86, 95], "compet": 92, "compil": [0, 3, 7, 12, 21, 29, 48, 58, 61, 62, 67, 68, 73, 79], "compile_command": 48, "compile_deep_gemm": 29, "complementari": 90, "complet": [1, 10, 11, 13, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 56, 59, 67, 69, 71, 77, 79, 80, 83, 88, 90, 92, 95], "completion_templ": [13, 20, 25, 26, 27, 28, 36, 37], "completion_token": [22, 24, 25, 26, 27, 29, 36, 40, 41, 42, 47, 80, 83, 88], "completion_tokens_detail": [24, 27, 40, 47], "completionchoic": 40, "completionusag": [24, 27, 40, 47], "complex": [0, 11, 16, 18, 23, 26, 37, 38, 40, 51, 59, 92, 95], "complianc": 22, "compon": [2, 5, 7, 11, 12, 17, 22, 38, 51, 59, 77, 80, 90, 98], "compos": [85, 86], "composedpipelin": 90, "composit": 3, "comprehens": [11, 22, 27, 29, 73, 95, 96], "compress": [21, 63], "compressedtensorsconfig": 17, "compressor": 63, "compris": 15, "comput": [6, 11, 13, 15, 16, 17, 18, 21, 24, 28, 29, 30, 36, 37, 42, 44, 50, 69, 70, 74, 96], "con": 1, "concaten": [29, 36], "concept": 90, "conceptu": 48, "concis": [26, 37, 40, 51, 59, 84, 98], "concret": 23, "concurr": [1, 11, 12, 13, 18, 21, 22, 23, 32, 45, 53, 61, 70, 74, 86], "conda": [56, 60, 71], "condit": [7, 11, 13, 15, 16, 27, 48], "confid": [24, 26, 75, 89], "config": [7, 10, 11, 13, 15, 17, 21, 22, 24, 36, 50, 52, 60, 62, 63, 67, 69, 73, 80, 85, 88, 89, 90, 91, 95, 98, 99], "config_file_path": 90, "configur": [0, 1, 7, 11, 13, 16, 17, 23, 28, 29, 35, 36, 48, 49, 51, 52, 53, 59, 67, 79, 80, 83, 86, 98], "configure_log": 14, "confirm": [24, 26, 58, 85], "conflict": [71, 85], "confus": [24, 26, 36], "congest": 37, "connect": [2, 3, 13, 15, 20, 24, 25, 26, 27, 28, 33, 36, 37, 38, 40, 41, 42, 47, 49, 52, 77, 81, 85], "connect_data": 22, "connection_mod": 22, "connections_act": 22, "connectx": 79, "consecut": [11, 15, 18, 21, 22, 73], "consecutive_failur": 22, "consecutive_success": 22, "consensu": 11, "consequ": [16, 48], "conserv": [12, 16, 21, 70, 89], "consid": [0, 11, 17, 22, 24, 26, 36, 40, 46, 70, 90], "consider": [3, 22], "consist": [2, 4, 5, 11, 21, 22, 26, 29, 32, 51, 59, 84, 86, 92], "consol": [49, 52, 90], "consolid": 73, "const": 48, "constant": [3, 46, 48], "constexpr": 48, "constrain": [21, 25], "constrained_json_disable_any_whitespac": [13, 20, 25, 26, 27, 28, 36, 37], "constrained_json_whitespace_pattern": [13, 20, 25, 26, 27, 28, 36, 37], "constraint": [1, 23, 25, 26, 46, 73, 77, 86, 95], "construct": 49, "constructor": [21, 98], "consult": [21, 26], "consum": [11, 12, 18, 95], "consumpt": 24, "contact": 80, "contain": [2, 11, 13, 15, 21, 22, 26, 29, 36, 40, 46, 48, 50, 56, 60, 67, 75, 79, 80, 83, 85, 86, 90, 96], "container": 79, "container_id": 85, "container_nam": 85, "containerd": 79, "containerport": [22, 79, 80, 83], "content": [3, 13, 14, 20, 21, 24, 25, 26, 27, 28, 31, 32, 35, 36, 38, 40, 41, 42, 45, 46, 47, 49, 50, 67, 80, 83, 88, 89, 95, 96, 97], "context": [10, 11, 18, 21, 22, 23, 24, 28, 32, 34, 35, 45, 49, 57, 61, 62, 69, 71, 73, 80, 83, 86, 92, 95], "context_len": [12, 13, 36, 79], "context_length": [13, 20, 21, 24, 25, 26, 27, 28, 36, 37], "contigu": [7, 11, 48], "continu": [8, 10, 11, 21, 22, 24, 30, 36, 37, 50, 57, 70, 73, 84, 90], "continue_gener": 23, "contract": 20, "contradict": 24, "contrast": 11, "contribut": [10, 22, 24, 37, 57, 65, 72, 80], "contributor": [0, 51, 59, 70, 92], "control": [1, 7, 10, 11, 13, 14, 15, 16, 21, 23, 24, 27, 30, 32, 40, 45, 46, 49, 50, 73, 79, 84, 90, 96], "conv": [28, 36], "conveni": [17, 50, 58, 77], "convent": [10, 15, 16], "convers": [7, 10, 23, 28, 34, 49, 72, 92, 95, 98], "convert": [11, 17, 22, 25, 26, 40, 56, 86, 95, 98], "convert_dict_to_tool": 27, "cool": [51, 59], "cooldown": [51, 59], "coordin": 70, "copi": [10, 11, 13, 19, 21, 28, 32, 45, 56, 87, 95], "copy_stream": 16, "core": [7, 11, 13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 57, 67, 70, 77, 86], "corner": 21, "corpu": 92, "correct": [0, 13, 22, 23, 24, 26, 27, 40, 50, 56, 98], "correctli": [26, 40, 50, 59, 79, 98, 99], "correl": [7, 22], "correspond": [1, 11, 13, 17, 21, 26, 27, 41, 46, 51, 59, 86, 98], "cost": [21, 22, 23, 35, 37, 50, 70, 90, 91, 92, 95], "cot": [20, 22], "couch": 96, "could": [13, 16, 21, 24, 26, 28, 33, 37, 58, 60, 62, 64, 79], "couldn": 13, "count": [3, 11, 21, 22, 26, 36, 40, 49, 53, 67, 70, 73], "counter": [22, 73, 85], "countless": 13, "countri": [13, 24, 25, 26, 36, 37, 40, 46, 47, 77], "coupl": [6, 7], "cours": 77, "cover": [11, 23, 26, 40, 41, 42, 79, 90, 98], "coverag": [51, 59], "cp": [21, 67, 71], "cp310": 56, "cp311": 60, "cp8": 30, "cp_size": [21, 30], "cpp": 50, "cpp_func": 48, "cpu": [1, 2, 10, 11, 13, 16, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 36, 37, 50, 51, 56, 57, 59, 61, 62, 73, 80, 81, 83, 90, 95], "cpu0": 60, "cpu_count": 15, "cpu_offload_gb": [13, 20, 25, 26, 27, 28, 36, 37], "cpufreq": [60, 61, 62], "cpuinfer": 21, "crash": [21, 83], "crash_dump": 14, "crash_dump_fold": [13, 20, 25, 26, 27, 28, 36, 37], "creat": [0, 1, 3, 7, 8, 11, 13, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 35, 36, 40, 41, 42, 46, 47, 51, 52, 56, 58, 59, 67, 70, 71, 83, 86, 88, 98], "create_graph": 3, "creativ": [28, 40], "creatur": 13, "credenti": 22, "critic": [1, 4, 11, 22, 50, 51, 59, 90], "crop": 13, "cross": [10, 11, 13, 16, 53, 91, 95], "cross_attention_kwarg": 90, "crt": 22, "crucial": [1, 16, 79], "crypto": 22, "crystal": 13, "cseti": 90, "csgmv": [13, 20, 21, 25, 26, 27, 28, 36, 37], "csrc": [48, 50], "cstddef": 48, "cstdint": 48, "csv": [21, 36], "ctrl": [13, 36, 79], "cu129": 56, "cu13": 56, "cu130": 56, "cu_full_len": 3, "cu_seqlen": 3, "cu_seqlens_kk": 3, "cu_window_len": 3, "cubla": 74, "cuda": [2, 4, 7, 11, 13, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 36, 37, 40, 41, 42, 45, 47, 48, 50, 52, 55, 56, 57, 61, 62, 69, 71, 73, 77, 79, 80, 83, 90], "cuda_fil": 48, "cuda_graph_b": [13, 20, 25, 26, 27, 28, 36, 37], "cuda_graph_max_b": [13, 20, 25, 26, 27, 28, 36, 37], "cuda_hom": 56, "cuda_launch_block": [80, 83], "cuda_profil": 50, "cuda_visible_devic": 55, "cuda_wrapp": 48, "cudaerror_t": 48, "cudagetlasterror": 48, "cudagraph": [21, 87], "cudamemcpyasync": 11, "cudaprofilerapi": 50, "cudaprofilerstart": 50, "cudaprofilerstop": 50, "cudart": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "cudastream": 48, "cudastream_t": 48, "cudnn": [21, 69], "cuh": 48, "cuisin": 37, "cultur": [24, 26, 36, 37], "cumul": [16, 46], "cun": 13, "curios": 13, "curiou": 90, "curl": [14, 22, 29, 35, 36, 46, 50, 55, 67, 70, 71, 80, 83, 85, 89, 90, 96], "curl_command": [42, 47], "curl_id": 41, "curl_text": 41, "current": [7, 8, 11, 13, 15, 16, 17, 18, 21, 24, 25, 26, 29, 33, 37, 46, 48, 49, 51, 59, 60, 61, 67, 70, 71, 73, 74, 80, 83, 86, 90, 93, 95, 96], "custom": [0, 7, 11, 13, 20, 22, 23, 25, 26, 27, 29, 30, 31, 32, 36, 37, 40, 49, 57, 60, 61, 73, 84, 85], "custom_backend_nam": 10, "custom_logit_processor": [29, 31, 46], "custom_op": 60, "custom_param": [29, 31, 46], "custom_param_list": 46, "custom_serv": 37, "custom_sigquit_handl": [13, 20, 25, 26, 27, 28, 36, 37], "custom_weight_load": [13, 20, 25, 26, 27, 28, 36, 37], "customlogitprocessor": [29, 31, 32, 46], "cut": [17, 29], "cutedsl": 21, "cutlass": [1, 7, 13, 17, 21, 73], "cutlass_mla": [1, 21], "cutlassmla": 29, "cycl": [7, 22], "d": [13, 21, 22, 29, 35, 37, 40, 41, 42, 47, 48, 50, 56, 77, 80, 81, 83, 85, 86, 88, 89, 90, 96], "d2h": [16, 21, 32, 45], "d45a6d3cee064aceb876f52c6b285b70": 26, "d_": 30, "d_ip": [61, 62], "da6ebe1e2f3d4ce6a16bb72b235fae97": 36, "dai": [13, 22, 27, 29, 33, 77], "dame": 37, "danger": 13, "dao": 29, "dark": 13, "dashboard": [22, 85], "data": [5, 7, 10, 12, 13, 15, 16, 18, 19, 20, 24, 26, 27, 28, 32, 33, 36, 37, 40, 41, 42, 45, 46, 47, 48, 50, 57, 58, 61, 70, 83, 85, 86, 88, 90, 91, 93, 95, 96, 98], "data0": 61, "data1": [79, 80, 83], "data_fil": 17, "data_path": 62, "data_ptr": 48, "databas": 22, "databrick": [66, 92], "dataclass": 22, "dataload": 21, "dataset": [17, 18, 30, 34, 50, 53, 58, 61, 67, 70, 71, 85, 91], "datasourc": 85, "date": [25, 26, 30, 33, 37], "davinci": [22, 60], "davinci0": 60, "davinci1": 60, "davinci10": 60, "davinci11": 60, "davinci12": 60, "davinci13": 60, "davinci14": 60, "davinci15": 60, "davinci2": 60, "davinci3": 60, "davinci4": 60, "davinci5": 60, "davinci6": 60, "davinci7": 60, "davinci8": 60, "davinci9": 60, "davinci_manag": 60, "dbazur": 52, "dbname": 22, "dbrx": [66, 92], "dc39eccfefd04b24832a954ab8ea373a": 36, "dc8cdfb21993a6cb46199d6b1d79f68a42b06439": 13, "dd": 90, "de": [24, 26, 84], "de9cdff9d7f6425dacbf269defc922a2": 26, "deactiv": 56, "deadlock": [21, 90], "death": 77, "deb": 50, "debian": 48, "debug": [2, 4, 7, 8, 14, 24, 48, 50, 96], "debug_tensor_dump_inject": [13, 20, 25, 26, 27, 28, 36, 37], "debug_tensor_dump_input_fil": [13, 20, 25, 26, 27, 28, 36, 37], "debug_tensor_dump_lay": [13, 20, 25, 26, 27, 28, 36, 37], "debug_tensor_dump_output_fold": [13, 20, 25, 26, 27, 28, 36, 37], "debugg": 4, "debugpi": 52, "dec": 21, "deceas": 77, "decemb": 25, "decentr": 7, "decid": [13, 21, 26, 37, 90], "decis": [22, 90], "declar": [26, 98], "decod": [5, 6, 10, 11, 12, 13, 29, 30, 42, 47, 49, 57, 60, 61, 62, 67, 73, 74, 83, 86, 89, 90, 92, 95, 99], "decode1": 22, "decode_addr": 30, "decode_attention_backend": [13, 20, 25, 26, 27, 28, 36, 37], "decode_count": 22, "decode_host": 6, "decode_host_ip": 62, "decode_log_interv": [13, 20, 25, 26, 27, 28, 36, 37], "decode_master_ip": 15, "decode_round_robin": [61, 62], "decode_unicod": [46, 47], "decompos": 6, "decord": 95, "decoupl": [6, 7, 16, 23, 95], "decreas": [12, 22, 40, 44, 70, 74], "decrypted_config_fil": [13, 20, 25, 26, 27, 28, 36, 37], "decrypted_draft_config_fil": [13, 20, 25, 26, 27, 28, 36, 37], "dedic": [11, 15, 16, 23, 37, 46, 50, 56, 67, 70, 71, 84, 90, 95, 98], "dee": [80, 83], "deep": [13, 23, 33, 96], "deep_gemm": [7, 21, 73], "deep_normal_mode_use_int8_qu": [61, 62], "deepep": [7, 15, 21, 30, 61, 62, 80, 83], "deepep_config": [13, 20, 25, 26, 27, 28, 36, 37], "deepep_mod": [13, 20, 25, 26, 27, 28, 36, 37], "deepep_normal_long_seq_per_round_token": 61, "deepep_normal_long_seq_round": 61, "deeper": [13, 23, 24, 51, 59], "deepgemm": [7, 21, 29], "deepli": [22, 36], "deepmind": 23, "deepseek": [1, 2, 7, 10, 11, 12, 17, 18, 20, 21, 22, 24, 26, 27, 52, 53, 56, 57, 60, 65, 66, 69, 79, 80, 82, 83, 92, 93, 95], "deepseek_r1_0528": 80, "deepseek_v3": 52, "deepseek_v3_mo": 79, "deepseekr10528": 80, "deepseekr1thinkingbudgetlogitprocessor": 29, "deepseekv3": [21, 27, 29], "deepseekv31": [21, 27, 30], "deepseekv32": [27, 30, 82], "deepseekv32_pd": 30, "deepspe": 90, "deepstack": 3, "def": [8, 25, 26, 27, 37, 46, 48, 62, 75, 77, 89, 98, 99], "default": [1, 2, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 36, 37, 40, 41, 42, 44, 47, 49, 50, 51, 56, 58, 59, 60, 67, 68, 70, 72, 73, 75, 77, 79, 83, 85, 86, 88, 89, 90, 95, 96, 98, 99], "default_stream": 16, "defeat": [13, 36], "defens": 37, "defer": [16, 21, 70], "defin": [1, 7, 8, 20, 21, 25, 26, 32, 45, 46, 48, 51, 56, 59, 72, 77, 81, 85, 90, 98], "definit": [22, 24, 26, 85], "degrad": [13, 16, 18, 24, 62, 79], "degre": [16, 27, 90], "dejpeg": 90, "delai": [2, 15, 17, 21, 22, 33, 50, 90], "delay": 21, "delet": [21, 22, 56], "delete_ckpt_after_load": [13, 20, 25, 26, 27, 28, 36, 37], "delimit": [20, 21, 27], "deliv": [16, 30, 57, 70, 92], "delta": [20, 21, 27, 29, 40, 47, 92], "demand": 13, "demo": 21, "demonstr": [7, 11, 13, 17, 27, 28, 36, 37, 40, 48, 92, 98], "denoise_steps_m": 90, "denot": [16, 21, 26], "dens": [13, 21, 30, 61, 62, 67, 80, 83, 92, 93], "deocod": 5, "dep": [49, 56, 71], "depend": [1, 11, 15, 16, 17, 18, 21, 26, 49, 51, 56, 59, 60, 67, 71, 83, 86, 90], "depict": 28, "deploi": [10, 15, 23, 29, 56, 61, 70, 82, 84, 87], "deploy": [2, 6, 7, 15, 16, 17, 21, 23, 29, 30, 32, 45, 56, 57, 67, 70, 79, 83, 91, 92, 95, 96], "deploy_and_serve_endpoint": 56, "deploymod": 61, "deprec": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 73, 77], "depth": [21, 22, 24, 92], "dequant": 18, "deregistrations_tot": 22, "deriv": [18, 24, 97], "descend": 96, "describ": [8, 28, 40, 42, 46, 51, 56, 58, 59, 61, 66, 68, 75, 85, 86, 88, 90], "descript": [4, 7, 8, 15, 21, 22, 23, 25, 26, 27, 29, 31, 34, 36, 38, 44, 46, 50, 51, 59, 67, 70, 73, 89, 90, 91, 92, 95, 96, 97, 98], "descriptor": [22, 49], "desert": 13, "design": [1, 6, 7, 9, 10, 15, 20, 22, 29, 42, 57, 70, 84, 86, 88, 92, 95, 96], "desir": [25, 67, 71], "desktop": 85, "desper": 13, "despit": 13, "destin": [13, 15, 37], "destroi": 23, "destroy_weights_update_group": 23, "detach": 28, "detail": [1, 3, 7, 10, 11, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 29, 30, 33, 34, 36, 37, 40, 44, 46, 49, 50, 51, 59, 67, 69, 70, 71, 74, 79, 84, 89, 90, 95, 98], "detailed_tip": 77, "detect": [13, 20, 21, 22, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 73, 77], "detector": 27, "determin": [11, 12, 13, 16, 21, 23, 26, 27, 67, 75, 86], "determinist": [21, 51, 57, 59, 84], "deterministiclogitprocessor": 46, "detoken": [46, 73], "detokenization_result": 36, "detokenize_payload": 36, "detokenize_respons": 36, "detokenize_url": 36, "detokenizermanag": [13, 36], "dev": [21, 48, 50, 55, 56, 58, 60, 67, 79, 80, 83, 90], "dev1": 36, "devcontain": 52, "devel": 55, "develop": [4, 7, 11, 13, 21, 22, 26, 27, 30, 37, 38, 40, 50, 51, 56, 59, 70, 71, 78, 84, 86, 92], "developer_guid": 98, "devic": [7, 10, 11, 13, 15, 17, 20, 21, 25, 26, 27, 28, 29, 30, 32, 36, 37, 45, 48, 51, 55, 56, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 73, 79, 80, 83, 90, 92, 95], "device_": 48, "device_config": 17, "device_list": 10, "device_map": 17, "device_nam": [15, 36], "device_rdma": 60, "device_typ": 60, "deviceconfig": 17, "devkit": 69, "devtool": 50, "df": 21, "dgx": 56, "diagnos": [37, 79], "diagnosi": 37, "diagram": 52, "dialogu": [10, 92], "dict": [3, 8, 21, 25, 26, 27, 28, 46], "dictionari": [21, 26, 27, 40], "did": [36, 90], "didn": [26, 27], "die": 13, "diet": 77, "differ": [3, 4, 5, 7, 11, 13, 15, 16, 17, 21, 22, 23, 24, 26, 28, 29, 30, 32, 36, 37, 42, 45, 47, 49, 52, 58, 67, 70, 73, 74, 79, 80, 83, 85, 86, 87, 89, 90, 94, 96, 98], "differenti": [7, 11], "difficult": [13, 23], "diffus": [57, 58, 91], "diffusers_kwarg": 90, "diffusion_hip": 58, "dim": 13, "dimens": [21, 48, 50], "dip": 61, "dip1": 61, "dip2": 61, "dir": [17, 21, 22, 50, 70, 79], "direct": [2, 10, 11, 21, 22, 23, 37, 67], "directli": [0, 2, 3, 8, 11, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 40, 48, 50, 51, 59, 80, 90, 98], "directori": [2, 21, 22, 30, 48, 50, 52, 67, 73, 85, 86, 90, 94, 98], "directoryorcr": [80, 83], "disabl": [4, 7, 10, 13, 16, 17, 20, 21, 22, 24, 26, 29, 30, 36, 37, 49, 50, 51, 52, 59, 61, 62, 67, 70, 71, 73, 74, 80, 83, 95, 96], "disable_chunked_prefix_cach": [13, 20, 25, 26, 27, 28, 36, 37], "disable_cuda_graph": [13, 20, 25, 26, 27, 28, 36, 37], "disable_cuda_graph_pad": [13, 20, 25, 26, 27, 28, 36, 37], "disable_custom_all_reduc": [13, 20, 25, 26, 27, 28, 36, 37], "disable_eagle3_qu": 61, "disable_fast_image_processor": [13, 20, 25, 26, 27, 28, 36, 37], "disable_flashinfer_autotun": [13, 20, 25, 26, 27, 28, 36, 37], "disable_flashinfer_cutlass_moe_fp4_allgath": [13, 20, 25, 26, 27, 28, 36, 37], "disable_hicache_numa_detect": [13, 20, 25, 26, 27, 28, 36, 37], "disable_hybrid_swa_memori": [13, 20, 25, 26, 27, 28, 36, 37], "disable_outlines_disk_cach": [13, 20, 25, 26, 27, 28, 36, 37], "disable_overlap_schedul": [13, 20, 25, 26, 27, 28, 36, 37], "disable_radix_cach": [13, 20, 25, 26, 27, 28, 36, 37], "disable_shared_experts_fus": [13, 20, 25, 26, 27, 28, 36, 37], "disable_tokenizer_batch_decod": [13, 20, 25, 26, 27, 28, 36, 37], "disaggreg": [23, 29, 57, 60, 61, 80, 82, 83, 84, 86], "disaggregation_bootstrap_port": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_decode_dp": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_decode_enable_fake_auto": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_decode_enable_offload_kvcach": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_decode_polling_interv": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_decode_tp": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_ib_devic": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_mod": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_prefill_pp": [13, 20, 25, 26, 27, 28, 36, 37], "disaggregation_transfer_backend": [13, 20, 25, 26, 27, 28, 36, 37], "disast": 23, "discard": [1, 23], "disclos": 37, "discourag": [40, 46], "discov": [13, 22], "discoveri": 83, "discrep": 23, "discuss": [10, 29, 37, 51, 59, 70], "diseas": [37, 77], "disjoint": 21, "disk": [2, 21, 73, 90, 94, 98], "dispatch": [1, 7, 21, 23, 73, 74, 80, 83], "dispatchoutput": 7, "displai": [0, 13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 52, 58, 77], "dist": [2, 13, 15, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 36, 40, 41, 42, 47, 61, 62, 70, 77, 79, 80, 81, 83, 93], "dist_init_addr": [13, 20, 25, 26, 27, 28, 36, 37], "dist_port": 30, "dist_timeout": [13, 20, 25, 26, 27, 28, 36, 37], "distil": [20, 26, 40, 67, 69, 90], "distinct": [3, 6, 15, 28], "distinguish": 86, "distrib_releas": 50, "distribut": [0, 2, 7, 11, 13, 15, 22, 30, 46, 56, 57, 79, 93], "distro": 58, "dit": 57, "dit_precis": 90, "div_ceil": 48, "dive": 23, "diverg": 84, "divers": [4, 7, 11, 23, 24, 37, 40, 46, 84], "divid": [18, 22, 49], "divis": [16, 21], "dkr": 56, "dlami": 52, "dlc": 56, "dldevic": 48, "dllm": [21, 89], "dllm_algorithm": [13, 20, 25, 26, 27, 28, 36, 37, 89], "dllm_algorithm_config": [13, 20, 25, 26, 27, 28, 36, 37], "dlpack": 48, "dmd": 90, "dn": 77, "dnspolici": [79, 80, 83], "do": [0, 1, 17, 21, 26, 27, 29, 37, 40, 48, 50, 51, 55, 56, 59, 61, 62, 67, 70, 74, 81, 96, 98], "doc": [11, 24, 25, 46, 47, 50, 51, 52, 56, 58, 59, 69, 75, 90, 92, 93, 98], "doc_patch": [13, 20, 24, 25, 26, 27, 36, 37, 40, 41, 42, 47, 77], "docker": [21, 29, 33, 50, 57, 59, 69, 73, 79, 85, 86, 94], "dockerfil": [56, 58, 60, 67, 90], "dockerhub": 60, "dockerx": 58, "doctor": 37, "document": [1, 10, 11, 13, 21, 22, 23, 24, 27, 29, 30, 33, 36, 37, 38, 40, 47, 48, 52, 53, 56, 58, 67, 68, 69, 71, 72, 73, 79, 81, 88, 90, 93, 95], "doe": [8, 11, 13, 14, 16, 21, 26, 37, 50, 51, 52, 59, 90, 98], "doesn": [22, 30, 73, 79], "dog": 96, "domain": [2, 22], "domin": [6, 13, 90], "don": [1, 8, 16, 24, 26, 27, 28, 34, 38, 40, 46, 50, 51, 52, 58, 59, 60, 77, 95, 98], "donald": 75, "done": [29, 46, 47, 50, 55, 61, 62, 70, 81], "doom": 13, "dot": [8, 95], "dotsvlm": 95, "doubl": [26, 40], "down": [12, 13, 22, 26, 33, 40, 51, 59, 73, 74, 75, 90], "down_mo": 36, "down_proj": [13, 21], "downcast": [36, 41], "download": [13, 17, 21, 24, 28, 36, 46, 48, 49, 50, 52, 56, 60, 63, 67, 70, 71, 93, 98], "download_cont": 90, "download_dir": [13, 20, 25, 26, 27, 28, 36, 37], "downstream": 22, "downward": [16, 79], "dp": [15, 21, 22, 29, 30, 32, 50, 57, 61, 62, 80, 83, 93], "dp_attent": 21, "dp_rank": 86, "dp_size": [12, 13, 20, 25, 26, 27, 28, 30, 36, 37, 62, 93], "dpbudget": 73, "dpkg": 50, "dpo": 84, "draft": [1, 7, 21, 24, 29, 30, 31, 33, 34, 44, 61, 62, 64, 70, 73], "dramat": [3, 10], "drastic": [51, 59], "draw": 37, "drench": 96, "dress": [77, 90], "dri": [55, 58, 90], "drift": 23, "drive": [28, 37], "driven": [37, 49], "driver": [28, 60, 61, 79], "drop": [13, 18, 60, 70, 73], "drun": [58, 60], "dry": 28, "ds_channel_config_path": [13, 20, 25, 26, 27, 28, 36, 37], "ds_heavy_channel_num": [13, 20, 25, 26, 27, 28, 36, 37], "ds_heavy_channel_typ": [13, 20, 25, 26, 27, 28, 36, 37], "ds_heavy_token_num": [13, 20, 25, 26, 27, 28, 36, 37], "ds_sparse_decode_threshold": [13, 20, 25, 26, 27, 28, 36, 37], "dsa": 1, "dshm": [79, 80, 83], "dsl": 7, "dst": 48, "dsv32": [30, 83], "dtype": [1, 13, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 36, 37, 44, 48, 61, 62, 69, 70, 90], "dual": [1, 67, 90], "dual_chunk_flash_attn": [1, 21], "dublin": 25, "duck": 75, "ducx_path": 15, "due": [4, 12, 15, 16, 17, 21, 50, 51, 52, 56, 59, 69, 70, 73, 75, 84, 86], "dummi": [2, 21, 46, 50], "dummy_hook_factori": 8, "dump": [25, 26, 41, 46, 83, 88], "dump_expert_distribution_record": 36, "duplic": [29, 51, 59], "durat": [29, 32, 45, 49, 50, 90], "duration_m": 90, "dure": [1, 3, 6, 7, 8, 11, 12, 13, 15, 16, 17, 18, 21, 23, 28, 32, 35, 36, 45, 46, 50, 67, 73, 74, 84, 86, 90, 96], "dusti": 69, "dustin": 69, "dv": 52, "dvyio": 90, "dwell": 13, "dynam": [4, 7, 11, 15, 17, 18, 22, 23, 24, 50, 63, 70, 74, 80, 83, 90, 95], "dynamic_batch_tokenizer_batch_s": [13, 20, 25, 26, 27, 28, 36, 37], "dynamic_batch_tokenizer_batch_timeout": [13, 20, 25, 26, 27, 28, 36, 37], "dynamic_smem": 48, "dynamo": [15, 21, 24], "e": [0, 1, 3, 4, 7, 8, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32, 33, 36, 40, 45, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 67, 68, 70, 71, 81, 85, 86, 90, 92, 93, 95, 96, 98], "e2": [21, 32, 45], "e29b": 22, "e2e_lat": [25, 26, 36, 47], "e2e_request_latency_second": 85, "e2e_request_latency_seconds_bucket": 85, "e2e_request_latency_seconds_count": 85, "e2e_request_latency_seconds_sum": 85, "e2m1": 18, "e4m3": [18, 29], "e5": [57, 66, 91], "e5m2": 18, "each": [0, 1, 2, 3, 4, 8, 11, 13, 15, 16, 18, 21, 22, 23, 26, 28, 29, 30, 32, 36, 37, 40, 44, 45, 46, 49, 50, 51, 53, 59, 67, 73, 77, 79, 81, 86, 88, 90, 95, 96, 98], "eager": [3, 13, 20, 21, 25, 26, 27, 28, 36, 37], "eagl": [1, 29, 30, 37, 61, 62, 64, 70], "eagle2": 21, "eagle3": [21, 24, 33, 34, 61], "ear": 13, "earli": [12, 23, 37, 92], "earlier": 75, "earn": 33, "eas": 90, "easi": [7, 17, 26, 51, 57, 59, 77, 84], "easier": [22, 35, 37, 52, 98], "easili": [37, 98], "east": 60, "eater": 77, "eb9964591c534af1bba02a66df9872a6": 25, "ebnf": 27, "ebnf_grammar": [25, 26], "ec": [80, 83], "echo": [30, 50, 55, 56, 58, 60, 61, 62, 70, 81], "econom": [24, 37], "ecosystem": 71, "ecr": 56, "ecr_registri": 56, "edg": [17, 92, 95], "edinburgh": 37, "edit": [51, 52, 55, 56, 59], "ef928c4358d243be870652b1d2d9ca82": 25, "effect": [1, 2, 11, 16, 18, 23, 24, 35, 40, 70, 73, 79, 90], "effective_max_running_requests_per_dp": 36, "effici": [2, 7, 10, 11, 13, 15, 16, 19, 21, 22, 23, 24, 28, 29, 30, 32, 35, 36, 37, 45, 46, 48, 51, 57, 59, 67, 69, 70, 84, 90, 91, 92, 95, 96], "effort": [1, 10], "eg": [13, 21, 32, 45], "eic": 21, "eiffel": [24, 26, 37], "eight": [79, 95], "eighth": 40, "either": [8, 11, 17, 21, 30, 33, 46, 56, 90], "elabor": 17, "elaps": [13, 36, 79], "elast": [7, 21, 23], "elastic_ep_backend": [13, 20, 25, 26, 27, 28, 36, 37], "element": [8, 18, 21, 37, 40, 48], "eleutherai": 75, "elif": 77, "elimin": [16, 23], "elit": 35, "els": [8, 13, 25, 26, 36, 51, 59, 96], "elsiu": 27, "embed": [13, 21, 22, 39, 40, 46, 47, 57, 95, 97, 98], "embed_token": 13, "embedding_process": [36, 41], "embrac": 23, "emili": 40, "emit": 50, "empir": 37, "emploi": [7, 11, 24, 46, 95], "empow": 23, "empti": [21, 23, 27, 36, 40, 48, 50], "empty_lik": 48, "emptydir": [79, 80, 83], "emul": 1, "en": [17, 66, 91], "enabl": [1, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 37, 40, 41, 42, 44, 45, 46, 48, 49, 52, 53, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 74, 80, 83, 84, 85, 86, 90, 91, 92, 93, 95, 96], "enable_ascend_moe_nz": 64, "enable_ascend_transfer_with_mooncak": 15, "enable_attn_tp_input_scatt": [13, 20, 25, 26, 27, 28, 36, 37], "enable_broadcast_mm_inputs_process": [13, 20, 25, 26, 27, 28, 36, 37], "enable_cache_report": [13, 20, 25, 26, 27, 28, 36, 37], "enable_cudagraph_gc": [13, 20, 25, 26, 27, 28, 36, 37], "enable_custom_logit_processor": [13, 20, 25, 26, 27, 28, 36, 37], "enable_deterministic_infer": [13, 20, 25, 26, 27, 28, 36, 37], "enable_double_spars": [13, 20, 25, 26, 27, 28, 36, 37], "enable_dp_attent": [13, 20, 25, 26, 27, 28, 36, 37], "enable_dp_lm_head": [13, 20, 25, 26, 27, 28, 36, 37], "enable_draft_weights_cpu_backup": [13, 20, 25, 26, 27, 28, 36, 37], "enable_dynamic_batch_token": [13, 20, 25, 26, 27, 28, 36, 37], "enable_dynamic_chunk": [13, 20, 25, 26, 27, 28, 36, 37], "enable_eplb": [13, 20, 25, 26, 27, 28, 36, 37], "enable_expert_distribution_metr": [13, 20, 25, 26, 27, 28, 36, 37], "enable_flashinfer_allreduce_fus": [13, 20, 25, 26, 27, 28, 36, 37], "enable_fp32_lm_head": [13, 20, 25, 26, 27, 28, 36, 37], "enable_fused_qk_norm_rop": [13, 20, 25, 26, 27, 28, 36, 37], "enable_hierarchical_cach": [13, 20, 25, 26, 27, 28, 36, 37], "enable_layerwise_nvtx_mark": [13, 20, 25, 26, 27, 28, 36, 37], "enable_lmcach": [13, 20, 25, 26, 27, 28, 36, 37], "enable_lora": [13, 20, 25, 26, 27, 28, 36, 37], "enable_lora_overlap_load": [13, 20, 25, 26, 27, 28, 36, 37], "enable_memory_sav": [13, 20, 25, 26, 27, 28, 36, 37], "enable_metr": [13, 20, 25, 26, 27, 28, 36, 37, 83], "enable_metrics_for_all_schedul": [13, 20, 25, 26, 27, 28, 36, 37], "enable_mixed_chunk": [13, 20, 25, 26, 27, 28, 36, 37], "enable_moe_nz": [61, 62], "enable_mscclpp": [13, 20, 25, 26, 27, 28, 36, 37], "enable_multi_layer_eagl": [13, 20, 25, 26, 27, 28, 36, 37], "enable_multimod": [13, 20, 25, 26, 27, 28, 36, 37], "enable_nan_detect": [13, 20, 25, 26, 27, 28, 36, 37], "enable_nccl_nvl": [13, 20, 25, 26, 27, 28, 36, 37], "enable_nsa_prefill_context_parallel": [13, 20, 25, 26, 27, 28, 36, 37], "enable_p2p_check": [13, 20, 25, 26, 27, 28, 36, 37], "enable_pdmux": [13, 20, 25, 26, 27, 28, 36, 37], "enable_piecewise_cuda_graph": [13, 20, 25, 26, 27, 28, 36, 37], "enable_precise_embedding_interpol": [13, 20, 25, 26, 27, 28, 36, 37], "enable_prefill_delay": [13, 20, 25, 26, 27, 28, 36, 37], "enable_prefix_mm_cach": [13, 20, 25, 26, 27, 28, 36, 37], "enable_priority_schedul": [13, 20, 25, 26, 27, 28, 36, 37], "enable_profile_cuda_graph": [13, 20, 25, 26, 27, 28, 36, 37], "enable_refresh": 22, "enable_request_time_stats_log": [13, 20, 25, 26, 27, 28, 36, 37], "enable_return_hidden_st": [13, 20, 25, 26, 27, 28, 36, 37], "enable_return_routed_expert": [13, 20, 25, 26, 27, 28, 36, 37], "enable_single_batch_overlap": [13, 20, 25, 26, 27, 28, 36, 37], "enable_symm_mem": [13, 20, 25, 26, 27, 28, 36, 37], "enable_think": [20, 40], "enable_tokenizer_batch_encod": [13, 20, 25, 26, 27, 28, 36, 37], "enable_torch_compil": [13, 20, 25, 26, 27, 28, 36, 37, 90], "enable_torch_compile_debug_mod": [13, 20, 25, 26, 27, 28, 36, 37], "enable_torch_symm_mem": [13, 20, 25, 26, 27, 28, 36, 37], "enable_trac": [13, 20, 25, 26, 27, 28, 36, 37], "enable_two_batch_overlap": [13, 20, 25, 26, 27, 28, 36, 37], "enable_weights_cpu_backup": [13, 20, 25, 26, 27, 28, 36, 37], "encapsul": [11, 23], "encod": [6, 28, 32, 40, 41, 46, 47, 57, 90, 95], "encoder_onli": [13, 20, 25, 26, 27, 28, 36, 37], "encoder_transfer_backend": [13, 20, 25, 26, 27, 28, 36, 37], "encoder_url": [13, 20, 25, 26, 27, 28, 36, 37], "encoding_for_model": 40, "encoding_format": 91, "encount": [12, 13, 16, 17, 29, 50, 56, 58, 60, 61, 67, 68, 70, 79, 85], "encourag": [12, 40, 46, 51, 59], "end": [3, 5, 7, 13, 16, 20, 21, 22, 25, 26, 32, 35, 36, 37, 38, 40, 46, 47, 48, 50, 77, 79, 85, 86, 90, 95, 98], "end_tag": [25, 26], "endem": [36, 96], "endpoint": [2, 6, 21, 23, 25, 26, 36, 47, 56, 77, 85, 86, 98], "enforc": [13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 48, 73, 77], "engag": [26, 28], "engin": [6, 11, 13, 15, 17, 19, 21, 22, 24, 29, 38, 40, 42, 50, 51, 57, 58, 59, 60, 63, 69, 74, 77, 80, 84, 89, 90, 93], "engine_metr": 22, "england": [25, 26, 46], "english": [26, 92], "enhanc": [7, 24, 77, 92, 95], "enjoi": [37, 96], "enough": [8, 12, 21, 23], "ensembl": 49, "ensur": [0, 2, 4, 7, 10, 11, 13, 15, 16, 21, 22, 23, 24, 26, 27, 29, 30, 33, 37, 49, 50, 51, 52, 58, 59, 60, 67, 69, 70, 81, 83, 84, 85, 96, 98], "enter": [52, 67, 86], "enterpris": [11, 17, 22, 56, 84, 92], "entir": [5, 8, 15, 22, 23, 25, 26, 50, 58, 90], "entri": [7, 8, 12, 22, 90], "entryclass": 98, "entrypoint": [2, 88, 98], "enum": [25, 26, 27, 90], "enumer": [17, 46, 77], "env": [3, 15, 22, 24, 56, 58, 60, 67, 79, 80, 83, 86, 90, 94], "env_fold": 81, "envelop": 21, "environ": [10, 11, 13, 15, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 40, 41, 42, 47, 49, 50, 51, 53, 55, 56, 57, 67, 71, 77, 79, 80, 81, 83, 85, 86, 94], "environment": 16, "eo": [12, 46, 49, 70], "eof": 21, "eom": 27, "ep": [6, 21, 29, 30, 32, 35, 45, 50, 61, 80, 83], "ep_dispatch_algorithm": [13, 20, 25, 26, 27, 28, 36, 37], "ep_num_redundant_expert": [13, 20, 25, 26, 27, 28, 36, 37], "ep_siz": [7, 13, 20, 25, 26, 27, 28, 36, 37], "epd": 57, "eplb": [7, 21, 80, 83], "eplb_algorithm": [13, 20, 25, 26, 27, 28, 36, 37], "eplb_min_rebalancing_utilization_threshold": [13, 20, 25, 26, 27, 28, 36, 37], "eplb_rebalance_layers_per_chunk": [13, 20, 25, 26, 27, 28, 36, 37], "eplb_rebalance_num_iter": [13, 20, 25, 26, 27, 28, 36, 37], "equal": [13, 20, 21, 30, 37, 48, 49], "equip": [30, 67], "equival": [22, 47, 58, 74], "erni": [66, 92, 95], "ernie4": 95, "err": 81, "error": [0, 2, 8, 13, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 36, 37, 40, 41, 42, 47, 48, 49, 50, 51, 59, 60, 67, 77, 79, 81, 85, 90, 96], "error_messag": 13, "error_typ": 88, "errors_tot": 22, "esc": 67, "especi": [2, 11, 12, 13, 16, 18, 21, 26, 27, 33, 37, 51, 52, 59, 90], "essenti": [10, 13, 22, 77, 79, 84, 85, 98], "establish": [20, 84], "estim": [16, 26, 73], "et": 33, "etc": [1, 3, 5, 8, 10, 17, 21, 22, 27, 49, 50, 57, 58, 60, 88, 90, 92, 98], "eth": 79, "ethernet": 79, "europ": [24, 26, 37, 47], "european": 24, "ev": 95, "eva": 90, "eval": [28, 30, 51, 53, 59, 98], "evalu": [4, 16, 18, 21, 23, 24, 30, 36, 49, 51, 57, 59, 70, 97], "evaluation_mod": 30, "even": [4, 16, 23, 26, 37, 52, 73, 75, 77, 92, 95], "even_k": 24, "evenli": 16, "event": [16, 21, 22, 27, 50], "eventu": 98, "ever": 35, "everi": [0, 5, 7, 8, 11, 14, 21, 48, 50, 51, 52, 59, 67, 86, 90], "everydai": 28, "everyth": 3, "everywher": 13, "evict": [11, 13, 21, 22], "evil": 13, "evolv": [7, 16, 22, 37], "exa": 33, "exa_api_kei": 33, "exact": [11, 22, 26, 33, 90], "exactli": [8, 13, 22, 26, 38, 50, 98], "examin": 37, "exampl": [0, 1, 8, 10, 11, 13, 15, 16, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34, 35, 37, 41, 42, 44, 48, 51, 52, 53, 55, 56, 59, 65, 71, 75, 77, 81, 85, 86, 93, 94], "example_function_nam": [25, 26], "example_imag": [28, 32, 42, 45, 46, 77], "example_nam": [25, 26], "example_valu": [25, 26], "exampleoutput": 40, "exaon": [66, 92], "exce": [11, 21, 22, 32, 45, 46, 51, 59, 67, 73, 98], "exceed": 62, "excel": [1, 51, 59, 92], "except": [1, 8, 21, 27, 30, 36, 70, 99], "excess": [13, 16, 22], "excit": 37, "exclud": [21, 56], "exclus": [50, 90], "exec": [0, 50, 52, 90], "execut": [0, 6, 7, 11, 16, 17, 21, 22, 23, 25, 26, 33, 50, 56, 67, 79, 80, 86, 90, 91, 97], "exercis": 77, "exhaust": 22, "exhibit": 92, "exist": [0, 1, 6, 10, 11, 17, 21, 24, 28, 51, 52, 59, 80, 83, 86, 90, 98], "exit": [67, 81], "exp": [27, 30, 66, 82], "expand": [1, 11, 77, 98], "expandable_seg": [61, 62, 64], "expans": [7, 24, 90], "expect": [3, 4, 8, 13, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 35, 36, 37, 40, 41, 42, 47, 48, 50, 67, 70, 77, 90], "expens": [51, 59], "experi": [4, 16, 17, 18, 28, 37, 80], "experienc": 29, "experiment": [16, 18, 21, 24, 29, 31, 33, 73], "expert": [12, 21, 29, 37, 46, 57, 61, 62, 67, 73, 80, 82, 83, 89, 92], "expert_distribution_recorder_buffer_s": [13, 20, 25, 26, 27, 28, 36, 37], "expert_distribution_recorder_mod": [13, 20, 25, 26, 27, 28, 36, 37], "expert_record_server_process": 36, "expir": 22, "explain": [13, 33, 37, 70, 86, 91, 98], "explan": [1, 27, 69, 71], "explicit": [8, 22, 23, 27], "explicitli": [13, 25, 34, 36, 67, 85, 86, 90], "exploit": 11, "explor": [1, 37, 40, 95], "expon": 18, "exponenti": [18, 21, 22], "export": [8, 10, 15, 16, 21, 22, 30, 33, 48, 49, 50, 52, 55, 56, 58, 59, 60, 61, 62, 64, 67, 70, 86, 90, 93, 94, 98], "export_metrics_to_fil": [13, 20, 25, 26, 27, 28, 36, 37], "export_metrics_to_file_dir": [13, 20, 25, 26, 27, 28, 36, 37], "exported_model": 17, "expos": [11, 14, 22, 23, 33, 40, 48, 49, 50, 80, 85, 90], "expr": [22, 61], "express": [46, 48, 77, 92, 95], "extend": [10, 11, 21, 22, 24, 27, 28, 29, 30, 40, 49, 53, 75, 90, 92, 96, 98], "extens": [48, 52, 57, 90, 95], "extern": [8, 10, 18, 21, 22, 33, 36], "extra": [10, 11, 21, 30, 44, 48, 49, 53, 56], "extra_bodi": [20, 25, 26, 29, 31, 40, 46], "extra_buff": [21, 44], "extract": [5, 37, 48, 51, 59, 95, 98], "extrem": [3, 11, 13, 16, 18, 27, 51, 59], "ey": 13, "f": [8, 13, 17, 20, 24, 25, 26, 27, 28, 32, 36, 37, 40, 41, 42, 45, 46, 47, 48, 56, 58, 60, 61, 62, 67, 68, 77, 79, 80, 86, 90, 93, 96, 98], "f1": 52, "f443f89ef3f24f14a2372ef66d3926e2": 40, "f5": 52, "f7ff": 79, "f_": 24, "f_1": 24, "f_k": 24, "fa": [70, 90], "fa3": [1, 3, 4, 10, 13, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 40, 41, 42, 45, 47, 77, 90], "fa4": [1, 21, 90], "fabdb6a30b49f79a7aba0f2ad9df9b399473380f": 52, "face": [13, 17, 21, 40, 57, 72, 90, 92, 98], "facilit": [16, 23, 29, 40, 67, 84, 91], "fact": [13, 26, 36], "facto": 84, "factor": [17, 21, 22, 24, 35, 49, 74], "factori": [21, 84], "factory_nam": 8, "factual": [37, 98], "fahrenheit": [25, 26, 27], "fail": [0, 8, 13, 17, 22, 23, 27, 36, 48, 49, 50, 51, 59, 75, 81, 90], "failur": [8, 15, 17, 51, 56, 59], "failurethreshold": 83, "fair": [51, 59], "fairi": 13, "fake": [17, 21], "fal": 90, "fall": [1, 7, 21, 22, 30, 88, 90, 96, 99], "fallback": [21, 22, 25, 26, 34, 46, 57, 90], "fals": [13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 40, 41, 46, 47, 50, 52, 73, 80, 83, 90, 96, 98], "famili": [1, 20, 22, 30, 40, 45, 66, 70, 89, 90, 91, 92, 95, 96, 97], "familiar": [28, 38], "famou": [26, 37, 40], "fan": 37, "far": [13, 46], "fascin": 37, "fashion": 37, "fast": [1, 8, 11, 21, 22, 23, 33, 35, 37, 38, 51, 57, 59, 90, 92], "fastapi": 21, "fastapi_root_path": [13, 20, 25, 26, 27, 28, 36, 37], "faster": [11, 13, 24, 51, 56, 59, 70, 73, 84, 89, 90, 91, 92, 95], "fastest": 24, "fasthunyuan": 90, "fastsafetensor": 21, "fastvideo": 90, "fastwan": 90, "fastwan2": 90, "fat": 77, "fatal": [8, 56], "fault": [15, 22, 23], "favor": [12, 40], "fbe0c586aa574487bdae7a156bb6e2b8": 47, "fcf": [13, 15, 20, 21, 25, 26, 27, 28, 36, 37], "fe36": 79, "fe64": 79, "fe6e": 79, "fe73": 79, "fe80": 79, "feasibl": 21, "feather": 77, "featur": [0, 1, 2, 3, 4, 5, 7, 8, 10, 13, 16, 21, 24, 26, 27, 28, 29, 30, 31, 32, 34, 42, 44, 45, 46, 50, 51, 59, 73, 78, 79, 84, 86, 89, 92, 95, 98], "feed": [22, 98], "feedback": 10, "feel": [40, 51, 59, 60, 67], "felt": 13, "femal": 40, "feroci": 13, "fetch": [11, 25, 26, 27, 49, 50], "few": [3, 13, 51, 58, 59], "few_shot_gsm8k": [51, 53, 59, 62], "fewer": [16, 67], "ff1af942335b4a3293b442cff7f66a1a": 13, "ffi": [22, 48], "ffn": 21, "fi": [61, 62, 81], "fiction": [37, 98], "field": [13, 21, 23, 25, 26, 36, 37, 40, 49, 90, 98], "fieldpath": [80, 83], "fieldref": [80, 83], "fierc": 13, "fifo": [13, 21, 22], "figur": [26, 52], "file": [0, 2, 11, 14, 18, 28, 32, 36, 45, 46, 48, 49, 51, 59, 67, 70, 71, 72, 74, 79, 88, 95, 98], "file_path": 22, "file_storage_path": [13, 20, 25, 26, 27, 28, 36, 37], "filenam": 21, "filesystem": 22, "fill": [1, 13, 77], "fillmor": 75, "filter": [22, 27], "final": [13, 20, 21, 24, 26, 27, 48, 74, 98], "final_hidden_st": 7, "final_respons": 27, "financi": 37, "find": [0, 13, 16, 20, 21, 24, 25, 26, 27, 30, 40, 46, 51, 56, 59, 70, 74, 79, 85, 86, 90, 96, 98], "fine": [7, 11, 15, 16, 27, 30, 32, 45, 50, 84, 90, 92, 95], "finer": 86, "finetun": 27, "finish": [13, 29, 50, 90], "finish_reason": [24, 25, 26, 27, 29, 36, 40, 42, 47, 80, 83], "finit": 13, "fire": [13, 36, 58, 67, 79], "firewal": [22, 38, 70], "firm": 33, "firmwar": 60, "first": [0, 1, 2, 3, 8, 10, 11, 12, 13, 16, 17, 20, 21, 22, 26, 29, 30, 36, 40, 41, 42, 49, 50, 51, 52, 53, 56, 59, 60, 67, 70, 73, 81, 85, 86, 90, 93, 98], "first_answ": 77, "firstli": 50, "fit": [11, 16, 21, 30, 56, 95], "five": [23, 51, 59], "fix": [0, 1, 3, 16, 51, 56, 59, 70, 90], "fla": 21, "flag": [2, 4, 7, 10, 21, 22, 26, 29, 30, 31, 40, 46, 49, 50, 52, 53, 67, 73, 86, 90, 91, 95], "flagship": 67, "flaki": [51, 59], "flash": [21, 32, 45, 73, 89, 90], "flash_attn": 30, "flash_attn_with_kvcach": 30, "flash_mla": 30, "flash_mla_sparse_fwd": 30, "flash_mla_with_kvcach": 30, "flash_rl": 21, "flashattent": [1, 4, 30, 70, 90], "flashattention3": 29, "flashattention_backend": 1, "flashinf": [1, 4, 7, 13, 20, 21, 24, 25, 26, 27, 28, 29, 36, 37, 56, 69, 73], "flashinfer_cudnn": 21, "flashinfer_cutedsl": [7, 21, 73], "flashinfer_cutlass": [7, 21, 73], "flashinfer_mla_disable_rag": [13, 20, 25, 26, 27, 28, 36, 37], "flashinfer_mxfp4": [7, 21], "flashinfer_mxfp4_moe_precis": [13, 20, 25, 26, 27, 28, 36, 37], "flashinfer_trtllm": [1, 7, 21, 73], "flashmla": [1, 21, 29], "flashmla_auto": [21, 30], "flashmla_decod": 21, "flashmla_kv": [21, 30], "flashmla_prefil": 21, "flashmla_spars": [21, 30], "flashrl": 21, "flatten": [3, 28, 40, 46], "flattened_bucket": 23, "fleet": 22, "flex_attent": [1, 21], "flexattent": 1, "flexibl": [7, 13, 23, 47, 70, 91, 96], "flexibli": 29, "flight": [16, 49], "flm": 92, "float": [4, 18, 21, 40, 46, 90, 91, 96], "float16": [17, 21, 24, 36, 41], "float32": [13, 17, 20, 21, 24, 25, 26, 27, 28, 36, 37, 41, 44], "float8": 17, "float8_e4m3fn": 18, "flow": [7, 23, 37, 86], "fluenci": 40, "flush": [21, 23, 37, 38, 46, 47, 49, 77], "flush_cach": [22, 23, 36, 49], "flux": 90, "fly": [17, 18], "flymi": 90, "fn": 90, "fn_name": 8, "fnmatch": 8, "focal": 33, "focu": [23, 90], "focus": [7, 23, 37, 40], "foe": 13, "folder": [0, 14, 21, 50, 52, 55, 67, 83, 85, 87], "follow": [0, 1, 3, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 29, 30, 32, 35, 36, 37, 40, 45, 46, 47, 48, 50, 51, 52, 55, 56, 58, 59, 60, 67, 69, 70, 74, 77, 78, 79, 80, 81, 85, 86, 88, 90, 92, 93, 95, 98, 99], "follow_bootstrap_room": 21, "foo": [25, 26], "food": 37, "fool": 33, "footprint": [1, 18], "forc": [13, 22, 37, 46, 53, 56, 67, 73, 90], "foreign": 48, "forest": [13, 90], "forev": 55, "fork": [50, 57, 77, 90], "form": [6, 8, 13, 26, 27, 35, 46, 50, 71, 90], "format": [2, 5, 7, 8, 13, 17, 19, 21, 23, 25, 26, 29, 36, 46, 50, 67, 70, 80, 85, 86, 90, 95], "former": [12, 15, 21, 62], "formerli": 78, "formid": 13, "fortress": 13, "forward": [1, 7, 8, 16, 22, 37, 51, 59, 73, 98, 99], "forward_batch": 98, "forward_batch_info": 98, "forward_decod": [1, 98], "forward_extend": [1, 98], "forward_hook": [8, 13, 20, 25, 26, 27, 28, 36, 37], "forward_stream": 16, "forwardbatch": 98, "fought": 13, "found": [4, 11, 13, 15, 16, 18, 21, 36, 37, 62, 64, 69, 79], "foundat": 92, "four": [13, 29, 37, 86], "fp": [90, 95], "fp16": [21, 81, 90], "fp32": [21, 90], "fp4": [1, 7, 17, 21, 57, 73], "fp4_e2m1": [18, 21], "fp4_gemm_runner_backend": [13, 20, 25, 26, 27, 28, 36, 37], "fp8": [1, 7, 12, 17, 21, 30, 31, 57, 67, 73, 81], "fp8_dynam": 17, "fp8_e4m3": [1, 18, 21, 30], "fp8_e5m2": [18, 21], "fp8_gemm_runner_backend": [13, 20, 25, 26, 27, 28, 36, 37], "fp8_kernel": 17, "fp8dq": [17, 21], "fp8wo": [17, 21], "fr": 24, "frac": 50, "fraction": [10, 15, 16, 21, 24, 29, 30, 31, 32, 34, 35, 45, 61, 62, 64, 69, 70, 74, 79, 80, 83], "fragment": [3, 27, 29, 73], "frame": [90, 95], "framework": [11, 23, 51, 57, 59, 83, 84, 90, 93, 96], "franc": [13, 17, 24, 25, 26, 27, 29, 31, 36, 37, 40, 46, 47, 75, 77, 91, 93, 98], "francisco": [25, 26, 27], "franklin": 69, "free": [13, 22, 26, 40, 51, 59, 60, 67], "freeli": 86, "french": [26, 36, 37], "freq_32768": 24, "frequenc": [11, 32, 45, 46, 73, 77], "frequency_penalti": [40, 46], "frequent": [3, 11, 12, 13, 15, 16, 21, 57], "fridai": 33, "friend": [13, 37], "friendli": 84, "from": [0, 1, 2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 33, 35, 37, 40, 41, 42, 46, 47, 48, 49, 50, 57, 62, 63, 69, 72, 73, 74, 77, 83, 84, 85, 86, 88, 89, 92, 93, 95, 96, 97, 99], "from_arg": 22, "from_pretrain": [17, 20, 25, 26, 27, 28, 36, 41, 90], "from_stat": 22, "front": [5, 11, 28], "frontend": [57, 72], "frontier": 84, "frozen": [3, 13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "fruit": 77, "fsdp": 21, "fulfil": 13, "full": [6, 7, 10, 12, 13, 21, 23, 29, 34, 36, 44, 50, 79, 84, 91, 92, 95], "full_argu": 27, "full_siz": 21, "fullattn": 90, "fulli": [0, 4, 6, 11, 17, 22, 27, 29, 30, 40, 51, 58, 59, 80, 83, 84, 90, 92], "fun": [26, 37], "func": 48, "func_latency_second": 85, "func_latency_seconds_bucket": 85, "func_latency_seconds_count": 85, "func_latency_seconds_sum": 85, "func_name1": 27, "func_name2": 27, "function": [0, 1, 7, 8, 11, 16, 21, 24, 25, 26, 40, 48, 51, 59, 70, 75, 77, 84, 85, 98], "function_cal": [22, 24, 27, 40, 47], "function_call_input": 27, "function_call_pars": 27, "function_call_respons": 27, "function_call_response_json": 27, "function_dict": 27, "function_nam": [25, 26], "functioncallpars": 27, "functool": [24, 48, 98], "fundament": 10, "furri": 90, "further": [6, 11, 16, 23, 24, 37, 56, 86], "furthermor": 24, "fuse": [7, 17, 18, 21, 30, 73], "fused_moe_triton": [36, 80], "fusedmo": [7, 30], "fusion": [17, 21, 61, 62, 73], "futur": [11, 17, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 51, 59, 73, 77, 80, 93, 98], "futurewarn": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "futurist": 90, "fuzzi": 26, "g": [0, 1, 3, 4, 7, 8, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 32, 33, 36, 45, 48, 49, 50, 51, 52, 53, 55, 56, 59, 67, 71, 85, 90, 92, 95, 96, 98], "g0519b0935": 36, "gain": [5, 7, 11, 28, 92], "garbag": 21, "garden": [13, 90], "gate": [17, 51, 59], "gate_proj": [13, 21], "gate_up_proj": 21, "gatewai": [12, 15, 21, 23, 57, 62, 88], "gather": [7, 21, 23, 30, 73, 95], "gaudi": 17, "gaug": 85, "gave": 13, "gb": [10, 12, 13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 42, 47, 70, 73, 77, 79], "gb200": [29, 34, 56, 57, 73], "gb300": 56, "gc": [21, 70], "gc_warning_threshold_sec": [13, 20, 25, 26, 27, 28, 36, 37], "gcc": 67, "gcp": 70, "gd": 11, "geisl": 36, "gem": 13, "gemm": [7, 13, 73], "gemma": [57, 66, 70, 92, 95, 97], "gemma2forsequenceclassif": [88, 97], "gemma3": 42, "gen": [12, 13, 67, 75, 77, 92], "gen_data": [20, 27], "gen_respons": [20, 27], "gen_second": 30, "gen_throughput": 85, "gen_url": [20, 27], "gener": [5, 6, 7, 11, 13, 15, 17, 18, 20, 21, 22, 25, 26, 27, 28, 30, 33, 34, 35, 38, 40, 48, 49, 50, 57, 67, 70, 79, 84, 85, 86, 87, 88, 89, 92, 93, 95, 98], "generate_request": 85, "generate_stream": 49, "generated_text": [20, 27, 49], "generatereqinput": 46, "generation_config": [21, 46], "generation_duration_second": 22, "generation_tokens_bucket": [13, 20, 25, 26, 27, 28, 36, 37], "generation_tokens_tot": 85, "generative_model": 98, "gentl": 13, "geographi": [25, 26], "germani": [24, 25, 26, 40], "get": [0, 8, 10, 13, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 41, 44, 49, 50, 51, 56, 59, 60, 61, 67, 71, 79, 80, 83, 91, 96, 98], "get_current_d": [25, 26], "get_current_weath": [25, 26, 27], "get_embed": 98, "get_image_featur": 98, "get_load": 22, "get_max_total_num_token": 36, "get_memory_pool_s": 36, "get_messag": [25, 26, 27], "get_model_info": [21, 22, 36, 77, 79], "get_model_load": 17, "get_prompt": 28, "get_server_arg": 36, "get_server_info": [21, 22, 36, 49], "get_start": 0, "get_tourist_attract": 27, "get_weath": [22, 27], "getattr": 8, "gf_auth_anonymous_en": 85, "gf_server_http_port": 85, "ggml": [25, 46], "gguf": [17, 21, 99], "ghp_xxxxx": 22, "giant": [36, 96], "gibberish": 49, "gid": 79, "gift": 13, "gigabyt": [11, 21], "git": [15, 30, 51, 55, 56, 58, 59, 60, 67, 68, 69, 70, 71, 90, 93], "github": [0, 3, 10, 15, 22, 28, 30, 32, 36, 42, 45, 46, 51, 56, 58, 59, 60, 67, 68, 69, 70, 71, 74, 77, 83, 86, 90, 92, 93, 95], "githubusercont": 42, "give": [13, 25, 26, 27, 55, 77, 98], "given": [8, 11, 16, 22, 24, 25, 26, 27, 28, 29, 30, 36, 46, 96], "glitter": 13, "glm": [5, 21, 22, 23, 27, 57, 66, 84, 90, 92, 95], "glm45": [21, 22, 31, 32], "glm47": [21, 31], "glm4moethinkingbudgetlogitprocessor": [31, 32], "glmasr": [13, 20, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 77], "glmasrconfig": [13, 20, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 77], "glob": [8, 21], "global": [11, 22, 25, 26, 86, 90], "global_force_attn_backend": 90, "global_force_attn_backend_context_manag": 90, "glog_v": 93, "gloo": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 73, 77], "gloo_socket_ifnam": [61, 62, 79, 83], "gme": [66, 91], "gnu": 67, "gnupg": 50, "go": [26, 33, 37, 40, 58, 60, 85], "goal": [40, 98], "golang": 22, "gold": [13, 22], "golden": [13, 96], "good": [12, 26, 29, 37, 51, 58, 59, 90], "googl": [57, 66, 70, 77, 84, 92, 95], "got": 48, "govern": [26, 37], "gpqa": 53, "gpqa_diamond": 18, "gpt": [18, 20, 21, 22, 27, 40, 57, 66, 92], "gptoss": 66, "gptq": [17, 21, 57], "gptq_marlin": [17, 21], "gpu": [3, 4, 5, 7, 10, 11, 12, 15, 16, 17, 18, 19, 21, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 44, 45, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 71, 73, 79, 80, 81, 82, 83, 84, 90, 94, 95], "gpu_id_step": [13, 20, 25, 26, 27, 28, 36, 37], "grade": [17, 56, 84], "gradual": [16, 70], "grafana": 85, "grain": [7, 11, 15, 30, 50, 77, 84, 86, 90, 95], "grammar": [25, 26, 27, 46, 81], "grammar_backend": [13, 20, 25, 26, 27, 28, 36, 37], "granit": [66, 92], "granular": [11, 16, 50, 53], "graph": [1, 2, 4, 7, 13, 17, 21, 23, 24, 29, 30, 36, 50, 52, 57, 61, 62, 74, 79, 80, 83, 90], "graph_kei": 3, "graphic": 71, "gre": 81, "great": [13, 88, 89], "greater": [2, 11, 13, 15, 16, 21, 24, 37, 96], "greatest": 40, "greedi": 46, "greedy_token_select": 75, "greenctx": 21, "greet": 46, "grep": [79, 80, 83], "grew": 13, "grid": 21, "grid_siz": 48, "grok": [66, 70, 92], "group": [1, 4, 7, 11, 13, 19, 21, 22, 29, 30, 49, 55, 58, 69, 73], "group_m": 24, "group_nam": 23, "group_siz": [17, 21], "grouped_gemm": 7, "grow": [13, 16, 26, 46], "growth": 26, "grpc": [21, 23, 86], "grpc_mode": [13, 20, 25, 26, 27, 28, 36, 37], "grpo": [4, 84], "grub_cmdline_linux": 58, "gryffindor": 77, "gserver": 49, "gsm8k": [18, 51, 52, 53, 59, 61, 98], "gsp": 49, "gt": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "gte": [36, 41, 57, 66, 91], "gte_qwen2": 66, "guarante": [11, 23, 25, 46, 96], "guard": [13, 17], "gui": 50, "guid": [10, 15, 17, 21, 23, 25, 27, 29, 35, 46, 47, 50, 56, 58, 60, 65, 70, 79, 90, 93, 97], "guidanc": [13, 22, 24, 67, 70, 74, 84, 98], "guidance_scal": 90, "guidelin": [51, 59, 98], "gz": [17, 50, 52, 90], "h": [22, 29, 30, 35, 41, 42, 47, 48, 50, 67, 71, 80, 83, 88, 89, 90, 96], "h100": [1, 24, 29, 32, 34, 45, 56, 57, 82, 90], "h20": [1, 2, 29, 30, 79], "h200": [1, 30, 31, 32, 34, 44, 45, 82, 90], "h2d": [13, 21], "ha": [1, 3, 8, 11, 12, 13, 16, 17, 18, 21, 22, 23, 24, 26, 27, 29, 30, 31, 33, 34, 36, 37, 44, 50, 51, 53, 59, 63, 67, 79, 83, 84, 86, 90, 92, 99], "had": [13, 16, 36, 40], "hadn": 50, "hair": 13, "half": [21, 22, 69, 77], "halt": 13, "hand": [5, 12, 16], "handl": [7, 8, 10, 15, 16, 18, 20, 21, 22, 23, 28, 29, 36, 46, 47, 50, 70, 79, 80, 91, 95, 98], "handler": [21, 51, 59], "handoff": 23, "hang": 21, "happen": [12, 17, 21, 23, 32, 45, 95, 99], "happi": [51, 59, 84], "har": 13, "hard": [10, 79], "hardwar": [1, 7, 13, 16, 17, 21, 30, 34, 51, 53, 58, 59, 60, 61], "harm": 52, "harri": [37, 77], "has_audio_understand": 36, "has_image_understand": 36, "hash": [22, 53, 73, 98], "hasn": 79, "hat": 92, "have": [13, 15, 16, 17, 21, 24, 25, 26, 29, 33, 37, 40, 42, 50, 51, 56, 58, 59, 60, 61, 67, 68, 70, 71, 73, 75, 79, 80, 84, 86, 89, 90, 92, 95, 96, 98], "hazard": 16, "hazel": 77, "hbm": 70, "hccl_algo": 61, "hccl_buffsiz": [61, 62, 64], "hccl_op_expansion_mod": [61, 64], "hccl_socket_ifnam": [61, 62], "hdk": 60, "he": 13, "head": [1, 11, 21, 30, 32, 38, 45, 50, 61, 62, 80, 81, 83, 95, 98], "head_nod": 81, "head_node_ip": 30, "header": [21, 22, 86, 88], "headlin": 33, "headshotx": 90, "health": [15, 38, 70, 73, 77, 83], "health_checks_tot": 22, "health_gener": [22, 36], "healthcar": 37, "healthi": [12, 13, 22, 23, 77], "hear": [26, 37], "heard": [13, 26], "heart": 13, "heartbeat": 15, "heavi": [6, 13, 21], "heavili": 27, "hei": 46, "height": 90, "heightxwidth": 49, "helfpul": 33, "hellaswag": 53, "hello": [17, 22, 27, 37, 38, 46, 93, 98], "helm": 80, "help": [0, 11, 12, 13, 16, 21, 25, 26, 27, 28, 33, 35, 37, 46, 49, 50, 51, 56, 58, 59, 70, 74, 77, 80, 83, 84, 85, 90, 95], "henc": 16, "her": [13, 96], "here": [10, 11, 12, 13, 17, 23, 24, 25, 26, 27, 28, 29, 36, 37, 40, 46, 47, 51, 56, 58, 59, 60, 62, 64, 77, 79, 80, 84, 85, 90, 99], "heritag": 37, "hesit": 13, "heterogen": 22, "heurist": [12, 30], "hf": [13, 17, 21, 24, 36, 49, 72, 89, 92, 95, 97, 98], "hf3f": [11, 21], "hf_chat_template_nam": [13, 20, 25, 26, 27, 28, 36, 37], "hf_home": [13, 36, 55], "hf_token": [22, 55, 56, 58, 60, 67, 90, 98], "hf_xxx": 55, "hh": 90, "hi": [13, 36, 37, 46, 81, 96], "hicach": [21, 57], "hicache_io_backend": [13, 20, 25, 26, 27, 28, 36, 37], "hicache_mem_layout": [13, 20, 25, 26, 27, 28, 36, 37], "hicache_ratio": [11, 13, 20, 21, 25, 26, 27, 28, 36, 37], "hicache_s": [11, 13, 20, 25, 26, 27, 28, 36, 37], "hicache_storage_backend": [13, 20, 25, 26, 27, 28, 36, 37], "hicache_storage_backend_extra_config": [11, 13, 20, 25, 26, 27, 28, 36, 37], "hicache_storage_prefetch_polici": [13, 20, 25, 26, 27, 28, 36, 37], "hicache_write_polici": [13, 20, 25, 26, 27, 28, 36, 37], "hicachefil": 11, "hicachestorag": 11, "hidden": [8, 13, 21, 24, 37, 46], "hidden_st": [98, 99], "hide": [7, 11, 13], "hierarch": [10, 11, 57], "hierarchi": [11, 50, 86], "hierarchical_sparse_attention_extra_config": [13, 20, 25, 26, 27, 28, 36, 37], "high": [7, 11, 13, 17, 21, 23, 24, 26, 27, 28, 29, 32, 33, 38, 45, 46, 53, 57, 69, 75, 77, 84, 90, 91, 92, 93, 95, 96], "higher": [1, 7, 10, 11, 12, 13, 16, 18, 21, 23, 24, 26, 33, 40, 46, 51, 59, 60, 70, 89, 90, 95, 96], "higherrorr": 22, "highest": [22, 46, 75], "highest_token_prob": 46, "highlat": 22, "highli": [6, 7, 23, 46], "highlight": [13, 20, 25, 26, 27, 36, 40, 41, 42, 47, 77], "hilab": 95, "himself": 13, "hint": 7, "hisi_hdc": 60, "histogram": [21, 22, 30, 85], "histogram_quantil": 22, "histor": [24, 73], "histori": [27, 37, 90], "historian": 40, "hit": [10, 11, 12, 22, 46, 79, 85], "hmm": [26, 40], "hobbi": 37, "hogwart": 37, "hold": 11, "holist": 95, "home": [22, 37, 52, 58, 67, 80], "hood": [23, 74], "hook": 7, "hook_cal": 8, "hook_factori": 21, "hook_factory_path": 8, "hook_spec": 8, "hope": 26, "hopper": [1, 7, 17, 21, 29, 30, 34, 73, 90], "horizon": 92, "horizont": [6, 22], "hose": 28, "host": [2, 10, 11, 13, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 53, 56, 58, 60, 61, 62, 67, 69, 70, 71, 73, 77, 79, 80, 83, 85, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], "hostipc": [79, 80, 83], "hostnam": [21, 61, 62, 81], "hostnetwork": [79, 80, 83], "hostpath": [79, 80, 83], "hot": 11, "hottest": 11, "hour": 29, "hous": 77, "how": [0, 1, 11, 12, 13, 16, 17, 21, 22, 23, 24, 26, 28, 29, 36, 37, 40, 49, 50, 57, 58, 67, 68, 71, 75, 81, 85, 95], "howee": 66, "howev": [5, 6, 11, 12, 13, 22, 27, 37, 44, 74, 79, 84, 86, 98, 99], "hpu": [21, 30], "html": [0, 25, 50, 87, 98], "http": [0, 2, 3, 4, 6, 10, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 74, 77, 78, 79, 80, 83, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 98], "http_proxi": 61, "http_server": [36, 88, 98], "http_worker_ipc": 13, "httpget": 83, "https_proxi": 61, "hub": [13, 21, 22, 26, 36, 37, 56, 58, 90, 99], "hufflepuff": 77, "hug": [17, 21, 40, 57, 72, 90, 92, 98], "huge": 24, "huggingfac": [13, 17, 21, 22, 28, 36, 46, 52, 55, 56, 58, 67, 90, 91, 92, 94, 95, 96, 97, 98], "huggingface_hub": 98, "huggingfacetb": [66, 92], "huihui": 66, "human": [8, 21, 37, 40, 89, 97], "human_ev": 53, "humanev": 53, "humor": [28, 42], "hundr": 67, "hunyuan": 90, "hunyuanvideo": 90, "hybrid": [5, 7, 15, 20, 21, 34, 40, 44, 92, 95], "hybrid_attn_backend": 1, "hyperparamet": [16, 21, 57], "i": [0, 1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 62, 67, 69, 70, 71, 72, 73, 74, 75, 77, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99], "i2v": 90, "ib": [10, 15, 21, 23, 30, 79, 80, 83], "ibdev2netdev": 79, "ibm": [66, 92], "ibstatu": 79, "ibv_devic": 79, "ibv_devinfo": 79, "icon": [24, 28, 37, 42], "id": [15, 20, 21, 23, 24, 25, 26, 27, 29, 36, 42, 46, 47, 48, 49, 50, 60, 61, 80, 83, 88, 90], "id2label": [22, 88], "idea": [11, 51, 59], "ideal": [10, 16, 22, 96], "ident": [3, 4, 11, 16, 23, 37, 58], "identif": [36, 50], "identifi": [2, 10, 20, 21, 26, 37, 50, 67, 71, 88, 90, 92, 95, 96, 97], "idl": [7, 11, 21, 23, 29], "idle_timeout": 22, "idx": 48, "ifnam": 61, "ignor": [13, 17, 20, 21, 24, 25, 26, 27, 28, 30, 36, 40, 41, 42, 47, 49, 70, 77, 90], "ignore_eo": 46, "igw": 22, "ii": 29, "iic": 66, "illustr": [67, 90], "im_end": [28, 46, 72, 77], "im_start": [28, 46, 72, 77], "imag": [3, 6, 21, 22, 36, 46, 49, 52, 56, 57, 58, 67, 69, 77, 79, 85, 91, 92, 95, 98], "image_byt": [77, 90], "image_data": [28, 46], "image_featur": 28, "image_fil": 77, "image_grid_thw": 28, "image_id": [56, 90], "image_nam": [60, 69], "image_output": 28, "image_pad": 28, "image_path": 91, "image_qa": 77, "image_tag": 56, "image_token": 28, "image_uri": 56, "image_url": [32, 42, 45, 77, 90, 96], "imagedataitem": 46, "imageri": 28, "imagin": 13, "imbal": [7, 15, 73], "img": 90, "imit": 98, "immedi": [11, 21, 22, 23, 49, 50, 51, 59], "immun": 77, "impact": [11, 22, 37, 50, 90, 95], "impair": 37, "imper": 90, "impl": [21, 93, 99], "implement": [1, 8, 10, 11, 18, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 40, 49, 60, 70, 73, 74, 75, 80, 86, 90, 92, 93, 95, 99], "impli": 33, "import": [0, 4, 8, 12, 13, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 36, 37, 38, 40, 41, 42, 46, 47, 48, 62, 70, 77, 88, 89, 90, 91, 93, 95, 96, 98, 99], "import_model_class": 98, "import_modul": 8, "import_new_model_class": 98, "importlib": [8, 13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "impos": 86, "impress": 28, "improv": [3, 4, 6, 7, 10, 11, 13, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 40, 41, 42, 44, 45, 47, 70, 77, 90, 92, 95, 96], "in_plac": 23, "inaccur": 50, "inc": [66, 92], "includ": [3, 6, 7, 11, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29, 30, 36, 37, 40, 48, 49, 50, 53, 57, 66, 67, 70, 74, 85, 88, 90, 91, 92, 96, 98], "inclus": 50, "inclusionai": [66, 89, 92], "incom": [11, 15, 21], "incompat": [1, 90], "incomplet": 23, "inconsist": [11, 27, 49], "incorpor": [13, 24, 77, 83, 92, 96], "incorrect": [24, 75], "incorrectli": 3, "increas": [2, 3, 7, 11, 13, 15, 16, 21, 22, 24, 26, 27, 29, 30, 37, 40, 44, 70, 77, 90, 92, 95], "increment": [11, 12, 22, 73], "incur": [5, 75], "inde": 26, "indent": [48, 88], "independ": [6, 22, 23, 29, 93], "indetermin": 74, "index": [0, 13, 22, 24, 27, 29, 30, 36, 40, 41, 42, 47, 50, 56, 60, 61, 67, 71, 80, 83, 88, 90, 96], "indic": [1, 12, 15, 18, 73, 79], "individu": [37, 50, 98], "inductor": 21, "inductor_root_cach": 87, "industri": [22, 34, 37, 57, 84], "ineffici": [6, 15, 50], "inexplic": 13, "inf": [46, 49, 67, 71, 85], "infer": [2, 6, 7, 11, 13, 15, 17, 21, 28, 29, 30, 32, 38, 44, 45, 49, 51, 56, 57, 58, 59, 67, 70, 71, 74, 79, 83, 84, 92, 95, 98], "inference_mod": 73, "infiniband": [21, 79, 80, 83], "infinit": [16, 21, 49], "info": [8, 10, 13, 20, 21, 22, 24, 25, 26, 27, 28, 32, 37, 40, 41, 42, 45, 47, 60, 77, 79, 81, 93, 96], "inform": [15, 21, 22, 25, 26, 27, 30, 33, 36, 37, 38, 46, 48, 50, 56, 67, 70, 77, 88, 99], "infra": [56, 70], "infrastructur": [15, 16, 22, 23, 51, 59, 84, 90], "ing": 29, "inher": [11, 16], "inherit": [1, 27, 98], "init": [2, 13, 15, 16, 21, 22, 30, 36, 61, 62, 70, 79, 80, 81, 83, 93], "init_cuda_graph_st": 1, "init_expert_loc": [13, 20, 25, 26, 27, 28, 36, 37], "init_forward_metadata": 1, "init_forward_metadata_capture_cuda_graph": 1, "init_forward_metadata_replay_cuda_graph": 1, "init_weights_update_group": 23, "initi": [1, 2, 6, 8, 11, 13, 15, 16, 20, 21, 22, 23, 24, 36, 40, 41, 42, 46, 48, 67, 74, 75, 77, 81, 86, 90, 93], "initialdelaysecond": [79, 83], "inject": [21, 22], "inner": [8, 18], "innov": [23, 29], "input": [4, 6, 7, 8, 11, 13, 15, 20, 21, 22, 24, 27, 30, 33, 36, 46, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 67, 70, 71, 74, 85, 88, 90, 91, 92, 96, 98], "input_emb": [21, 46, 98], "input_hidden_st": 7, "input_id": [21, 27, 28, 41, 46, 98], "input_ids_embed": 41, "input_item": 22, "input_len": 49, "input_seq_len": 70, "input_text": 36, "insert": [67, 86], "insid": [3, 22, 50, 52, 55, 56], "inspect": [12, 22, 50], "inspir": [11, 37], "inst": 95, "instal": [15, 21, 28, 33, 38, 47, 48, 49, 50, 52, 53, 54, 55, 57, 65, 73, 79, 80, 83, 85, 86], "installationguid": 50, "instanc": [10, 11, 13, 15, 17, 19, 21, 22, 23, 24, 40, 46, 50, 61, 67, 70, 75, 85], "instanti": 22, "instantli": 50, "instead": [8, 11, 13, 16, 18, 20, 21, 24, 25, 26, 27, 28, 33, 36, 37, 40, 41, 42, 46, 47, 49, 51, 59, 73, 74, 77, 85, 88, 90, 98], "instinct": [58, 90], "instruct": [0, 1, 3, 4, 5, 6, 10, 13, 15, 17, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 56, 58, 59, 60, 61, 66, 67, 69, 71, 77, 79, 81, 85, 87, 90, 91, 92, 94, 95, 98, 99], "instruct_lora_4_alpha_16": 13, "instrument": 86, "int": [3, 15, 21, 22, 23, 25, 26, 46, 48], "int32": [40, 46, 48], "int32_t": 48, "int4": [17, 57, 69, 73, 92], "int4_awq": 21, "int4wo": [17, 21, 69], "int64_t": 48, "int8": [17, 21, 29, 67], "int8_kernel": 17, "int8dq": [17, 21], "int8wo": [17, 21], "integ": [21, 25, 26, 46, 49, 88], "integr": [6, 7, 17, 21, 23, 28, 33, 48, 51, 57, 59, 73, 79, 90, 91, 92, 95, 98], "integratedtermin": 52, "intel": [1, 17, 34, 56, 57, 67, 71], "intel_amx": 21, "intel_xpu": [1, 34, 71], "intellig": [10, 35, 37, 38, 90, 92, 95, 96, 98], "intend": 37, "intens": [6, 13, 15, 23], "intention": 13, "inter": [19, 21, 49, 70], "interact": [0, 21, 23, 37, 38, 50, 90], "interconnect": 5, "interest": [37, 51, 59, 80, 84], "interfac": [7, 22, 85, 88, 90, 91, 96, 98], "interface_v1": 10, "interleav": [7, 42], "intermedi": [8, 21], "intern": [8, 22, 40, 50, 52, 53, 79, 85, 88, 98], "internal_st": 36, "internet": 37, "internlm": [66, 92, 97], "internlm2": [66, 92, 97], "internlm2forrewardmod": 97, "internlm2forrewardmodel": 88, "internvl": 5, "interpol": 21, "interpret": [20, 27, 33], "interrupt": [15, 23], "interv": [15, 21, 22, 51, 59, 73], "intervent": 7, "intervitensinc": 67, "intfloat": [66, 91], "intra": 16, "introduc": [6, 7, 11, 12, 13, 15, 16, 18, 21, 23, 29, 36, 51, 59, 71, 74, 79], "introduct": [37, 51, 59, 89, 98], "introductori": 98, "invalid": [8, 30, 88], "invari": [4, 21], "inventori": 22, "invest": 37, "investig": 74, "invoc": 30, "invok": [8, 17, 27], "involv": [5, 11, 20, 29, 86, 98], "io": [0, 10, 11, 21, 22, 28, 60, 78, 79, 80, 83, 98], "io_struct": [27, 46], "iommu": 58, "ip": [2, 19, 21, 33, 60, 61, 73, 77, 81, 85], "ip1": [61, 62], "ip2": [61, 62], "ipc": [32, 45, 52, 56, 58, 60, 67, 90, 94], "ipc_lock": [80, 83], "ipynb": [0, 13], "ipython": 37, "irang": 48, "ireland": [25, 26], "iron": [42, 77], "is_async": 23, "is_embed": [13, 20, 25, 26, 27, 28, 36, 37], "is_gener": 36, "is_healthi": 22, "is_matryoshka": 91, "is_multimodal_model": 98, "isl": 70, "isn": 79, "isol": [17, 22, 79], "issu": [4, 10, 11, 13, 16, 17, 18, 21, 23, 29, 30, 34, 37, 51, 56, 58, 59, 60, 61, 67, 68, 71, 74, 77, 85, 86, 90, 96], "itali": [25, 26, 40, 77], "itd": 52, "item": [8, 22, 28, 36, 51, 59, 90, 96], "item1": 21, "item2": 21, "item_first": 36, "item_id": 22, "items_stor": 22, "iter": [2, 16, 21, 36, 50], "iter_lin": [46, 47], "itl": 49, "its": [3, 7, 11, 13, 16, 21, 22, 24, 25, 26, 33, 36, 37, 40, 46, 50, 51, 59, 73, 75, 86, 90, 91, 92, 98], "itself": 23, "j": 81, "j_master": 81, "j_node": 81, "jaeger": 86, "jamesliu1": 24, "janeiro": 26, "janu": [66, 95], "japan": [13, 24, 40, 77], "japanes": [90, 92], "jason9693": [22, 88, 97], "javascript": 26, "jax": [13, 21, 70, 84], "jax_compilation_cache_dir": 70, "jean": 42, "jet": [92, 95], "jetpack": 69, "jetson": [56, 57], "jetvlm": 95, "jinja": [22, 27, 29, 30, 96], "jit": [7, 21, 70, 73], "jit_cach": 70, "jit_kernel": 48, "jitter": 22, "job": [22, 37, 51, 59, 81], "jobs_presenting_ipod": [32, 45, 95], "johnni": 69, "joi": 13, "join": [8, 10, 13, 27, 57, 70], "jointli": 92, "joke": 4, "journei": 13, "joy": 96, "jpeg": [49, 96], "jpg": [90, 91], "json": [4, 8, 10, 11, 13, 17, 18, 20, 21, 22, 24, 27, 29, 32, 35, 36, 41, 42, 45, 47, 48, 49, 50, 51, 52, 59, 63, 77, 80, 83, 85, 86, 88, 89, 90, 91, 95, 96, 98], "json_data": 13, "json_model_override_arg": [13, 20, 25, 26, 27, 28, 36, 37], "json_output": 77, "json_schema": [25, 26, 46], "judg": 38, "judgment": 11, "jul": 25, "jump": [20, 33], "jupyt": 0, "just": [11, 12, 13, 21, 26, 35, 48, 55, 70, 72, 73, 89, 90, 98, 99], "justmycod": 52, "k": [13, 24, 26, 36, 46, 67], "k2": [20, 22, 27, 66, 82, 92], "k8": [22, 56, 79, 83], "k_cach": [30, 48], "k_proj": [13, 21], "k_scale": 18, "kblocksiz": 48, "kconstant": 48, "kda": 92, "kdlcpu": 48, "kdlcuda": 48, "keep": [0, 5, 13, 21, 22, 23, 26, 32, 33, 40, 45, 51, 52, 59, 81, 90, 95, 98], "keep_mm_feature_on_devic": [13, 20, 25, 26, 27, 28, 36, 37], "keep_paus": 23, "keepal": 22, "kei": [1, 6, 7, 8, 11, 15, 16, 18, 21, 23, 25, 26, 28, 29, 33, 36, 37, 40, 46, 50, 58, 70, 77, 80, 83, 95, 98], "kept": [13, 33], "kernel": [1, 3, 4, 7, 10, 11, 13, 17, 18, 20, 23, 25, 26, 27, 28, 29, 30, 36, 37, 50, 56, 58, 61, 62, 67, 68, 70, 73, 74, 84, 90], "kernel_ascend": 21, "key_stat": 99, "keyword": 98, "kfd": [55, 58, 90], "kill": 50, "kimi": [20, 21, 22, 27, 40, 57, 66, 82, 92, 95], "kimi_k2": [20, 21, 27], "kind": [13, 22, 79, 80, 83], "king": 36, "kingdom": [13, 40, 77], "kit": 69, "kk": 3, "kl": 84, "klein": 90, "knew": 13, "knight": 13, "know": [26, 36, 38, 40, 98], "knowledg": [24, 25, 26, 40], "known": [17, 24, 26, 36, 37, 40, 57, 92], "korean": 92, "kt": 21, "kt_cpuinfer": [13, 20, 25, 26, 27, 28, 36, 37], "kt_max_deferred_experts_per_token": [13, 20, 25, 26, 27, 28, 36, 37], "kt_method": [13, 20, 25, 26, 27, 28, 36, 37], "kt_num_gpu_expert": [13, 20, 25, 26, 27, 28, 36, 37], "kt_threadpool_count": [13, 20, 25, 26, 27, 28, 36, 37], "kt_weight_path": [13, 20, 25, 26, 27, 28, 36, 37], "kubectl": [56, 79, 80, 83], "kubernet": [11, 21, 82], "kv": [1, 6, 10, 11, 13, 15, 16, 21, 23, 29, 30, 34, 36, 44, 50, 57, 60, 70, 74, 92], "kv16": 18, "kv4": [1, 18], "kv8": 18, "kv_cach": [18, 23], "kv_cache_dtyp": [13, 20, 25, 26, 27, 28, 30, 36, 37], "kv_events_config": [13, 20, 25, 26, 27, 28, 36, 37], "kvcach": [10, 11, 15, 16, 21, 34, 36, 48, 49], "kwarg": 99, "l": [16, 26, 38, 46, 81, 90], "l0": 22, "l1": [11, 22], "l12": 33, "l15": 33, "l2": 11, "l27": 33, "l31": 33, "l34": 33, "l38": 33, "l3a": 36, "l4": [22, 56], "l40": [29, 56], "l53": 33, "l57": 33, "l7": 22, "la": 37, "lab": [4, 46, 66, 84, 90, 93, 95], "label": [13, 20, 21, 22, 23, 25, 26, 27, 28, 36, 37, 50, 51, 55, 59, 79, 80, 83, 85, 86, 88, 96], "label1": 21, "label2": 21, "label_0": [22, 88], "label_1": [22, 88], "label_n": 22, "label_token_id": 36, "lack": [17, 49], "lai": 13, "landmark": [24, 26, 37], "landscap": 90, "lang": 77, "languag": [5, 6, 11, 13, 15, 16, 21, 35, 37, 40, 42, 45, 47, 48, 56, 57, 67, 70, 72, 84, 99], "language_onli": [13, 20, 25, 26, 27, 28, 36, 37], "larg": [1, 2, 3, 7, 11, 12, 13, 15, 16, 18, 21, 22, 23, 26, 29, 32, 35, 45, 49, 50, 56, 57, 67, 70, 82, 84, 90, 91, 95, 96], "larger": [3, 11, 12, 13, 15, 16, 18, 21, 24, 26, 28, 29, 30, 46, 67, 70, 71, 73, 90, 92, 95], "largest": [24, 26, 37, 47, 92], "last": [8, 20, 21, 24, 48, 55, 56, 58, 60, 86, 88, 90], "last_gen_throughput": 36, "last_hidden_st": 28, "lastli": 98, "late": 33, "latenc": [3, 7, 11, 13, 15, 21, 22, 23, 29, 30, 32, 45, 49, 50, 51, 53, 57, 59, 85, 90, 91, 95, 96], "latent": [1, 21], "later": [3, 8, 12, 14, 23, 26, 27, 55, 69, 75], "latest": [16, 22, 25, 26, 30, 33, 34, 45, 56, 60, 61, 67, 70, 78, 79, 83, 84, 85, 90, 91, 92, 94], "latter": 11, "launch": [0, 2, 3, 6, 7, 10, 14, 17, 18, 23, 25, 26, 33, 37, 43, 46, 50, 51, 52, 53, 56, 58, 59, 60, 69, 72, 73, 81, 85, 86, 87, 90, 93, 94, 98], "launch_rout": [6, 15, 22, 30, 50, 60, 61, 62, 80, 83, 86], "launch_serv": [1, 2, 3, 4, 5, 6, 7, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 56, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 77, 79, 80, 81, 83, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99], "launch_server_cmd": [13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77], "launcher": 22, "launchkernel": 48, "laundri": 28, "law": 29, "layer": [1, 3, 5, 7, 8, 10, 11, 13, 16, 17, 18, 22, 24, 29, 34, 36, 51, 59, 73, 74, 80, 83, 90, 96, 98], "layer_first": [10, 11, 13, 20, 21, 25, 26, 27, 28, 36, 37], "layer_id": 98, "layerwis": 21, "layerwise_profil": 50, "layout": [5, 7, 11, 21, 70], "lb": [61, 62, 86], "lccl": 93, "ld_library_path": [61, 67], "ld_preload": 67, "le": [22, 85], "lead": [3, 4, 6, 11, 13, 15, 16, 17, 23, 24, 34, 35, 46, 49, 74, 84], "leader": [79, 80, 83], "leadercr": 80, "leadertempl": [79, 80], "leaderworkerset": [79, 80, 83], "leaderworkertempl": [79, 80], "leaf": 11, "leak": 22, "lean": 77, "learn": [0, 1, 4, 19, 21, 26, 37, 40, 57, 58, 84, 91, 92, 95, 96, 97, 98], "least": [1, 13, 16, 21, 27, 46, 77, 79], "leav": [46, 60], "led": 3, "left": [28, 52], "legion": 13, "len": [8, 46, 47, 49, 50, 53, 61, 67, 70, 71], "length": [3, 4, 11, 13, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 40, 41, 42, 45, 46, 47, 48, 49, 50, 61, 62, 69, 73, 77, 80, 83, 90], "less": [12, 15, 37, 49, 50, 84], "let": [8, 20, 21, 22, 23, 24, 26, 27, 40, 98], "letter": [25, 26, 27, 40, 42], "level": [1, 5, 10, 11, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 36, 40, 41, 42, 45, 46, 47, 50, 58, 73, 77, 86, 90, 92, 93], "level0": 61, "level1": 61, "leverag": [7, 11, 19, 36, 58, 84, 92, 99], "lfu": 21, "lg": 92, "lgai": [66, 92], "li": 86, "lib": [13, 20, 22, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 61, 67, 71, 77], "lib64": 67, "libfabr": 15, "libiomp5": 67, "librari": [7, 21, 22, 23, 29, 30, 56, 67, 84, 98], "libtbbmalloc": 67, "libtcmalloc": 67, "licens": 92, "lid": 79, "life": [1, 28, 37], "lifecycl": 22, "lifespan": 77, "lift": 33, "light": [13, 26], "lighter": 22, "lightn": [30, 90], "lightweight": [5, 90], "lightx2v": 90, "like": [1, 2, 3, 4, 7, 8, 11, 12, 13, 16, 17, 20, 23, 24, 26, 27, 29, 32, 36, 37, 44, 48, 50, 51, 59, 60, 67, 73, 79, 85, 89, 90, 91, 96], "likelihood": 40, "lila": 13, "limit": [6, 10, 11, 12, 13, 15, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 36, 37, 40, 41, 42, 45, 47, 49, 50, 69, 73, 74, 75, 77, 79, 80, 83], "limit_mm_data_per_request": [13, 20, 25, 26, 27, 28, 36, 37], "line": [7, 13, 15, 17, 21, 25, 26, 27, 32, 33, 36, 37, 45, 51, 59, 67, 71, 85, 90], "linear": [11, 17, 44, 63, 92], "linearli": 46, "ling": [66, 92], "linguist": 95, "link": [0, 15, 60, 79, 98], "link_lay": 79, "link_up": 79, "linkedin": 78, "linkup": 79, "lint": [0, 51, 59], "linux": [52, 55, 60, 67], "linux64cli": 52, "linux_aarch64": 60, "list": [4, 8, 13, 19, 20, 21, 23, 24, 27, 29, 33, 36, 38, 40, 41, 46, 47, 50, 51, 59, 73, 74, 77, 84, 86, 88, 96, 98], "list_lora": 90, "listen": [19, 21, 90], "lite": [66, 92, 95], "liter": [27, 40], "literatur": 40, "littl": [5, 90], "liuhaotian": [91, 95], "live": [13, 22, 37, 50], "livenessprob": 83, "ll": [20, 26, 27, 40, 50, 79, 90], "llada2": 89, "llada2moemodellm": 89, "llama": [1, 13, 17, 21, 22, 24, 25, 36, 42, 46, 49, 50, 52, 56, 57, 58, 60, 66, 69, 70, 71, 72, 84, 85, 87, 91, 92, 95, 97, 99], "llama2": [24, 95], "llama3": [21, 22, 24, 27, 66, 95], "llama4": [27, 43], "llama4forconditionalgener": 28, "llama_ckpt": 98, "llama_dir": 98, "llama_wrapp": 98, "llamaattent": 98, "llamaconfig": 98, "llamaforcausallm": [13, 98], "llamaforsequenceclassif": [88, 97], "llamaforsequenceclassificationwithnormal_weight": 88, "llamamlp": 98, "llamawrapp": 98, "llava": [42, 46, 66, 91, 95], "llavavid": 95, "llguidanc": [21, 25], "llm": [4, 5, 7, 11, 15, 16, 18, 20, 22, 24, 25, 26, 27, 28, 30, 32, 34, 37, 38, 49, 56, 58, 61, 63, 66, 67, 70, 71, 75, 84, 89, 92, 93, 95, 98], "llmcompressor": 17, "llvm": 48, "lm": [21, 61, 62, 80, 83], "lm_head": [13, 17, 24, 98], "lmcach": 11, "lmdeploi": 49, "lmhead": 24, "lmm": [46, 66, 95], "lmsy": [24, 27, 33, 74, 78, 81, 84], "lmsysorg": [22, 30, 52, 55, 56, 58, 60, 78, 80, 83, 90, 94], "ln": 3, "lo": [61, 62], "load": [2, 6, 7, 8, 11, 12, 15, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 36, 37, 40, 41, 42, 46, 47, 48, 49, 50, 61, 62, 63, 67, 72, 77, 80, 84, 85, 90, 99], "load_balance_method": [13, 20, 25, 26, 27, 28, 36, 37], "load_config": 17, "load_dataset": 17, "load_decod": 90, "load_encod": 90, "load_format": [13, 20, 21, 23, 25, 26, 27, 28, 36, 37], "load_imag": [46, 77], "load_jit": 48, "load_lora_adapt": 13, "load_model": 17, "loadconfig": 17, "loaded_adapt": [13, 90], "loader": [17, 19, 23, 98], "local": [0, 13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 36, 38, 40, 41, 42, 47, 49, 51, 52, 56, 59, 60, 61, 62, 67, 70, 77, 89, 90, 92, 93, 95, 97, 98], "local_attention_s": 21, "local_dir": 98, "local_host": 61, "local_host1": [61, 62], "local_host2": [61, 62], "local_input_imag": 90, "local_ip": [15, 30], "localattent": 90, "localhost": [2, 4, 13, 14, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 70, 77, 85, 90, 95], "locat": [0, 11, 21, 22, 23, 24, 25, 26, 27, 28, 37, 46, 47, 48, 50, 52, 67, 80, 83], "lock": 22, "lof": 21, "log": [2, 8, 10, 12, 13, 20, 24, 25, 26, 27, 32, 36, 40, 41, 42, 45, 46, 47, 56, 67, 73, 77, 79, 83, 85, 90, 93], "log_level": [13, 20, 25, 26, 27, 28, 36, 37], "log_level_http": [13, 20, 25, 26, 27, 28, 36, 37], "log_request": [13, 20, 25, 26, 27, 28, 36, 37], "log_requests_format": [13, 20, 25, 26, 27, 28, 36, 37], "log_requests_level": [13, 20, 25, 26, 27, 28, 36, 37], "log_requests_target": [13, 20, 25, 26, 27, 28, 36, 37], "logger": [8, 21], "logic": [3, 7, 8, 16, 22, 23, 27, 40, 46, 88], "login": [56, 85], "logit": [21, 22, 29, 31, 32, 73, 98], "logit_bia": 40, "logits_processor": 98, "logitsprocessor": 98, "logitsprocessoroutput": 98, "logo": [42, 90], "logprob": [4, 21, 24, 27, 29, 40, 42, 46, 47, 74, 75, 80, 83, 96], "logprob_start_len": [46, 74], "london": [24, 25, 26, 36, 40, 75, 77], "long": [0, 3, 10, 11, 12, 13, 18, 21, 22, 23, 24, 29, 49, 50, 57, 74, 92, 95], "longer": [11, 15, 16, 18, 21, 40, 51, 52, 59, 73, 75], "longest": 12, "look": [3, 8, 12, 25, 26, 30, 37, 48, 49, 51, 59, 71, 72, 77, 98], "loop": [16, 22, 23, 37, 77, 90], "lora": [46, 49, 57, 70, 84, 95], "lora0": 13, "lora0_new": 13, "lora1": [13, 90], "lora2": [13, 90], "lora3": 13, "lora_1": 90, "lora_2": 90, "lora_a": 90, "lora_b": 90, "lora_backend": [13, 20, 25, 26, 27, 28, 36, 37], "lora_eviction_polici": [13, 20, 25, 26, 27, 28, 36, 37], "lora_id": 13, "lora_nam": [13, 21, 90], "lora_nicknam": 90, "lora_path": [13, 20, 21, 25, 26, 27, 28, 36, 37, 40, 46, 49, 90], "lora_target_modul": [13, 20, 25, 26, 27, 28, 36, 37], "loraref": 13, "lose": 15, "loss": [13, 17, 90], "lot": [51, 59], "loui": 36, "louvr": [24, 36, 37], "love": [13, 22, 26, 37, 88], "low": [3, 7, 11, 12, 21, 24, 26, 29, 33, 40, 46, 49, 50, 53, 57, 74, 96], "low_lat": [7, 21, 61, 62, 83], "lowconfid": [21, 89], "lower": [1, 5, 11, 12, 17, 18, 21, 22, 29, 32, 40, 51, 59, 70, 73, 74, 89, 90, 98], "lowercas": 90, "lpm": [12, 21], "lru": [13, 20, 21, 25, 26, 27, 28, 36, 37], "lru_cach": [24, 98], "lsb": 50, "lsof": 85, "lspci": 79, "lssf": 67, "lt": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "lustr": 50, "lw": [30, 79, 82, 83], "lws_group_siz": [79, 80, 83], "lws_leader_address": [79, 80, 83], "lws_worker_index": [79, 80, 83], "lyon": [26, 37], "m": [1, 2, 3, 4, 5, 6, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 77, 79, 80, 81, 83, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99], "m2": [43, 53, 92], "m3": [36, 66, 96], "ma": 27, "maas_hosted_model": 80, "machin": [1, 4, 21, 30, 37, 51, 52, 56, 58, 59, 60, 85, 87, 96, 98], "made": [13, 16, 36, 37], "madrid": [24, 40], "magic": [13, 77], "magnific": [13, 40], "magnitud": 37, "mai": [11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 30, 33, 36, 37, 49, 50, 51, 52, 53, 58, 59, 67, 74, 77, 79, 80, 83, 86, 90, 91, 94, 95, 96, 97], "main": [2, 4, 5, 16, 26, 28, 32, 36, 37, 42, 45, 46, 49, 51, 59, 60, 67, 71, 77, 80, 83, 86, 89, 90, 91, 95, 98], "main_doc": [80, 83], "mainli": [11, 21, 36], "mainstream": [61, 66], "maintain": [4, 11, 16, 18, 21, 35, 37, 51, 59, 70, 86, 90, 98], "major": [11, 24, 25, 26, 30, 37, 40, 51, 59, 79, 84, 98], "make": [0, 1, 3, 4, 12, 21, 22, 23, 25, 26, 27, 28, 29, 35, 36, 37, 40, 50, 51, 59, 60, 79, 84, 88, 89, 96, 98], "make_cpp_arg": 48, "make_hook": 21, "malakai": 13, "malform": 8, "mamba": [92, 95], "mamba_full_memory_ratio": [13, 20, 25, 26, 27, 28, 36, 37], "mamba_scheduler_strategi": [13, 20, 25, 26, 27, 28, 36, 37], "mamba_ssm_dtyp": [13, 20, 25, 26, 27, 28, 36, 37], "mamba_track_interv": [13, 20, 25, 26, 27, 28, 36, 37], "mambaradixcach": 44, "man": 42, "manag": [2, 7, 10, 14, 15, 16, 17, 21, 23, 27, 56, 67, 70], "mani": [1, 3, 11, 12, 13, 16, 21, 22, 23, 28, 29, 36, 37, 40, 49, 50, 51, 59, 67, 74, 75, 87, 96, 98], "manifest": 21, "manner": [24, 46], "mantissa": 18, "manual": [0, 23, 29, 34, 50, 51, 59, 69, 86, 90, 94], "manufactur": 37, "manylinux2014_aarch64": 56, "manylinux2014_x86_64": 56, "map": [21, 22, 23, 24, 52, 85, 88], "mar": 40, "marbl": 13, "marcu": 13, "margin": 11, "mark": [15, 21, 26, 86], "markdown": [0, 90], "marker": 21, "market": [33, 37], "marlin": [17, 21, 73], "marseil": 26, "martel": 36, "mask": [7, 46, 73], "mask_strategi": 90, "mask_strategy_file_path": 90, "massachusett": 27, "master": [2, 13, 23], "master_address": 23, "master_node_ip": 16, "master_port": 23, "match": [1, 3, 8, 12, 21, 22, 23, 25, 26, 27, 30, 34, 36, 38, 46, 48, 53, 56, 70, 73, 85, 90, 98], "matched_stop": [24, 27, 29, 40, 42, 47, 80, 83], "matchlabel": [22, 80], "materi": [77, 78], "math": [49, 66, 77, 92, 97], "mathemat": 74, "matrix": [7, 29, 57, 73], "matryoshka_dimens": 91, "matter": [13, 18, 90], "maturin": 22, "maverick": 34, "max": [3, 7, 13, 15, 16, 21, 22, 24, 29, 30, 32, 36, 44, 45, 49, 53, 60, 61, 62, 67, 70, 73, 74, 79, 80, 83, 87, 90, 95], "max_concurr": [49, 70], "max_connect": 22, "max_content_len": 3, "max_delay_pass": 21, "max_execution_time_m": 22, "max_export_batch_s": 73, "max_fram": 95, "max_gen_tok": 34, "max_len": 3, "max_loaded_lora": [13, 20, 25, 26, 27, 28, 36, 37], "max_lora_chunk_s": [13, 20, 25, 26, 27, 28, 36, 37], "max_lora_rank": [13, 20, 25, 26, 27, 28, 36, 37], "max_loras_per_batch": [13, 20, 25, 26, 27, 28, 36, 37], "max_mamba_cache_s": [13, 20, 25, 26, 27, 28, 36, 37], "max_memory_pag": 22, "max_model_len": 36, "max_new_token": [4, 12, 13, 17, 20, 25, 26, 27, 46, 47, 62, 89], "max_pixel": 95, "max_position_embed": 24, "max_prefill_token": [12, 13, 20, 25, 26, 27, 28, 36, 37, 79], "max_queued_request": [13, 20, 25, 26, 27, 28, 36, 37], "max_req_input_len": 36, "max_running_request": [12, 13, 20, 25, 26, 27, 28, 36, 37, 79, 89], "max_stack_s": 22, "max_token": [24, 25, 26, 27, 29, 31, 32, 40, 42, 45, 46, 47, 53, 77, 80, 83, 95], "max_total_num_token": [12, 13, 36, 79], "max_total_token": [13, 20, 24, 25, 26, 27, 28, 36, 37], "maxim": [1, 7, 11, 12, 13, 22, 23, 24, 70], "maximum": [1, 3, 12, 13, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 36, 37, 40, 41, 42, 45, 46, 47, 53, 67, 70, 73, 74, 77, 90, 96], "maxium": 84, "maxsurg": 80, "maxunavail": 80, "mayb": [24, 26], "mb": 73, "mc": 90, "mc_force_mnnvl": 15, "mc_te_metr": [80, 83], "mcdse": 57, "mcp": 33, "md": [0, 30, 32, 51, 59, 98], "me": [4, 22, 24, 25, 26, 37, 38, 40, 77], "meal": 77, "mean": [7, 11, 12, 15, 16, 21, 22, 25, 26, 27, 30, 36, 49, 58, 67, 73, 90, 95, 96, 99], "meaning": 88, "meant": 13, "measur": [46, 49, 53, 70], "mechan": [11, 16, 17, 23, 29, 30, 91, 97], "medatada": 1, "median": [13, 49], "mediev": 37, "medium": [33, 53, 79, 80, 83, 90], "meet": [11, 21, 26, 37, 78, 98], "megatron": [84, 92], "meituan": 67, "melanoleuca": [36, 96], "mellanox": 79, "mem": [10, 11, 13, 15, 16, 21, 24, 29, 30, 31, 32, 34, 35, 36, 45, 50, 61, 62, 64, 69, 70, 73, 74, 79, 80, 81, 83], "mem_fraction_stat": [12, 13, 20, 25, 26, 27, 28, 36, 37], "member": [80, 98], "memfabr": [15, 62], "memfabric_hybrid": 15, "memori": [1, 3, 6, 7, 11, 13, 15, 16, 24, 29, 32, 34, 36, 44, 45, 50, 67, 69, 79, 80, 83, 90, 95], "memory_usag": 36, "mention": 26, "mere": 19, "merg": [22, 29, 36, 49, 50, 60, 95], "merge_lora_weight": 90, "merge_profil": 50, "merged_output": 37, "merger": 3, "messag": [8, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 35, 36, 38, 40, 42, 45, 46, 47, 49, 80, 83, 88, 95], "messages_requir": 27, "messages_specif": 27, "met": [13, 37], "meta": [1, 2, 4, 13, 15, 17, 21, 22, 24, 25, 27, 28, 34, 46, 49, 50, 52, 56, 58, 60, 66, 67, 69, 71, 72, 81, 85, 87, 92, 95, 98, 99], "meta_info": [25, 26, 36, 47, 96], "metadata": [1, 2, 8, 10, 16, 21, 22, 24, 27, 40, 42, 47, 50, 73, 79, 80, 83, 95], "metal": 67, "method": [2, 7, 10, 16, 21, 22, 23, 24, 29, 30, 38, 40, 46, 48, 50, 58, 61, 62, 63, 68, 76, 84, 95, 98], "methodologi": [19, 92], "metric": [10, 21, 30, 32, 45, 53, 57, 62, 73, 90], "metropolitan": 26, "mha": [11, 18, 30], "mha_one_shot": 30, "mi300": 57, "mi300x": [29, 58, 90], "mi30x": 90, "mi325x": 90, "mi350": 30, "mi355": [30, 57], "mi355x": 29, "miami": 28, "micro": [7, 16, 21], "microsc": 18, "microservic": 22, "microsoft": [52, 66, 92, 95], "mid": [24, 33], "middl": [24, 37], "might": [13, 14, 17, 26, 28, 36, 46, 52, 56, 71, 73, 74, 85], "migrat": 88, "mild": [40, 96], "mile": [23, 57, 84], "millard": 75, "million": 26, "mimo": [24, 66, 92, 95], "min": [0, 11, 21, 33, 46, 51, 59], "min_new_token": 46, "min_p": 46, "mind": [0, 51, 59], "mindspor": 57, "mini": [61, 62, 86, 89, 92, 95], "minicpm": [66, 92, 95], "minicpm3": [66, 92], "minim": [7, 8, 11, 16, 18, 24, 51, 59, 70, 90, 95], "minimax": [22, 53, 57, 92], "minimaxai": 35, "minimum": [17, 21, 22, 29, 30, 51, 59, 90], "minist": 26, "ministri": 77, "minor": [13, 21, 51, 59], "minut": [12, 13, 14, 15, 19, 22, 29, 36, 51, 59, 77], "mirror": 22, "misalign": 16, "misconfigur": 8, "misinform": 36, "mislead": [28, 75], "mismatch": [23, 36, 93], "miss": [8, 49, 72, 88], "mission": [37, 40], "misti": 13, "mistral": [21, 22, 27, 57, 66, 91, 92, 95], "mistralai": [27, 66, 92, 95], "mitig": [11, 13, 16, 23, 34], "mix": [1, 7, 17, 21, 28, 37, 70], "mix_ip": 61, "mixtral": 92, "mixtur": [7, 29, 67, 89, 92], "ml": [56, 79, 90], "mla": [11, 18, 21, 70, 92], "mlc": 25, "mllm": [21, 98], "mlp": [3, 8, 17, 21, 73, 95], "mlx5_0": [10, 21, 80, 83], "mlx5_1": [21, 83], "mlx5_2": 83, "mlx5_3": 83, "mlx5_4": 83, "mlx5_5": [80, 83], "mlx5_6": [80, 83], "mlx5_7": 83, "mlx5_bond_0": [30, 79, 80], "mlx5_bond_1": [30, 79, 80], "mlx5_bond_2": [30, 79, 80], "mlx5_bond_3": [30, 79, 80], "mlx5_roce0": 15, "mm": [1, 5, 21, 24, 32, 45, 60, 64, 90, 95], "mm_attention_backend": [13, 20, 25, 26, 27, 28, 36, 37], "mm_enable_dp_encod": [13, 20, 25, 26, 27, 28, 36, 37], "mm_fp4": 73, "mm_item": 28, "mm_max_concurrent_cal": [13, 20, 25, 26, 27, 28, 36, 37], "mm_per_request_timeout": [13, 20, 25, 26, 27, 28, 36, 37], "mm_process_config": [13, 20, 25, 26, 27, 28, 36, 37], "mmap": 21, "mmlu": [34, 53, 98], "mmlu_pro": 34, "mmmu": [49, 53, 98], "mnt": 61, "mobil": [92, 95], "mocked_fake_id_for_offline_gener": 90, "mod_part": 8, "modal": [32, 34, 45, 49, 57, 73, 91, 95], "mode": [1, 2, 4, 6, 7, 8, 10, 16, 20, 21, 23, 30, 34, 36, 37, 40, 49, 52, 53, 60, 61, 67, 69, 73, 74, 79, 80, 83, 87], "model": [0, 1, 2, 6, 7, 10, 11, 12, 13, 15, 16, 18, 19, 23, 24, 25, 30, 31, 32, 33, 34, 37, 38, 42, 44, 45, 46, 47, 50, 51, 52, 55, 56, 58, 59, 62, 63, 64, 65, 69, 72, 75, 77, 79, 80, 81, 83, 84, 85, 87, 99], "model_arch_name_to_cl": 98, "model_arg": 34, "model_checksum": [13, 20, 25, 26, 27, 28, 36, 37], "model_class": 98, "model_config": [17, 24, 36, 41, 98], "model_dump_json": 25, "model_executor": 98, "model_id": [17, 22], "model_id_or_path": [67, 71], "model_impl": [13, 20, 25, 26, 27, 28, 36, 37, 93], "model_info": [13, 36, 77], "model_json_schema": [25, 26], "model_load": [17, 98], "model_loader_extra_config": [13, 20, 25, 26, 27, 28, 36, 37], "model_nam": [17, 20, 27, 30, 36, 85, 88, 98], "model_name_tool_choic": 27, "model_path": [10, 13, 17, 20, 23, 25, 26, 27, 28, 36, 37, 61, 62, 70, 81, 89, 90, 93, 98], "model_path_or_id": 90, "model_typ": 36, "model_valid": 25, "model_validate_json": 25, "modelconfig": 17, "modelcontextprotocol": 22, "modelopt": [7, 18, 21], "modelopt_checkpoint_restore_path": [13, 17, 20, 25, 26, 27, 28, 36, 37], "modelopt_checkpoint_save_path": [13, 17, 20, 25, 26, 27, 28, 36, 37], "modelopt_export_path": [13, 17, 20, 25, 26, 27, 28, 36, 37], "modelopt_fp4": [1, 17, 21], "modelopt_fp8": [17, 21], "modelopt_qu": [13, 20, 25, 26, 27, 28, 36, 37], "modelopt_quantize_and_export": 17, "modelregistri": 98, "modelrunn": [8, 98], "modelscop": [49, 57, 66, 73], "modelslim": [21, 61, 62, 63], "moder": [40, 77, 97], "modern": [6, 11, 24, 37, 84], "modif": [22, 51, 59, 79], "modifi": [3, 7, 8, 17, 22, 23, 40, 50, 51, 52, 56, 59, 60, 79, 80, 85, 90, 98], "modul": [7, 8, 10, 11, 13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 48, 50, 52, 77, 90, 98, 99], "modular": [7, 84, 90], "module_cache_s": 22, "module_nam": 8, "module_path": [10, 11, 21], "module_typ": [8, 22], "module_uuid": 22, "moe": [1, 15, 17, 23, 29, 30, 35, 46, 61, 62, 63, 66, 67, 70, 73, 80, 83, 84, 89, 92, 93, 95], "moe_a2a_backend": [13, 20, 25, 26, 27, 28, 30, 36, 37], "moe_dense_tp_s": [13, 20, 25, 26, 27, 28, 30, 36, 37], "moe_runn": 7, "moe_runner_backend": [13, 20, 25, 26, 27, 28, 36, 37], "moe_wna16": 21, "moerunn": 7, "moerunnercor": 7, "moment": 96, "monitor": [2, 23, 83, 85, 86], "mont": 52, "mood": [77, 90], "mooncak": [6, 7, 11, 13, 20, 21, 25, 26, 27, 28, 36, 37, 49, 60], "mooncake_devic": 10, "mooncake_global_segment_s": 10, "mooncake_ib_devic": [13, 20, 25, 26, 27, 28, 36, 37], "mooncake_mast": 10, "mooncake_protocol": 10, "mooncake_te_meta_data_serv": 10, "moonshot": 92, "moonshotai": [27, 92, 95], "more": [2, 3, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 36, 37, 40, 42, 44, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 67, 71, 73, 74, 77, 79, 86, 89, 90, 91, 93, 95, 96, 98, 99], "morgan": 33, "most": [0, 1, 5, 11, 12, 13, 26, 27, 29, 33, 37, 40, 50, 51, 57, 59, 67, 72, 77, 79, 90, 98, 99], "mostli": 74, "motlei": 33, "mount": [52, 55], "mountain": [13, 90], "mountpath": [79, 80, 83], "move": [10, 11, 16, 23, 37, 73, 95], "movement": [11, 13], "movi": 37, "mp4": [32, 45, 90, 95], "mrl": 91, "ms_enable_lccl": 93, "mscclpp": 21, "msg": 24, "mt": 24, "mt43244": 79, "mtp": [7, 24, 29, 30, 73], "much": [0, 11, 12, 16, 26, 51, 59, 98], "muggl": 77, "mul": 73, "multi": [1, 10, 13, 16, 23, 28, 32, 34, 45, 56, 57, 71, 73, 79, 90, 93, 95, 98], "multi_item_scoring_delimit": [13, 20, 25, 26, 27, 28, 36, 37], "multi_modal_item": 28, "multi_modal_projector": 28, "multi_node_deploy": 30, "multi_turn_qa": 77, "multiformatpars": 27, "multilingu": [91, 92, 97], "multimod": [1, 3, 6, 21, 28, 32, 34, 42, 45, 57, 64, 77, 92], "multimodal_gen": 90, "multimodal_language_model": 98, "multimodal_processor": 98, "multimodaldataitem": 73, "multipart": 90, "multipl": [1, 2, 5, 6, 7, 11, 15, 16, 21, 22, 24, 27, 29, 30, 33, 40, 46, 49, 50, 51, 59, 70, 73, 77, 81, 86, 90, 92, 93, 95, 98], "multipli": [16, 22], "multiprocessingseri": 23, "muscl": 77, "museum": [24, 26, 37], "must": [1, 6, 8, 11, 13, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 38, 46, 48, 50, 51, 59, 79, 86, 90, 98], "mus\u00e9": 37, "mutual": [22, 50, 90], "mv": [58, 60, 68], "mvbench": 53, "mxfp4": [7, 17, 18, 21, 29], "my": [2, 21, 24, 26, 37, 51, 59, 93, 98], "my_checkpoint": 17, "my_middlewar": 22, "my_model": 72, "my_model_templ": 72, "my_packag": 21, "my_project": 8, "myattent": 99, "myhuaweicloud": 60, "mymodel": 99, "mystic": 13, "n": [1, 4, 11, 13, 20, 21, 22, 24, 25, 26, 27, 30, 36, 37, 38, 40, 46, 47, 48, 49, 67, 71, 77, 80, 81, 83, 90, 91, 96], "n1": [24, 40, 47], "n10": 40, "n2": [24, 40, 47], "n3": [24, 40, 47], "n4": 40, "n5": 40, "n6": 40, "n7": 40, "n8": 40, "n9": 40, "na": [60, 61], "name": [0, 2, 10, 11, 13, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 67, 70, 71, 72, 75, 77, 79, 80, 83, 85, 86, 88, 90, 93, 98], "name1": 49, "name2": 49, "name_non_stream": 27, "name_to_modul": 8, "named_modul": [8, 21], "named_tensor": 23, "namespac": [22, 48, 83, 90], "nan": [21, 36], "nano": [92, 95], "nanoth": 24, "narrow": 13, "nativ": [1, 7, 11, 13, 22, 23, 33, 46, 49, 57, 70, 79, 84, 90, 92, 95], "natur": [6, 11, 23, 40, 51, 59], "naur": 27, "navig": 85, "navit": 95, "nbefor": 36, "nbetween": 36, "nbstripout": 0, "nbut": 24, "nc": 81, "ncapit": 24, "nccl": [13, 20, 21, 23, 25, 26, 27, 28, 29, 36, 37, 73, 74, 79, 80, 81, 83], "nccl_debug": 79, "nccl_ib_gid_index": [52, 58, 79, 83], "nccl_ib_hca": [80, 83], "nccl_ib_qps_per_connect": [80, 83], "nccl_ib_sl": [80, 83], "nccl_ib_split_data_on_qp": [80, 83], "nccl_ib_tc": [80, 83], "nccl_ib_timeout": 83, "nccl_init_addr": 81, "nccl_min_nchannel": [80, 83], "nccl_net_plugin": [80, 83], "nccl_port": [13, 20, 25, 26, 27, 28, 36, 37], "nccl_socket_ifnam": [79, 83], "ncontent": 26, "ndescrib": 46, "ndetoken": 36, "ndr": 79, "ndv5": 58, "nearbi": 77, "nearest": 16, "nearli": 58, "necessari": [11, 26, 56, 59, 74, 79, 98], "necessarili": [26, 90], "necessit": 16, "need": [1, 2, 3, 4, 7, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 40, 48, 49, 50, 51, 52, 55, 58, 59, 60, 63, 67, 70, 72, 74, 77, 79, 80, 83, 84, 85, 86, 90, 91, 93, 94, 95, 98, 99], "neg": [40, 46, 73, 90], "negat": 18, "nemo": [27, 30, 92], "nemo_skills_aime25_": 30, "nemo_skills_disable_uncommitted_changes_check": 30, "nemotron": [92, 95], "nest": 86, "nest_asyncio": [28, 37], "netdev": 79, "network": [2, 22, 36, 52, 58, 60, 67, 69, 74, 79, 80, 83, 85, 96], "networkconfig": 80, "neural": [36, 96], "neuralmag": 17, "neutral": [37, 98], "never": [13, 37], "new": [0, 3, 10, 11, 12, 13, 19, 21, 22, 23, 25, 26, 28, 33, 36, 37, 40, 46, 51, 54, 55, 57, 59, 67, 70, 73, 79, 80, 86, 88, 92], "new2": 90, "new_token_ratio": 12, "new_york": [25, 26], "newer": [56, 67], "newfound": 13, "newli": [11, 30, 98], "newmodeldetector": 27, "next": [11, 16, 20, 23, 24, 26, 27, 43, 46, 48, 66, 86, 90, 92, 95, 96, 98], "next_token_logit": 98, "nextn": [21, 44, 61, 62, 73], "nf": 50, "ngener": [25, 26, 37], "nhere": 26, "nhmm": 26, "nhttp": 36, "ni": [24, 26], "nic": [11, 79], "nice": 37, "nicknam": 90, "night": 13, "nightli": [56, 60, 90], "nimag": 28, "ninth": 40, "nixl": [11, 21], "nlp": [36, 41, 66, 91, 92], "nn": [8, 79, 99], "nnal": [60, 61, 62], "nnext": 26, "nnode": [2, 13, 15, 16, 20, 21, 25, 26, 27, 28, 30, 36, 37, 61, 62, 70, 79, 80, 81, 83, 93], "nnow": 26, "no_answ": 30, "no_buff": [13, 20, 21, 25, 26, 27, 28, 36, 37, 44], "no_grad": 98, "no_proxi": 22, "no_stop_trim": [27, 46], "node": [10, 11, 16, 19, 22, 23, 24, 30, 36, 56, 57, 61, 62, 73, 79, 80, 83, 86, 90, 93], "node0_ip": 70, "node1": 79, "node_rank": [13, 20, 25, 26, 27, 28, 36, 37, 61, 62], "nodeport": [80, 83], "nodeselector": [80, 83], "nohealthywork": 22, "nois": [4, 22, 90], "nokai": 24, "non": [1, 8, 16, 21, 22, 23, 38, 40, 48, 49, 51, 59, 73, 77, 88, 89, 98], "nondeterminist": 74, "none": [7, 8, 13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 46, 47, 62, 73, 80, 83, 90, 98], "norm": 21, "normal": [1, 7, 20, 21, 22, 27, 36, 61, 62, 70, 83, 86, 90], "normal_text": [22, 27], "northern": 24, "notabl": [26, 28, 67], "notablefact": 26, "notat": 26, "note": [11, 12, 13, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 34, 36, 37, 38, 40, 41, 42, 47, 48, 51, 52, 55, 58, 59, 67, 70, 71, 72, 73, 77, 79, 80, 81, 83, 86, 88, 93, 94, 96, 98], "notebook": [0, 13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77], "noth": [13, 21], "notic": [16, 60, 74, 79, 80], "notr": 37, "nousresearch": 58, "novel": [19, 40], "now": [1, 21, 24, 26, 33, 36, 40, 48, 50, 52, 58, 77, 88, 98], "nowadai": [51, 59], "noyon": 36, "npcach": 21, "nproc": 2, "nprompt": [37, 98], "npu": [1, 7, 21, 30, 56, 57, 62, 64, 93], "nput": 26, "npx": 22, "nround": 36, "nsa": [1, 21, 30, 61], "nsa_decode_backend": [13, 20, 25, 26, 27, 28, 36, 37], "nsa_prefill_backend": [13, 20, 25, 26, 27, 28, 36, 37], "nsa_prefill_cp_mod": [13, 20, 25, 26, 27, 28, 36, 37], "nsight": 21, "nsy": [50, 52, 90], "ntask": 81, "nthe": 24, "ntoken": 36, "null": [13, 20, 21, 25, 26, 27, 28, 29, 36, 37, 41, 42, 56, 80, 83, 88, 90], "num": [21, 24, 29, 30, 31, 34, 44, 49, 50, 51, 52, 53, 58, 59, 61, 62, 64, 67, 70, 71, 80, 83, 85, 90], "num_block": 48, "num_choic": 24, "num_class": [22, 88], "num_concurr": 34, "num_continuous_decode_step": [13, 20, 25, 26, 27, 28, 36, 37], "num_el": 48, "num_entri": 30, "num_fewshot": 34, "num_fram": [90, 95], "num_gpu": 90, "num_hidden_lay": 50, "num_inference_step": 90, "num_key_value_head": 50, "num_lay": [40, 46], "num_lora_layers_with_weight": 90, "num_paused_request": [23, 36], "num_prompt": 70, "num_prompts_per_concurr": 70, "num_quest": 62, "num_queue_req": 85, "num_reserved_decode_token": [13, 20, 25, 26, 27, 28, 36, 37], "num_running_req": 85, "num_shot": 62, "num_stag": 24, "num_step": 50, "num_thread": 48, "num_token": [40, 46], "num_token_to_fetch": 11, "num_triton_choic": 24, "num_used_token": 85, "num_warp": 24, "numa": [21, 67], "numa_balanc": [58, 60, 61, 62], "numa_nod": [13, 20, 25, 26, 27, 28, 36, 37], "number": [1, 2, 3, 11, 12, 13, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 59, 67, 70, 73, 77, 85, 86, 88, 89, 90, 96], "numer": [29, 36, 74], "numexpr": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "numexpr_max_thread": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "numpi": [21, 49], "nurgaliyev": 69, "nutanix": 13, "nutrient": 77, "nv": 69, "nvda": 33, "nvfp4": [7, 17, 18, 21, 29, 73], "nvfp4_awq": 21, "nvidia": [1, 7, 18, 21, 29, 30, 33, 34, 50, 51, 55, 56, 57, 59, 73, 79, 80, 83, 90, 92, 95], "nvidia_h100_80gb_hbm3": 36, "nvidia_h100_80gb_hbm3_down": 36, "nvila": 95, "nvl": 21, "nvl72": [15, 29], "nvme": 52, "nvpmodel": 69, "nvrtc": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 73, 77], "nvshmem_bootstrap_uid_sock_ifnam": 83, "nvshmem_disable_p2p": 83, "nvshmem_enable_nic_pe_map": 80, "nvshmem_hca_list": 80, "nvshmem_hca_pe_map": 80, "nvshmem_ib_gid_index": [80, 83], "nvshmem_ib_sl": 83, "nvshmem_ib_traffic_class": [80, 83], "nvtx": 21, "nwait": [24, 26], "ny": [25, 26, 27], "nyc": 22, "nyou": 46, "n\u00fa\u00f1ez": 69, "n\u4f60\u597d\u5440": [80, 83], "n\u55ef": [80, 83], "n\u6211\u7684\u4efb\u52a1\u5c31\u662f\u966a\u4f60\u804a\u5929": [80, 83], "n\u7528\u6237\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u80cc\u666f\u4fe1\u606f": [80, 83], "n\u7528\u6ce2\u6d6a\u7ebf\u7ed3\u5c3e\u53ef\u4ee5\u8f6f\u5316\u8bed\u6c14": [80, 83], "n\u8003\u8651\u5230\u4e2d\u6587\u7528\u6237": [80, 83], "o": [10, 11, 15, 22, 23, 24, 25, 26, 41, 46, 50, 52, 55, 60, 66, 81, 90, 95], "o_proj": [13, 21], "oai": [49, 61], "oai_serv": 22, "ob": 60, "object": [5, 8, 11, 21, 22, 24, 25, 26, 27, 29, 37, 40, 41, 42, 46, 47, 48, 49, 80, 83, 88, 90, 96], "observ": [18, 24, 57, 86], "obstacl": [3, 13], "obtain": [11, 16, 24, 27, 36, 75, 79, 86], "occasion": [12, 96], "occup": [37, 50, 77], "occur": [12, 13, 36, 46, 74], "ocp": 18, "ocr": 95, "odd": [13, 28, 49], "odel": 20, "oder": 36, "ofassistantgener": 25, "ofed_info": 79, "off": [7, 13, 22, 24, 29, 44, 58, 73, 89, 90, 91, 93], "offer": [7, 16, 46, 92, 95, 96, 97], "offic": 26, "offici": [21, 22, 24, 26, 29, 30, 34, 36, 51, 52, 58, 59, 67, 72, 80, 93], "offlin": [15, 18, 42, 50, 53, 57, 60, 63], "offload": [10, 11, 23, 90], "offload_group_s": [13, 20, 25, 26, 27, 28, 36, 37], "offload_mod": [13, 20, 25, 26, 27, 28, 36, 37], "offload_num_in_group": [13, 20, 25, 26, 27, 28, 36, 37], "offload_prefetch_step": [13, 20, 25, 26, 27, 28, 36, 37], "offset": 23, "often": [7, 11, 22, 23, 26, 29, 36, 73, 97], "ok": [13, 22, 36, 79], "okai": [12, 26, 40], "old": [13, 37, 40], "older": 79, "ollama": 57, "ollama_host": 38, "olmo": [66, 92], "om": 56, "omit": [23, 40, 48, 75, 91], "omni": 95, "onboard": 22, "onc": [1, 8, 11, 13, 23, 27, 36, 41, 42, 47, 51, 52, 59, 60, 67, 75, 79, 87, 90], "oncal": [51, 59], "ondemand": 60, "one": [1, 8, 11, 13, 15, 16, 20, 21, 22, 25, 26, 27, 28, 30, 33, 34, 36, 40, 42, 46, 47, 49, 50, 51, 56, 58, 59, 60, 67, 68, 73, 74, 75, 85, 90, 91, 99], "oneshot": 17, "onevis": [42, 46, 66, 95], "ongo": [15, 23, 34, 50], "onli": [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 34, 35, 38, 46, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 69, 71, 73, 74, 75, 77, 79, 90, 92, 93, 95, 98], "onlin": [29, 49, 50, 81], "only_run": 98, "onrequest": 22, "onrespons": 22, "onto": 56, "oom": [12, 34, 74, 95], "op": [5, 11, 21, 60], "op_api": 61, "open": [0, 18, 22, 24, 28, 34, 50, 51, 52, 53, 56, 57, 58, 59, 61, 67, 68, 84, 85, 90, 92, 95], "openai": [21, 24, 29, 31, 33, 35, 36, 46, 49, 57, 66, 67, 70, 71, 72, 75, 77, 88, 91, 92, 95], "openai_api_complet": 13, "openai_api_kei": [49, 55], "openapi": 47, "openbmb": [66, 92, 95], "openssl": 22, "opentelemetri": [21, 86], "oper": [1, 3, 4, 7, 10, 11, 15, 18, 20, 21, 22, 23, 24, 29, 30, 36, 50, 51, 56, 59, 60, 62, 67, 70, 73, 77, 80, 83, 91], "operation_duration_second": 22, "operations_tot": 22, "opinion": 37, "opp": [60, 61], "opportun": 70, "opt": [17, 52, 56, 58, 67], "optic": 95, "optim": [1, 2, 4, 7, 9, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24, 28, 34, 36, 37, 44, 51, 56, 58, 59, 80, 84, 92, 93, 96], "option": [3, 10, 13, 15, 17, 20, 22, 23, 24, 26, 29, 33, 40, 48, 50, 56, 70, 75, 85, 86, 88, 89, 98], "oraclecloud": 22, "orang": 42, "orchestr": [7, 22, 90], "order": [3, 4, 13, 21, 22, 36, 37, 77, 90, 95, 96], "org": [27, 31, 32, 48, 56, 60, 67, 71, 74, 81, 84, 87, 90, 92, 95], "organ": [10, 22], "organiz": 22, "orient": [11, 28], "orig_logit": 98, "origin": [1, 13, 16, 17, 20, 24, 25, 26, 27, 29, 30, 36, 40, 41, 42, 47, 77, 88, 90, 96], "orin": 57, "orion": 92, "orionstarai": 92, "orsai": 37, "oserror": 56, "osl": 70, "oss": [18, 20, 21, 27, 40, 57, 66, 92], "ostri": 90, "otel_exporter_otlp_traces_protocol": 86, "otel_trac": 86, "other": [0, 1, 2, 5, 13, 14, 16, 17, 21, 24, 26, 27, 29, 34, 36, 37, 40, 42, 44, 51, 53, 56, 58, 59, 60, 70, 73, 74, 75, 77, 81, 85, 86, 87, 89, 92, 95, 98], "otherwis": [1, 3, 21, 30, 49, 50, 86, 90, 91, 99], "otlp": [21, 22, 86], "otlp_traces_endpoint": [13, 20, 25, 26, 27, 28, 36, 37, 86], "ottawa": [40, 47], "ottawa3": 77, "our": [0, 13, 17, 24, 30, 33, 37, 46, 51, 59, 60, 74, 80, 84, 88], "out": [13, 20, 21, 22, 24, 26, 27, 28, 32, 34, 36, 40, 45, 50, 51, 56, 59, 67, 77, 81, 84, 94], "outcom": 37, "outcomes_tot": 22, "outdat": 67, "outer": [8, 18], "outer_linear_hook": 8, "outlin": [21, 25, 27, 29, 46, 73, 90], "output": [0, 4, 5, 7, 8, 11, 13, 17, 20, 21, 22, 24, 29, 30, 33, 36, 37, 41, 42, 47, 48, 51, 52, 53, 57, 58, 59, 61, 67, 70, 71, 73, 74, 77, 79, 80, 81, 85, 89, 92, 93, 95, 97, 98], "output_dir": [17, 30, 50], "output_hidden_st": 28, "output_id": [25, 26, 36, 47], "output_len": 49, "output_path": 90, "output_seq_len": 70, "output_text": 33, "outweigh": 21, "ov": [46, 66, 95], "over": [0, 7, 8, 11, 13, 15, 17, 21, 22, 26, 30, 37, 50, 57, 73, 90], "overal": [7, 29, 70, 77], "overgrown": 13, "overhead": [3, 5, 11, 12, 13, 18, 21, 22, 23, 24, 28, 30, 37, 50, 51, 57, 59, 73, 90, 95], "overlap": [2, 11, 16, 21, 24, 29, 30, 31, 33, 37, 44, 50, 62, 67, 70, 71, 73, 75, 80], "overload": 22, "overrid": [10, 11, 22, 24, 34, 46, 49, 50, 51, 56, 59, 72, 90, 91, 95], "overview": [11, 25, 29, 41, 51, 59], "overweight": 33, "overwrit": [73, 90], "ovis_garden": 90, "own": [13, 21, 22, 24, 26, 30, 36, 51, 56, 59, 60, 67, 71, 81], "p": [21, 30, 33, 46, 56, 58, 67, 80, 85, 90, 94], "p2p": [2, 16, 21, 73], "p2pwork": 16, "p50": 22, "p95": [22, 49], "p99": [22, 49], "p_": 24, "p_ip": [61, 62], "packag": [2, 8, 13, 20, 24, 25, 26, 27, 28, 33, 36, 40, 41, 42, 47, 51, 56, 58, 59, 60, 67, 68, 70, 71, 73, 77, 80, 86, 90, 93], "pad": [1, 21, 73, 98], "pad_input_id": 98, "page": [1, 10, 11, 13, 16, 21, 30, 33, 41, 44, 56, 57, 70, 71, 73, 74, 80, 83, 90, 99], "page_first": [10, 11, 21], "page_first_direct": [10, 11, 21], "page_first_kv_split": 21, "page_head": 21, "page_s": [1, 11, 13, 20, 21, 25, 26, 27, 28, 36, 37], "pai": 79, "pain": 23, "pair": [10, 11, 18, 26, 42, 49], "pairwis": 36, "palac": [26, 40], "panda": [36, 96], "pandoc": 0, "pant": 28, "paper": [1, 13, 24, 37], "paragraph": 77, "parallel": [0, 5, 11, 12, 13, 15, 18, 24, 27, 28, 32, 45, 50, 52, 57, 61, 62, 67, 70, 73, 79, 80, 82, 83, 89, 90, 93, 97], "param": [13, 18, 21, 27, 36, 49, 92], "param1": 27, "param2": 27, "param_dict": 46, "paramet": [2, 3, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 35, 36, 47, 48, 50, 51, 52, 53, 56, 57, 59, 60, 67, 70, 71, 73, 74, 80, 81, 83, 92, 95, 98], "parameter": 8, "pari": [13, 24, 25, 26, 27, 29, 31, 36, 37, 40, 46, 47, 75, 77, 96], "paris2": 77, "parisian": 36, "park": [28, 42, 77], "pars": [17, 20, 27, 33, 40, 56, 63, 73, 88, 90], "parse_function_cal": 27, "parse_non_stream": [20, 27], "parse_streaming_incr": 27, "parse_url": [20, 27], "parser": [21, 26, 28, 29, 31, 35, 40, 56, 57, 92], "part": [1, 3, 8, 11, 13, 24, 26, 28, 29, 42, 74, 77, 80, 96], "partern": 84, "partial": [21, 22, 23, 27, 84], "particip": 2, "particular": [26, 27], "particularli": [4, 7, 18, 26, 50], "partit": [16, 21, 23, 29, 73, 81], "partli": 27, "partnership": 84, "pass": [0, 7, 8, 11, 13, 16, 21, 23, 24, 28, 30, 38, 40, 48, 49, 51, 53, 59, 73, 90, 95, 98], "passag": 96, "passersbi": 28, "passion": 37, "password": [22, 56, 85], "past": [67, 90], "patch": [3, 56, 86], "patch14": [66, 91], "patchleadertempl": 83, "patchworkertempl": 83, "path": [1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 64, 67, 69, 70, 72, 73, 75, 77, 79, 80, 81, 83, 85, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99], "patient": 37, "patronu": 77, "pattern": [3, 8, 11, 15, 21, 23, 25, 26, 46, 50, 51, 59, 79, 90], "pattern1": 8, "pattern2": 8, "paus": [7, 52, 70], "pause_gener": 23, "payload": [22, 23, 25, 26, 49, 83, 91, 96], "pci": 58, "pcie": 13, "pd": [6, 29, 57, 82, 86], "pd_role": 83, "pdmux": 21, "pdmux_config_path": [13, 20, 25, 26, 27, 28, 36, 37], "peak": [7, 12, 16, 21, 29, 74], "pedestrian": 96, "peer": [2, 13, 16, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 73, 77], "pem": 22, "penalti": 40, "pend": [22, 23], "peopl": [13, 24, 26, 37, 51, 59], "per": [1, 2, 11, 12, 13, 15, 17, 18, 21, 22, 23, 24, 29, 32, 36, 45, 46, 49, 50, 51, 59, 70, 73, 81, 83, 85, 90, 95], "per_row": [17, 21], "per_tensor": [17, 21], "perfect": 16, "perfectli": 4, "perfetto": [50, 86, 90], "perform": [1, 3, 5, 6, 7, 10, 11, 13, 16, 17, 20, 21, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 45, 47, 50, 51, 57, 58, 59, 62, 67, 69, 71, 75, 77, 79, 84, 86, 91, 92, 93, 96, 98], "perhap": 26, "period": [7, 22, 51, 59, 73], "periodsecond": [79, 80, 83], "perman": [13, 85], "permiss": [22, 51, 59], "permut": 7, "permutemethodpool": 7, "persimmon": [66, 92], "persist": [22, 90], "person": [28, 37, 77], "pet": 37, "petit_nvfp4": 21, "phase": [1, 11, 15, 16, 21, 24, 29, 70, 73, 86], "phenomenon": 16, "phi": [66, 92, 95], "philadelphia": 28, "philosophi": [23, 40], "philschmid": 13, "phoenix": 77, "phrase": 40, "phy": 79, "physic": [23, 73], "physical_st": 79, "piano": 90, "pick": [22, 26, 49, 51, 59, 73], "pickl": 14, "piec": [13, 42], "piecewis": [3, 21], "piecewise_cuda_graph_compil": [13, 20, 25, 26, 27, 28, 36, 37], "piecewise_cuda_graph_max_token": [13, 20, 25, 26, 27, 28, 36, 37], "piecewise_cuda_graph_token": [13, 20, 25, 26, 27, 28, 36, 37], "pigeon": 37, "pil": [28, 46], "pillow": 49, "pin": [21, 90], "ping": 44, "pip": [0, 2, 15, 17, 21, 22, 30, 38, 50, 53, 54, 55, 58, 60, 61, 67, 68, 70, 71, 86, 93], "pip1": 61, "pip2": 61, "pip3": [30, 51, 56, 59, 71], "pipelin": [0, 21, 22, 24, 28, 57, 73, 97], "pipeline_class": 90, "pipeline_nam": 90, "pipelineconfig": 90, "pipelinestag": 90, "piqu": 13, "pixel": 28, "pixel_art_style_lora_z_image_turbo": 90, "pixel_valu": 28, "place": [5, 7, 11, 13, 26, 27, 32, 37, 48, 51, 59], "plai": [37, 90, 96], "plain": 22, "plan": [1, 13, 22, 27, 36, 37, 52, 56, 70, 73, 90], "plane": [23, 37], "planet": 40, "platform": [1, 34, 56, 67, 93], "playground": [14, 98], "pleas": [1, 13, 15, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 33, 36, 37, 40, 41, 42, 46, 47, 50, 51, 52, 53, 56, 58, 59, 60, 61, 67, 68, 69, 70, 71, 73, 74, 77, 79, 81, 83, 86, 90, 93, 95, 98], "plu": [20, 32, 45, 77, 90, 92], "plugin": [11, 15, 27, 70, 79], "png": [28, 32, 42, 45, 46, 49, 77, 90], "po": [80, 83], "pod": 22, "point": [4, 7, 8, 18, 21, 22, 23, 26, 28, 33, 80, 83, 85, 86, 98], "poisson": 49, "polici": [4, 11, 12, 13, 15, 21, 23, 24, 37, 60, 61, 62, 83], "polit": [24, 36, 37], "poll": [21, 73, 90], "pong": 44, "pool": [3, 11, 13, 21, 22, 32, 36, 45, 73, 74], "pool_siz": 22, "poorli": 75, "popul": [25, 26, 37, 46, 98], "popular": [17, 37, 40, 57, 67], "port": [0, 2, 6, 10, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 49, 50, 52, 53, 56, 58, 60, 61, 62, 70, 72, 73, 77, 79, 80, 81, 83, 85, 86, 89, 90, 91, 92, 94, 95, 96, 97, 99], "port_tool_choic": 27, "portion": [2, 3, 18, 27, 74], "posit": [16, 22, 28, 40, 44, 46, 73, 95, 98], "possibl": [0, 11, 12, 16, 21, 37, 51, 59, 98], "possibli": [77, 86], "post": [4, 7, 13, 17, 20, 22, 23, 24, 25, 26, 27, 32, 36, 38, 41, 42, 45, 46, 47, 49, 50, 57, 74, 79, 80, 81, 83, 86, 88, 89, 90, 91, 95, 96], "post2": [56, 58, 90], "postgr": 22, "postgres_db_url": 22, "postpon": 84, "potenti": [16, 18, 21, 24, 36, 37, 71, 86, 89], "potter": [37, 77], "power": [13, 22, 23, 30, 35, 37, 38, 50, 57, 58, 84, 95], "power_of_two": 22, "pp": [16, 21, 50], "pp_async_batch_depth": [13, 20, 25, 26, 27, 28, 36, 37], "pp_max_micro_batch_s": [13, 20, 25, 26, 27, 28, 36, 37], "pp_proxy_tensor": 98, "pp_size": [13, 20, 25, 26, 27, 28, 36, 37], "ppo": 84, "ppproxytensor": 98, "pprint": [29, 31], "pr": [0, 7, 13, 18, 30, 34, 44, 51, 59, 83, 90, 98], "practic": [9, 23, 29, 50, 51, 59, 65, 90], "pre": [0, 1, 7, 17, 18, 21, 22, 28, 46, 58, 60, 85], "prealloc": 73, "preced": [40, 51, 59, 90], "preciou": 13, "precis": [3, 7, 11, 17, 18, 21, 26, 29, 67, 70, 90], "precompil": [24, 29, 73], "precomput": [46, 73], "precomputed_embed": [28, 46], "predefin": [21, 98], "predict": [16, 22, 37, 49, 75, 88, 89, 92], "predictor": 16, "preempt": [21, 51, 59], "preemption": 21, "prefer": [0, 11, 18, 21, 22, 27, 36, 49, 51, 52, 59, 67, 90, 97], "preferred_sampling_param": [13, 20, 25, 26, 27, 28, 36, 37], "prefetch": [21, 90], "prefetch_threshold": 11, "prefetch_timeout_bas": 11, "prefetch_timeout_per_ki_token": 11, "prefil": [4, 6, 7, 10, 11, 13, 20, 25, 26, 27, 28, 29, 30, 32, 36, 37, 45, 57, 60, 61, 62, 73, 74, 79, 83, 85, 86, 96, 98], "prefill1": 22, "prefill_addr": 30, "prefill_attention_backend": [13, 20, 25, 26, 27, 28, 36, 37], "prefill_count": 22, "prefill_delayer_forward_passes_bucket": [13, 20, 25, 26, 27, 28, 36, 37], "prefill_delayer_max_delay_pass": [13, 20, 25, 26, 27, 28, 36, 37], "prefill_delayer_token_usage_low_watermark": [13, 20, 25, 26, 27, 28, 36, 37], "prefill_delayer_wait_seconds_bucket": [13, 20, 25, 26, 27, 28, 36, 37], "prefill_head_ip": 30, "prefill_host": 6, "prefill_host_ip": 62, "prefill_in1024": 80, "prefill_ip": 61, "prefill_master_ip": 15, "prefill_max_request": [13, 20, 25, 26, 27, 28, 36, 37], "prefix": [1, 4, 11, 12, 16, 21, 22, 29, 30, 44, 49, 50, 56, 57, 70, 73, 74, 90, 98], "preliminari": [2, 18], "prepar": [4, 16, 21, 30, 48, 73, 79], "prepare_data": 30, "prepend": 11, "preprocess": [6, 21], "prereleas": 90, "prerequisit": 50, "presence_penalti": [40, 46], "present": [11, 26, 67, 95, 96], "preserv": [23, 27], "preset": [49, 80], "presid": [26, 37, 75], "press": [13, 36, 37, 52, 67, 79], "pressur": [11, 23], "pretrain": 92, "pretrainedmodel": 99, "pretti": [26, 29, 31], "prev": [46, 47], "prevent": [11, 12, 13, 15, 16, 21, 22, 40, 51, 52, 59, 71, 74, 79], "preview": 0, "previou": [16, 29, 33, 85, 86, 92], "previous": [18, 21, 46, 90], "price": 33, "primari": [22, 71, 90], "primarili": [18, 51, 56, 59, 73, 90, 92], "prime": 26, "primit": [22, 75], "princess": 13, "principl": [23, 86], "print": [4, 13, 17, 26, 27, 28, 32, 33, 36, 37, 38, 40, 41, 45, 46, 47, 49, 50, 61, 62, 77, 88, 89, 90, 91, 93, 95, 96, 98], "print_highlight": [20, 24, 25, 26, 27, 36, 40, 41, 42, 46, 47, 77], "prior": [7, 60, 67], "priorit": [51, 59], "prioriti": [21, 22, 51, 59, 88], "priority_scheduling_preemption_threshold": [13, 20, 25, 26, 27, 28, 36, 37], "prithivmlmod": 90, "privaci": [40, 84], "privat": [3, 11, 21, 22], "privileg": [52, 58, 60, 67, 79, 80, 83], "pro": [1, 34, 66, 71, 95, 98], "proactiv": 11, "prob": [21, 22, 88], "probabl": [21, 22, 23, 24, 26, 36, 46, 88], "probe": 22, "problem": [15, 17, 20, 23, 56, 60, 79], "proc": [58, 60], "proce": 22, "proceed": 11, "process": [2, 5, 6, 11, 13, 15, 16, 21, 22, 23, 24, 28, 29, 30, 32, 36, 37, 40, 45, 49, 50, 51, 53, 56, 59, 67, 70, 73, 79, 85, 86, 88, 90, 92, 95, 96], "process_tracing_init": 86, "processor": [21, 29, 31, 32, 40, 42, 67, 77, 95, 98], "processor_output": [28, 46], "produc": [4, 27, 49, 85, 92], "product": [4, 11, 16, 17, 21, 23, 30, 33, 56, 57, 70, 84, 99], "profil": [16, 21, 23, 24, 49, 51, 57, 59, 70], "profile_id": 50, "profile_log": 50, "profiler_python": 50, "program": [40, 52, 91, 95, 96], "programmat": [17, 22, 50], "progress": [16, 22], "progress_bar": 77, "prohibit": 16, "proj": 90, "project": [0, 3, 5, 17, 18, 22, 26, 28, 30, 32, 33, 36, 37, 42, 45, 46, 54, 55, 56, 58, 60, 67, 68, 70, 71, 72, 77, 78, 83, 86, 90, 92, 95], "projector": [28, 95], "prometheu": [14, 21, 85], "promis": [16, 37, 89], "promot": 28, "prompt": [1, 4, 12, 17, 20, 21, 22, 25, 26, 27, 28, 29, 33, 36, 37, 40, 46, 49, 50, 53, 58, 61, 67, 70, 71, 74, 85, 89, 90, 93, 95, 98], "prompt_token": [22, 24, 25, 26, 27, 29, 36, 40, 41, 42, 47, 80, 83, 88], "prompt_tokens_bucket": [13, 20, 25, 26, 27, 28, 36, 37], "prompt_tokens_detail": [21, 24, 27, 29, 40, 41, 42, 47, 80, 83, 88], "prompt_tokens_tot": 85, "pronounc": 18, "propag": [16, 86], "proper": [26, 48, 49, 51, 59, 67, 79, 95], "properli": [18, 26, 48, 58, 70, 79, 86], "properti": [25, 26, 27, 28, 29, 46, 48], "propos": [11, 16, 27], "prospect": 13, "protect": 22, "protein": 77, "proto": [22, 86], "protobuf": 86, "protocol": [22, 79, 80, 83, 88], "protocol_buffers_python_implement": 93, "prototyp": [21, 28], "proven": [23, 57], "provid": [2, 4, 7, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 35, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 67, 70, 73, 77, 81, 85, 86, 88, 90, 91, 92, 93, 95, 97, 98], "proxi": [21, 60], "prss": 52, "prune": [22, 95], "pt": [21, 24, 28, 58, 66, 92, 95], "pth": 17, "ptq": 17, "ptxa": 56, "pub": 50, "public": [37, 78], "public_sglang_ci": 36, "publish": 21, "pull": [0, 3, 22, 28, 30, 33, 51, 52, 55, 59, 60], "pullei": 28, "punica": 13, "pure": [21, 30, 51, 59, 77], "purpos": [7, 11, 13, 14, 16, 21, 28, 38, 48], "pursu": 37, "push": [0, 51, 56, 59], "put": [16, 22, 23, 25, 26], "pwd": [17, 59], "py": [1, 2, 7, 13, 14, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 33, 36, 37, 40, 41, 42, 46, 47, 48, 50, 51, 52, 53, 54, 56, 58, 59, 68, 72, 77, 88, 90, 98], "py3": 60, "pybase64": 49, "pydant": [25, 26], "pyo3": 22, "pypi": [22, 51, 59], "pyproject": [51, 54, 58, 59, 60, 67, 68, 71], "pyproject_cpu": 67, "pyproject_npu": 60, "pyproject_oth": [58, 68], "pyproject_xpu": 71, "python": [1, 2, 6, 7, 8, 10, 11, 15, 19, 20, 21, 23, 25, 26, 30, 32, 34, 36, 37, 40, 45, 46, 49, 50, 51, 52, 53, 54, 56, 58, 59, 61, 62, 64, 67, 68, 69, 70, 71, 72, 77, 80, 81, 85, 86, 89, 90, 92, 93, 94, 95, 98, 99], "python3": [1, 3, 4, 5, 10, 13, 14, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 70, 77, 79, 80, 81, 83, 85, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99], "python_execution_backend": 33, "python_serv": 33, "python_tag": 27, "pythonpath": 59, "pytorch": [1, 8, 17, 21, 48, 56, 67, 71, 73, 74, 87], "pytorch_npu_alloc_conf": [61, 62, 64], "pytorch_vers": 60, "p\u8282\u70b9": 61, "q": [29, 30, 95], "q2": 33, "q4_k_m": 17, "q_b_proj": 73, "q_proj": [13, 21], "qa": 11, "qdrep": 50, "qingdao": 29, "qk": [13, 20, 21, 25, 26, 27, 28, 36, 37], "qkv": [3, 17, 21], "qkv_proj": [21, 50], "qlora": 84, "qoq": 21, "qperf": 79, "quad": 20, "quadrat": 16, "quai": 60, "qualiti": [17, 24, 25, 36, 37, 70, 77, 89, 90, 91, 92], "quant": [17, 21], "quant_config": [17, 98], "quant_method": 7, "quant_model_descript": 63, "quant_path": 17, "quantiz": [1, 7, 12, 13, 20, 25, 26, 27, 28, 29, 36, 37, 57, 61, 62, 63, 67, 70, 92, 98], "quantization_param_path": [13, 20, 25, 26, 27, 28, 36, 37], "quantizationconfig": 98, "quantizationmodifi": 17, "quantize_and_sav": 17, "quantize_and_serv": [13, 20, 25, 26, 27, 28, 36, 37], "quantizeconfig": 17, "quantized_model": 17, "quantized_tinyllama_fp4": 17, "quantized_tinyllama_fp8": 17, "quark_int4fp8_mo": 21, "quarot": 66, "queri": [0, 11, 14, 21, 25, 26, 27, 36, 49, 57, 95], "query_st": 99, "query_weath": 29, "quest": 13, "question": [20, 24, 29, 30, 31, 36, 37, 40, 49, 51, 52, 53, 57, 58, 59, 61, 68, 77, 95, 96], "queu": 21, "queue": [13, 15, 23, 36, 73, 79, 85], "queue_schedul": 60, "quick": [28, 47, 50, 51, 56, 59, 70, 90], "quickli": [0, 13, 50, 51, 59, 90], "quickstart": 57, "quiet": 60, "quit": [13, 26, 36, 79], "quot": [26, 33], "quotat": 26, "qwen": [0, 1, 2, 3, 4, 5, 13, 16, 17, 20, 21, 22, 26, 27, 28, 36, 37, 38, 40, 42, 44, 45, 47, 49, 50, 51, 56, 57, 59, 64, 66, 67, 71, 77, 90, 91, 92, 94, 95, 96, 97, 98], "qwen1": 36, "qwen2": [0, 1, 3, 5, 13, 17, 22, 27, 36, 37, 38, 40, 41, 42, 46, 47, 49, 51, 59, 66, 71, 77, 80, 83, 88, 91, 94, 95, 97, 98], "qwen25": [21, 27], "qwen2_5_vlforconditionalgener": [28, 95], "qwen2forcausallm": 36, "qwen2forrewardmodel": [88, 97], "qwen2forsequenceclassif": [22, 88, 97], "qwen2vl": 98, "qwen3": [2, 3, 5, 6, 10, 18, 20, 21, 22, 27, 43, 53, 56, 60, 65, 66, 67, 84, 91, 92, 93, 95], "qwen3_cod": [21, 27], "qwen3_rerank": 96, "qwen3_vl_rerank": 96, "qwen3forcausallm": 92, "qwen3forsequenceclassif": 88, "qwen_image_edit_inpaint": 90, "qwen_vl": 95, "qwenimag": 90, "qwenimage_denois": 90, "qwq": [26, 66, 67], "r": [0, 22, 25, 26, 40, 66, 77, 88, 90, 92], "r1": [1, 2, 7, 10, 17, 18, 20, 21, 22, 26, 40, 43, 53, 56, 58, 66, 67, 69, 79, 80, 92, 93], "r7b": 92, "raccoon": 90, "race": 15, "radix": [4, 16, 21, 22, 30, 36, 49, 50, 60, 61, 62, 70, 74, 80, 83, 96], "radix_cach": 4, "radix_eviction_polici": [13, 20, 25, 26, 27, 28, 36, 37], "radixattent": [10, 11, 21, 57, 98], "radixtre": 11, "rag": [21, 30], "rai": 84, "rain": 96, "rais": [8, 21, 33, 36, 49, 86], "raise_for_statu": 36, "ralli": 33, "ram": 21, "ran": 98, "random": [21, 22, 24, 49, 50, 53, 58, 61, 67, 70, 71, 83, 85, 90], "random_se": [13, 20, 25, 26, 27, 28, 36, 37], "randomli": [46, 49], "rang": [11, 12, 13, 16, 17, 18, 21, 24, 34, 36, 40, 46, 49, 50, 57, 61, 67, 70, 71, 85, 89], "rank": [2, 13, 15, 16, 18, 20, 21, 23, 25, 26, 27, 28, 29, 30, 36, 37, 40, 41, 42, 47, 50, 61, 62, 67, 70, 73, 77, 79, 80, 81, 83, 93, 96, 97], "rank0": 90, "rank_offset": 23, "rapid": 11, "rapidli": 37, "rate": [8, 10, 11, 24, 33, 61, 67, 71, 79, 85], "rate_limit": 22, "rate_limit_tot": 22, "rather": [12, 17, 22], "ratio": [7, 10, 11, 18, 21, 22, 34, 44, 49, 61, 67, 70, 71, 85, 90], "ravenclaw": 77, "raw": [16, 18, 32, 42, 45, 46, 77, 90, 95, 98], "raw_tool": 27, "rbac": 22, "rbg": [30, 82], "rbg_pd": 30, "rc": 50, "rc1": 60, "rc2": [60, 93], "rc_rdma_write_bw": 79, "rdma": [7, 10, 11, 52, 58, 60, 80, 83], "re": [0, 21, 26, 28, 29, 37, 51, 52, 56, 59, 70, 79, 84, 90, 98], "reach": [11, 33, 73, 84], "reachabl": 49, "react": [51, 59], "reaction": [51, 59], "read": [11, 21, 26, 46, 52, 58, 70, 90, 95], "readabl": [8, 21, 26, 36, 48], "readi": [2, 11, 12, 13, 17, 21, 26, 30, 36, 50, 58, 67, 79, 81, 92, 98], "readinessprob": [79, 80, 83], "readm": [51, 59, 98], "real": [11, 17, 21, 25, 26, 27, 50, 92], "realism": 90, "realismlora": 90, "realli": 37, "realloc": [3, 58], "rear": [28, 42], "reasoing_cont": 26, "reason": [3, 14, 16, 18, 21, 23, 27, 31, 35, 44, 45, 53, 56, 57, 73, 92, 95], "reasoning_cont": [20, 24, 26, 27, 29, 40, 42, 47, 80, 83], "reasoning_effort": 33, "reasoning_pars": [13, 20, 25, 26, 27, 28, 36, 37], "reasoning_text": [20, 22], "reasoning_token": [24, 27, 40, 41, 42, 47], "reasoningpars": 20, "rebal": [21, 83], "rebalanc": [7, 21, 22], "reboot": 58, "rebuild": [0, 23], "recal": [24, 26], "recaptur": 23, "recapture_cuda_graph": 23, "receipt": 28, "receiv": [11, 15, 22, 29, 86, 98], "recent": [13, 21, 26, 33, 37, 51, 59, 74], "recip": [17, 87], "reckon": 13, "recogn": [20, 34, 48, 92, 98], "recognit": [37, 95], "recommend": [0, 1, 2, 7, 10, 11, 13, 15, 16, 17, 18, 21, 23, 27, 29, 30, 33, 34, 35, 37, 40, 48, 50, 51, 53, 56, 59, 60, 67, 90, 93], "recompil": 22, "recomput": 23, "reconstruct": [29, 36], "reconstructed_text": 36, "record": [11, 21, 36, 73, 86], "record_shap": 73, "recoveri": [22, 23, 56], "recreategrouponpodrestart": [79, 80], "recv": [21, 73], "recycl": 23, "red": [40, 90, 92], "redefin": 35, "redesign": 16, "redhatai": 67, "redirect": 23, "redis_pool_max": 22, "redis_retention_dai": 22, "redis_url": 22, "rednot": 95, "redoc": 47, "reduc": [0, 1, 2, 3, 4, 5, 7, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 36, 37, 40, 41, 42, 46, 47, 50, 51, 59, 70, 74, 77, 86, 90, 91, 95], "reduct": [4, 13, 18, 22, 29, 56, 92], "redund": [11, 16, 17, 18, 21, 28, 80, 83, 90, 95], "redundantli": 11, "ref": [32, 45, 95], "refactor": 7, "refer": [7, 10, 11, 12, 15, 18, 21, 26, 27, 29, 30, 33, 40, 41, 42, 46, 47, 48, 50, 51, 53, 56, 58, 59, 67, 71, 74, 79, 81, 83, 93, 95, 98], "reference_hf": 98, "reference_imag": 96, "refin": [96, 97], "refit": 84, "reflect": 90, "refresh_interv": 22, "refus": [13, 24, 27, 40, 47], "regard": 86, "regardless": [21, 49], "regex": [21, 25, 26, 77], "region": [22, 23, 24, 26, 50, 56], "regist": [7, 8, 10, 21, 22, 50, 90], "register_forward_hook": 8, "register_fused_func": 7, "register_post_permut": 7, "register_pre_permut": 7, "registr": [8, 22], "registrations_tot": 22, "registri": [22, 98], "regress": [17, 51, 59, 89], "regul": 22, "regular": [8, 13, 24, 46, 48, 77], "regular_count": 22, "regular_expression_gen": 77, "reinforc": [4, 84, 92, 95, 97], "reiniti": 13, "reinstal": [22, 56, 67], "reject": [22, 24], "rel": [0, 4, 5, 18, 22, 90], "relat": [13, 30, 42, 48, 51, 56, 59, 67, 72, 79, 80, 83, 90], "relationship": [11, 37, 86], "relaunch": 96, "relax": [15, 37], "releas": [13, 20, 22, 24, 25, 26, 27, 28, 33, 36, 37, 40, 41, 42, 47, 50, 51, 56, 58, 59, 60, 77, 80, 90], "release_memory_occup": [21, 23], "release_weights_occup": 21, "relev": [0, 13, 24, 25, 26, 37, 53, 96], "reli": [23, 51, 59, 98], "reliabl": [4, 27, 92], "reload": 13, "remain": [1, 13, 16, 74, 86, 95], "remax": 84, "rememb": [0, 13, 24, 26, 41], "remind": [25, 26], "remot": [1, 13, 15, 16, 19, 21, 24, 29, 30, 32, 34, 35, 36, 38, 45, 58, 60, 61, 62, 64, 67, 70, 71, 79, 80, 83, 90, 91, 95, 96, 97], "remote_inst": [19, 21], "remote_instance_weight_loader_backend": [13, 20, 25, 26, 27, 28, 36, 37], "remote_instance_weight_loader_seed_instance_ip": [13, 20, 25, 26, 27, 28, 36, 37], "remote_instance_weight_loader_seed_instance_service_port": [13, 20, 25, 26, 27, 28, 36, 37], "remote_instance_weight_loader_send_weights_group_port": [13, 20, 25, 26, 27, 28, 36, 37], "remote_instance_weight_loader_start_seed_via_transfer_engin": [13, 20, 25, 26, 27, 28, 36, 37], "remov": [0, 8, 13, 20, 22, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 46, 47, 52, 58, 60, 77, 95, 98], "render": 90, "renderd176": 55, "renderd184": 55, "renown": [24, 37, 40], "reorder": [12, 29], "rep": 50, "repeat": [13, 22, 23, 28, 30, 32, 37, 45, 46, 52, 53], "repetit": [40, 46], "repetition_penalti": [13, 36, 46], "replac": [13, 17, 21, 37, 47, 56, 58, 60, 67, 70, 81, 85, 86, 90, 98], "replai": [1, 3, 23, 50], "replay_request_dump": 14, "repli": [25, 26], "replic": [5, 7], "replica": [22, 79, 80, 83], "repo": [21, 24, 50, 51, 52, 59, 90, 92, 95], "repo_id": 98, "report": [10, 21, 30, 32, 45, 48, 49, 50, 70, 74, 98], "repositori": [2, 7, 10, 36, 52, 60, 67, 69, 70], "repository_nam": 56, "repres": [11, 13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 48, 77, 86, 91], "represent": [21, 91], "reproduc": [16, 40, 90], "republ": 37, "req": [13, 21, 36, 49, 79, 86], "req_id": 86, "req_root_span": 86, "request": [0, 4, 5, 6, 7, 10, 11, 13, 15, 16, 18, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 37, 40, 44, 46, 49, 50, 52, 53, 57, 58, 61, 62, 73, 74, 79, 80, 81, 83, 85, 89, 95, 98], "request_duration_second": 22, "request_errors_tot": 22, "request_r": 49, "requestexcept": 36, "requests_act": 22, "requests_tot": 22, "requir": [0, 1, 3, 6, 7, 11, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 40, 44, 46, 48, 49, 52, 53, 56, 58, 60, 66, 67, 74, 79, 86, 88, 89, 91, 96, 97, 98, 99], "require_reason": 26, "rerank": [22, 24, 57], "reranker_process": 36, "rerun": [51, 59], "research": [37, 66, 92], "resembl": 77, "reserv": [5, 12, 13, 21], "resid": [11, 13, 22], "residu": [3, 21, 90], "resiz": 21, "resolut": [3, 49, 56, 90, 95], "resolv": [0, 8, 15, 17, 22, 29, 48, 51, 59, 74, 79, 90, 91], "resolve_cal": 8, "resolve_devic": 48, "resort": 88, "resourc": [6, 11, 13, 15, 16, 22, 28, 51, 56, 59, 69, 79, 80, 83, 84, 91, 98], "resp": 90, "respect": [29, 40, 47, 86], "respond": [22, 27], "respons": [5, 11, 13, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 36, 37, 38, 40, 41, 42, 45, 46, 47, 75, 90, 91, 95, 97], "response1": 36, "response2": 36, "response_cont": 25, "response_data": 25, "response_format": [25, 26, 90], "response_json": [36, 96], "response_non_stream": [20, 27], "response_requir": 27, "response_sent_to_client_t": [25, 26, 36, 47], "response_specif": 27, "response_stream": [20, 27], "responses_tot": 22, "rest": [26, 89, 90], "restart": [23, 29, 36, 48, 52, 55, 79], "restartpolici": [79, 80, 83], "restor": [17, 21, 90], "restrict": [13, 22, 26, 30, 48, 49], "result": [3, 4, 11, 13, 15, 16, 18, 20, 21, 22, 23, 25, 26, 29, 33, 36, 37, 40, 41, 44, 49, 50, 51, 59, 67, 70, 75, 88, 90, 92, 95, 96, 97, 98], "resume_memory_occup": [21, 23], "resume_weights_occup": 21, "retain": [32, 45], "retent": 22, "reth0": 79, "reth2": 79, "reth4": 79, "reth6": 79, "retoken": 49, "retract": [12, 21, 23, 73], "retracted_req": 12, "retri": 0, "retries_exhausted_tot": 22, "retries_tot": 22, "retriev": [10, 11, 22, 48, 91, 92, 96], "retry_backoff_second": 22, "retryabl": 22, "return": [8, 11, 16, 21, 22, 23, 25, 26, 27, 36, 46, 48, 77, 88, 90, 91, 96, 98], "return_dict": [20, 25, 26, 27, 36], "return_hidden_st": 46, "return_logprob": [25, 26, 46], "return_routed_expert": [40, 46], "return_tensor": 28, "return_text_in_logprob": 46, "reus": [0, 1, 10, 11, 17, 21, 22, 30, 44, 51, 59, 98], "reusabl": [11, 48], "reuter": 33, "rev": 79, "revert": 16, "revis": [13, 20, 21, 25, 26, 27, 28, 36, 37], "reward": [23, 47, 57], "reward_process": 36, "rf": [56, 58], "rich": [29, 31, 37], "rid": [13, 46, 80, 83, 86, 88], "right": [18, 24, 26, 40, 74], "rigid": 23, "rigor": [51, 59], "ring": [22, 61, 90], "ring_degre": 90, "rio": 26, "rise": 37, "risen": 33, "risk": [12, 24, 77], "river": 37, "rl": [4, 21, 24, 57, 66, 84, 92, 95], "rl2": 84, "rl_on_policy_target": [13, 20, 25, 26, 27, 28, 36, 37], "rl_quant_profil": [13, 20, 25, 26, 27, 28, 36, 37], "rl_team": 84, "rlhf": [84, 97], "rlimit_nofil": 49, "rm": [55, 56, 58, 60, 66, 68, 69, 97], "rmsnorm": [21, 98], "road": [28, 40], "roadmap": [4, 7, 13, 29, 30, 34, 70, 78], "roadsid": 28, "roar": 60, "robin": [21, 61, 62], "robust": [23, 49, 91], "roce": [52, 58], "rocki": 13, "rocm": [1, 21, 30, 57, 58], "rocm630": 55, "rocm700": 90, "role": [20, 22, 24, 25, 26, 27, 28, 29, 31, 32, 35, 36, 37, 38, 40, 42, 45, 46, 47, 79, 80, 83, 89, 95], "role_end": 89, "rolebasedgroup": 83, "rolebind": 22, "roleref": 22, "roll": [13, 36, 58, 67, 79, 84], "rollingupd": 80, "rollingupdateconfigur": 80, "rollout": [23, 57, 84], "rolloutstrategi": 80, "roman": [37, 40], "rome": [25, 26, 40], "rome2": 77, "rome3": 77, "rooflin": 16, "room": [16, 86], "root": [11, 21, 25, 26, 30, 46, 50, 52, 56, 58, 60, 67, 79, 80, 83, 86, 87, 90, 94, 98], "rope": [21, 28, 73], "rose": 37, "rotari": [21, 95], "rotat": 22, "roughli": [26, 33, 74], "round": [21, 27, 49, 61, 62], "round_robin": [13, 20, 21, 22, 25, 26, 27, 28, 36, 37, 61, 62], "rout": [7, 15, 21, 23, 38, 46, 49, 88, 92, 95], "routed_expert": 40, "router": [6, 7, 12, 21, 30, 50, 60, 62, 83, 84, 86], "router_api_kei": 22, "router_log": 22, "routerarg": 22, "routin": 56, "rst": 0, "rule": [12, 21, 22, 28, 36, 70, 90], "run": [0, 1, 2, 3, 4, 8, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 57, 61, 68, 70, 71, 73, 74, 77, 79, 80, 81, 83, 85, 87, 94, 95, 96, 98], "run_batch": 77, "run_ev": [30, 53, 62], "run_llm": 98, "runnabl": [0, 48], "runner": [1, 3, 7, 21, 36, 73], "runner_allow_runasroot": 55, "runnerinput": 7, "runneroutput": 7, "running_queu": 23, "runtim": [7, 13, 16, 17, 20, 23, 24, 28, 36, 37, 40, 41, 42, 46, 47, 50, 51, 56, 57, 59, 69, 70, 71, 73, 77, 90, 95, 98], "runtime_vers": 70, "runtimecheck": 48, "runtimedevicecheck": 48, "runtimeendpoint": [75, 77], "runtimeerror": 50, "rust": [80, 88], "rustc": 22, "rustl": 22, "rustup": 22, "ruthless": 13, "s3": 11, "safe": [13, 20, 22, 23, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "safeguard": 90, "safest": 23, "safetensor": [13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77, 90], "safeti": 37, "sage": 90, "sage_attn": 90, "sage_attn_3": 90, "sageattent": 90, "sageattention3": 90, "sai": [13, 40, 77], "same": [3, 4, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 30, 36, 40, 46, 48, 50, 51, 59, 60, 70, 74, 77, 86, 88, 90, 96, 98], "sampl": [1, 8, 13, 22, 29, 30, 31, 36, 47, 49, 56, 57, 60, 74, 95, 98], "sampler": 95, "sampling_arg": 90, "sampling_backend": [13, 20, 25, 26, 27, 28, 36, 37], "sampling_default": [13, 20, 25, 26, 27, 28, 36, 37], "sampling_param": [4, 13, 17, 20, 25, 26, 27, 37, 46, 47, 89, 90, 93, 98], "sampling_se": 4, "samplingparam": [46, 90], "san": [25, 26, 27], "sandbox": [22, 33], "saniti": [51, 59], "sassi": 37, "sat": 13, "satir": 28, "satisfi": [16, 26], "satur": [16, 23], "save": [2, 12, 13, 17, 21, 23, 36, 44, 50, 52, 67, 70, 73, 74, 90, 95], "save_dir": 17, "save_pretrain": 17, "saver": [21, 23], "saw": 13, "sbatch": 81, "sbin": 60, "scalabl": [6, 7, 67, 95], "scalar": [18, 97], "scale": [6, 7, 11, 15, 16, 17, 21, 22, 23, 29, 30, 35, 46, 49, 56, 82, 84, 90, 92, 96], "scaled_dot_product_attent": 90, "scaling_factor": 18, "scaling_governor": [60, 61, 62], "scarc": [5, 13], "scatter": [21, 61, 62, 86], "scenario": [1, 4, 7, 10, 11, 13, 16, 18, 21, 28, 29, 30, 53, 80, 83, 95], "scene": [28, 37, 42, 95, 96], "sched_migration_cost_n": [61, 62], "schedul": [3, 6, 10, 11, 12, 13, 16, 22, 23, 24, 29, 30, 31, 33, 37, 44, 49, 51, 57, 59, 67, 70, 71, 73, 83, 86, 90], "schedule_conserv": [13, 20, 25, 26, 27, 28, 36, 37], "schedule_delay_milli": 73, "schedule_low_priority_values_first": [13, 20, 25, 26, 27, 28, 36, 37], "schedule_polici": [13, 20, 25, 26, 27, 28, 36, 37], "scheduler_output_processor_mixin": [51, 59], "scheduler_recv_interv": [13, 20, 25, 26, 27, 28, 36, 37], "schema": [13, 21, 23, 25, 26, 46, 77], "schema_get_current_d": [25, 26], "schema_get_current_weath": [25, 26], "scheme": [7, 11, 17], "school": 26, "scienc": 92, "scientist": 37, "scontrol": 81, "scope": [22, 90], "scorch": 13, "score": [23, 30, 53, 96, 97, 98], "score_process": 36, "scout": [27, 28, 34, 66, 92], "scrape": [22, 85], "scratch": 95, "screenshot": 86, "script": [14, 17, 29, 30, 33, 37, 49, 50, 51, 52, 53, 56, 58, 59, 67, 69, 71, 73, 81, 88, 90, 93, 98], "sd": 90, "sdk": [22, 56, 86, 90], "sdpa": [1, 21, 90], "seamless": [6, 7, 17, 88], "seamlessli": [10, 84], "search": [11, 21, 25, 26, 29, 30, 77, 91, 92, 95, 96], "seat": [26, 37], "sec": [21, 22, 79, 83], "seccomp": 58, "second": [2, 13, 15, 19, 21, 22, 24, 32, 42, 45, 47, 49, 51, 53, 59, 70, 73, 85, 90, 92], "second_answ": 77, "secret": [13, 22, 56, 58, 60, 67, 90], "section": [7, 13, 15, 22, 23, 26, 28, 40, 46, 48, 60, 61, 66, 74, 79, 80, 83, 85, 86, 90, 95, 98], "secur": [21, 50, 56, 58, 79], "securitycontext": [79, 80, 83], "see": [1, 3, 7, 10, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25, 29, 37, 38, 40, 41, 46, 47, 50, 56, 67, 70, 71, 74, 77, 79, 85, 90, 92, 95, 96, 98, 99], "seed": [4, 19, 21, 40, 70, 90], "seed_instance_ip": 19, "seed_instance_service_port": 19, "seek": [3, 37], "seem": [13, 26, 27, 28, 40, 49], "seen": [13, 28, 34, 37, 44], "segment": [3, 21, 86], "sein": [36, 37], "seldom": 16, "select": [6, 8, 11, 13, 16, 17, 21, 22, 23, 24, 30, 34, 40, 46, 49, 56, 73, 80, 83], "select_expert": 7, "selection_tot": 22, "selector": [22, 23, 79, 80, 83, 90], "self": [7, 8, 37, 40, 41, 42, 46, 98, 99], "self_attn": 50, "semant": [37, 91, 96], "send": [0, 12, 14, 19, 21, 22, 25, 26, 40, 42, 46, 49, 50, 57, 58, 74, 81, 86, 95], "send_on": 50, "send_weights_nccl_group_ports_list": 19, "sender": 86, "sens": [13, 37], "sensetim": 92, "sensit": [11, 13, 22, 53], "sent": [22, 49, 67, 71], "sentenc": [26, 33, 40, 42, 46], "sep": 72, "sep_styl": 72, "separ": [2, 6, 13, 15, 16, 20, 21, 24, 25, 26, 27, 36, 40, 41, 42, 47, 50, 51, 59, 61, 70, 77, 80, 86, 95], "separate_reason": [20, 40], "separate_reasoning_data": 20, "separate_reasoning_response_json": 20, "seq": [13, 20, 21, 25, 26, 27, 28, 30, 36, 37, 79], "seq_len": 3, "seqlen": 3, "sequenc": [3, 6, 11, 13, 15, 16, 18, 21, 22, 23, 24, 29, 40, 46, 50, 66, 70, 90, 97], "sequenti": [80, 92], "seren": 90, "seri": [16, 20, 26, 27, 29, 35, 66, 67, 71, 90, 92, 97], "serial": [22, 23, 46], "serialized_named_tensor": 23, "serv": [0, 7, 11, 16, 22, 23, 24, 28, 29, 30, 31, 34, 40, 44, 50, 56, 57, 79, 81, 84, 91, 96], "served_model_nam": [13, 20, 25, 26, 27, 28, 36, 37], "server": [0, 3, 6, 10, 11, 12, 13, 14, 17, 18, 19, 24, 25, 26, 29, 30, 31, 33, 37, 44, 46, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 69, 70, 72, 73, 79, 81, 85, 86, 87, 88, 89, 94, 98], "server_address": 30, "server_arg": [8, 13, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77, 90, 98], "server_info": 36, "server_ip": 79, "server_nam": 86, "server_process": [13, 20, 24, 25, 26, 27, 36, 40, 47, 77], "server_process_tool_choic": 27, "server_typ": 30, "serverarg": [8, 13, 20, 25, 26, 27, 28, 36, 37, 90], "servers_act": 22, "servic": [3, 6, 19, 21, 28, 33, 40, 41, 42, 50, 56, 67, 79, 83, 85, 88], "service_nam": 22, "service_ti": [24, 27, 40, 47], "serviceaccount": 22, "servicenow": 92, "serving_classifi": 88, "session": [22, 27, 50, 86], "set": [1, 3, 5, 7, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 40, 41, 42, 44, 46, 47, 49, 50, 51, 52, 53, 56, 59, 62, 67, 69, 70, 71, 72, 73, 74, 77, 79, 81, 85, 86, 87, 89, 91, 93, 94, 95, 97, 98, 99], "set_default_backend": 77, "set_env": [61, 62], "set_lora": 90, "setenv": 61, "setup": [7, 15, 21, 23, 28, 40, 50, 56, 57, 67, 70, 79, 90, 96], "setup_musa": 68, "setup_rocm": 58, "setuptool": [67, 71], "sever": [11, 13, 17, 19, 22, 36, 37, 46, 50, 67, 98], "sft": 84, "sgl": [0, 3, 5, 10, 17, 20, 21, 22, 25, 26, 27, 28, 30, 32, 33, 36, 37, 42, 45, 46, 48, 52, 54, 55, 56, 57, 58, 60, 67, 68, 70, 71, 75, 77, 78, 80, 81, 83, 86, 88, 89, 92, 93, 95, 98], "sgl_": 73, "sgl_cach": 80, "sgl_cache1": 80, "sgl_cache4": 83, "sgl_dg_use_nvrtc": 73, "sgl_enable_jit_deepgemm": 83, "sgl_ext": 40, "sgl_grpc_endpoint": 22, "sgl_jax": 70, "sgl_kernel": [48, 56], "sgl_tokenizer_path": 22, "sgl_use_deepgemm_bmm": 73, "sglang": [1, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 28, 33, 35, 37, 40, 41, 42, 43, 46, 47, 48, 49, 54, 55, 61, 62, 64, 65, 67, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97], "sglang_": 73, "sglang_allow_overwrite_longer_context_len": 73, "sglang_blackwell_overlap_shared_experts_outside_sbo": 73, "sglang_block_nonzero_rank_children": 73, "sglang_cache_dit_bn": 90, "sglang_cache_dit_en": 90, "sglang_cache_dit_fn": 90, "sglang_cache_dit_mc": 90, "sglang_cache_dit_rdt": 90, "sglang_cache_dit_scm_cache_bin": 90, "sglang_cache_dit_scm_compute_bin": 90, "sglang_cache_dit_scm_polici": 90, "sglang_cache_dit_scm_preset": 90, "sglang_cache_dit_taylors": 90, "sglang_cache_dit_ts_ord": 90, "sglang_cache_dit_warmup": 90, "sglang_chunked_prefix_cache_threshold": [73, 80], "sglang_clip_max_new_tokens_estim": 73, "sglang_cpu_omp_threads_bind": 67, "sglang_cutlass_mo": 73, "sglang_data_parallel_budget_interv": 73, "sglang_debug_memory_pool": 73, "sglang_deepep_bf16_dispatch": [64, 73], "sglang_deepep_ll_combine_send_num_sm": 73, "sglang_deepep_num_max_dispatch_tokens_per_rank": [61, 62, 64, 73], "sglang_detokenizer_max_st": 73, "sglang_dev": 52, "sglang_dg_cache_dir": 73, "sglang_diffusion_attention_config": 90, "sglang_disable_consecutive_prefill_overlap": 73, "sglang_disable_fa4_warmup": 73, "sglang_disable_outlines_disk_cach": 73, "sglang_disable_request_log": 73, "sglang_disaggregation_bootstrap_timeout": [15, 61, 83], "sglang_disaggregation_heartbeat_interv": 15, "sglang_disaggregation_heartbeat_max_failur": 15, "sglang_disaggregation_nixl_backend": 15, "sglang_disaggregation_queue_s": 15, "sglang_disaggregation_thread_pool_s": 15, "sglang_disaggregation_waiting_timeout": [15, 83], "sglang_dp_round_robin": [61, 62], "sglang_dynamic_chunking_smooth_factor": 16, "sglang_enable_flashinfer_fp8_gemm": [21, 73], "sglang_enable_jit_deepgemm": [29, 73, 80], "sglang_enable_overlap_plan_stream": [61, 62, 64], "sglang_enable_spec_v2": [24, 29, 30, 31, 33, 61, 62, 64], "sglang_enable_torch_compil": 73, "sglang_enable_torch_inference_mod": 73, "sglang_enable_tp_memory_inbalance_check": 73, "sglang_eplb_heatmap_collection_interv": 73, "sglang_flashinfer_fp4_gemm_backend": [21, 73], "sglang_flashinfer_num_max_dispatch_tokens_per_rank": 73, "sglang_force_fp8_marlin": 73, "sglang_forward_unknown_tool": 73, "sglang_fused_mla_enable_rope_fus": 73, "sglang_hack_deepep_new_mod": 80, "sglang_hack_deepep_num_sm": 80, "sglang_health_check_timeout": 73, "sglang_host_ip": 73, "sglang_imag": 58, "sglang_in_deepgemm_precompile_stag": 73, "sglang_int4_weight": 73, "sglang_is_first_rank_on_nod": 73, "sglang_is_flashinfer_avail": 73, "sglang_is_in_ci": [55, 73], "sglang_is_in_ci_amd": 73, "sglang_jit_deepgemm_compile_work": 73, "sglang_jit_deepgemm_precompil": 73, "sglang_logging_config_path": 73, "sglang_mm_buffer_size_mb": 73, "sglang_mm_precompute_hash": 73, "sglang_moe_nvfp4_dispatch": 73, "sglang_moe_pad": 73, "sglang_mooncake_custom_mem_pool": 15, "sglang_mooncake_trans_thread": 80, "sglang_nccl_all_gather_in_overlap_scheduler_sync_batch": 73, "sglang_npu": 60, "sglang_npu_use_mlapo": [61, 62], "sglang_npu_use_multi_stream": 61, "sglang_nsa_enable_mtp_precompute_metadata": 73, "sglang_nsa_fuse_topk": 73, "sglang_nvfp4_ckpt_fp8_gemm_in_attn": 73, "sglang_nvfp4_ckpt_fp8_nextn_mo": 73, "sglang_one_visible_device_per_process": 73, "sglang_otlp_exporter_max_export_batch_s": [73, 86], "sglang_otlp_exporter_schedule_delay_milli": [73, 86], "sglang_per_token_group_quant_8bit_v2": 73, "sglang_port": 73, "sglang_pp_layer_partit": [16, 30, 73], "sglang_profile_record_shap": 73, "sglang_profile_with_stack": [50, 73], "sglang_queued_timeout_m": 73, "sglang_random": 49, "sglang_record_step_tim": 73, "sglang_request_dump": 14, "sglang_rout": [6, 15, 21, 22, 30, 50, 60, 61, 62, 80, 83, 86], "sglang_scheduler_decrease_prefill_idl": 61, "sglang_scheduler_max_recv_per_pol": 73, "sglang_scheduler_recv_skipper_weight_decod": 73, "sglang_scheduler_recv_skipper_weight_default": 73, "sglang_scheduler_recv_skipper_weight_non": 73, "sglang_scheduler_recv_skipper_weight_verifi": 73, "sglang_scheduler_skip_all_gath": [61, 62], "sglang_server_host": 85, "sglang_set_cpu_affin": [60, 61, 62, 64, 73, 80, 83], "sglang_skip_p2p_check": 73, "sglang_skip_sgl_kernel_version_check": 83, "sglang_storag": [13, 20, 21, 25, 26, 27, 28, 36, 37], "sglang_support_cutlass_block_fp8": [21, 73], "sglang_symm_mem_prealloc_gb_s": 73, "sglang_test_request_time_stat": 73, "sglang_test_retract": 73, "sglang_test_retract_no_prefill_b": 73, "sglang_tool_strict_level": 73, "sglang_torch_profiler_dir": [49, 50, 73], "sglang_use_ait": 73, "sglang_use_cpu_engin": 67, "sglang_use_cuda_ipc_transport": [32, 45], "sglang_use_custom_triton_kernel_cach": 73, "sglang_use_fia_nz": [61, 62], "sglang_use_modelscop": [49, 73, 94], "sglang_vit_enable_cuda_graph": 3, "sglang_vlm_cache_size_mb": [32, 45], "sglang_wait_weights_ready_timeout": 73, "sglang_zhync": 52, "sglangtracepropagatecontext": 86, "sglangtracereqcontext": 86, "sglangtracethreadcontext": 86, "sglroutertestatp_high": 22, "sgmv": 13, "sh": [0, 22, 54, 56, 58, 61, 62, 67, 69, 83], "shadow": 13, "shakhizat": 69, "shanghai_ai_laboratori": 66, "shape": [3, 8, 13, 17, 23, 28, 37, 40, 46, 48, 50, 73], "shard": [13, 15, 20, 23, 24, 25, 26, 27, 28, 30, 36, 37, 40, 41, 42, 47, 77], "sharded_st": 21, "share": [1, 7, 10, 11, 12, 13, 15, 18, 21, 22, 23, 25, 26, 32, 33, 45, 49, 51, 55, 59, 61, 62, 70, 73, 78, 79, 80, 84, 86, 90, 96], "sharegpt": [49, 50], "sharpli": 33, "she": 13, "shell": [41, 42, 47, 50, 52], "ship": 87, "shirt": [28, 77], "shm": [21, 52, 55, 56, 58, 60, 67, 79, 80, 83, 90], "shone": 13, "short": [21, 30, 33, 37, 40, 46, 49, 90, 98], "shorter": 75, "shorthand": 21, "shot": [27, 30, 51, 52, 53, 59], "should": [4, 11, 12, 13, 16, 18, 21, 23, 24, 26, 27, 29, 30, 31, 33, 35, 37, 40, 48, 50, 52, 67, 72, 79, 80, 85, 86, 90, 96, 98], "show": [2, 4, 13, 16, 18, 21, 27, 28, 30, 33, 38, 40, 42, 56, 58, 60, 77, 79, 81, 90, 95], "show_time_cost": [13, 20, 25, 26, 27, 28, 36, 37], "showcas": 81, "shown": [1, 13, 27, 28, 50, 58, 89, 90], "shrub": 13, "shuffl": [7, 21], "shut": 90, "shutdown": [20, 21, 25, 26, 27, 28, 37, 98], "side": [3, 13, 21, 28, 50, 88, 95], "sig": [79, 80, 83], "sigmoid": 36, "sign": [18, 28, 37], "signal": 33, "signatur": [8, 98], "signific": [2, 5, 7, 15, 16, 18, 29, 36, 37, 51, 59, 74, 92], "significantli": [2, 11, 16, 19, 30, 32, 33, 45, 56, 62, 70, 77, 90], "sigquit": 21, "silent": [23, 24], "silu": 73, "siluandmul": 98, "similar": [1, 36, 40, 46, 48, 96, 98], "similar_imag": 96, "similarli": [11, 67, 74, 92, 98], "simpl": [11, 12, 17, 18, 22, 26, 28, 30, 38, 48, 77, 79, 90, 98], "simplenamespac": 62, "simpler": [18, 50], "simplest": 23, "simpli": [17, 25, 36, 56, 63, 75, 90, 91, 96], "simplic": 23, "simplifi": [7, 29, 50, 70], "simul": [7, 53], "simultan": [15, 16, 70, 90], "sin_cos_w": 3, "sinc": [5, 11, 13, 16, 20, 24, 25, 26, 27, 28, 33, 34, 36, 37, 40, 41, 42, 44, 47, 51, 56, 59, 77], "singl": [4, 11, 18, 21, 22, 27, 28, 29, 30, 40, 46, 50, 51, 53, 56, 57, 58, 59, 67, 70, 73, 81, 90, 98], "singleprocess": 24, "sink": 22, "size": [1, 2, 3, 4, 5, 7, 10, 11, 13, 15, 17, 18, 21, 22, 23, 28, 29, 30, 31, 32, 33, 35, 36, 44, 45, 48, 49, 50, 52, 53, 55, 56, 58, 60, 61, 62, 64, 67, 69, 70, 71, 73, 74, 79, 80, 81, 83, 90, 91, 92, 93, 95, 96, 97], "size_t": 48, "sk": [33, 49, 55, 90], "skew": 46, "skill": [13, 30], "skip": [0, 8, 13, 17, 21, 36, 49, 50, 52, 53, 58, 70, 73, 87, 90], "skip_server_warmup": [13, 20, 25, 26, 27, 28, 36, 37], "skip_special_token": [20, 22, 27, 36, 46], "skip_tokenizer_init": [13, 20, 25, 26, 27, 28, 36, 37], "skipper": 73, "sky": [13, 56, 70], "skyserv": 56, "skywork": [36, 57, 66, 97], "slack": [10, 51, 59, 70, 78], "slash": [51, 59], "sleep": [2, 21, 55, 77, 81, 84, 90, 96], "sleep_on_idl": [13, 20, 25, 26, 27, 28, 36, 37], "slice": 90, "slice_span": 86, "slide": [1, 29, 70, 78, 84], "sliding_tile_attn": 90, "slight": 74, "slightli": [26, 40, 74], "slime": [57, 84], "slo": 11, "slot": 13, "slow": [12, 18, 21, 23, 74, 87, 90], "slowdown": 49, "slower": [11, 21, 89], "slowli": 12, "slurm_log": 81, "slurm_nodeid": 81, "slurm_nodelist": 81, "slurm_procid": 81, "slytherin": 77, "sm": [21, 73, 79], "sm10": 21, "sm100": [21, 30, 73], "sm103": 56, "sm120": 90, "sm75": 56, "sm80": 90, "sm86": 90, "sm89": 90, "sm90": [21, 30, 73, 90], "sm_103a": 56, "sm_group_num": [13, 20, 25, 26, 27, 28, 36, 37], "sm_sglang_": 56, "sm_sglang_input_argu": 56, "sm_sglang_model_path": 56, "sm_sglang_reasoning_pars": 56, "small": [0, 3, 5, 11, 12, 13, 16, 21, 23, 24, 29, 30, 33, 50, 51, 59, 66, 74, 92, 95], "small3": 92, "smaller": [11, 12, 13, 16, 18, 21, 22, 51, 56, 59, 70, 74, 90, 97], "smallest": 46, "smartphon": 37, "smg": 22, "smg_db_": 22, "smg_discovery_": 22, "smg_http_": 22, "smg_http_rate_limit_tot": 22, "smg_http_request_duration_seconds_bucket": 22, "smg_http_requests_tot": 22, "smg_http_responses_tot": 22, "smg_mcp_": 22, "smg_mcp_servers_act": 22, "smg_mcp_tool_calls_tot": 22, "smg_mcp_tool_duration_seconds_bucket": 22, "smg_router_": 22, "smg_router_generation_duration_second": 22, "smg_router_generation_duration_seconds_bucket": 22, "smg_router_requests_tot": 22, "smg_router_tokens_tot": 22, "smg_router_tpot_second": 22, "smg_router_tpot_seconds_bucket": 22, "smg_router_ttft_second": 22, "smg_router_ttft_seconds_bucket": 22, "smg_worker_": 22, "smg_worker_cb_": 22, "smg_worker_cb_st": 22, "smg_worker_cb_transitions_tot": 22, "smg_worker_connections_act": 22, "smg_worker_health_checks_tot": 22, "smg_worker_pool_s": 22, "smg_worker_requests_act": 22, "smg_worker_retries_exhausted_tot": 22, "smg_worker_retries_tot": 22, "smollm": [66, 92], "smooth": [40, 41, 42, 51, 59], "smoother": 21, "smoothli": 50, "snapshot": [13, 32, 36, 45, 98], "snapshot_download": 98, "snc": 67, "snippet": [27, 33, 50, 51, 59], "so": [0, 1, 3, 8, 12, 13, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 36, 37, 40, 41, 42, 46, 47, 50, 51, 59, 67, 77, 90, 98], "social": 37, "societi": [36, 37], "socket": [2, 67, 79], "soft": [13, 21, 49], "soft_watchdog_timeout": [13, 20, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77], "softmax": [22, 36], "softwar": 93, "solar": 92, "sole": 24, "solid": 24, "solut": [3, 11, 16, 20, 21, 23, 56], "solv": [3, 16, 20], "some": [0, 1, 12, 16, 17, 23, 26, 27, 29, 37, 40, 48, 49, 50, 51, 52, 55, 56, 59, 77, 79, 80, 85, 86, 90, 91, 92, 96, 97, 98], "somehow": 13, "someon": [28, 37], "someth": [13, 24, 26, 48], "sometim": [3, 14, 24, 26, 36, 74, 79, 96], "somewhat": 42, "somewher": 26, "soon": [17, 93, 95, 99], "sophia": 13, "sophist": [35, 37, 40], "sorcer": 13, "sort": [46, 96], "sota": 92, "sound": 13, "sourc": [4, 15, 23, 24, 25, 26, 33, 34, 46, 48, 50, 53, 57, 61, 62, 81, 85, 92, 95, 98], "south": 47, "sp": 90, "sp_size": 90, "space": [11, 40, 44, 46, 49, 91, 94], "spaces_between_special_token": 46, "spain": [24, 40], "spam": [51, 59], "span": [11, 22, 50, 86, 92], "spark": [56, 57], "sparkl": 13, "spars": [30, 90, 92], "sparseautomodelforcausallm": 17, "speak": 74, "spec": [1, 21, 22, 24, 47, 62, 70, 79, 80, 83, 88], "spec_nam": 8, "speci": [36, 96], "special": [7, 13, 20, 23, 26, 27, 30, 37, 46, 53, 88, 92, 93, 95, 97], "specif": [1, 8, 10, 11, 16, 17, 18, 21, 22, 26, 29, 40, 46, 50, 51, 56, 59, 60, 71, 90, 92, 93, 95], "specifi": [1, 4, 6, 7, 11, 13, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 40, 41, 42, 45, 46, 47, 50, 55, 56, 58, 60, 67, 70, 72, 75, 77, 85, 86, 90, 91, 96], "specific_funct": 27, "specul": [7, 29, 30, 49, 57, 61, 62, 64, 84], "speculative_accept_threshold_acc": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_accept_threshold_singl": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_algorithm": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_attention_mod": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_draft_attention_backend": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_draft_load_format": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_draft_model_path": [13, 20, 24, 25, 26, 27, 28, 36, 37], "speculative_draft_model_quant": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_draft_model_revis": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_eagle_topk": [13, 20, 24, 25, 26, 27, 28, 36, 37], "speculative_moe_a2a_backend": [13, 20, 24, 25, 26, 27, 28, 36, 37], "speculative_moe_runner_backend": [13, 20, 24, 25, 26, 27, 28, 36, 37], "speculative_ngram_branch_length": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_capac": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_match_typ": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_max_bfs_breadth": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_max_match_window_s": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_min_bfs_breadth": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_ngram_min_match_window_s": [13, 20, 25, 26, 27, 28, 36, 37], "speculative_num_draft_token": [13, 20, 21, 24, 25, 26, 27, 28, 36, 37], "speculative_num_step": [13, 20, 24, 25, 26, 27, 28, 36, 37], "speculative_token_map": [13, 20, 25, 26, 27, 28, 36, 37], "speech": [37, 92], "speed": [11, 21, 23, 24, 29, 30, 33, 44, 49, 74, 79, 90, 95], "speedup": [28, 29, 30, 84, 90], "spell": [13, 40], "spent": 13, "spike": [7, 37, 90], "split": [1, 4, 7, 8, 11, 13, 17, 20, 21, 22, 25, 26, 27, 28, 36, 37, 49, 51, 59], "split_kv": 1, "spoke": 13, "spot": [13, 70], "sprai": 28, "spread": 13, "sql": [13, 40], "sqrt": 98, "squar": 98, "src": [22, 48, 52, 83, 88], "srt": [1, 2, 13, 14, 17, 20, 22, 24, 28, 29, 31, 36, 40, 41, 42, 46, 47, 77, 80, 88, 92, 95, 98, 99], "srun": 81, "ss": 90, "sse": [22, 33], "ssf": 22, "ssh": [38, 52], "ssm": [21, 44], "st": 56, "st_attn": 90, "stabil": [7, 16, 23, 29, 30, 84], "stabilityai": [66, 92], "stabl": [4, 40, 52, 56, 58, 90, 92], "stablelm": [66, 92], "stack": [22, 23, 24, 50, 73, 83, 84, 85, 90, 95], "stag": 77, "stage": [6, 7, 15, 16, 21, 22, 29, 30, 31, 33, 51, 59], "stage_duration_second": 22, "stai": [0, 16, 37, 71, 73, 77], "stall": 23, "stand": [12, 21, 26, 42, 77], "standalon": 21, "standard": [1, 4, 7, 8, 11, 20, 22, 40, 70, 79, 88, 90, 98], "stanlei": 33, "star": [13, 57], "starcod": 92, "starcoder2": 92, "starsfridai": 90, "start": [0, 13, 14, 16, 17, 19, 20, 21, 24, 26, 27, 29, 30, 33, 36, 40, 46, 47, 50, 51, 56, 58, 59, 60, 63, 67, 69, 70, 71, 77, 79, 85, 86, 94, 98], "start_expert_distribution_record": 36, "start_profil": 49, "start_step": 50, "start_tag": [25, 26], "startswith": [46, 47], "startup": [8, 13, 21, 22, 24, 30, 35, 36, 52, 58, 70, 79, 80, 83, 93], "startuppolici": 80, "starvat": 13, "stat": [21, 22, 24, 36], "state": [8, 11, 12, 13, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 40, 44, 46, 47, 51, 59, 73, 77, 79, 84, 90, 92], "statefulset": 56, "statement": [37, 98], "static": [7, 10, 15, 16, 21, 23, 24, 29, 30, 31, 32, 34, 35, 45, 48, 50, 61, 62, 63, 64, 69, 70, 74, 79, 80, 83, 90], "static_cast": 48, "static_config": 85, "statist": [7, 17, 22, 49, 73], "statu": [22, 23, 25, 26, 36, 48, 52, 56, 70, 77, 79, 85, 88, 90], "status_cod": 13, "std": 49, "stdin": 56, "stdio": 22, "stdout": 21, "steadi": 12, "steadili": 26, "step": [0, 11, 13, 16, 17, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 34, 44, 50, 51, 52, 56, 59, 61, 62, 64, 67, 70, 73, 79, 87, 98], "step3": [21, 22, 27], "still": [6, 12, 13, 15, 21, 26, 27, 30, 33, 36, 40, 80, 86, 90], "stochast": 4, "stock": 33, "stolen": 13, "stop": [11, 12, 13, 21, 24, 25, 26, 36, 40, 42, 46, 47, 50, 77, 85], "stop_after_first": 25, "stop_expert_distribution_record": 36, "stop_profil": 49, "stop_regex": 46, "stop_str": 72, "stop_token_id": 46, "storag": [18, 21], "store": [8, 10, 11, 21, 22, 44, 48, 50, 62, 86], "stori": [38, 40], "str": [8, 13, 21, 22, 23, 25, 26, 27, 46, 98], "straightforward": [12, 22, 26], "strateg": 7, "strategi": [11, 12, 13, 15, 16, 21, 22, 23, 44, 89, 90], "strawberri": 40, "stream": [16, 21, 22, 25, 26, 29, 38, 40, 48, 73, 89, 98], "stream_and_merg": 37, "stream_interv": [13, 20, 25, 26, 27, 28, 36, 37], "stream_output": [13, 20, 25, 26, 27, 28, 36, 37], "stream_reason": 20, "streamabl": 22, "streamlin": [17, 35, 91], "streams_per_devic": [61, 62, 64], "street": [28, 42, 77, 90, 96], "strength": 90, "strengthen": 77, "strict": [49, 73], "strictli": [13, 16, 21], "stride": [24, 48], "string": [4, 8, 11, 12, 13, 21, 22, 23, 25, 26, 27, 28, 29, 36, 40, 46, 88, 90, 96], "strip": [46, 47], "strong": [7, 11, 33, 37, 45, 75, 92, 95], "strongest": 11, "strongli": [7, 17, 40, 48, 53, 58], "struct": 48, "structal": 46, "structur": [7, 11, 16, 21, 22, 23, 27, 57, 73, 77, 86, 90, 95], "structural_tag": [25, 26, 46], "stuck": [22, 79], "student": 77, "studio": 52, "stumbl": 13, "stunt": 28, "style": [21, 22, 23, 24, 49, 90, 99], "style_lora": 90, "styliz": 42, "sub": [29, 36, 67], "subclass": [7, 20], "subcommand": 90, "subdirectori": 0, "subdomainpolici": 80, "subject": [22, 90], "submit": [12, 49, 51, 53, 59, 81], "submodul": 8, "suboptim": 6, "subprocess": [21, 41, 42, 47], "subsequ": [3, 11, 16, 23, 70], "subset": [75, 90, 96], "substanti": [11, 15], "succe": 80, "succeed": [23, 36], "success": [13, 22, 23, 36, 52, 58], "successfulli": [11, 13, 56, 60, 79, 85], "successor": [37, 92], "successthreshold": 83, "sudo": [58, 60, 69], "suffer": 23, "suffici": [11, 12, 48, 70, 95], "suffix": [51, 59], "suggest": [10, 12, 17, 25, 28, 32, 37, 45, 53, 62, 69], "suit": 90, "suitabl": [11, 16, 21, 96], "sum": [20, 22, 33, 36], "summar": [37, 77, 89, 92, 95], "summari": [22, 49, 77], "summon": 13, "sun": 96, "sunni": 40, "sunset": [90, 96], "super": [92, 98], "supercharg": 58, "superior": [70, 92], "suppli": [18, 21, 22, 29, 75], "support": [2, 6, 8, 11, 12, 13, 14, 15, 16, 17, 19, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 36, 37, 41, 42, 44, 45, 46, 48, 50, 51, 56, 58, 59, 63, 65, 69, 71, 73, 75, 77, 79, 84], "suppos": [13, 48], "sur": 36, "sure": [0, 3, 20, 24, 26, 27, 36, 40, 47, 50, 51, 59, 60, 77, 79, 98], "surg": 33, "surpass": 92, "surprisingli": 92, "surround": 13, "svc": [80, 83], "swa": [21, 34], "swa_full_tokens_ratio": [13, 20, 25, 26, 27, 28, 36, 37], "swa_siz": 21, "swagger": 47, "swap": 3, "swappi": [60, 61, 62], "switch": [7, 10, 13, 16, 20, 21, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 49, 56, 77, 79, 99], "sy": [58, 60, 61, 62, 83], "symbol": [26, 48, 90], "symbolic_correct": 30, "symbolicdevic": 48, "symbolicdtyp": 48, "symbolics": 48, "symm": [21, 73], "symmetr": [21, 73], "sync": [16, 23, 52, 73], "sync_duration_second": 22, "synchron": [10, 13, 16, 22, 29, 51, 59], "syntact": 21, "syntax": [13, 22, 26, 40], "synthet": 49, "sys_ptrac": 58, "sysctl": [60, 61, 62], "system": [2, 7, 9, 10, 13, 15, 17, 21, 25, 26, 27, 28, 33, 37, 40, 46, 48, 49, 53, 57, 61, 62, 67, 72, 73, 77, 79, 80, 83, 84, 85, 89, 92, 96, 98], "system_fingerprint": [24, 27, 40, 47], "systemat": 70, "systemcut": 25, "systemprompt": 10, "t": [1, 8, 13, 16, 21, 22, 24, 26, 27, 28, 30, 33, 34, 38, 40, 46, 50, 51, 52, 56, 58, 59, 60, 67, 73, 77, 79, 95, 98], "t2v": 90, "t4": 56, "t_": 24, "t_2": 24, "tabl": [1, 4, 21, 67, 71, 73, 89, 90, 92, 95, 98], "tag": [8, 20, 21, 22, 23, 27, 38, 46, 51, 59, 60, 73], "tail": [16, 23], "tailor": [15, 32, 45], "taint": [80, 83], "take": [0, 1, 8, 12, 13, 15, 16, 17, 21, 22, 24, 29, 36, 40, 50, 51, 52, 58, 59, 67, 70, 79, 90, 94, 98], "tale": 13, "talent": 13, "taller": 13, "tar": 52, "target": [1, 7, 8, 13, 16, 17, 21, 22, 24, 33, 49, 50, 73, 85], "target_modul": 21, "target_pattern": 8, "targetport": [79, 80, 83], "tarn59": 90, "task": [2, 18, 23, 34, 35, 36, 37, 38, 40, 51, 59, 81, 88, 90, 91, 92, 95, 96, 97], "task_queue_en": [61, 62], "task_typ": 90, "taught": 13, "taxi": [28, 42, 77], "taxicab": 28, "taylor": 90, "tbo": 21, "tbo_token_distribution_threshold": [13, 20, 25, 26, 27, 28, 36, 37], "tcp": [15, 22, 60, 61, 62, 79, 80, 83], "tcpsocket": [79, 80], "teacach": 90, "teacher": 77, "team": [17, 23, 29, 52, 90], "tech": 30, "technic": [13, 25, 30, 84], "techniqu": [7, 11, 13, 16, 17, 18, 21, 37, 70, 90, 91], "technologi": [22, 37, 79], "tee": [50, 60, 61, 62], "tele": 92, "teleai": 92, "tell": [4, 33, 37, 38, 40, 50, 85], "temp": 4, "temperatur": [13, 17, 20, 21, 24, 25, 26, 27, 29, 30, 36, 37, 40, 42, 46, 47, 49, 77, 89, 93, 98], "templ": 40, "templat": [13, 20, 21, 22, 29, 30, 34, 36, 40, 46, 48, 49, 57, 80, 83, 91, 95, 96, 98], "tempor": 95, "temporari": [15, 48], "temporarili": [22, 73], "tenant": 22, "tend": 79, "tensor": [3, 5, 8, 11, 12, 13, 16, 18, 19, 32, 45, 50, 51, 57, 59, 63, 67, 70, 73, 79, 80, 83, 90, 93, 95, 97, 98], "tensormatch": 48, "tensorrt": [7, 21, 49], "tensorview": 48, "term": [11, 21], "termin": [2, 10, 11, 13, 20, 22, 23, 24, 25, 26, 27, 32, 36, 40, 41, 42, 45, 47, 50, 52, 56, 58, 67, 71, 77], "terminate_process": [13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77], "terminu": 30, "terrifi": 13, "territori": 37, "test": [1, 2, 4, 13, 18, 20, 21, 24, 25, 26, 27, 32, 33, 36, 37, 40, 41, 42, 45, 47, 48, 50, 53, 55, 61, 63, 67, 69, 77, 79, 81, 90, 95, 96], "test_add_const": 48, "test_classify_api": 88, "test_determinist": 4, "test_eagle_infer_a": [51, 59], "test_eagle_infer_b": [51, 59], "test_eval_accuracy_larg": [51, 59], "test_generation_model": 98, "test_gpt_oss_1gpu": 51, "test_moe_eval_accuracy_larg": 59, "test_oth": 98, "test_vision_openai_server_": 98, "test_vision_openai_server_a": 98, "test_vision_openai_server_b": 98, "testgenerationmodel": 98, "text": [4, 5, 13, 17, 20, 21, 22, 24, 25, 26, 27, 28, 32, 35, 37, 38, 40, 41, 42, 45, 46, 47, 49, 88, 89, 90, 91, 92, 93, 95, 98], "text_complet": 40, "text_embed": 41, "text_encod": 90, "text_encoder_precis": 90, "text_input": 91, "text_it": 77, "text_qa": 77, "textual": [5, 98], "textur": 5, "th": 21, "than": [11, 12, 13, 15, 16, 17, 18, 21, 22, 24, 26, 30, 35, 37, 46, 51, 56, 59, 67, 77, 90, 94, 96, 98], "thank": [24, 51, 59, 69, 79, 81], "the_big": 36, "thei": [0, 7, 8, 13, 15, 16, 26, 36, 37, 40, 42, 46, 67, 73, 77, 79, 85, 92, 95, 97, 98], "them": [1, 5, 7, 13, 14, 17, 23, 26, 29, 33, 36, 37, 40, 49, 51, 52, 58, 59, 67, 73, 74, 80, 85, 86, 90, 95, 98], "therebi": 11, "therefor": [11, 12, 13, 16, 20, 36, 40, 90], "thi": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 66, 68, 69, 70, 72, 73, 74, 75, 77, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99], "thief": 13, "thing": [12, 37, 98, 99], "think": [4, 20, 21, 22, 23, 24, 26, 27, 30, 35, 44, 53, 66, 80, 83, 89, 92, 95], "think_end_token": 26, "thinking_budget": [29, 31], "third": [33, 37, 40], "thorough": 26, "thoroughli": 98, "those": [13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77, 90], "though": [16, 26, 77], "thought": [22, 24], "thousand": 11, "thread": [13, 15, 20, 21, 22, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 47, 77, 86], "thread_finish_flag": 86, "thread_label": 86, "thread_span": 86, "threadidx": 48, "threadpool": 21, "three": [1, 4, 6, 10, 11, 13, 23, 24, 25, 40, 46, 47, 77], "threshold": [11, 14, 21, 22, 30, 73, 89, 90], "threshold_acc": 21, "thrill": 13, "thrive": 37, "throne": 13, "through": [7, 11, 13, 16, 22, 27, 28, 29, 30, 40, 48, 49, 50, 51, 58, 59, 60, 67, 70, 78, 90, 95], "throughout": 22, "throughput": [5, 7, 13, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 36, 40, 41, 42, 45, 47, 49, 51, 53, 57, 59, 74, 77, 84, 85, 90, 92, 95, 96, 98], "thu": [13, 16, 30, 36, 40, 52, 90, 95, 98, 99], "thudm": 92, "thumb": 12, "thunlp": 24, "ti2v": 90, "tier": [6, 10, 11, 22], "tight": 13, "tightli": 6, "tiktoken": [22, 40], "tile": 21, "tile_sample_min_height": 90, "tile_sample_min_width": 90, "tilelang": [21, 30], "time": [0, 1, 2, 3, 7, 11, 12, 13, 15, 16, 17, 19, 21, 22, 24, 25, 26, 29, 30, 32, 36, 40, 41, 45, 46, 48, 49, 50, 51, 52, 53, 59, 67, 73, 74, 79, 81, 85, 98], "time_per_output_token_second": 85, "time_per_output_token_seconds_bucket": 85, "time_per_output_token_seconds_count": 85, "time_per_output_token_seconds_sum": 85, "time_to_first_token_second": 85, "time_to_first_token_seconds_bucket": 85, "time_to_first_token_seconds_count": 85, "time_to_first_token_seconds_sum": 85, "timelin": 50, "timeout": [10, 11, 15, 16, 21, 22, 29, 30, 32, 34, 45, 61, 62, 64, 73, 83], "timeoutsecond": 83, "timestamp": [49, 88], "timestep": [24, 90], "timezon": [25, 26], "tini": 90, "tinyllama": 17, "tip": [0, 16, 48, 74, 77], "tip_suggest": 77, "titl": [37, 98], "tl": 24, "tlsv1": 22, "tmp": [14, 21, 22, 50, 55, 70, 73, 86], "tmp_autoround": 17, "tn": 22, "to_stat": 22, "to_str": [29, 31, 46], "todai": [27, 29, 35, 40], "todo": 60, "togeth": [3, 11, 13, 15, 17, 20, 21, 22, 24, 25, 26, 27, 30, 36, 40, 41, 42, 47, 73, 77, 90, 95], "tok": [49, 53], "token": [1, 3, 6, 7, 11, 13, 15, 17, 18, 20, 23, 25, 26, 27, 31, 34, 35, 41, 44, 46, 53, 56, 58, 61, 62, 64, 67, 70, 72, 73, 79, 80, 83, 85, 86, 88, 89, 90, 92, 95, 96, 98], "token_capac": 36, "token_id": [36, 40, 46], "token_ids_logprob": 46, "token_idx": [21, 30], "token_length_norm": 75, "token_step": 23, "token_usag": 85, "tokenization_result": 36, "tokenize_payload": 36, "tokenize_respons": 36, "tokenize_url": 36, "tokenizer_free_server_process": 36, "tokenizer_manag": 27, "tokenizer_metrics_allowed_custom_label": [13, 20, 25, 26, 27, 28, 36, 37], "tokenizer_metrics_custom_labels_head": [13, 20, 25, 26, 27, 28, 36, 37], "tokenizer_mod": [13, 20, 25, 26, 27, 28, 36, 37], "tokenizer_path": [13, 20, 25, 26, 27, 28, 36, 37], "tokenizer_worker_num": [13, 20, 25, 26, 27, 28, 36, 37], "tokenizermanag": [13, 36], "tokenizers_parallel": [25, 26, 41], "tokens_to_gener": 30, "tokens_tot": 22, "tokyo": [13, 24, 27, 40, 77], "tokyo3": 77, "told": 13, "toler": [15, 18, 22, 23, 80, 83], "tolist": 28, "toml": [11, 21, 51, 54, 58, 59, 60, 67, 68, 71], "tongyi": 90, "too": [12, 13, 16, 22, 26, 29, 49, 51, 59, 70], "tool": [8, 20, 21, 23, 25, 26, 29, 30, 31, 35, 50, 56, 57, 77, 86, 92, 95], "tool_cal": [24, 27, 29, 40, 42, 47, 80, 83], "tool_call_id": 27, "tool_call_pars": [13, 20, 25, 26, 27, 28, 36, 37], "tool_calls_tot": 22, "tool_chat_template_deepseekv3": [27, 29], "tool_chat_template_deepseekv31": 27, "tool_chat_template_deepseekv32": 30, "tool_chat_template_llama4_python": 27, "tool_choic": 27, "tool_dict": 27, "tool_duration_second": 22, "tool_get_current_d": [25, 26], "tool_get_current_weath": [25, 26], "tool_iterations_tot": 22, "tool_nam": 27, "tool_serv": [13, 20, 25, 26, 27, 28, 36, 37], "tool_to_cal": 27, "tool_ttl": 22, "tool_us": [21, 77], "toolcallitem": 27, "toolchain": 22, "toolkit": [60, 61, 62, 69], "toolkit_aarch64_20251121": 60, "tools_tag_list": 27, "top": [11, 24, 27, 30, 37, 46, 51, 59, 84, 92], "top_k": [13, 36, 40, 46, 98], "top_logprobs_num": 46, "top_p": [13, 17, 20, 21, 25, 26, 27, 30, 36, 37, 40, 46, 49, 93], "topk": [1, 7, 21, 24, 29, 30, 31, 34, 44, 61, 62, 64, 70, 73], "topkoutput": 7, "topo": 83, "topologi": [22, 83], "torch": [1, 7, 12, 13, 15, 21, 23, 29, 36, 41, 48, 50, 56, 60, 67, 71, 73, 79, 98, 99], "torch_compile_caching_tutori": 87, "torch_compile_max_b": [13, 20, 25, 26, 27, 28, 36, 37], "torch_dtyp": [17, 28], "torch_empty_cach": 23, "torch_log": 24, "torch_memory_sav": 23, "torch_n": [1, 21, 36, 91, 96], "torch_npu": 60, "torch_npu_vers": 60, "torch_sdpa": 90, "torchao": [21, 67, 71], "torchao_config": [13, 20, 25, 26, 27, 28, 36, 37], "torchaudio": [67, 71], "torchinductor_cache_dir": [21, 87], "torchinductor_root": 21, "torchrun": 2, "torchvis": [56, 60, 67, 71], "torchvision_vers": 60, "total": [11, 12, 13, 15, 16, 21, 22, 23, 30, 35, 40, 49, 50, 61, 67, 88, 92, 96], "total_input_token": 49, "total_kv_token": 30, "total_output_token": 49, "total_q_token": 30, "total_request": 21, "total_retract": [25, 26, 36, 47], "total_token": [21, 22, 24, 27, 29, 40, 41, 42, 47, 80, 83, 88], "toulous": 26, "tourist": [26, 27, 37], "toward": [16, 28, 33, 46, 95, 97], "tower": [24, 26, 37], "tp": [1, 5, 7, 10, 11, 15, 16, 21, 22, 23, 27, 29, 30, 31, 32, 33, 34, 35, 40, 44, 45, 50, 52, 53, 58, 60, 61, 62, 64, 67, 70, 71, 79, 80, 81, 83, 90, 93, 97], "tp0": 79, "tp1": 79, "tp16": 81, "tp2": 79, "tp3": 79, "tp4": 79, "tp5": 79, "tp6": [67, 79], "tp7": 79, "tp8": 29, "tp_rank": 86, "tp_size": [7, 11, 13, 20, 25, 26, 27, 28, 30, 36, 37, 61, 81, 90, 93], "tpot": [49, 61], "tpot_second": 22, "tpu": [56, 57], "tpu_vm": 70, "tpuv6": 70, "tqdm": 49, "tr": 50, "trace": [14, 21, 24, 49, 57, 73, 79], "trace_context": 86, "trace_get_proc_propagate_context": 86, "trace_get_remote_propagate_context": 86, "trace_req_finish": 86, "trace_req_start": 86, "trace_set_proc_propagate_context": 86, "trace_set_remote_propagate_context": 86, "trace_set_thread_info": 86, "trace_slice_end": 86, "trace_slice_start": 86, "tracing_compos": 86, "track": [11, 21, 22, 23, 30, 34, 36, 50, 86, 88], "trade": [7, 22, 23, 33, 40, 44, 91], "tradeoff": 21, "tradit": [10, 16, 37, 77], "tradition": 15, "traffic": [22, 23, 37, 53, 70, 85], "trail": 26, "train": [4, 17, 21, 23, 24, 27, 30, 36, 50, 57, 91, 92, 95], "trainer": 23, "trait": [3, 37], "trajectori": 33, "transfer": [2, 6, 7, 10, 13, 15, 16, 19, 21, 52, 60, 61, 62, 86], "transfer_engin": [19, 21], "transferengin": 11, "transform": [3, 5, 13, 16, 17, 20, 21, 24, 25, 26, 27, 28, 33, 36, 40, 41, 42, 47, 49, 57, 72, 77, 90, 92, 95, 98], "transformer_2": 90, "transformersmodel": 99, "transit": [22, 40, 41, 42], "transitions_tot": 22, "translat": 37, "transport": [32, 37, 40, 45], "trap": 13, "travel": [13, 26, 27], "travers": 11, "treacher": 13, "treat": [36, 73], "treatment": 37, "tree": [13, 21, 22, 24, 36, 70], "trend": [37, 98], "trepid": 13, "trial": 4, "trick": 24, "tricki": 26, "trigger": [11, 21, 25, 26, 36, 50, 67, 73], "triggered_tag": 25, "trillion": [16, 92], "trim": [27, 46], "triniti": 92, "trip": 27, "triton": [1, 4, 7, 13, 21, 29, 34, 36, 56, 67, 71, 73, 91, 96], "triton_3_5_1": 36, "triton_ascend": 60, "triton_attention_num_kv_split": [13, 20, 25, 26, 27, 28, 36, 37], "triton_attention_reduce_in_fp32": [13, 20, 25, 26, 27, 28, 36, 37], "triton_attention_split_tile_s": [13, 20, 25, 26, 27, 28, 36, 37], "triton_attn": 21, "triton_backend": 1, "triton_kernel": [7, 21], "triton_mm_10": 24, "triton_mm_102": 24, "triton_mm_103": 24, "triton_mm_106": 24, "triton_mm_107": 24, "triton_mm_11": 24, "triton_mm_111": 24, "triton_mm_113": 24, "triton_mm_114": 24, "triton_mm_115": 24, "triton_mm_116": 24, "triton_mm_119": 24, "triton_mm_12": 24, "triton_mm_120": 24, "triton_mm_123": 24, "triton_mm_124": 24, "triton_mm_128": 24, "triton_mm_130": 24, "triton_mm_133": 24, "triton_mm_136": 24, "triton_mm_137": 24, "triton_mm_139": 24, "triton_mm_14": 24, "triton_mm_140": 24, "triton_mm_141": 24, "triton_mm_142": 24, "triton_mm_145": 24, "triton_mm_147": 24, "triton_mm_148": 24, "triton_mm_149": 24, "triton_mm_150": 24, "triton_mm_153": 24, "triton_mm_154": 24, "triton_mm_157": 24, "triton_mm_158": 24, "triton_mm_162": 24, "triton_mm_164": 24, "triton_mm_167": 24, "triton_mm_17": 24, "triton_mm_170": 24, "triton_mm_171": 24, "triton_mm_172": 24, "triton_mm_174": 24, "triton_mm_175": 24, "triton_mm_176": 24, "triton_mm_179": 24, "triton_mm_18": 24, "triton_mm_20": 24, "triton_mm_22": 24, "triton_mm_23": 24, "triton_mm_26": 24, "triton_mm_27": 24, "triton_mm_30": 24, "triton_mm_31": 24, "triton_mm_36": 24, "triton_mm_37": 24, "triton_mm_4": 24, "triton_mm_45": 24, "triton_mm_46": 24, "triton_mm_47": 24, "triton_mm_48": 24, "triton_mm_49": 24, "triton_mm_50": 24, "triton_mm_54": 24, "triton_mm_55": 24, "triton_mm_56": 24, "triton_mm_58": 24, "triton_mm_60": 24, "triton_mm_61": 24, "triton_mm_64": 24, "triton_mm_65": 24, "triton_mm_68": 24, "triton_mm_69": 24, "triton_mm_7": 24, "triton_mm_74": 24, "triton_mm_75": 24, "triton_mm_8": 24, "triton_mm_83": 24, "triton_mm_84": 24, "triton_mm_85": 24, "triton_mm_87": 24, "triton_mm_88": 24, "triton_mm_89": 24, "triton_mm_92": 24, "triton_mm_93": 24, "triton_mm_94": 24, "triton_mm_96": 24, "triton_mm_97": 24, "triton_mm_98": 24, "triton_mm_99": 24, "triton_ptxas_path": 56, "tritonattn": 3, "tritonrunnercor": 7, "trivial": [13, 20, 21, 23, 25, 26, 27, 28, 36, 37], "troubleshoot": [57, 79], "troy": 36, "trt": [7, 30, 49], "trtllm": [1, 21, 29], "trtllm_mha": [1, 21, 34], "trtllm_mla": [1, 21], "true": [1, 12, 13, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 36, 37, 38, 40, 41, 42, 45, 46, 47, 49, 50, 55, 61, 62, 64, 70, 73, 77, 79, 80, 83, 85, 86, 89, 90, 91, 94, 96, 98, 99], "truncat": [21, 24, 50, 91], "truss": 49, "trust": [1, 15, 16, 21, 22, 24, 29, 30, 32, 34, 35, 37, 45, 51, 52, 58, 59, 60, 61, 62, 64, 67, 70, 71, 79, 80, 83, 84, 90, 91, 95, 96, 97], "trust_remote_cod": [13, 17, 20, 25, 26, 27, 28, 36, 37, 89, 99], "truth": 23, "try": [8, 11, 13, 17, 21, 24, 26, 29, 36, 37, 51, 56, 59, 60, 74, 79], "tse": 21, "ttft": [5, 13, 15, 16, 30, 32, 49, 53, 70, 98], "ttft_second": 22, "tune": [7, 11, 13, 21, 24, 27, 30, 32, 45, 57, 58, 71, 80, 84, 87, 90, 92, 97], "tuned_8sm": 80, "tunix": [57, 84], "tunnel": [38, 52], "tupl": 8, "turbo": [40, 90], "turn": [8, 10, 22, 23, 29, 61], "tutori": [25, 28, 40, 41, 42, 87], "tvm": 48, "tvm_ffi": 48, "twice": [11, 74], "twine": 54, "twitter": 78, "two": [1, 2, 5, 8, 10, 11, 12, 13, 15, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 37, 42, 44, 46, 52, 56, 72, 73, 74, 77, 79, 80, 81, 86, 90, 96, 98, 99], "txt": 0, "type": [4, 7, 8, 13, 18, 22, 23, 25, 26, 27, 29, 32, 33, 35, 36, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 62, 70, 80, 83, 85, 88, 89, 90, 95, 96, 98], "type_check": 48, "typic": [3, 5, 6, 12, 13, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 34, 36, 40, 41, 42, 47, 48, 49, 51, 56, 59, 60, 67, 70, 77, 79, 90], "typo": 26, "u": [3, 13, 27, 33, 70, 75, 80, 84, 98], "ubuntu": [48, 50, 60, 67, 79], "ubuntu1804": 50, "ubuntu22": [55, 60], "ucx": 15, "ud": 2, "ui": [47, 50, 85, 86, 90], "uk": 24, "ultra": [11, 90, 92], "ulyss": 90, "ulysses_degre": 90, "ulyssesattent": 90, "unabl": 98, "unavail": [21, 90], "uncach": 4, "uncertain": 37, "unchang": 46, "unconditional_likelihood_norm": 75, "unconfin": 58, "under": [0, 6, 8, 11, 13, 21, 23, 27, 50, 51, 59, 70, 71, 73, 74, 85, 90, 92, 98], "underli": [3, 16], "understand": [0, 11, 13, 36, 37, 51, 59, 70, 86, 92, 95], "understood": 5, "underutil": 16, "unexpect": 13, "unicod": 22, "unifi": [6, 7, 13, 22, 24, 29, 40, 84, 90], "uniform": [16, 21, 22, 77, 90], "uniformli": 30, "unintend": 46, "union": [13, 21, 46], "uniqu": [4, 88, 90], "unit": [13, 22, 25, 26, 27, 28, 37, 40, 47, 77], "unittest": [51, 59, 98], "univers": 37, "unix": [2, 88], "unknown": 73, "unless": [1, 49], "unlik": [18, 23, 24, 48, 89], "unload": 13, "unload_lora_adapt": 13, "unlock": [7, 22], "unmerge_lora_weight": 90, "unnecessari": 37, "unparallel": 13, "unpermut": 7, "unpin": 13, "unquant": 61, "unrel": 11, "unrestrict": 46, "unset": [21, 61, 62], "unsloth": 84, "unspecifi": [1, 21, 49], "unstabl": 3, "unsuccess": 23, "unsupport": 24, "unsur": [92, 95], "until": [12, 13, 16, 29, 36, 46, 50, 70, 81], "untrust": 22, "unus": 83, "unusu": [28, 42], "unwrap": 48, "up": [7, 11, 12, 13, 15, 16, 19, 21, 26, 29, 33, 34, 35, 36, 37, 42, 50, 51, 56, 58, 59, 67, 69, 71, 79, 84, 85, 86, 90, 92], "up_proj": [13, 21], "upcast": [17, 29], "upcom": [30, 33], "updat": [2, 3, 10, 13, 16, 17, 21, 22, 26, 27, 35, 50, 55, 73, 74, 78, 85, 98], "update_weight": 36, "update_weights_from_disk": [23, 36], "update_weights_from_distribut": 23, "update_weights_from_tensor": 23, "upgrad": [30, 55, 56, 58, 67, 68, 71, 90, 96], "upload": [22, 90], "upload_pypi": 54, "upon": [11, 13, 36, 41, 85, 86, 93, 95], "upper": 11, "upsid": 33, "upstag": 92, "upstream": [22, 90], "upstream_responses_tot": 22, "upward": 33, "urban": [28, 42, 77], "urgent": [51, 59], "url": [6, 13, 14, 21, 22, 24, 28, 32, 33, 36, 42, 45, 46, 47, 49, 50, 56, 60, 67, 70, 71, 85, 86, 90, 91, 95, 96], "us": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 44, 45, 46, 49, 51, 55, 57, 59, 68, 72, 75, 77, 79, 80, 81, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 98, 99], "us_president_exampl": 75, "usabl": [17, 69, 92], "usag": [3, 10, 21, 23, 24, 27, 28, 31, 36, 38, 41, 42, 46, 47, 48, 51, 59, 69, 70, 74, 75, 79, 80, 83, 96], "use_fast": 28, "use_fast_accum": 24, "use_mla_backend": 36, "user": [4, 7, 11, 12, 13, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 35, 36, 37, 38, 40, 42, 45, 46, 47, 50, 51, 53, 59, 67, 72, 75, 77, 80, 83, 84, 88, 90, 91, 93, 95, 96], "usernam": [56, 85], "userwarn": 24, "usp": 90, "uspattent": 90, "usr": [13, 20, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 56, 60, 61, 62, 67, 77], "usual": [16, 28, 40, 56, 67, 85, 96], "utf": [46, 47], "util": [5, 6, 7, 11, 12, 13, 16, 20, 21, 23, 24, 25, 26, 27, 28, 36, 37, 40, 41, 42, 46, 47, 58, 67, 70, 77, 79, 84, 90, 91], "uuid": 22, "uv": [15, 33, 67, 70], "uv_config_fil": 67, "uvicorn": [13, 21, 36, 79], "uvicorn_access_log_exclude_prefix": [13, 20, 25, 26, 27, 28, 36, 37], "v": [4, 7, 13, 17, 22, 23, 36, 48, 52, 55, 56, 58, 66, 67, 71, 88, 90, 92, 94, 95, 98], "v0": [27, 34, 36, 55, 56, 58, 60, 66, 79, 90, 92, 97], "v01": [66, 92], "v1": [13, 17, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 45, 46, 47, 49, 66, 79, 80, 83, 86, 88, 90, 91, 92, 95, 96], "v1_5": 92, "v1alpha1": 83, "v2": [7, 21, 24, 36, 49, 66, 70, 92, 95, 96], "v3": [1, 7, 15, 17, 20, 21, 27, 43, 52, 53, 61, 66, 83, 92, 93, 95], "v32": [30, 83], "v6e": 70, "v7": 70, "v_cach": 48, "v_proj": [13, 21], "v_scale": 18, "vae": 90, "vae_config": 90, "vae_path": 90, "vae_precis": 90, "vae_sp": 90, "vae_til": 90, "valid": [0, 2, 4, 17, 21, 25, 26, 27, 30, 46, 48, 50, 51, 58, 59, 70, 73, 90, 91, 96], "valu": [3, 6, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 40, 45, 46, 48, 50, 51, 56, 59, 62, 67, 73, 74, 79, 80, 83, 89, 90, 95, 96], "valuabl": 98, "value1": [21, 27], "value2": [21, 27], "value_st": 99, "valueerror": [8, 36], "valuefrom": [80, 83], "vanilla": 90, "var": [60, 83], "vari": [3, 4, 7, 18, 23, 26, 49], "variabl": [3, 10, 13, 15, 16, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 40, 41, 42, 47, 48, 49, 50, 55, 56, 57, 67, 70, 77, 79, 85, 86, 93, 94, 98], "varianc": [7, 23, 51, 59], "variant": [3, 7, 20, 50, 56, 66, 92, 95, 97], "variat": 16, "varieti": 1, "variou": [1, 11, 15, 17, 40, 42, 66, 73, 77], "varlen": 30, "vast": 92, "vc_task_index": 61, "ve": [26, 79], "vector": [24, 29, 51, 59, 91], "veget": 77, "vehicl": 28, "veil": 13, "vendor": [22, 61], "venv": [67, 70], "verb": 22, "verbos": [14, 21], "veri": [3, 5, 12, 13, 16, 26, 30, 32, 37, 42, 45, 46, 51, 59, 74, 98], "verif": [1, 21, 24, 29, 30, 31, 33, 48, 53, 73], "verifi": [1, 2, 4, 13, 18, 21, 22, 30, 48, 49, 53, 58, 67, 69, 70, 71, 73, 85, 88], "verl": [23, 57, 84], "versatil": [92, 95], "version": [2, 21, 22, 23, 29, 36, 37, 44, 51, 52, 56, 59, 67, 70, 71, 73, 77, 79, 93, 95, 96], "versu": 23, "vertic": [22, 37], "via": [6, 7, 8, 13, 14, 15, 17, 18, 19, 21, 22, 23, 30, 33, 36, 46, 49, 50, 51, 59, 67, 70, 71, 85, 86, 89, 92, 95], "vibrant": [37, 57], "vicuna": 95, "video": [3, 21, 53, 55, 58, 78, 96], "video_data": 95, "video_id": 90, "video_pruning_r": 95, "video_sparse_attn": 90, "video_url": [32, 45, 95, 96], "videomm": 53, "vienn": 36, "view": [0, 27, 28, 79, 85, 86], "viewer": 28, "vigor": 77, "vim": 67, "vine": 13, "virtual": [13, 20, 23, 24, 25, 26, 27, 28, 30, 36, 37, 40, 41, 42, 47, 67, 77], "virtualenv": 22, "visibl": [50, 73], "vision": [3, 5, 6, 39, 40, 45, 46, 47, 49, 66, 92, 95, 98, 99], "vision_end": 28, "vision_flat": 28, "vision_model": 28, "vision_process": 42, "vision_start": 28, "visionattent": 98, "visit": [17, 37, 70], "visual": [3, 5, 28, 46, 50, 52, 86, 90, 95], "visualstudio": 52, "vit": [3, 5, 6, 32, 66, 91, 95, 98], "vital": 7, "vitcudagraphrunn": 3, "vl": [3, 5, 17, 27, 42, 43, 49, 50, 60, 66, 77, 91, 95], "vl2": [66, 95], "vllm": [17, 49, 50, 66, 88], "vlm": [5, 6, 17, 21, 23, 37, 49, 57, 84, 95, 98], "vlm1": 95, "vm": [58, 60, 61, 62, 70], "vmoba": 90, "vmoba_attn": 90, "vocab": 21, "vocabulari": [21, 24], "voic": 13, "void": 48, "volum": [52, 60, 77, 79, 80, 83], "volumemount": [79, 80, 83], "vram": 3, "vsa": 90, "vscode_cli_alpine_x64_cli": 52, "vx": 56, "w": [24, 25, 26, 40, 46, 60, 61, 62, 77, 90], "w2a16": 17, "w3a16": 17, "w3c": 22, "w4a16": [17, 63], "w4a4": 63, "w4a8": [29, 61, 62, 63], "w4a8_awq": 21, "w4afp8": 21, "w8a16": [17, 63], "w8a8": [29, 61, 62, 63, 66, 67], "w8a8_fp8": [17, 21], "w8a8_int8": [17, 21, 67], "w8a8fp8config": 17, "wa": [13, 16, 26, 27, 33, 36, 37, 40, 50, 79, 88], "wai": [0, 2, 3, 13, 16, 26, 27, 28, 37, 48, 50, 60, 71, 77, 90, 98], "wait": [2, 10, 11, 13, 16, 21, 22, 23, 24, 26, 36, 40, 41, 42, 50, 51, 59, 73, 77, 79, 80, 81, 85, 90], "wait_complet": [10, 11, 21], "wait_for_serv": [13, 20, 24, 25, 26, 27, 36, 40, 41, 42, 47, 77], "waiting_queu": 23, "wake": 84, "walk": [13, 48, 51, 59, 90], "walkthrough": 98, "wall": [49, 89], "wallet": 22, "wan": [57, 90], "wan2": 90, "wan_pipelin": 90, "wand": 77, "wanpipelin": 90, "want": [8, 14, 17, 21, 26, 27, 36, 37, 40, 46, 50, 51, 56, 59, 60, 67, 79, 86, 87, 90, 95, 98], "warmup": [13, 20, 21, 25, 26, 27, 28, 36, 37, 49, 50, 67, 70, 73, 90], "warmup_name1": 21, "warmup_name2": 21, "warn": [8, 12, 13, 18, 20, 21, 22, 24, 25, 26, 27, 28, 36, 40, 41, 42, 47, 49, 77], "warn_onc": 24, "warrior": 13, "wash": 28, "washington": [13, 40, 47], "wasip2": 22, "wasm32": 22, "watch": [21, 22, 37], "watchdog": [13, 16, 21, 30, 36, 61, 62, 64], "watchdog_timeout": [13, 20, 25, 26, 27, 28, 36, 37], "water": [13, 28], "waterfal": 13, "watermark": 21, "watsonx": 92, "wave": [1, 21], "wb": 90, "wcde": 90, "we": [0, 3, 6, 13, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 42, 47, 48, 50, 51, 52, 53, 56, 58, 59, 60, 61, 67, 70, 74, 77, 79, 80, 84, 86, 90, 94, 98, 99], "wear": [13, 28, 77], "weather": [25, 26, 27, 29, 40, 96], "web": [56, 85, 86, 96], "web_search_preview": 33, "webassembli": 22, "websit": [0, 93], "week": [27, 51, 59, 77], "weekli": 78, "weight": [2, 7, 12, 13, 17, 19, 49, 50, 52, 55, 61, 62, 63, 64, 69, 73, 77, 92, 98], "weight_load_func": 21, "weight_loader_disable_mmap": [13, 20, 25, 26, 27, 28, 36, 37], "weight_update_group": 23, "weight_vers": [13, 20, 23, 24, 25, 26, 27, 28, 36, 37, 40, 42, 47], "weilin": 24, "welcom": [10, 51, 59, 66, 70, 72], "well": [11, 16, 21, 23, 24, 26, 33, 37, 57, 77, 90, 92, 98], "went": 13, "were": [13, 36, 40], "wget": [52, 60], "what": [8, 13, 17, 20, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 38, 40, 42, 45, 47, 75, 77, 84, 90, 91, 95, 96, 98, 99], "whatev": 13, "whatnot": 26, "wheel": [51, 56, 59], "when": [0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 58, 59, 62, 63, 67, 72, 73, 74, 77, 85, 86, 88, 90, 95, 96, 98], "whenev": [22, 50, 51, 59], "where": [4, 7, 11, 13, 15, 16, 18, 21, 23, 25, 26, 27, 28, 29, 30, 32, 37, 40, 45, 46, 50, 75, 77, 96, 98], "wherea": 11, "wherev": 13, "whether": [1, 11, 21, 23, 26, 36, 46, 50, 51, 53, 59, 73, 86, 90, 96], "which": [0, 3, 4, 6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 40, 42, 44, 46, 47, 48, 49, 50, 51, 56, 59, 60, 67, 70, 71, 72, 74, 79, 86, 88, 90, 92, 98, 99], "while": [3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 35, 36, 40, 41, 42, 47, 50, 55, 73, 74, 77, 81, 90, 92], "whisper": 13, "whitespac": 21, "whl": [22, 56, 60, 67, 71], "who": [13, 19, 35, 37, 40, 70], "whole": [22, 30, 77], "whose": [13, 21, 46], "why": [13, 26, 37], "wide": [11, 21, 29, 57], "widespread": [37, 57], "width": [17, 18, 90], "wild": 91, "window": [1, 3, 16, 21, 22, 28, 51, 59, 70, 92], "wine": 37, "wise": [7, 13, 90], "wish": 86, "witch": 37, "with_devic": 48, "with_dtyp": 48, "with_stack": [50, 73], "with_strid": 48, "with_xxx": 48, "wither": 13, "within": [6, 7, 11, 13, 15, 17, 18, 21, 22, 24, 26, 28, 30, 40, 51, 52, 56, 59, 71, 77, 79, 85, 86], "without": [1, 7, 11, 13, 18, 21, 22, 23, 24, 30, 36, 37, 40, 50, 51, 59, 63, 70, 73, 90, 96, 98], "wizard": [13, 37], "woman": [40, 90, 96], "won": [1, 13, 16, 35, 98], "wonder": 26, "wood": 77, "word": [13, 36, 40, 46, 77], "work": [1, 10, 16, 17, 22, 23, 26, 27, 37, 40, 46, 51, 55, 56, 59, 60, 72, 73, 79, 80, 83, 84, 88, 90, 96, 99], "workaround": [15, 50], "worker": [2, 15, 21, 23, 29, 30, 61, 62, 70, 73, 79, 80, 83], "worker1": 22, "worker2": 22, "worker_id": 22, "worker_typ": 22, "workers_discov": 22, "workertempl": [79, 80], "workflow": [22, 36, 49, 51, 59, 84, 92], "workload": [6, 11, 12, 13, 16, 18, 21, 22, 23, 24, 29, 32, 44, 45, 49, 50, 58, 70, 79, 83, 90, 92], "workspac": [52, 80, 83, 90], "world": [21, 22, 23, 26, 35, 37, 47, 57, 92], "world_siz": [23, 90], "worldwid": 57, "worst": 13, "worth": 37, "would": [13, 25, 26, 27, 50, 67, 86], "wrap": [24, 26, 49], "wrapper": [1, 21, 22, 24, 48], "write": [0, 1, 10, 13, 21, 26, 37, 40, 46, 89, 90, 98], "write_back": [11, 21], "write_through": [10, 11, 13, 20, 21, 25, 26, 27, 28, 36, 37], "write_through_select": [11, 21], "written": [11, 30, 80], "wrong": [36, 56], "www": 78, "x": [13, 20, 21, 22, 25, 26, 27, 28, 36, 37, 48, 50, 56, 60, 63, 67, 78, 79, 80, 83, 89, 91, 92, 96, 98], "x1": [80, 83], "x64": 55, "x86_64": [22, 50, 56, 67], "x_": 81, "xai": [22, 92], "xdit": 90, "xeon": [29, 56, 57, 67], "xf": 52, "xformer": 90, "xgrammar": [13, 20, 21, 25, 26, 27, 28, 36, 37, 46, 71, 81], "xiaomi": [24, 92, 95], "xiaomimimo": [24, 66, 92, 95], "xlab": 90, "xml": 22, "xpu": [1, 21, 34, 56, 57], "xvers": [66, 92], "xx": 15, "xxx": [10, 15, 55, 61, 62], "xxxx": 15, "xxxxx": 50, "xxxxxx": 27, "y": [0, 22, 30, 40, 50, 55, 56, 71], "yaml": [11, 21, 22, 56, 70, 79, 80, 85, 86, 89, 90], "ye": [4, 24, 26, 36, 40, 73, 80, 83], "yeah": [24, 26, 40], "year": [26, 33, 37, 40], "yearli": 26, "yellow": [28, 42, 77], "yet": [13, 49, 79, 90, 95], "yield": [7, 11, 16], "yieldoper": 7, "yml": [51, 56, 59, 83], "york": [25, 26, 27, 28], "you": [0, 1, 3, 4, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 66, 67, 68, 69, 70, 71, 72, 74, 77, 79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 94, 95, 96, 98, 99], "young": 40, "your": [0, 1, 4, 10, 12, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 37, 40, 41, 42, 47, 49, 50, 51, 52, 53, 56, 58, 59, 61, 62, 66, 67, 70, 71, 74, 77, 79, 80, 81, 83, 84, 85, 86, 90, 93, 95, 98], "your_aws_account": 56, "your_aws_region": 56, "your_exa_kei": 33, "your_image_tag": 56, "your_model_path": 85, "your_module_path": 10, "your_repository_nam": 56, "your_user_nam": [51, 59], "yourhicacheclassnam": 10, "yourkei": 49, "yourself": 37, "yuanxiang": 92, "yum": 79, "z": [56, 81, 90], "zai": [27, 31, 32, 90, 95], "zealand": 40, "zero": [10, 11, 17, 19, 23, 27, 57, 73, 84], "zhao": 24, "zhipu": 92, "zhipuai": [66, 92], "zhousx": 24, "zip": [25, 26, 36, 37, 93, 98], "zmq": 86, "zmq_to_schedul": [6, 13, 20, 21, 25, 26, 27, 28, 36, 37], "zmq_to_token": [6, 21], "zsh": 52, "\u00e9lys\u00e9": [24, 36], "\u00eele": [24, 26], "\u4e0d\u8fc7\u8981\u63a7\u5236\u8868\u60c5\u7b26\u53f7\u6570\u91cf": [80, 83], "\u4e5f\u53ef\u80fd\u662f\u60f3\u786e\u8ba4\u6211\u7684\u8eab\u4efd\u548c\u529f\u80fd\u8303\u56f4": [80, 83], "\u4f60\u53ef\u4ee5\u628a\u6211\u5f53\u6210\u4e00\u4e2a\u77e5\u8bc6\u4e30\u5bcc": [80, 83], "\u4f60\u662f\u8c01": [80, 83], "\u521a\u597d\u80fd\u4e2d\u548cai\u7684\u673a\u68b0\u611f": [80, 83], "\u529f\u80fd\u5b9a\u4f4d": [80, 83], "\u53c8\u80fd\u907f\u514d\u8ba9\u7528\u6237\u9762\u5bf9\u7a7a\u767d\u8f93\u5165\u6846\u65f6\u4e0d\u77e5\u6240\u63aa": [80, 83], "\u540c\u65f6\u7a81\u51fa\u5b9e\u7528\u4ef7\u503c\u6765\u964d\u4f4e\u964c\u751f\u611f": [80, 83], "\u540d\u5b57\u53eb": [80, 83], "\u5b66\u4e60": [80, 83], "\u5de5\u4f5c": [80, 83], "\u5e94\u8be5\u7528\u7b80\u4f53\u4e2d\u6587\u56de\u590d": [80, 83], "\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b": [80, 83], "\u5fb7\u56fd\u7684\u9996\u90fd\u662f\u67cf\u6797": 96, "\u6211\u662f\u4f60\u7684ai\u52a9\u624b": [80, 83], "\u65e2\u80fd\u4e86\u89e3\u9700\u6c42": [80, 83], "\u670d\u52a1\u8303\u56f4": [80, 83], "\u6cd5\u56fd\u7684\u9996\u90fd\u662f\u5df4\u9ece": 96, "\u6cd5\u56fd\u9996\u90fd\u662f\u54ea\u91cc": 96, "\u6df1\u5ea6\u6c42\u7d22": [80, 83], "\u751f\u6d3b": [80, 83], "\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u5f88\u57fa\u7840\u7684\u81ea\u6211\u4ecb\u7ecd\u95ee\u9898": [80, 83], "\u7531\u6df1\u5ea6\u6c42\u7d22\u516c\u53f8": [80, 83], "\u7ed3\u5c3e\u7528\u5f00\u653e\u6027\u95ee\u9898\u5f15\u5bfc\u5bf9\u8bdd\u5f88\u5173\u952e": [80, 83], "\u89e3\u7b54\u95ee\u9898": [80, 83], "\u8bed\u6c14\u7b80\u6d01\u4e2d\u6027": [80, 83], "\u8eab\u4efd\u5f52\u5c5e": [80, 83], "\u8fd9\u53ef\u80fd\u662f\u7b2c\u4e00\u6b21\u4e92\u52a8\u65f6\u7684\u5e38\u89c4\u5f00\u573a\u767d": [80, 83], "\u8fd9\u79cd\u573a\u666f\u4e0b\u65b0\u7528\u6237\u7684\u53ef\u80fd\u6027\u8f83\u9ad8": [80, 83], "\u907f\u514d\u663e\u5f97\u8f7b\u6d6e": [80, 83], "\u90a3\u4e2a\u7b11\u8138\u8868\u60c5": [80, 83], "\u91cd\u70b9\u8981\u8bf4\u660e\u4e09\u70b9": [80, 83], "\u968f\u53eb\u968f\u5230\u7684\u5c0f\u5e2e\u624b": [80, 83], "\u9700\u8981\u7ed9\u51fa\u6e05\u6670\u53cb\u597d\u7684\u81ea\u6211\u4ecb\u7ecd": [80, 83], "\u9999\u8549\u662f\u9ec4\u8272\u7684\u6c34\u679c": 96}, "titles": ["SGLang Documentation", "Attention Backend", "Checkpoint Engine Integration", "Cuda Graph for Multi-Modal Encoder in SGLang", "Deterministic Inference", "DP for Multi-Modal Encoder in SGLang", "EPD Disaggregation", "Expert Parallelism", "Model Hooks", "Hierarchical KV Caching (HiCache)", "SGLang HiCache Best Practices", "HiCache System Design and Optimization", "Hyperparameter Tuning", "LoRA Serving", "Observability", "PD Disaggregation", "Pipeline Parallelism for Long Context", "Quantization", "Quantized KV Cache", "R-Fork", "Reasoning Parser", "Server Arguments", "SGLang Model Gateway", "SGLang for RL Systems", "Speculative Decoding", "Structured Outputs", "Structured Outputs For Reasoning Models", "Tool Parser", "Query VLM with Offline Engine", "DeepSeek V3/V3.1/R1 Usage", "DeepSeek V3.2 Usage", "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang", "GLM-4.6V / GLM-4.5V Usage", "GPT OSS Usage", "Llama4 Usage", "MiniMax M2.1/M2 Usage", "SGLang Native APIs", "Offline Engine API", "Ollama-Compatible API", "OpenAI-Compatible APIs", "OpenAI APIs - Completions", "OpenAI APIs - Embedding", "OpenAI APIs - Vision", "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)", "Qwen3-Next Usage", "Qwen3-VL Usage", "Sampling Parameters", "Sending Requests", "Development Guide for JIT Kernels", "Bench Serving Guide", "Benchmark and Profiling", "Contribution Guide", "Development Guide Using Docker", "Evaluating New Models with SGLang", "PyPI Package Release Process", "Set Up Self-Hosted Runners for GitHub Action", "Install SGLang", "SGLang Documentation", "AMD GPUs", "Contribution Guide", "SGLang installation with NPUs support", "Best Practice on Ascend NPU", "DeepSeek examples", "&lt;no title&gt;", "Qwen3 examples", "Ascend NPUs", "Support Models on Ascend NPU", "CPU Servers", "Moore Threads GPUs", "NVIDIA Jetson Orin", "TPU", "XPU", "Custom Chat Template", "Environment Variables", "Troubleshooting and Frequently Asked Questions", "Choices Methods in SGLang", "Frontend Language", "SGLang Frontend Language", "Learn More and Join the Community", "Deploy On Kubernetes", "LWS Based PD Deploy", "Multi-Node Deployment", "Multi-Node Deployment", "DeepSeekV32-Exp RBG Based PD Deploy", "Post-Training Integration", "Production Metrics", "Production Request Tracing", "Enabling cache for torch.compile", "Classification API", "Diffusion Language Models", "Diffusion Models", "Embedding Models", "Large Language Models", "MindSpore Models", "Use Models From ModelScope", "Multimodal Language Models", "Rerank Models", "Reward Models", "How to Support New Models", "Transformers fallback in SGLang"], "titleterms": {"": [4, 98], "0": [4, 74, 80, 83], "1": [16, 28, 29, 35, 38, 48, 52, 55, 56, 58, 60, 61, 62, 64, 67, 70, 80, 81, 83, 90, 91], "100m": 61, "10m": 61, "11m": 61, "128k": 16, "12m": 61, "16": 2, "18m": 61, "2": [2, 24, 27, 28, 30, 38, 48, 52, 55, 56, 60, 61, 62, 67, 70, 73, 80, 83, 90, 91], "2025": 30, "20m": 61, "235b": [16, 61, 64], "2507": 64, "2k": 61, "3": [24, 27, 28, 38, 48, 55, 56, 61, 67, 70, 81, 90], "30b": [4, 64], "30m": 61, "32b": [61, 64], "3b": 67, "4": [27, 28, 31, 32, 34, 56, 61, 62, 70], "40": 22, "405b": 81, "429": 22, "480b": 61, "5": [28, 31, 56, 61], "50m": 61, "5v": 32, "6": [31, 56], "6v": 32, "7": [31, 56], "7b": [70, 90], "8": 29, "800i": [61, 62, 64], "8b": [4, 64, 70], "8card": 61, "A": [36, 40, 41, 42, 47, 77], "For": [21, 26, 28, 60, 73], "In": [30, 50, 83], "On": 79, "One": 83, "The": [4, 74], "To": 23, "With": [56, 90], "a2": 61, "a22b": [16, 64], "a3": [61, 62, 64], "a3b": [4, 64], "about": 16, "abov": [32, 45], "acceler": 90, "access": 74, "accuraci": [18, 30, 34, 51, 53, 59], "achiev": 12, "action": 55, "adapt": [40, 90], "adaptor": [13, 60], "add": [1, 22, 48, 51, 55, 59, 86, 98], "address": 3, "adjust": [12, 16], "admin": 22, "adopt": 84, "advanc": [15, 17, 37, 52, 57, 70, 73, 90], "aim": 30, "all": [7, 83], "amd": 58, "an": [90, 98], "api": [13, 17, 20, 21, 22, 25, 26, 27, 28, 33, 36, 37, 38, 39, 40, 41, 42, 47, 50, 88, 90], "approach": 28, "ar": [74, 85], "architectur": [2, 11, 22], "area": 70, "arg": 21, "argument": [3, 4, 13, 21, 90], "ascend": [15, 60, 61, 65, 66], "ask": 74, "async": [16, 22], "asynchron": 37, "asyncio": 37, "atla": [61, 62, 64], "attent": [1, 3, 21, 29, 70, 90], "authent": [22, 49], "auto": [17, 58], "automat": [1, 52], "avail": [17, 22], "avoid": 12, "aw": 56, "awar": 22, "b": 12, "back": [11, 27], "backend": [1, 3, 4, 7, 10, 11, 13, 15, 19, 21, 22, 27, 49, 70, 73, 90], "backward": 96, "balanc": [7, 22, 23, 58, 60], "base": [16, 80, 83, 90], "basic": [4, 28, 40, 57, 70, 77, 79, 90], "batch": [7, 12, 21, 22, 37, 77], "behavior": [4, 8, 20], "being": 85, "bench": 49, "bench_offline_throughput": 50, "bench_serv": 50, "benchmark": [30, 34, 50, 51, 59, 61, 67, 70, 71, 73, 98], "benefit": [2, 17], "best": [10, 16, 18, 22, 61], "bf16": [32, 45], "bia": 40, "bin": 90, "binari": 22, "bind": 22, "block": 29, "breaker": 22, "bucket": 22, "budget": [29, 31, 32], "buffer": 3, "bug": 50, "build": [22, 30, 51], "built": 33, "c": 48, "cach": [9, 12, 18, 21, 22, 36, 44, 73, 87, 90], "call": [22, 27, 28, 29, 30, 73], "cann": 60, "capabl": 91, "capac": 12, "captur": 36, "case": [16, 79], "categori": 22, "caus": 4, "chang": 90, "chat": [27, 40, 72], "check": [22, 36, 48, 85], "checkpoint": [2, 21], "choic": [27, 75], "choos": [13, 49], "chunk": [12, 16, 70], "ci": [51, 59, 73, 90], "circuit": 22, "class": 88, "classif": [22, 88], "classifi": 36, "cli": [38, 90], "client": [27, 41, 42, 47, 89, 91, 96], "clone": [51, 59], "cloud": [56, 70], "co": 22, "code": [48, 51, 54, 59, 89, 99], "collabor": 84, "collect": 85, "combin": 90, "command": [1, 3, 5, 21, 32, 45, 50, 67, 89, 92, 95, 96, 97, 99], "commit": [51, 59, 90], "common": [21, 56, 96], "commun": [7, 10, 16, 22, 78, 93], "comparison": [22, 70], "compat": [13, 20, 25, 26, 27, 38, 39, 60, 88, 90, 96], "compil": [24, 70, 87], "complet": 40, "complex": [77, 86], "compon": 60, "compos": 56, "comprehens": 70, "compressor": 17, "comput": [7, 73, 90], "concurr": 49, "config": [8, 55], "configur": [2, 4, 8, 10, 15, 21, 22, 30, 34, 40, 44, 55, 58, 61, 70, 73, 85, 89, 90], "connect": [22, 70], "connector": 22, "consider": [18, 50], "constrain": [46, 77], "constraint": 3, "contain": [52, 55, 69], "content": [22, 29, 90], "context": [16, 30], "continu": 23, "contribut": [51, 59, 70, 90], "control": [12, 22, 77], "convent": 90, "convers": 22, "core": [10, 22, 46], "count": 90, "cp": 30, "cpu": [60, 67], "crash": 14, "creat": [48, 60, 80, 90], "cross": [36, 96], "cuda": [1, 3, 12, 74], "curl": [41, 42, 47, 88], "current": 27, "custom": [10, 21, 28, 46, 70, 72, 90], "customop": 60, "data": [11, 21, 22, 29], "dataset": 49, "dbcach": 90, "debug": [21, 22, 52, 73, 79, 93, 98], "debugg": 52, "decod": [1, 7, 15, 21, 22, 24, 31, 33, 34, 36, 44, 46, 50, 70, 77, 80, 96], "decrypt": 21, "deepep": [60, 73], "deepgemm": 73, "deepseek": [15, 16, 29, 30, 40, 43, 58, 61, 62, 67, 73, 81], "deepseekv32": 83, "default": [4, 30, 46, 52], "defin": 27, "demo": 33, "denois": 90, "depend": [0, 93], "deploi": [17, 22, 79, 80, 83], "deploy": [10, 11, 22, 35, 61, 80, 81, 82], "deprec": 21, "design": [3, 11], "detail": 88, "determin": 4, "determinist": [4, 23, 74], "detoken": [22, 36], "dev": 52, "develop": [48, 52, 57], "devic": 93, "dialog": 77, "diamond": 30, "differ": [1, 91], "diffus": [21, 89, 90], "dimens": 91, "disabl": [58, 60, 90], "disaggreg": [6, 10, 11, 15, 16, 21, 22, 30, 50, 62], "discoveri": 22, "disk": [23, 36], "distribut": [21, 23, 36, 50, 70, 73, 90], "dit": 90, "doc": 0, "docker": [22, 30, 52, 55, 56, 58, 60, 67, 70, 71, 90], "document": [0, 51, 57, 59, 70, 96, 98], "doe": 49, "doubl": 21, "download": [29, 90], "dp": [5, 12], "dsa": 30, "dump": [14, 21, 90], "durat": 22, "dynam": [3, 10, 13, 16, 21], "eagl": [21, 24, 31, 34, 44], "eagle3": [64, 70], "easi": 23, "ebnf": [25, 26, 40, 46], "edit": 90, "embed": [28, 36, 41, 66, 91, 96], "enabl": [10, 16, 18, 27, 50, 87], "encod": [3, 5, 21, 36, 96], "encount": 74, "end": 49, "end_profil": 50, "endpoint": [22, 38, 46, 49, 50, 88, 90], "engin": [2, 20, 23, 25, 26, 27, 28, 37, 67, 70, 71, 98], "environ": [48, 59, 60, 70, 73, 90, 93], "ep": 7, "epd": 6, "error": [12, 70, 74, 88], "evalu": [52, 53], "even": 74, "exampl": [2, 3, 4, 5, 7, 17, 22, 27, 29, 32, 36, 40, 45, 46, 49, 50, 58, 62, 64, 67, 70, 79, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99], "execut": 27, "exp": 83, "experiment": [1, 30], "expert": [7, 36, 40], "explain": 49, "explicitli": 93, "export": 17, "express": [25, 26], "extend": 86, "extens": 7, "extern": [70, 98], "extra": 90, "factor": [16, 18], "factori": 8, "failur": 22, "fallback": 99, "faq": [29, 80, 83, 90], "featur": [17, 22, 57, 70, 90, 99], "field": [8, 22, 88], "file": [21, 22, 50, 80, 83, 85, 89, 90], "fine": 23, "fit": 3, "flag": [23, 32, 45], "flap": 22, "flow": [22, 77], "flush": 36, "forc": 27, "fork": [19, 51, 59], "format": [18, 22, 27, 28, 49, 51, 59, 72, 88, 96], "forward": 21, "fp4": 18, "fp8": [16, 18, 29, 32, 45], "fraction": 12, "framework": [7, 60, 86], "frequenc": 24, "frequent": 74, "from": [11, 23, 30, 36, 51, 52, 56, 58, 59, 60, 67, 68, 70, 71, 90, 94, 98], "frontend": [76, 77], "full": [22, 32, 45, 90], "function": [22, 23, 27, 29, 30, 73], "futur": 13, "gatewai": 22, "gemm": 21, "gener": [4, 23, 36, 37, 46, 47, 73, 77, 90], "get": [36, 40, 57, 90], "github": [54, 55], "glm": [31, 32, 43], "go": 22, "gpqa": 30, "gpt": [33, 43], "gptqmodel": 17, "gpu": [13, 58, 68], "grain": 23, "grammar": 21, "graph": [3, 12], "greedi": [4, 75], "group": 23, "growth": 22, "grpc": 22, "grub": 58, "gsm8k": [30, 62], "guid": [1, 48, 49, 51, 52, 57, 59, 85, 86], "guidanc": [7, 16, 51, 59], "guidelin": [0, 10], "h20": 16, "h200": 29, "handl": [27, 88], "hang": 74, "hardwar": [32, 45, 57, 70], "head": 29, "health": [22, 36], "hf3f": 10, "hicach": [9, 10, 11], "hierarch": [9, 21], "high": [12, 22, 61, 70], "highlight": 24, "hiradixtre": 11, "histori": 22, "hook": [8, 21], "hook_factori": 8, "host": [52, 55], "hot": 22, "how": [27, 51, 59, 70, 86, 90, 98], "http": [21, 22, 50], "hybrid": [1, 60], "hyperparamet": 12, "i": [6, 11, 15], "id": [22, 40, 41], "illeg": 74, "imag": [28, 32, 42, 45, 60, 80, 83, 90, 96], "imbal": 22, "impact": 18, "implement": [7, 16, 48, 88, 98], "import": [32, 45, 50], "increas": 12, "infer": [4, 12, 22, 23, 37, 69, 81, 90, 93], "info": 36, "inform": 90, "initi": 27, "input": [3, 16, 28, 32, 41, 42, 45, 95], "instal": [0, 2, 17, 22, 30, 51, 56, 58, 59, 60, 67, 68, 69, 70, 71, 90, 93], "instruct": [64, 96], "integ": 48, "integr": [2, 10, 11, 15, 22, 84], "interact": 98, "interest": 86, "interfac": [11, 48], "intern": 73, "introduct": 93, "issu": [15, 22, 70, 79, 93], "item": 21, "itl": 16, "jetson": 69, "jinja": 72, "jit": 48, "join": 78, "json": [25, 26, 40, 46, 72], "jsonl": 49, "k8": 80, "kei": [10, 22, 49, 79, 90], "kernel": [21, 48, 51, 59, 60], "known": [3, 5], "ktransform": 21, "kubernet": [22, 56, 79], "kv": [9, 12, 18], "l3": 11, "languag": [22, 60, 66, 76, 77, 89, 92, 95, 98], "larg": [60, 66, 92, 98], "latenc": [61, 70], "latent": 29, "launch": [1, 20, 21, 22, 27, 29, 30, 31, 32, 34, 36, 38, 40, 41, 42, 44, 45, 47, 48, 67, 70, 71, 77, 89, 91, 92, 95, 96, 97, 99], "layer": [21, 50], "layerwis": 50, "layout": 10, "lb": 80, "learn": 78, "length": [16, 75], "level": 8, "librari": [38, 60], "lifecycl": [8, 23], "likelihood": 75, "limit": [22, 51, 59, 90, 95], "line": 50, "list": [22, 67, 70, 71, 90], "llama": [4, 15, 27, 28, 34, 43, 67, 81, 98], "llama3": 58, "llama4": 34, "llm": [17, 21, 53], "lm_eval": 34, "lmcach": 21, "load": [10, 13, 22, 23], "loader": 21, "local": 11, "locat": 90, "log": [14, 21, 22], "logic": 1, "logit": [40, 46], "long": [16, 30, 70], "lora": [13, 21, 40, 90], "low": [61, 70, 90], "lw": 80, "m2": 35, "make": [54, 91], "mamba": [21, 44], "manag": [3, 22, 73, 90], "manifest": [80, 83], "manual": 52, "map": 60, "marker": 50, "mask": 90, "match": 11, "matrix": [1, 70, 90], "matryoshka": 91, "matter": [4, 10], "max": 12, "maximum": 28, "mcp": 22, "mem": 12, "memfabr": 60, "memori": [10, 12, 18, 21, 22, 23, 60, 70, 73, 74], "merg": [51, 59, 90], "merger": 50, "messag": [27, 90], "metadata": 11, "method": [17, 56, 60, 70, 75, 90], "metric": [14, 22, 49, 85], "mha": 1, "middlewar": 22, "mindspor": 93, "minilb": 80, "minimax": [35, 43], "mix": [60, 61, 62, 96], "mla": [1, 29], "modal": [3, 5, 21, 41, 77], "mode": [11, 15, 22, 27, 32, 45, 50, 62, 93], "model": [3, 4, 5, 8, 17, 20, 21, 22, 26, 27, 28, 29, 35, 36, 40, 41, 43, 49, 53, 57, 60, 61, 66, 67, 70, 71, 73, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "modelopt": 17, "modelscop": 94, "modul": 22, "moe": [4, 7, 21, 36, 40, 64], "monitor": 22, "mooncak": [10, 15], "moor": 68, "more": [43, 78], "motiv": 3, "mp": 90, "mtl": 22, "multi": [2, 3, 5, 11, 15, 21, 22, 24, 29, 30, 41, 50, 70, 77, 81, 82, 88], "multimod": [46, 60, 66, 90, 91, 95, 96, 98], "multipl": [4, 13, 42], "multiplex": 21, "name": 8, "nativ": [20, 25, 26, 27, 36, 47], "nccl": 19, "nest": 37, "never": 22, "new": [1, 7, 20, 27, 48, 53, 90, 98], "newcom": [51, 59], "next": [44, 61], "ngram": 21, "nixl": 15, "node": [2, 15, 21, 29, 50, 70, 81, 82], "non": [4, 20, 27, 32, 37, 45], "normal": [46, 75], "note": [22, 32, 33, 45, 46, 49, 50, 56, 90, 95], "npu": [59, 60, 61, 65, 66], "nsa": 73, "nsight": [50, 90], "numa": [58, 60], "nvidia": [16, 17, 69], "nvlink": 15, "nvtx": 50, "observ": [14, 22], "obtain": 60, "offlin": [12, 17, 20, 25, 26, 27, 28, 37, 93, 98], "offload": 21, "ollama": 38, "one": 29, "onli": [36, 96], "onlin": 17, "oom": 70, "open": 23, "openai": [13, 20, 22, 25, 26, 27, 39, 40, 41, 42, 47, 90], "opentelemetri": 22, "optim": [10, 11, 21, 29, 30, 32, 45, 61, 67, 70, 71, 73, 90, 95], "option": [2, 8, 12, 21, 27, 46, 49, 52, 73, 90, 96], "oracl": 22, "organ": 11, "orin": 69, "oss": [33, 43], "other": [12, 46, 49, 50], "our": 98, "out": [12, 60, 70, 74], "output": [25, 26, 27, 28, 40, 46, 49, 50, 69, 90, 91], "overal": 11, "overflow": 22, "overlap": [7, 13], "overrid": 21, "overview": [2, 7, 8, 22, 88, 90], "ovi": 90, "packag": [22, 54], "parallel": [2, 7, 16, 21, 29, 30, 77], "paramet": [10, 11, 32, 40, 45, 46, 88, 90, 96], "pars": 22, "parser": [20, 22, 27, 30, 33], "path": 90, "paus": 23, "pd": [10, 11, 15, 16, 21, 22, 30, 50, 60, 61, 62, 80, 83], "penal": 46, "perf": 90, "perform": [2, 18, 22, 24, 28, 53, 60, 61, 70, 73, 90, 95], "pin": 13, "pip": [56, 90], "pipelin": [16, 30, 90], "pitfal": 96, "plane": 22, "platform": [57, 90], "polici": [10, 22, 90], "pool": 12, "popular": 43, "port": 98, "possibl": 50, "post": 84, "postgresql": 22, "postpon": 23, "power": 60, "pp": 30, "practic": [10, 16, 18, 22, 61], "pre": [51, 59], "precis": [32, 45], "precomput": 28, "predict": [24, 29, 30], "prefetch": [10, 11], "prefil": [1, 12, 15, 16, 21, 22, 50, 70, 80], "prepar": [59, 60, 80, 83], "preprocess": 28, "prerequisit": [22, 38, 49, 60, 69, 79, 80, 83, 85, 90], "preset": 90, "prevent": 60, "prioriti": 90, "privaci": 22, "process": 54, "processor": [28, 46], "product": [14, 22, 85, 86], "profil": [15, 50, 52, 73, 90], "prometheu": 22, "prompt": 77, "promql": 22, "propag": 22, "protect": 90, "protobuf": 93, "proxi": 22, "pypi": [54, 70], "python": [17, 22, 27, 33, 35, 38, 41, 42, 47, 48, 60, 88], "pytorch": [50, 60, 90], "quantis": [32, 45], "quantiz": [17, 18, 21, 69, 73, 99], "quark_int4fp8_mo": 17, "queri": [28, 96], "question": 74, "queu": 22, "queue": [12, 22], "quick": [22, 33, 38, 49, 91], "quickstart": 90, "qwen": [6, 43, 61, 70], "qwen2": 28, "qwen3": [4, 16, 40, 44, 45, 61, 64, 70, 96], "r": 19, "r1": [29, 61, 81], "radix": 44, "rang": 48, "rank": [11, 24], "rate": [22, 49, 51, 59], "raw": 28, "rbg": 83, "rdma": 79, "re": 86, "readi": 22, "reason": [20, 22, 26, 29, 30, 33, 40], "recommend": [22, 32, 45, 58, 70], "redi": 22, "refactor": 16, "refer": [2, 17, 22, 24, 57, 69, 70, 90], "refit": 23, "regex": [40, 46], "regist": 98, "regular": [22, 25, 26], "relat": [11, 21], "releas": [23, 54], "reliabl": 22, "remain": 79, "remot": [52, 99], "replai": 14, "report": [53, 90], "repositori": [51, 59], "reproduc": 4, "req": 12, "request": [12, 14, 20, 22, 27, 32, 41, 42, 45, 47, 51, 59, 67, 70, 71, 86, 88, 91, 96], "requestmetricsexport": 21, "requir": [8, 15, 27, 35, 70, 90, 93], "rerank": [36, 66, 96], "resourc": 70, "respons": [4, 22, 33, 88, 96], "restrict": 3, "result": [27, 30, 34, 53, 74], "resum": 23, "retri": 22, "return": 40, "return_docu": 96, "review": [51, 59], "reward": [36, 66, 88, 97], "rich": 11, "rl": 23, "robin": 30, "roce": 79, "rocm": 90, "root": 4, "rotari": 3, "round": [17, 30, 36], "rout": [22, 40], "router": [15, 22, 23, 38], "run": [12, 29, 51, 55, 56, 58, 59, 60, 62, 64, 67, 69, 90, 93], "runner": [55, 96], "runtim": [21, 22, 25, 26, 27, 48], "rust": 22, "sagemak": 56, "sampl": [4, 21, 24, 46, 90], "save": 18, "sbo": 7, "scale": 18, "scenario": [79, 86], "scene": 60, "schedul": [15, 21], "schema": [8, 20], "scheme": 60, "scm": 90, "score": [21, 36, 88], "script": 70, "search": 33, "secur": 22, "select": [1, 7, 15, 36, 75, 90, 93], "self": 55, "send": [27, 32, 45, 47], "separ": [22, 60], "sequenc": 30, "seri": 61, "serv": [13, 21, 49, 67, 70, 71, 90, 98], "server": [2, 4, 15, 20, 21, 22, 23, 27, 32, 36, 38, 40, 41, 42, 45, 47, 50, 67, 74, 77, 90, 91, 93], "servic": [22, 60, 80], "set": [22, 30, 55, 58, 60, 90], "setup": [2, 48, 52, 85, 86], "sgl": [51, 59, 90], "sglang": [0, 2, 3, 4, 5, 10, 20, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 36, 38, 44, 45, 50, 51, 52, 53, 56, 57, 58, 59, 60, 68, 69, 75, 77, 90, 98, 99], "sh": 55, "share": 50, "simplest": 28, "singl": [2, 7, 13, 15, 88], "size": [12, 16], "skypilot": [56, 70], "sleep": 23, "slice": 86, "slide": 90, "slurm": 81, "smart": 38, "smooth": 16, "snippet": 89, "softwar": 70, "solut": 4, "some": 93, "sourc": [22, 30, 51, 56, 58, 59, 60, 67, 68, 70, 71, 90], "spars": 21, "sparsiti": 21, "spec": 8, "special": 90, "specif": [20, 27, 32, 45, 70, 73], "spectul": 7, "specul": [1, 21, 24, 31, 33, 34, 44, 70], "speed": [12, 51, 59], "split": 30, "srt": [25, 26, 27], "sta": 90, "stabl": 3, "stage": 90, "standard": 30, "start": [22, 38, 49, 52, 55, 57, 90, 91, 93], "start_profil": 50, "static": [3, 12], "step": [1, 48, 55, 58, 90], "storag": [10, 11, 22, 50, 73], "stream": [20, 27, 37, 46, 47, 49, 77], "structur": [25, 26, 40, 46, 48, 69], "studi": 16, "style": [0, 51, 59], "submiss": 12, "success": 79, "suit": 98, "summari": [8, 38], "support": [1, 3, 4, 5, 7, 10, 18, 20, 21, 22, 26, 27, 35, 40, 49, 57, 60, 66, 70, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99], "swap": 60, "switch": 90, "synchron": [11, 37], "system": [11, 23, 35, 50, 58, 60, 70, 90], "tabl": 22, "tag": [25, 26], "target": 90, "target_modul": 8, "taylors": 90, "tbo": 7, "temperatur": [4, 74], "templat": [27, 72], "tensor": [2, 21, 23, 29, 48], "terminu": 67, "test": [22, 30, 34, 35, 51, 59, 62, 70, 73, 88, 98], "text": [36, 96], "think": [29, 31, 32, 40], "thread": 68, "three": 28, "throughput": [12, 29, 61, 70], "tile": 90, "time": [70, 90], "tip": [30, 34, 44, 50, 51, 59, 90], "tl": 22, "todo": 79, "token": [12, 16, 21, 22, 24, 29, 30, 36, 40, 49, 75], "tool": [22, 27, 33, 73], "top": 8, "top_n": 96, "torch": [24, 87], "torchao": [17, 69], "tp": [2, 12], "tpu": 70, "trace": [22, 50, 86, 90], "train": 84, "transfer": 11, "transferengin": 19, "transform": 99, "transport": [15, 22], "trigger": [51, 59], "trip": 36, "triton": 60, "troubleshoot": [2, 22, 49, 70, 74, 85, 90, 93], "try": 12, "tune": [12, 16, 22, 73], "turn": 77, "two": 7, "type": 21, "ultra": 16, "uncondit": 75, "understand": 28, "unifi": [11, 15], "unit": [51, 59], "unmerg": 90, "unsloth": 17, "up": [23, 52, 55], "updat": [0, 23, 36, 51, 54, 58, 59], "upload": 54, "us": [17, 23, 38, 40, 41, 42, 47, 48, 50, 52, 56, 58, 60, 67, 70, 71, 73, 88, 90, 94], "usag": [2, 4, 6, 12, 13, 15, 17, 18, 19, 20, 22, 26, 29, 30, 32, 33, 34, 35, 37, 40, 43, 44, 45, 50, 57, 67, 77, 85, 88, 90, 95], "user": 1, "util": 48, "uv": [56, 90], "v": 1, "v1": 36, "v3": [16, 29, 30, 40, 58, 62, 67, 73, 81], "v32": 61, "variabl": [73, 90], "verif": [4, 70], "verifi": 90, "version": [54, 60], "via": [24, 90, 98], "video": [32, 45, 90, 95], "view": [50, 90], "vision": [28, 42], "vl": [6, 28, 45, 64, 96], "vllm": 98, "vlm": [28, 53], "vscode": 52, "wake": 23, "warmup": 58, "warn": 90, "wasm": 22, "web": 33, "weight": [21, 23, 29, 36, 90], "what": [6, 11, 15, 49], "why": [4, 6, 10, 11, 15, 16, 23], "wise": [29, 50], "without": 27, "work": 13, "worker": [22, 50], "workflow": [0, 11, 17, 50], "workload": 7, "wrapper": 98, "write": [8, 11, 48, 51, 59], "x": [29, 62, 64, 90], "xgrammar": 69, "xpu": 71, "ye": 96, "you": 86, "your": 48}})