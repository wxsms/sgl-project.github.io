Search.setIndex({"alltitles": {"--perf-dump-path (Stage/Step Timing Dump)": [[74, "perf-dump-path-stage-step-timing-dump"]], "/generate Endpoint": [[51, "generate-endpoint"]], "0. Prerequisites": [[104, "prerequisites"], [107, "prerequisites"]], "1. Background and implementation overview": [[13, "background-and-implementation-overview"]], "1. Image Preparation": [[104, "image-preparation"], [107, "image-preparation"]], "1. Launch SGLang Server": [[43, "launch-sglang-server"]], "1. Launch a Matryoshka\u2011capable model": [[119, "launch-a-matryoshkacapable-model"]], "1. Raw Images - Simplest approach": [[30, "1.-Raw-Images---Simplest-approach"]], "1.1 Architecture / control path": [[13, "architecture-control-path"]], "2. All In One manifest file": [[107, "all-in-one-manifest-file"]], "2. Deployment Manifest Files": [[104, "deployment-manifest-files"]], "2. Idle-state requirement (strict)": [[13, "idle-state-requirement-strict"]], "2. Make requests with different output dimensions": [[119, "make-requests-with-different-output-dimensions"]], "2. Processor Output - For custom preprocessing": [[30, "2.-Processor-Output---For-custom-preprocessing"]], "2. Use Ollama CLI": [[43, "use-ollama-cli"]], "2.1 DP (data parallel) semantics": [[13, "dp-data-parallel-semantics"]], "3. How to use (HTTP Admin API)": [[13, "how-to-use-http-admin-api"]], "3. Precomputed Embeddings - For maximum performance": [[30, "3.-Precomputed-Embeddings---For-maximum-performance"]], "3. Use Ollama Python Library": [[43, "use-ollama-python-library"]], "3.1 Query current storage backend status": [[13, "query-current-storage-backend-status"]], "3.2 Attach (enable) a storage backend": [[13, "attach-enable-a-storage-backend"]], "3.3 Detach (disable) the storage backend": [[13, "detach-disable-the-storage-backend"]], "4. Behavior and caveats": [[13, "behavior-and-caveats"]], "AMD GPUs": [[79, null]], "API Endpoint": [[118, "api-endpoint"]], "API Reference": [[24, "api-reference"]], "API related": [[23, "api-related"], [88, "api-related"]], "ASCEND": [[17, "ascend"]], "Accuracy": [[58, "accuracy"]], "Accuracy Evaluation": [[84, "accuracy-evaluation"]], "Accuracy Impact": [[20, "accuracy-impact"]], "Accuracy Test with aime 2025": [[33, "accuracy-test-with-aime-2025"]], "Accuracy Test with gpqa-diamond": [[33, "accuracy-test-with-gpqa-diamond"]], "Accuracy Test with gsm8k": [[33, "accuracy-test-with-gsm8k"]], "Accuracy Test with lm_eval": [[39, "accuracy-test-with-lm-eval"]], "Achieve a high token usage": [[14, "achieve-a-high-token-usage"]], "Achieving high throughput for offline batch inference": [[14, "achieving-high-throughput-for-offline-batch-inference"]], "Activation Logic": [[5, "activation-logic"]], "Add Tokenizer (Async)": [[24, "add-tokenizer-async"]], "Add Worker": [[24, "add-worker"]], "Add a Runner": [[60, "add-a-runner"]], "Add new kernels": [[57, "add-new-kernels"]], "Add the Model to the Test Suite": [[115, "add-the-model-to-the-test-suite"]], "Adjust the request submission speed to control #queue-req": [[14, "adjust-the-request-submission-speed-to-control-queue-req"]], "Admin and Health Endpoints": [[24, "admin-and-health-endpoints"]], "Adoption": [[108, "adoption"]], "Advanced Configuration": [[17, "advanced-configuration"], [17, "id5"], [70, "advanced-configuration"]], "Advanced Features": [[19, "advanced-features"], [77, null], [94, "advanced-features"]], "Advanced Usage": [[42, "Advanced-Usage"]], "Advanced: Speculative Decoding (EAGLE3)": [[94, "advanced-speculative-decoding-eagle3"]], "Architecture": [[2, "architecture"], [24, "architecture"], [24, "id7"]], "Architecture Overview": [[75, "architecture-overview"]], "Areas for Contribution": [[94, "areas-for-contribution"]], "Args for multi-item scoring": [[23, "args-for-multi-item-scoring"], [88, "args-for-multi-item-scoring"]], "Arguments": [[61, "arguments"]], "Arguments for LoRA Serving": [[15, "Arguments-for-LoRA-Serving"]], "Ascend NPU Guidance": [[8, "ascend-npu-guidance"]], "Ascend NPUs": [[87, null]], "Attention Backend": [[1, null]], "Attention Backend Comparison": [[94, "attention-backend-comparison"]], "Attention Backend Selection Guide (CUDA)": [[1, "attention-backend-selection-guide-cuda"]], "Attention Backends": [[69, null], [73, "attention-backends"]], "Attention backend arguments": [[3, "attention-backend-arguments"]], "Authentication": [[53, "authentication"]], "Automatic Selection Logic": [[1, "automatic-selection-logic"]], "Available Pipeline Stages": [[75, "available-pipeline-stages"]], "Available Quantization Methods": [[19, "available-quantization-methods"]], "Avoid out-of-memory errors by tuning --chunked-prefill-size, --mem-fraction-static, and --max-running-requests": [[14, "avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests"]], "Backend Compatibility": [[29, "Backend-Compatibility"]], "Backend options": [[69, "backend-options"]], "Backends for All-to-All Communication": [[8, "backends-for-all-to-all-communication"]], "Backends for MoE Computation": [[8, "backends-for-moe-computation"]], "Basic Example: Qwen-7B": [[94, "basic-example-qwen-7b"]], "Basic Offline Engine API Call": [[30, "Basic-Offline-Engine-API-Call"]], "Basic Profiling": [[74, "basic-profiling"]], "Basic Usage": [[4, "basic-usage"], [45, "Basic-Usage"], [67, "basic-usage"], [70, "basic-usage"], [77, null], [101, "Basic-Usage"]], "Basic example": [[103, "basic-example"]], "Batch Tokenize Request": [[24, "batch-tokenize-request"]], "Batching": [[101, "Batching"]], "Bench Serving Guide": [[53, null]], "Benchmark": [[54, "benchmark"], [82, "benchmark"], [82, "id4"], [82, "id6"], [82, "id8"], [82, "id10"], [82, "id12"], [82, "id14"], [82, "id16"], [82, "id18"], [82, "id20"], [82, "id22"], [82, "id24"], [82, "id26"], [82, "id28"], [82, "id30"], [82, "id32"], [82, "id34"], [82, "id36"], [82, "id38"], [82, "id40"], [82, "id42"], [82, "id44"], [82, "id46"], [82, "id48"], [82, "id50"], [82, "id52"], [82, "id54"], [82, "id56"], [82, "id58"], [82, "id60"], [115, "benchmark"]], "Benchmark and Profiling": [[54, null]], "Benchmark the speed": [[55, "benchmark-the-speed"], [80, "benchmark-the-speed"]], "Benchmarking Results": [[33, "benchmarking-results"], [39, "benchmarking-results"]], "Benchmarking with Requests": [[90, "benchmarking-with-requests"], [94, "benchmarking-with-requests"], [95, "benchmarking-with-requests"]], "Benefits of ModelOpt": [[19, "benefits-of-modelopt"]], "Best Practice for Long Context": [[18, "best-practice-for-long-context"]], "Best Practice for Pipeline Parallelism with PD Disaggregation": [[18, "best-practice-for-pipeline-parallelism-with-pd-disaggregation"]], "Best Practice on Ascend NPU": [[82, null]], "Best Practices": [[5, "best-practices"], [20, "best-practices"]], "Bidirectional Attention in Multimodal Model Serving": [[127, "bidirectional-attention-in-multimodal-model-serving"]], "Block-wise FP8": [[32, "block-wise-fp8"]], "Build From Source": [[33, "build-from-source"]], "Build from source": [[55, "build-from-source"]], "Building Modules": [[24, "building-modules"]], "Built-in Tools": [[38, "built-in-tools"]], "C++ Implementation": [[57, "c-implementation"]], "C++ Utilities": [[57, "c-utilities"]], "CANN": [[81, "cann"]], "CFG Support": [[72, "cfg-support"]], "CI Execution": [[0, "ci-execution"]], "CI rate limits": [[55, "ci-rate-limits"], [80, "ci-rate-limits"]], "CI-Based Change Protection": [[65, "ci-based-change-protection"]], "CLI Quick Reference": [[67, "cli-quick-reference"]], "CPU Servers": [[90, null]], "CPU performance power scheme": [[81, "cpu-performance-power-scheme"]], "CUDA Error: Illegal Memory Access Encountered": [[98, "cuda-error-illegal-memory-access-encountered"]], "CUDA Out of Memory": [[98, "cuda-out-of-memory"]], "Cache Decision": [[72, "cache-decision"]], "Cache-Aware Policy Tuning": [[24, "cache-aware-policy-tuning"]], "Cache-DiT": [[71, "cache-dit"], [73, "cache-dit"]], "Cache-DiT Acceleration": [[70, null]], "Cache-DiT Configuration": [[66, "cache-dit-configuration"]], "Caching Acceleration": [[66, null]], "Caching Acceleration for Diffusion Models": [[71, null]], "Caching Strategies": [[73, "caching-strategies"]], "Call with Precomputed Embeddings": [[30, "Call-with-Precomputed-Embeddings"], [30, "id2"]], "Call with Processor Output": [[30, "Call-with-Processor-Output"], [30, "id1"]], "Capture expert selection distribution in MoE models": [[41, "Capture-expert-selection-distribution-in-MoE-models"]], "Case Study on NVIDIA H20": [[18, "case-study-on-nvidia-h20"]], "Chat Completions": [[45, "Chat-Completions"]], "Check if the metrics are being collected": [[109, "check-if-the-metrics-are-being-collected"]], "Checkpoint Engine Integration": [[2, null]], "Checkpoint Engine Options": [[2, "checkpoint-engine-options"]], "Choices Methods in SGLang": [[99, null]], "Choosing LoRA Backend": [[15, "Choosing-LoRA-Backend"]], "Choosing model and tokenizer": [[53, "choosing-model-and-tokenizer"]], "Chunked Prefill": [[94, "chunked-prefill"]], "Chunked Prefill Size and Smoothing Factor": [[18, "chunked-prefill-size-and-smoothing-factor"]], "Circuit Breaker": [[24, "circuit-breaker"]], "Circuit Breaker Flapping": [[24, "circuit-breaker-flapping"]], "Classification API": [[24, "classification-api"], [118, null]], "Classification Models (Multi-class)": [[118, "classification-models-multi-class"]], "Classify (reward model)": [[41, "Classify-(reward-model)"]], "Client Request": [[119, "client-request"]], "Cloud Storage": [[66, "cloud-storage"]], "Cloud Storage Support": [[61, "cloud-storage-support"]], "Co-launch Router and Workers": [[24, "co-launch-router-and-workers"]], "Code Structure": [[57, "code-structure"]], "Code style guidance": [[55, "code-style-guidance"], [80, "code-style-guidance"]], "Collaboration": [[108, "collaboration"]], "Combined Configuration Example": [[70, "combined-configuration-example"]], "Command Example": [[3, "command-example"], [6, "command-example"]], "Command Line Usage": [[54, "command-line-usage"]], "Commit Message Convention": [[65, "commit-message-convention"]], "Common Notes": [[76, "common-notes"]], "Common Pitfalls": [[121, "common-pitfalls"], [121, "id3"]], "Common launch commands": [[23, "common-launch-commands"]], "Communication patterns in DPA + EP:": [[5, "communication-patterns-in-dpa-ep"]], "Community and Support": [[11, "community-and-support"]], "Comparison": [[24, "comparison"]], "Compatibility": [[118, "compatibility"]], "Compatibility Matrix": [[64, null]], "Compilation Long-Time": [[94, "compilation-long-time"]], "Completions": [[45, "Completions"]], "Complex Prompts": [[101, "Complex-Prompts"]], "Component Version Mapping For SGLang": [[81, "component-version-mapping-for-sglang"]], "Comprehensive Benchmark Script": [[94, "comprehensive-benchmark-script"]], "Computation and Communication Overlap": [[8, "computation-and-communication-overlap"]], "Configuration": [[24, "configuration"], [24, "id3"], [69, "configuration"], [72, "configuration"]], "Configuration Files": [[109, "configuration-files"]], "Configuration Guidelines": [[11, "configuration-guidelines"]], "Configuration Options": [[2, "configuration-options"]], "Configuration Reference": [[24, "configuration-reference"]], "Configuration Tips": [[33, "configuration-tips"], [39, "configuration-tips"], [49, "configuration-tips"]], "Configuration file support": [[23, "configuration-file-support"], [88, "configuration-file-support"]], "Configuration overview": [[9, "configuration-overview"]], "Connection Issues": [[94, "connection-issues"]], "Constrained Decoding": [[101, "Constrained-Decoding"]], "Constrained decoding": [[51, "constrained-decoding"]], "Continue Generation": [[25, "continue-generation"]], "Contributing": [[78, "contributing"], [94, "contributing"]], "Contributing to SGLang Diffusion": [[65, null]], "Contribution Guide": [[55, null], [80, null]], "Control Plane": [[24, "control-plane"]], "Control flow": [[101, "Control-flow"]], "Conversation and Response APIs": [[24, "conversation-and-response-apis"]], "Core HiCache Parameters": [[11, "core-hicache-parameters"]], "Core Settings": [[24, "core-settings"]], "Core parameters": [[51, "core-parameters"]], "Crash Dump and Replay": [[16, "crash-dump-and-replay"]], "Create Docker": [[81, "create-docker"]], "Create decode k8s service": [[104, "create-decode-k8s-service"]], "Create prefill k8s service": [[104, "create-prefill-k8s-service"]], "Creating Service for Prefill and Decode": [[104, "creating-service-for-prefill-and-decode"]], "Creating Your Own Quantized Checkpoints": [[19, "creating-your-own-quantized-checkpoints"]], "Cross-Encoder Rerank (embedding runner)": [[121, "cross-encoder-rerank-embedding-runner"]], "Cuda Graph for Multi-Modal Encoder in SGLang": [[3, null]], "Currently supported parsers:": [[29, "Currently-supported-parsers:"]], "Custom Attention Backends": [[94, "custom-attention-backends"]], "Custom Chat Template": [[96, null]], "Custom Storage Backend Integration": [[11, "custom-storage-backend-integration"]], "Custom logit processor": [[51, "custom-logit-processor"]], "Custom weight loader": [[23, "custom-weight-loader"], [88, "custom-weight-loader"]], "DBCache Parameters": [[70, "dbcache-parameters"]], "DP for Multi-Modal Encoder in SGLang": [[6, null]], "DP, DPA and SGLang DP Router": [[5, null]], "DPA with Expert Parallelism for MoE": [[5, "dpa-with-expert-parallelism-for-moe"]], "DSA long sequence context parallel optimization(experimental)": [[33, "dsa-long-sequence-context-parallel-optimization-experimental"]], "Data Parallelism (DP)": [[5, "data-parallelism-dp"]], "Data Parallelism Attention": [[32, "data-parallelism-attention"]], "Data Parallelism Attention (DPA)": [[5, "data-parallelism-attention-dpa"]], "Data Plane": [[24, "data-plane"]], "Data Structure": [[78, "data-structure"]], "Data Transfer Optimization": [[12, "data-transfer-optimization"]], "Data Write-back": [[12, "data-write-back"]], "Data parallelism": [[23, "data-parallelism"], [88, "data-parallelism"]], "Datasets": [[53, "datasets"]], "Debug": [[103, "debug"]], "Debug Mode": [[91, "debug-mode"], [113, "debug-mode"]], "Debug SGLang with VSCode Debugger": [[56, "debug-sglang-with-vscode-debugger"]], "Debug tensor dumps": [[23, "debug-tensor-dumps"], [88, "debug-tensor-dumps"]], "Debugging": [[24, "debugging"]], "Decode": [[104, "decode"]], "Decode Server Configuration": [[17, "decode-server-configuration"]], "DeepEP Ascend Introduction": [[8, "deepep-ascend-introduction"]], "DeepEP Configuration": [[97, "deepep-configuration"]], "DeepEP-compatible Library": [[81, "deepep-compatible-library"]], "DeepGEMM Configuration (Advanced Optimization)": [[97, "deepgemm-configuration-advanced-optimization"]], "DeepSeek Multi-Node": [[17, "deepseek-multi-node"], [17, "id4"], [17, "id8"]], "DeepSeek OCR (OCR-1 / OCR-2)": [[31, null]], "DeepSeek Series Models": [[82, "deepseek-series-models"]], "DeepSeek V3.2 Usage": [[33, null]], "DeepSeek V3/R1": [[105, "deepseek-v3-r1"]], "DeepSeek V3/V3.1/R1 Usage": [[32, null]], "DeepSeek examples": [[83, null]], "DeepSeek-R1 2K-2K 50ms on A3 16 Cards Separation Mode": [[82, "deepseek-r1-2k-2k-50ms-on-a3-16-cards-separation-mode"]], "DeepSeek-R1 2K-2K 50ms on A3 8 Cards Mixed Mode": [[82, "deepseek-r1-2k-2k-50ms-on-a3-8-cards-mixed-mode"]], "DeepSeek-R1 3_5K-1K 20ms on A3 32 Cards Separation Mode": [[82, "deepseek-r1-3-5k-1k-20ms-on-a3-32-cards-separation-mode"]], "DeepSeek-R1 3_5K-1_5K 20ms on A3 32 Cards Separation Mode": [[82, "deepseek-r1-3-5k-1-5k-20ms-on-a3-32-cards-separation-mode"]], "DeepSeek-R1 3_5K-1_5K 50ms on A3 16 Cards Separation Mode": [[82, "deepseek-r1-3-5k-1-5k-50ms-on-a3-16-cards-separation-mode"]], "DeepSeek-R1 3_5K-1_5K 50ms on A3 32 Cards Separation Mode": [[82, "deepseek-r1-3-5k-1-5k-50ms-on-a3-32-cards-separation-mode"]], "DeepSeek-R1 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode": [[82, "deepseek-r1-3-5k-1-5k-50ms-on-a3-8-cards-mixed-mode"]], "DeepSeek-R1 3_9K-1K 20ms on A3 32 Cards Separation Mode": [[82, "deepseek-r1-3-9k-1k-20ms-on-a3-32-cards-separation-mode"]], "DeepSeek-R1 6K-1_6K 20ms on A3 32 Cards Separation Mode": [[82, "deepseek-r1-6k-1-6k-20ms-on-a3-32-cards-separation-mode"]], "DeepSeek-V3.1 with 128K Input Token Length": [[18, "deepseek-v3-1-with-128k-input-token-length"]], "DeepSeek-V3.2-Exp 64K-3K 30ms on A3 32 Cards Separation Mode": [[82, "deepseek-v3-2-exp-64k-3k-30ms-on-a3-32-cards-separation-mode"]], "DeepSeekV32-Exp RBG Based PD Deploy": [[107, null]], "Default Behavior": [[4, "default-behavior"]], "Define Messages": [[29, "Define-Messages"]], "Define Tools for Function Call": [[29, "Define-Tools-for-Function-Call"]], "Define a Tool Function": [[29, "Define-a-Tool-Function"]], "Denoising Stage Profiling": [[74, "denoising-stage-profiling"]], "Deploy On Kubernetes": [[103, null]], "Deploy minilb and lb service": [[104, "deploy-minilb-and-lb-service"]], "Deploying Modules": [[24, "deploying-modules"]], "Deploying Quantized Models": [[19, "deploying-quantized-models"]], "Deployment": [[78, "deployment"], [84, "deployment"]], "Deployment Modes": [[24, "deployment-modes"]], "Deployment with HF3FS": [[11, "deployment-with-hf3fs"]], "Deployment with Mooncake": [[11, "deployment-with-mooncake"]], "Deployment with Python": [[40, "deployment-with-python"]], "Deprecated arguments": [[23, "deprecated-arguments"]], "Design and Restrictions": [[3, "design-and-restrictions"]], "Deterministic Inference": [[4, null], [25, "deterministic-inference"]], "Deterministic Inference with Non-Greedy Sampling (Temperature > 0)": [[4, "deterministic-inference-with-non-greedy-sampling-temperature-0"]], "Detokenize Request": [[24, "detokenize-request"]], "Detokenize Response": [[24, "detokenize-response"]], "Developer Guide": [[77, null]], "Development Guide Using Docker": [[56, null]], "Development Guide for JIT Kernels": [[57, null]], "Diffusers Backend": [[61, "diffusers-backend"]], "Diffusers Backend Configuration": [[70, "diffusers-backend-configuration"]], "Diffusion": [[34, null]], "Diffusion LLM": [[23, "diffusion-llm"]], "Diffusion Language Models": [[124, null]], "Diffusion Language Models (dLLMs)": [[35, null]], "Disable NUMA Auto-Balancing": [[79, "disable-numa-auto-balancing"]], "Disable NUMA balancing": [[81, "disable-numa-balancing"]], "Distributed Computing": [[97, "distributed-computing"]], "Distributed environment warning": [[70, "distributed-environment-warning"]], "Distributed inference": [[70, "distributed-inference"]], "Docker": [[24, "docker"], [33, "docker"]], "Docs Workflow": [[0, "docs-workflow"]], "Documentation": [[67, "documentation"], [94, "documentation"], [115, "documentation"]], "Documentation Build, Deployment, and CI": [[0, "documentation-build-deployment-and-ci"]], "Documentation Style Guidelines": [[0, "documentation-style-guidelines"]], "Double Sparsity": [[23, "double-sparsity"]], "Download Weights": [[32, "download-weights"]], "Duration Buckets": [[24, "duration-buckets"]], "Dynamic Backend Loading": [[11, "dynamic-backend-loading"]], "Dynamic LoRA loading": [[15, "Dynamic-LoRA-loading"]], "Dynamic batch tokenizer": [[23, "dynamic-batch-tokenizer"], [88, "dynamic-batch-tokenizer"]], "Dynamic inputs to fit static constraints of CUDA Graph": [[3, "dynamic-inputs-to-fit-static-constraints-of-cuda-graph"]], "EAGLE Decoding": [[26, "EAGLE-Decoding"]], "EAGLE Speculative Decoding": [[36, "eagle-speculative-decoding"], [39, "eagle-speculative-decoding"], [49, "eagle-speculative-decoding"]], "EAGLE-2 Decoding via Frequency-Ranked Speculative Sampling": [[26, "EAGLE-2-Decoding-via-Frequency-Ranked-Speculative-Sampling"]], "EAGLE-2 Decoding with torch.compile": [[26, "EAGLE-2-Decoding-with-torch.compile"]], "EAGLE-2 decoding": [[26, "EAGLE-2-decoding"]], "EAGLE-3 Decoding": [[26, "EAGLE-3-Decoding"]], "EBNF": [[27, "EBNF"], [27, "id2"], [27, "id6"], [28, "EBNF"], [28, "id2"], [28, "id6"]], "EP with Spectulative Decoding": [[8, "ep-with-spectulative-decoding"]], "EPD Disaggregation": [[7, null]], "Easy To Postpone Generation": [[25, "easy-to-postpone-generation"]], "Embedding Models": [[89, "embedding-models"], [119, null]], "Enable Cache-DiT acceleration": [[67, "enable-cache-dit-acceleration"]], "Enable Dynamic Chunking and Adjust Smoothing Factor for Ultra-long ITL": [[18, "enable-dynamic-chunking-and-adjust-smoothing-factor-for-ultra-long-itl"]], "Enabling Quantized KV Cache": [[20, "enabling-quantized-kv-cache"]], "Enabling cache for torch.compile": [[111, null]], "Encode (embedding model)": [[41, "Encode-(embedding-model)"]], "Encode prefill disaggregation": [[23, "encode-prefill-disaggregation"], [88, "encode-prefill-disaggregation"]], "End-to-end examples": [[53, "end-to-end-examples"]], "Endpoints": [[43, "endpoints"], [62, "endpoints"]], "Environment Preparation": [[84, "environment-preparation"]], "Environment Setup": [[57, "environment-setup"]], "Environment Variables": [[70, "environment-variables"], [97, null]], "Environment Verification": [[94, "environment-verification"]], "Error Handling": [[118, "error-handling"]], "Evaluating New Models with SGLang": [[58, null]], "Evaluation": [[56, "evaluation"]], "Example Client Code Snippet": [[124, "example-client-code-snippet"]], "Example Client Request": [[121, "example-client-request"]], "Example Client Request (supports optional instruct, top_n, and return_documents)": [[121, "example-client-request-supports-optional-instruct-top-n-and-return-documents"]], "Example Configuration File": [[124, "example-configuration-file"]], "Example Configurations": [[4, "example-configurations"]], "Example Launch Command": [[124, "example-launch-command"]], "Example Usage": [[118, "example-usage"]], "Example Usage Commands": [[90, "example-usage-commands"]], "Example launch Command": [[116, "example-launch-command"], [123, "example-launch-command"], [125, "example-launch-command"], [127, "example-launch-command"]], "Example usage with the above optimizations:": [[37, "example-usage-with-the-above-optimizations"], [50, "example-usage-with-the-above-optimizations"]], "Example workflow": [[54, "example-workflow"]], "Example: DeepSeek-V3 Models": [[45, "Example:-DeepSeek-V3-Models"]], "Example: Implementing Qwen-Image-Edit": [[75, "example-implementing-qwen-image-edit"]], "Example: Implementing and Serving a Llama Wrapper Model": [[115, "example-implementing-and-serving-a-llama-wrapper-model"]], "Example: Qwen3 Models": [[45, "Example:-Qwen3-Models"]], "Example: Required Tool Choice": [[29, "Example:-Required-Tool-Choice"]], "Example: Running DeepSeek-V3.1-Terminus": [[90, "example-running-deepseek-v3-1-terminus"]], "Example: Running Llama-3.2-3B": [[90, "example-running-llama-3-2-3b"]], "Example: Running Ovis-Image-7B": [[61, "example-running-ovis-image-7b"]], "Example: Specific Function Choice": [[29, "Example:-Specific-Function-Choice"]], "Example: Switching LoRAs": [[62, "example-switching-loras"]], "Examples": [[8, "examples"], [8, "id1"], [24, "examples"], [24, "id9"], [51, "examples"], [53, "examples"], [79, "examples"]], "Examples of Offline Model Quantization": [[19, "examples-of-offline-model-quantization"]], "Execute the Tool": [[29, "Execute-the-Tool"]], "Expert Parallelism": [[8, null]], "Expert parallelism": [[88, "expert-parallelism"]], "Explicitly select devices": [[91, "explicitly-select-devices"], [113, "explicitly-select-devices"]], "Extending SGLang": [[112, null]], "Extensible EP Framework": [[8, "extensible-ep-framework"]], "External Resources": [[94, "external-resources"]], "Extra Diffusers Arguments": [[61, "extra-diffusers-arguments"]], "FAQ": [[32, "faq"], [74, "faq"], [104, "faq"], [107, "faq"]], "FP4 Accuracy": [[20, "fp4-accuracy"]], "FP4 Format": [[20, "fp4-format"]], "FP8 (quantised) mode": [[37, "fp8-quantised-mode"], [50, "fp8-quantised-mode"]], "FP8 Accuracy": [[20, "fp8-accuracy"]], "FP8 Format": [[20, "fp8-format"]], "Feature Support Matrix": [[94, "feature-support-matrix"]], "Features": [[24, "features"], [78, "features"]], "Fine-Grained Engine Sleep and Wake Up": [[25, "fine-grained-engine-sleep-and-wake-up"]], "Flush Cache": [[41, "Flush-Cache"]], "For CUDA 13": [[76, "for-cuda-13"]], "For Multi-Modal": [[23, "for-multi-modal"], [88, "for-multi-modal"]], "For PD-Multiplexing": [[23, "for-pd-multiplexing"], [88, "for-pd-multiplexing"]], "For checkpoint decryption": [[23, "for-checkpoint-decryption"], [88, "for-checkpoint-decryption"]], "For deterministic inference": [[88, "for-deterministic-inference"]], "For registering hooks": [[88, "for-registering-hooks"]], "Forcing Pythonic Tool Call Output Without a Chat Template": [[29, "Forcing-Pythonic-Tool-Call-Output-Without-a-Chat-Template"]], "Fork and clone the repository": [[55, "fork-and-clone-the-repository"], [80, "fork-and-clone-the-repository"]], "Format code with pre-commit": [[55, "format-code-with-pre-commit"], [80, "format-code-with-pre-commit"]], "Forward hooks": [[23, "forward-hooks"]], "Framework Overview": [[8, "framework-overview"]], "Frequently Asked Questions": [[98, "frequently-asked-questions"]], "Frontend Language": [[100, null], [100, null]], "Full Pipeline Profiling": [[74, "full-pipeline-profiling"]], "Full TLS Configuration Example": [[24, "full-tls-configuration-example"]], "Function Call Parsing": [[24, "function-call-parsing"]], "Function Calling / Tool Use": [[97, "function-calling-tool-use"]], "Function Calling and Reasoning Parser": [[33, "function-calling-and-reasoning-parser"]], "Function calling for DeepSeek Models": [[32, "function-calling-for-deepseek-models"]], "Future Works": [[15, "Future-Works"]], "GLM-4.6V / GLM-4.5V Usage": [[37, null]], "GLM-5": [[84, null]], "GPT OSS Usage": [[38, null]], "General Configuration": [[97, "general-configuration"]], "Generate": [[61, "generate"]], "Generate (one-off generation)": [[67, "generate-one-off-generation"]], "Generate (text generation model)": [[41, "Generate-(text-generation-model)"]], "Generating Multiple Reproducible Responses": [[4, "generating-multiple-reproducible-responses"]], "Get Model Info": [[41, "Get-Model-Info"]], "Get Server Info": [[41, "Get-Server-Info"]], "Get Started": [[77, null]], "Getting Started": [[67, "getting-started"]], "Getting Token IDs": [[45, "Getting-Token-IDs"]], "GitHub Pages": [[78, "github-pages"]], "GitHub Token": [[78, "github-token"]], "Go Bindings": [[24, "go-bindings"]], "Greedy Token Selection": [[99, "greedy-token-selection"]], "Guidance about Dynamic Chunking": [[18, "guidance-about-dynamic-chunking"]], "Guidance on SGLang configuration in Ascend NPU": [[8, "guidance-on-sglang-configuration-in-ascend-npu"]], "HTTP API Usage": [[54, "http-api-usage"]], "HTTP server": [[23, "http-server"], [88, "http-server"]], "Handle Tools": [[29, "Handle-Tools"], [29, "id1"]], "Hardware Platforms": [[77, null]], "Hardware-specific notes / recommendations": [[37, "hardware-specific-notes-recommendations"], [50, "hardware-specific-notes-recommendations"]], "Health Check": [[41, "Health-Check"]], "Health Checks": [[24, "health-checks"]], "HiCache System Design and Optimization": [[12, null]], "HiRadixTree: Metadata Organization in HiCache": [[12, "hiradixtree-metadata-organization-in-hicache"]], "Hierarchical KV Caching (HiCache)": [[10, null]], "Hierarchical cache": [[23, "hierarchical-cache"], [88, "hierarchical-cache"]], "Hierarchical sparse attention": [[23, "hierarchical-sparse-attention"]], "High Availability": [[24, "high-availability"]], "High Throughput": [[82, "high-throughput"], [82, "id2"]], "High-Performance Configuration: Qwen3-8B": [[94, "high-performance-configuration-qwen3-8b"]], "History and Data Connectors": [[24, "history-and-data-connectors"]], "Hook lifecycle and behavior": [[9, "hook-lifecycle-and-behavior"]], "Hook spec schema": [[9, "hook-spec-schema"]], "How DPA Works": [[5, "how-dpa-works"]], "How It Works": [[72, "how-it-works"]], "How to Contribute": [[94, "how-to-contribute"]], "How to Extend the Tracing Framework to Support Complex Tracing Scenarios": [[110, "how-to-extend-the-tracing-framework-to-support-complex-tracing-scenarios"]], "How to Generate a Report": [[65, "how-to-generate-a-report"]], "How to Support New Diffusion Models": [[75, null]], "How to Support New Models": [[115, null]], "How to Support a New Language Model": [[115, "how-to-support-a-new-language-model"]], "How to Support a New Multimodal Large Language Model": [[115, "how-to-support-a-new-multimodal-large-language-model"]], "How to Trigger CI Tests": [[55, "how-to-trigger-ci-tests"], [80, "how-to-trigger-ci-tests"]], "How to add Tracing for slices you\u2019re interested in?": [[110, "how-to-add-tracing-for-slices-you-re-interested-in"]], "How to enable": [[29, "How-to-enable"]], "How to support a new model?": [[29, "How-to-support-a-new-model?"]], "How to update sgl-kernel": [[55, "how-to-update-sgl-kernel"], [80, "how-to-update-sgl-kernel"]], "How to update sgl-kernel-npu": [[80, "how-to-update-sgl-kernel-npu"]], "Hybrid attention (different backends for prefill vs decode) (Experimental)": [[1, "hybrid-attention-different-backends-for-prefill-vs-decode-experimental"]], "Hyperparameter Tuning": [[14, null]], "Image & Video Generation Models": [[34, "image-video-generation-models"]], "Image Generation": [[62, "image-generation"]], "Image Generation Models": [[64, "image-generation-models"]], "Image Reranking (text query, image/mixed documents)": [[121, "image-reranking-text-query-image-mixed-documents"]], "Image input:": [[37, "image-input"], [50, "image-input"]], "Implementation Details": [[118, "implementation-details"]], "Implementation Refactoring based on Async Communication": [[18, "implementation-refactoring-based-on-async-communication"]], "Implementing New Backends": [[8, "implementing-new-backends"]], "Implementing Our Model": [[115, "implementing-our-model"]], "Important Notes": [[54, "important-notes"]], "Important Server Parameters and Flags": [[37, "important-server-parameters-and-flags"], [50, "important-server-parameters-and-flags"]], "In sequence splitting": [[33, "in-sequence-splitting"]], "Inference Endpoints": [[24, "inference-endpoints"]], "Initialize the Client": [[29, "Initialize-the-Client"]], "Install Dependency": [[0, "install-dependency"]], "Install From Source": [[90, "install-from-source"], [95, "install-from-source"]], "Install SGLang": [[76, null], [79, "install-sglang"], [92, "install-sglang"]], "Install SGLang from Source": [[55, "install-sglang-from-source"], [80, "install-sglang-from-source"]], "Install SGLang-Diffusion": [[68, null]], "Install Using Docker": [[90, "install-using-docker"], [95, "install-using-docker"]], "Install Using Docker (Recommended)": [[79, "install-using-docker-recommended"]], "Install from Source": [[79, "install-from-source"], [92, "install-from-source"]], "Installation": [[2, "installation"], [19, "installation"], [24, "installation"], [24, "id5"], [24, "id8"], [33, "installation"], [67, "installation"], [74, "installation"], [84, "installation"], [90, "installation"], [91, "installation"], [94, "installation"], [95, "installation"], [113, "installation"]], "Installing SGLang from source": [[81, "installing-sglang-from-source"]], "Installing and running SGLang with Jetson Containers": [[93, "installing-and-running-sglang-with-jetson-containers"]], "Integer Range": [[57, "integer-range"]], "Integration with PD Disaggregation": [[11, "integration-with-pd-disaggregation"]], "Integration with PD-Disaggregation Deployment Mode": [[12, "integration-with-pd-disaggregation-deployment-mode"]], "Interactive Debugging": [[115, "interactive-debugging"]], "Introduction": [[84, "introduction"], [91, "introduction"], [113, "introduction"]], "Issues with Unified Scheduling": [[17, "issues-with-unified-scheduling"]], "JSON": [[27, "JSON"], [27, "id1"], [27, "id5"], [28, "JSON"], [28, "id1"], [28, "id5"]], "JSON Format": [[96, "json-format"]], "JSONL output format": [[53, "jsonl-output-format"]], "Jinja Format": [[96, "jinja-format"]], "Jump to sections": [[26, "Jump-to-sections"]], "Kernel Backends (Attention, Sampling, Grammar, GEMM)": [[23, "kernel-backends-attention-sampling-grammar-gemm"], [88, "kernel-backends-attention-sampling-grammar-gemm"]], "Kernel Launching": [[57, "kernel-launching"]], "Key Components for Implementation": [[75, "key-components-for-implementation"]], "Key Configurations with Storage Backends Enabled": [[11, "key-configurations-with-storage-backends-enabled"]], "Key Features": [[67, "key-features"], [71, "key-features"]], "Key Inference Metrics (gRPC mode)": [[24, "key-inference-metrics-grpc-mode"]], "Key benefits of DPA": [[5, "key-benefits-of-dpa"]], "Key characteristics": [[5, "key-characteristics"]], "Keys to success": [[103, "keys-to-success"]], "Known supported models": [[3, "known-supported-models"], [6, "known-supported-models"]], "Ktransformers": [[23, "ktransformers"]], "Kubernetes Deployment": [[24, "kubernetes-deployment"]], "Kubernetes Discovery": [[24, "kubernetes-discovery"]], "L1 Distance Tracking": [[72, "l1-distance-tracking"]], "LLMs": [[58, "llms"], [58, "id1"]], "LMCache": [[23, "lmcache"], [88, "lmcache"]], "LWS Based PD Deploy": [[104, null]], "Language Bindings": [[24, "language-bindings"]], "Large Language Models": [[89, "large-language-models"], [125, null]], "Latency Optimization": [[94, "latency-optimization"]], "Latency Testing": [[94, "latency-testing"]], "Launch A Server": [[41, "Launch-A-Server"], [45, "Launch-A-Server"], [46, "Launch-A-Server"], [47, "Launch-A-Server"], [52, "Launch-A-Server"], [101, "Launch-A-Server"]], "Launch Command": [[121, "launch-command"], [121, "id1"], [121, "id2"]], "Launch Command for Different Attention Backends": [[1, "launch-command-for-different-attention-backends"]], "Launch DeepSeek V3.1/V3/R1 with SGLang": [[32, "launch-deepseek-v3-1-v3-r1-with-sglang"]], "Launch DeepSeek V3.2 with SGLang": [[33, "launch-deepseek-v3-2-with-sglang"]], "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang": [[36, null]], "Launch Llama 4 with SGLang": [[39, "launch-llama-4-with-sglang"]], "Launch Qwen3-Next with SGLang": [[49, "launch-qwen3-next-with-sglang"]], "Launch Server": [[119, "launch-server"]], "Launch commands for SGLang": [[37, "launch-commands-for-sglang"], [50, "launch-commands-for-sglang"]], "Launch of the Serving Engine": [[90, "launch-of-the-serving-engine"], [94, "launch-of-the-serving-engine"], [95, "launch-of-the-serving-engine"]], "Launch server": [[31, "launch-server"]], "Launch with one node of 8 x H200": [[32, "launch-with-one-node-of-8-x-h200"]], "Launching the Server": [[22, "Launching-the-Server"], [29, "Launching-the-Server"]], "Layer-wise NVTX Profiling with Nsight Systems": [[54, "layer-wise-nvtx-profiling-with-nsight-systems"]], "Learn More and Join the Community": [[102, null]], "Limitations": [[70, "limitations"]], "List Workers": [[24, "list-workers"]], "Llama 3.1 405B": [[105, "llama-3-1-405b"]], "Llama 4 Basic Call": [[30, "Llama-4-Basic-Call"]], "Llama Models": [[4, "llama-models"]], "Llama Single Node": [[17, "llama-single-node"], [17, "id3"], [17, "id7"]], "Llama4 Usage": [[39, null]], "LoRA": [[23, "lora"], [88, "lora"]], "LoRA GPU Pinning": [[15, "LoRA-GPU-Pinning"]], "LoRA Management": [[62, "lora-management"]], "LoRA Overlap Loading": [[15, "LoRA-Overlap-Loading"]], "LoRA Serving": [[15, null]], "Load Balancing Policies": [[5, "load-balancing-policies"], [24, "load-balancing-policies"]], "Load Balancing Router": [[25, "load-balancing-router"]], "Load Imbalance / Hot Workers": [[24, "load-imbalance-hot-workers"]], "Local Match": [[12, "local-match"]], "Logging": [[16, "logging"], [23, "logging"], [24, "logging"], [88, "logging"]], "Logit Bias Support": [[45, "Logit-Bias-Support"], [45, "id1"]], "Low Latency": [[82, "low-latency"], [82, "id1"]], "Low Throughput": [[94, "low-throughput"]], "MCP Configuration File": [[24, "mcp-configuration-file"]], "MCP Integration": [[24, "mcp-integration"]], "MHA Backends": [[1, "mha-backends"]], "MLA Backends": [[1, "mla-backends"]], "MORI Configuration": [[97, "mori-configuration"]], "Make a release in GitHub": [[59, "make-a-release-in-github"]], "Mamba Cache": [[23, "mamba-cache"], [88, "mamba-cache"]], "Mamba Radix Cache": [[49, "mamba-radix-cache"]], "Markdown Export (make markdown)": [[0, "markdown-export-make-markdown"]], "Matryoshka Embedding Example": [[119, "matryoshka-embedding-example"]], "MemFabric-Hybrid": [[81, "memfabric-hybrid"]], "Memory Growth": [[24, "memory-growth"]], "Memory Layout Optimization": [[11, "memory-layout-optimization"]], "Memory Management": [[97, "memory-management"]], "Memory Optimization": [[94, "memory-optimization"]], "Memory Savings": [[20, "memory-savings"]], "Memory and scheduling": [[23, "memory-and-scheduling"], [88, "memory-and-scheduling"]], "Method 1: Installing from source with prerequisites": [[81, "method-1-installing-from-source-with-prerequisites"]], "Method 1: Using PyPI (Recommended)": [[94, "method-1-using-pypi-recommended"]], "Method 1: With pip or uv": [[68, "method-1-with-pip-or-uv"], [76, "method-1-with-pip-or-uv"]], "Method 2: From Source": [[94, "method-2-from-source"]], "Method 2: From source": [[68, "method-2-from-source"], [76, "method-2-from-source"]], "Method 2: Using Docker Image": [[81, "method-2-using-docker-image"]], "Method 3: Using Docker": [[68, "method-3-using-docker"], [94, "method-3-using-docker"]], "Method 3: Using docker": [[76, "method-3-using-docker"]], "Method 4: Cloud TPU with SkyPilot": [[94, "method-4-cloud-tpu-with-skypilot"]], "Method 4: Using Kubernetes": [[76, "method-4-using-kubernetes"]], "Method 5: Using docker compose": [[76, "method-5-using-docker-compose"]], "Method 6: Run on Kubernetes or Clouds with SkyPilot": [[76, "method-6-run-on-kubernetes-or-clouds-with-skypilot"]], "Method 7: Run on AWS SageMaker": [[76, "method-7-run-on-aws-sagemaker"]], "Method comparison (mini table)": [[26, "Method-comparison-(mini-table)"]], "Methods": [[99, "methods"]], "Metric Categories (40+ metrics)": [[24, "metric-categories-40-metrics"]], "Metrics Explained": [[78, "metrics-explained"]], "Metrics explained": [[53, "metrics-explained"]], "MindSpore Models": [[91, null], [113, null]], "MiniMax M2.1/M2 Usage": [[40, null]], "MoE": [[23, "moe"]], "Model Deployment": [[82, "model-deployment"], [82, "id3"], [82, "id5"], [82, "id7"], [82, "id9"], [82, "id11"], [82, "id13"], [82, "id15"], [82, "id17"], [82, "id19"], [82, "id21"], [82, "id23"], [82, "id25"], [82, "id27"], [82, "id29"], [82, "id31"], [82, "id33"], [82, "id35"], [82, "id37"], [82, "id39"], [82, "id41"], [82, "id43"], [82, "id45"], [82, "id47"], [82, "id49"], [82, "id51"], [82, "id53"], [82, "id55"], [82, "id57"], [82, "id59"]], "Model Hooks": [[9, null]], "Model Thinking/Reasoning Support": [[45, "Model-Thinking/Reasoning-Support"]], "Model Weight": [[84, "model-weight"]], "Model and tokenizer": [[23, "model-and-tokenizer"], [88, "model-and-tokenizer"]], "Model override args": [[23, "model-override-args"], [88, "model-override-args"]], "Model-Specific Behaviors": [[22, "Model-Specific-Behaviors"]], "Model-Specific Configurations": [[72, "model-specific-configurations"]], "Model-Specific Options": [[97, "model-specific-options"]], "Models x Optimization": [[64, "models-x-optimization"]], "Modern Data Parallelism SGLang Model Gateway (SMG)": [[5, "modern-data-parallelism-sglang-model-gateway-smg"]], "Monitoring with PromQL": [[24, "monitoring-with-promql"]], "Mooncake": [[17, "mooncake"]], "Moore Threads GPUs": [[92, null]], "Motivation": [[3, "motivation"]], "Multi Token Prediction": [[26, "Multi-Token-Prediction"]], "Multi-Modal Embedding Model": [[46, "Multi-Modal-Embedding-Model"]], "Multi-Model Inference Gateway": [[24, "multi-model-inference-gateway"]], "Multi-Node Deployment": [[105, null], [106, null], [106, null]], "Multi-Node Distributed Serving": [[94, "multi-node-distributed-serving"]], "Multi-Node Inference on SLURM": [[105, "multi-node-inference-on-slurm"]], "Multi-Node Profiling and Shared Storage Considerations": [[54, "multi-node-profiling-and-shared-storage-considerations"]], "Multi-Node Setup (2 Nodes)": [[2, "multi-node-setup-2-nodes"]], "Multi-Node Setup with Tensor Parallelism (TP=16)": [[2, "multi-node-setup-with-tensor-parallelism-tp-16"]], "Multi-Node Tensor Parallelism": [[32, "multi-node-tensor-parallelism"]], "Multi-Rank Synchronization": [[12, "multi-rank-synchronization"]], "Multi-head Latent Attention (MLA) Throughput Optimizations": [[32, "multi-head-latent-attention-mla-throughput-optimizations"]], "Multi-layer Eagle speculative decoding": [[23, "multi-layer-eagle-speculative-decoding"]], "Multi-modal Generation": [[101, "Multi-modal-Generation"]], "Multi-node Deployment": [[84, "multi-node-deployment"]], "Multi-node distributed serving": [[23, "multi-node-distributed-serving"], [88, "multi-node-distributed-serving"]], "Multi-token Prediction": [[32, "multi-token-prediction"], [33, "multi-token-prediction"]], "Multi-turn Dialog": [[101, "Multi-turn-Dialog"]], "Multimodal": [[51, "multimodal"]], "Multimodal Embedding Example": [[119, "multimodal-embedding-example"]], "Multimodal Inputs Limitation": [[127, "multimodal-inputs-limitation"]], "Multimodal Language Models": [[89, "multimodal-language-models"], [127, null]], "Multimodal Query Reranking (query with image)": [[121, "multimodal-query-reranking-query-with-image"]], "Multiple-Image Inputs": [[47, "Multiple-Image-Inputs"]], "NCCL as backend": [[21, "nccl-as-backend"]], "NIXL": [[17, "nixl"]], "NIXL Backend Selection": [[17, "nixl-backend-selection"]], "NSA Backend Configuration (For DeepSeek V3.2)": [[97, "nsa-backend-configuration-for-deepseek-v3-2"]], "NVFP4 Checkpoint": [[33, "nvfp4-checkpoint"]], "NVIDIA Jetson Orin": [[93, null]], "NVLink Transport Configuration": [[17, "nvlink-transport-configuration"]], "Native API and SGLang Runtime (SRT)": [[27, "Native-API-and-SGLang-Runtime-(SRT)"], [28, "Native-API-and-SGLang-Runtime-(SRT)"], [29, "Native-API-and-SGLang-Runtime-(SRT)"]], "Native DP Mode": [[5, "native-dp-mode"]], "Nest Asyncio": [[42, "Nest-Asyncio"]], "Ngram Speculative Decoding": [[26, "Ngram-Speculative-Decoding"]], "Ngram speculative decoding": [[23, "ngram-speculative-decoding"], [88, "ngram-speculative-decoding"]], "Non-FP8 (BF16 / full precision) mode": [[37, "non-fp8-bf16-full-precision-mode"], [50, "non-fp8-bf16-full-precision-mode"]], "Non-Streaming Request": [[22, "Non-Streaming-Request"], [29, "Non-Streaming-Request"]], "Non-streaming Asynchronous Generation": [[42, "Non-streaming-Asynchronous-Generation"]], "Non-streaming Synchronous Generation": [[42, "Non-streaming-Synchronous-Generation"]], "Normal": [[51, "normal"]], "Note on defaults": [[51, "note-on-defaults"]], "Notebook Execution (make compile)": [[0, "notebook-execution-make-compile"]], "Notes": [[24, "notes"], [38, "notes"], [53, "notes"], [74, "notes"]], "Notes for ROCm / MPS": [[69, "notes-for-rocm-mps"]], "Nsight Systems": [[74, "nsight-systems"]], "OOM (Out of Memory) Errors": [[94, "oom-out-of-memory-errors"]], "Observability": [[16, null], [24, "observability"]], "Obtain CANN Image": [[81, "obtain-cann-image"]], "Obtain Image": [[81, "obtain-image"]], "Offline Batch Inference": [[42, "Offline-Batch-Inference"]], "Offline Engine API": [[22, "Offline-Engine-API"], [27, "Offline-Engine-API"], [28, "Offline-Engine-API"], [29, "Offline-Engine-API"], [42, null]], "Offline Quantization": [[19, "offline-quantization"]], "Offline infer": [[91, "offline-infer"]], "Offline inference": [[113, "offline-inference"]], "Offloading": [[23, "offloading"], [88, "offloading"]], "Ollama-Compatible API": [[43, null]], "Online Quantization": [[19, "online-quantization"]], "Open-To-Use Refit Functionality": [[25, "open-to-use-refit-functionality"]], "OpenAI APIs - Completions": [[45, null]], "OpenAI APIs - Embedding": [[46, null]], "OpenAI APIs - Vision": [[47, null]], "OpenAI Backend Proxy": [[24, "openai-backend-proxy"]], "OpenAI Compatible API": [[22, "OpenAI-Compatible-API"], [27, "OpenAI-Compatible-API"], [28, "OpenAI-Compatible-API"], [29, "OpenAI-Compatible-API"]], "OpenAI-Compatible APIs": [[44, null]], "OpenAI-compatible API usage": [[15, "OpenAI-compatible-API-usage"]], "OpenAI-compatible request example": [[31, "openai-compatible-request-example"]], "OpenTelemetry Tracing": [[24, "opentelemetry-tracing"]], "Optimal Configuration": [[82, "optimal-configuration"]], "Optimization/debug options": [[23, "optimization-debug-options"], [88, "optimization-debug-options"]], "Optimizations": [[32, "optimizations"]], "Optimized Model List": [[90, "optimized-model-list"], [94, "optimized-model-list"], [95, "optimized-model-list"]], "Option 1. Use the default dev container automatically from VSCode": [[56, "option-1-use-the-default-dev-container-automatically-from-vscode"]], "Option 1: Run with Local Server (Recommended)": [[78, "option-1-run-with-local-server-recommended"]], "Option 2. Start up containers manually (advanced)": [[56, "option-2-start-up-containers-manually-advanced"]], "Option 2: Fetch Data Manually": [[78, "option-2-fetch-data-manually"]], "Oracle Configuration": [[24, "oracle-configuration"]], "Other Params": [[88, "other-params"]], "Other key options": [[53, "other-key-options"]], "Other options": [[51, "other-options"]], "Other tips": [[54, "other-tips"]], "Output Files": [[54, "output-files"]], "Output Location": [[74, "output-location"]], "Overall Architecture": [[12, "overall-architecture"]], "Overall Workflow": [[12, "overall-workflow"]], "Overview": [[2, "overview"], [24, "overview"], [24, "id4"], [69, "overview"], [70, "overview"], [71, "overview"], [72, "overview"], [73, "overview"], [118, "overview"]], "PD Disaggregation": [[17, null], [33, "pd-disaggregation"]], "PD Disaggregation with PP + CP": [[33, "pd-disaggregation-with-pp-cp"]], "PD Mixed Scene": [[81, "pd-mixed-scene"], [81, "id1"]], "PD Mode Discovery": [[24, "pd-mode-discovery"]], "PD Separation Scene": [[81, "pd-separation-scene"]], "PD disaggregation": [[23, "pd-disaggregation"], [88, "pd-disaggregation"]], "Parallelism": [[101, "Parallelism"]], "Parameters": [[45, "Parameters"], [45, "id3"], [72, "parameters"], [118, "parameters"]], "Parser Endpoints": [[24, "parser-endpoints"]], "Pause Generation": [[25, "pause-generation"]], "Penalizers": [[51, "penalizers"]], "Perf Baseline Generation Script": [[63, null]], "Performance": [[24, "performance"], [58, "performance"], [84, "performance"]], "Performance Benefits": [[2, "performance-benefits"]], "Performance Considerations": [[20, "performance-considerations"]], "Performance Highlights": [[26, "Performance-Highlights"]], "Performance Optimization": [[67, "performance-optimization"], [73, null], [94, "performance-optimization"], [127, "performance-optimization"]], "Performance Reporting": [[65, "performance-reporting"]], "Performance Tips": [[70, "performance-tips"]], "Performance Tuning": [[97, "performance-tuning"]], "Pipeline Parallel + Context Parallel (PP + CP)": [[33, "pipeline-parallel-context-parallel-pp-cp"]], "Pipeline Parallelism for Long Context": [[18, null]], "Platform support matrix": [[69, "platform-support-matrix"]], "Platform-Specific: MUSA (Moore Threads GPUs)": [[68, "platform-specific-musa-moore-threads-gpus"]], "Platform-Specific: ROCm (AMD GPUs)": [[68, "platform-specific-rocm-amd-gpus"]], "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)": [[48, null]], "Port a Model from vLLM to SGLang": [[115, "port-a-model-from-vllm-to-sglang"]], "Possible PyTorch bugs": [[54, "possible-pytorch-bugs"]], "Post-Training Integration": [[108, null]], "PostgreSQL Configuration": [[24, "postgresql-configuration"]], "Prefetch Policies": [[11, "prefetch-policies"]], "Prefetch from L3": [[12, "prefetch-from-l3"]], "Prefill": [[104, "prefill"]], "Prefill Server Configuration": [[17, "prefill-server-configuration"]], "Prefill-Decode Disaggregation": [[24, "prefill-decode-disaggregation"], [84, "prefill-decode-disaggregation"]], "Prefill/Decode": [[24, "prefill-decode"]], "Prepare Environment": [[80, "prepare-environment"]], "Preparing the Running Environment": [[81, "preparing-the-running-environment"]], "Prerequisites": [[24, "prerequisites"], [43, "prerequisites"], [53, "prerequisites"], [61, "prerequisites"], [62, "prerequisites"], [93, "prerequisites"], [103, "prerequisites"], [109, "prerequisites"]], "Prevent swapping out system memory": [[81, "prevent-swapping-out-system-memory"]], "Production Metrics": [[16, "production-metrics"], [109, null]], "Production Recommendations": [[24, "production-recommendations"]], "Production Request Tracing": [[110, null]], "Profile": [[56, "profile"]], "Profile Decode Workers": [[54, "profile-decode-workers"]], "Profile In PD Disaggregation Mode": [[54, "profile-in-pd-disaggregation-mode"]], "Profile Prefill Workers": [[54, "profile-prefill-workers"]], "Profile a server with HTTP API endpoints": [[54, "profile-a-server-with-http-api-endpoints"]], "Profile a server with sglang.bench_offline_throughput": [[54, "profile-a-server-with-sglang-bench-offline-throughput"]], "Profile a server with sglang.bench_serving": [[54, "profile-a-server-with-sglang-bench-serving"]], "Profile a server with sglang.profiler": [[54, "profile-a-server-with-sglang-profiler"]], "Profile with Nsight": [[54, "profile-with-nsight"]], "Profile with PyTorch Profiler": [[54, "profile-with-pytorch-profiler"]], "Profiler Trace Merger for Distributed Traces": [[54, "profiler-trace-merger-for-distributed-traces"]], "Profiling": [[73, "profiling"]], "Profiling & Benchmarking": [[97, "profiling-benchmarking"]], "Profiling Multimodal Generation": [[74, null]], "Profiling in PD Disaggregation Mode": [[17, "profiling-in-pd-disaggregation-mode"]], "Prometheus Metrics": [[24, "prometheus-metrics"]], "Prompt examples": [[31, "prompt-examples"]], "PyPI Package Release Process": [[59, null]], "PyTorch Profiler": [[74, "pytorch-profiler"]], "Python API Usage": [[19, "python-api-usage"]], "Python Bindings": [[24, "python-bindings"]], "Python Interface": [[57, "python-interface"]], "Python Package": [[24, "python-package"]], "Python Tool": [[38, "python-tool"]], "Python Version": [[81, "python-version"]], "Pythonic Tool Call Format (Llama-3.2 / Llama-3.3 / Llama-4)": [[29, "Pythonic-Tool-Call-Format-(Llama-3.2-/-Llama-3.3-/-Llama-4)"]], "Pytorch and Pytorch Framework Adaptor on Ascend": [[81, "pytorch-and-pytorch-framework-adaptor-on-ascend"]], "Quantization": [[19, null], [97, "quantization"], [116, "quantization"]], "Quantization and Export Workflow": [[19, "quantization-and-export-workflow"]], "Quantization and data type": [[23, "quantization-and-data-type"], [88, "quantization-and-data-type"]], "Quantized KV Cache": [[20, null]], "Query VLM with Offline Engine": [[30, null]], "Querying Llama 4 Vision Model": [[30, "Querying-Llama-4-Vision-Model"]], "Querying Qwen2.5-VL Model": [[30, "Querying-Qwen2.5-VL-Model"]], "Queue Overflow (429)": [[24, "queue-overflow-429"]], "Quick Demo": [[38, "quick-demo"]], "Quick Overview": [[71, "quick-overview"]], "Quick Start": [[24, "quick-start"], [43, "quick-start"], [67, "quick-start"], [71, "quick-start"], [78, "quick-start"], [119, "quick-start"]], "Quick Start For SMG": [[5, "quick-start-for-smg"]], "Quick fixes to common problems": [[76, "quick-fixes-to-common-problems"]], "Quick guidance": [[26, "Quick-guidance"]], "Quick start": [[53, "quick-start"]], "Qwen Series Models": [[82, "qwen-series-models"]], "Qwen VL": [[7, "qwen-vl"]], "Qwen3 examples": [[86, null]], "Qwen3-235B-A22B 11K-1K 10ms on A3 8 Cards Mixed Mode": [[82, "qwen3-235b-a22b-11k-1k-10ms-on-a3-8-cards-mixed-mode"]], "Qwen3-235B-A22B 2K-2K 100ms on A3 8 Cards Mixed Mode": [[82, "qwen3-235b-a22b-2k-2k-100ms-on-a3-8-cards-mixed-mode"]], "Qwen3-235B-A22B 2K-2K 50ms on A3 16 Cards Mixed Mode": [[82, "qwen3-235b-a22b-2k-2k-50ms-on-a3-16-cards-mixed-mode"]], "Qwen3-235B-A22B 2K-2K 50ms on A3 8 Cards Mixed Mode": [[82, "qwen3-235b-a22b-2k-2k-50ms-on-a3-8-cards-mixed-mode"]], "Qwen3-235B-A22B 3_5K-1_5K 50ms on A3 24 Cards Separation Mode": [[82, "qwen3-235b-a22b-3-5k-1-5k-50ms-on-a3-24-cards-separation-mode"]], "Qwen3-235B-A22B 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode": [[82, "qwen3-235b-a22b-3-5k-1-5k-50ms-on-a3-8-cards-mixed-mode"]], "Qwen3-235B-A22B-FP8 with 128K Input Token Length": [[18, "qwen3-235b-a22b-fp8-with-128k-input-token-length"]], "Qwen3-30B-A3B (MoE Model)": [[4, "qwen3-30b-a3b-moe-model"]], "Qwen3-30B-A3B 3_5K-1_5K 50ms on A3 1 Card Mixed Mode": [[82, "qwen3-30b-a3b-3-5k-1-5k-50ms-on-a3-1-card-mixed-mode"]], "Qwen3-32B 18K-4K 12ms on A3 8 Cards Mixed Mode": [[82, "qwen3-32b-18k-4k-12ms-on-a3-8-cards-mixed-mode"]], "Qwen3-32B 2K-2K 50ms on A2 8 Cards Mixed Mode": [[82, "qwen3-32b-2k-2k-50ms-on-a2-8-cards-mixed-mode"]], "Qwen3-32B 2K-2K 50ms on A3 2 Cards Mixed Mode": [[82, "qwen3-32b-2k-2k-50ms-on-a3-2-cards-mixed-mode"]], "Qwen3-32B 3_5K-1_5K 50ms on A2 8 Cards Mixed Mode": [[82, "qwen3-32b-3-5k-1-5k-50ms-on-a2-8-cards-mixed-mode"]], "Qwen3-32B 3_5K-1_5K 50ms on A3 2 Cards Mixed Mode": [[82, "qwen3-32b-3-5k-1-5k-50ms-on-a3-2-cards-mixed-mode"]], "Qwen3-32B 4K-1_5K 11ms on A2 8 Cards Mixed Mode": [[82, "qwen3-32b-4k-1-5k-11ms-on-a2-8-cards-mixed-mode"]], "Qwen3-32B 4K-1_5K 11ms on A3 4 Cards Mixed Mode": [[82, "qwen3-32b-4k-1-5k-11ms-on-a3-4-cards-mixed-mode"]], "Qwen3-32B 6K-1_5K 18ms on A2 8 Cards Mixed Mode": [[82, "qwen3-32b-6k-1-5k-18ms-on-a2-8-cards-mixed-mode"]], "Qwen3-32B 6K-1_5K 18ms on A3 4 Cards Mixed Mode": [[82, "qwen3-32b-6k-1-5k-18ms-on-a3-4-cards-mixed-mode"]], "Qwen3-8B": [[4, "qwen3-8b"]], "Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 16 Cards Mixed Mode": [[82, "qwen3-coder-480b-a35b-instruct-3-5k-1-5k-50ms-on-a3-16-cards-mixed-mode"]], "Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 24 Cards Separation Mode": [[82, "qwen3-coder-480b-a35b-instruct-3-5k-1-5k-50ms-on-a3-24-cards-separation-mode"]], "Qwen3-Coder-480B-A35B-Instruct 3_5K-1_5K 50ms on A3 8 Cards Mixed Mode": [[82, "qwen3-coder-480b-a35b-instruct-3-5k-1-5k-50ms-on-a3-8-cards-mixed-mode"]], "Qwen3-Next Usage": [[49, null]], "Qwen3-Next-80B-A3B-Instruct 3_5K-1_5K 50ms on A3 2 Cards Mixed Mode": [[82, "qwen3-next-80b-a3b-instruct-3-5k-1-5k-50ms-on-a3-2-cards-mixed-mode"]], "Qwen3-Reranker (decoder-only yes/no rerank)": [[121, "qwen3-reranker-decoder-only-yes-no-rerank"]], "Qwen3-VL Usage": [[50, null]], "Qwen3-VL-Reranker (multimodal decoder-only rerank)": [[121, "qwen3-vl-reranker-multimodal-decoder-only-rerank"]], "R-Fork": [[21, null]], "RDMA RoCE case": [[103, "rdma-roce-case"]], "Rate Limiting and Queuing": [[24, "rate-limiting-and-queuing"]], "Rate, concurrency, and streaming": [[53, "rate-concurrency-and-streaming"]], "Reasoning Content for DeepSeek R1 & V3.1": [[32, "reasoning-content-for-deepseek-r1-v3-1"]], "Reasoning Parser": [[22, null]], "Reasoning Parser Integration": [[24, "reasoning-parser-integration"]], "Recommended setup for DeepSeek": [[5, "recommended-setup-for-deepseek"]], "Redis Configuration": [[24, "redis-configuration"]], "Reference": [[5, "reference"], [19, "reference"], [67, "reference"]], "References": [[2, "references"], [26, "References"], [67, "references"], [70, "references"], [71, "references"], [72, "references"], [73, "references"], [77, null], [93, "references"], [94, "references"]], "Registering an External Model Implementation": [[115, "registering-an-external-model-implementation"]], "Regular HTTP Routing": [[24, "regular-http-routing"]], "Regular expression": [[27, "Regular-expression"], [27, "id3"], [27, "id7"], [28, "Regular-expression"], [28, "id3"], [28, "id7"]], "Related Parameters": [[12, "related-parameters"]], "Release Memory": [[25, "release-memory"]], "Reliability and Flow Control": [[24, "reliability-and-flow-control"]], "Remaining issues": [[103, "remaining-issues"]], "Remote code": [[116, "remote-code"]], "Reporting Results": [[58, "reporting-results"]], "Request": [[24, "request"]], "Request Dump and Replay": [[16, "request-dump-and-replay"]], "Request Format": [[118, "request-format"]], "Request ID Propagation": [[24, "request-id-propagation"]], "Request Parameters (Multimodal)": [[121, "request-parameters-multimodal"]], "RequestMetricsExporter configuration": [[23, "requestmetricsexporter-configuration"], [88, "requestmetricsexporter-configuration"]], "Requesting a review for merge": [[55, "requesting-a-review-for-merge"], [80, "requesting-a-review-for-merge"]], "Requirements": [[17, "requirements"], [17, "id1"], [91, "requirements"], [113, "requirements"]], "Rerank Models": [[89, "rerank-models"], [121, null]], "Response": [[24, "response"], [24, "id1"]], "Response Fields": [[24, "response-fields"], [118, "response-fields"]], "Response Format": [[118, "response-format"], [121, "response-format"]], "Responses API": [[38, "responses-api"]], "Responses API & Built-in Tools": [[38, "responses-api-built-in-tools"]], "Resume Memory": [[25, "resume-memory"]], "Retries": [[24, "retries"]], "Retrieval & Ranking": [[120, null]], "Returning Routed Experts (MoE Models)": [[45, "Returning-Routed-Experts-(MoE-Models)"], [45, "id4"]], "Reward Models": [[89, "reward-models"], [123, null]], "Reward Models (Single score)": [[118, "reward-models-single-score"]], "RoCE scenario": [[103, "roce-scenario"]], "Rotary buffer management": [[3, "rotary-buffer-management"]], "Round robin splitting (default setting)": [[33, "round-robin-splitting-default-setting"]], "Router API Key": [[24, "router-api-key"]], "Router Integration": [[17, "router-integration"]], "Run Model": [[91, "run-model"], [113, "run-model"]], "Run and add unit tests": [[55, "run-and-add-unit-tests"], [80, "run-and-add-unit-tests"]], "Running DeepSeek in PD mixed mode on 1 x Atlas 800I A3.": [[83, "running-deepseek-in-pd-mixed-mode-on-1-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation mode on 2 x Atlas 800I A3.": [[83, "running-deepseek-with-pd-disaggregation-mode-on-2-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3.": [[83, "running-deepseek-with-pd-disaggregation-on-4-x-atlas-800i-a3"]], "Running DeepSeek-V3": [[79, "running-deepseek-v3"], [83, "running-deepseek-v3"]], "Running Inference": [[93, "running-inference"]], "Running Llama3.1": [[79, "running-llama3-1"]], "Running Qwen3": [[86, "running-qwen3"]], "Running Qwen3-235B-A22B-Instruct-2507 MOE on 1 x Atlas 800I A3.": [[86, "running-qwen3-235b-a22b-instruct-2507-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-30B-A3B MOE on 1 x Atlas 800I A3.": [[86, "running-qwen3-30b-a3b-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-32B on 1 x Atlas 800I A3 with Qwen3-32B-Eagle3.": [[86, "running-qwen3-32b-on-1-x-atlas-800i-a3-with-qwen3-32b-eagle3"]], "Running Qwen3-32B on 1 x Atlas 800I A3.": [[86, "running-qwen3-32b-on-1-x-atlas-800i-a3"]], "Running Qwen3-VL-8B-Instruct on 1 x Atlas 800I A3.": [[86, "running-qwen3-vl-8b-instruct-on-1-x-atlas-800i-a3"]], "Running SGLang Service": [[81, "running-sglang-service"]], "Running Service For Large Language Models": [[81, "running-service-for-large-language-models"]], "Running Service For Multimodal Language Models": [[81, "running-service-for-multimodal-language-models"]], "Running examples on Multi-Node": [[32, "running-examples-on-multi-node"]], "Running quantization with TorchAO": [[93, "running-quantization-with-torchao"]], "Runtime Attach/Detach HiCache Storage Backend (No Restart)": [[13, null]], "Runtime Checking": [[57, "runtime-checking"]], "Runtime Configuration": [[24, "runtime-configuration"]], "Runtime options": [[23, "runtime-options"], [88, "runtime-options"]], "Rust Binary": [[24, "rust-binary"]], "SCM (Step Computation Masking)": [[70, "scm-step-computation-masking"]], "SCM disabled for low step count": [[70, "scm-disabled-for-low-step-count"]], "SGLang Diffusion": [[67, null], [77, null]], "SGLang Diffusion OpenAI API": [[62, null]], "SGLang Documentation": [[0, null], [77, null]], "SGLang Frontend Language": [[101, null]], "SGLang HiCache Best Practices": [[11, null]], "SGLang Kernels NPU": [[81, "sglang-kernels-npu"]], "SGLang Model Gateway": [[24, null]], "SGLang Native API": [[22, "SGLang-Native-API"]], "SGLang Native APIs": [[41, null]], "SGLang Performance Dashboard": [[78, null]], "SGLang Server Options": [[2, "sglang-server-options"]], "SGLang diffusion CLI Inference": [[61, null]], "SGLang for RL Systems": [[25, null]], "SGLang installation with NPUs support": [[81, null]], "SGLang\u2019s Solution": [[4, "sglang-s-solution"]], "SMG-Based DP (Recommended)": [[5, "smg-based-dp-recommended"]], "SMG\u2019s Performance": [[5, "smg-s-performance"]], "STEP 1: Write the C++ kernel": [[57, "step-1-write-the-c-kernel"]], "STEP 2: Create Python Interfaces": [[57, "step-2-create-python-interfaces"]], "STEP 3: Use your kernel": [[57, "step-3-use-your-kernel"]], "Sampling Parameters": [[51, null], [61, "sampling-parameters"]], "Sampling parameters": [[51, "id1"]], "Scaling Factors": [[20, "scaling-factors"]], "Security Best Practices": [[24, "security-best-practices"]], "Security Configurations": [[24, "security-configurations"]], "Security and Authentication": [[24, "security-and-authentication"]], "Select a backend via CLI": [[69, "select-a-backend-via-cli"]], "Selection priority": [[69, "selection-priority"]], "Self-Hosted": [[78, "self-hosted"]], "Send Results Back to Model": [[29, "Send-Results-Back-to-Model"]], "Sending Image/Video Requests": [[37, "sending-image-video-requests"], [50, "sending-image-video-requests"]], "Sending Requests": [[52, null]], "Separate Launch (HTTP)": [[24, "separate-launch-http"]], "Separate Reasoning Request": [[24, "separate-reasoning-request"]], "Serve": [[61, "serve"], [62, "serve"]], "Serve (HTTP server)": [[67, "serve-http-server"]], "Server Arguments": [[4, "server-arguments"], [23, null], [61, "server-arguments"]], "Server flag": [[25, "server-flag"]], "Service Discovery (Kubernetes)": [[24, "service-discovery-kubernetes"]], "Serving Multiple Adaptors": [[15, "Serving-Multiple-Adaptors"]], "Serving Our Model Via SGLang\u2019s Offline Engine": [[115, "serving-our-model-via-sglang-s-offline-engine"]], "Serving Single Adaptor": [[15, "Serving-Single-Adaptor"]], "Set Up Self-Hosted Runners for GitHub Actions": [[60, null]], "Setup Docker Container": [[56, "setup-docker-container"]], "Setup Guide": [[109, "setup-guide"], [110, "setup-guide"]], "Setup VSCode on a Remote Host": [[56, "setup-vscode-on-a-remote-host"]], "Single GPU inference": [[70, "single-gpu-inference"]], "Single Node Setup": [[2, "single-node-setup"]], "Single-Batch Overlap (SBO)": [[8, "single-batch-overlap-sbo"]], "Single-node Deployment": [[84, "single-node-deployment"]], "Sliding Tile Attention": [[64, "sliding-tile-attention"]], "Smart Router": [[43, "smart-router"]], "Software Requirements": [[94, "software-requirements"]], "Some communication environment issues": [[91, "some-communication-environment-issues"], [113, "some-communication-environment-issues"]], "Some dependencies of protobuf": [[91, "some-dependencies-of-protobuf"], [113, "some-dependencies-of-protobuf"]], "Special requirements": [[64, "special-requirements"]], "Specialized Models": [[122, null]], "Speculative Decoding": [[26, null], [38, "speculative-decoding"], [94, "speculative-decoding"]], "Speculative Decoding V2 (Overlap Scheduler)": [[26, "Speculative-Decoding-V2-(Overlap-Scheduler)"]], "Speculative decoding": [[23, "speculative-decoding"], [88, "speculative-decoding"]], "Speculative decoding with hybrid attention": [[1, "speculative-decoding-with-hybrid-attention"]], "Stable addresses": [[3, "stable-addresses"]], "Standalone Speculative Decoding (Small Draft Model)": [[26, "Standalone-Speculative-Decoding-(Small-Draft-Model)"]], "Standard DP for MLA models": [[5, "standard-dp-for-mla-models"]], "Standard Installation (NVIDIA GPUs)": [[68, "standard-installation-nvidia-gpus"]], "Standard Usage": [[33, "standard-usage"]], "Start server": [[91, "start-server"], [113, "start-server"]], "Start the server": [[61, "start-the-server"], [62, "start-the-server"]], "Step 1: Start a docker container.": [[60, "step-1-start-a-docker-container"]], "Step 2: Configure the runner by config.sh": [[60, "step-2-configure-the-runner-by-config-sh"]], "Step 3: Run the runner by run.sh": [[60, "step-3-run-the-runner-by-run-sh"]], "Steps to add a new attention backend": [[1, "steps-to-add-a-new-attention-backend"]], "Storage & Caching": [[97, "storage-caching"]], "Storage and Privacy": [[24, "storage-and-privacy"]], "Streaming": [[51, "streaming"], [52, "Streaming"], [52, "id1"], [101, "Streaming"]], "Streaming Asynchronous Generation": [[42, "Streaming-Asynchronous-Generation"]], "Streaming Request": [[22, "Streaming-Request"], [29, "Streaming-Request"]], "Streaming Synchronous Generation": [[42, "Streaming-Synchronous-Generation"]], "Structural Tag": [[27, "Structural-Tag"], [27, "id4"], [27, "id8"], [28, "Structural-Tag"], [28, "id4"]], "Structured Outputs": [[27, null]], "Structured Outputs (JSON, Regex, EBNF)": [[45, "Structured-Outputs-(JSON,-Regex,-EBNF)"], [51, "structured-outputs-json-regex-ebnf"]], "Structured Outputs For Reasoning Models": [[28, null]], "Structured output with XGrammar": [[93, "structured-output-with-xgrammar"]], "Summary": [[9, "summary"], [26, "Summary"], [43, "summary"]], "Support": [[91, "support"], [113, "support"]], "Support Features on Ascend NPU": [[88, null]], "Support Matrix": [[1, "support-matrix"]], "Support Models on Ascend NPU": [[89, null]], "Supported Arguments": [[61, "supported-arguments"]], "Supported Backends": [[4, "supported-backends"]], "Supported Backends and Selection Guidance": [[8, "supported-backends-and-selection-guidance"]], "Supported Configuration Parameters": [[69, "supported-configuration-parameters"]], "Supported Formats": [[20, "supported-formats"], [24, "supported-formats"]], "Supported Models": [[28, "Supported-Models"], [40, "supported-models"], [70, "supported-models"], [71, "supported-models"], [72, "supported-models"], [77, null], [91, "supported-models"], [113, "supported-models"], [117, null], [118, "supported-models"], [119, "supported-models"], [124, "supported-models"]], "Supported Models & Parsers": [[22, "Supported-Models-&-Parsers"]], "Supported Models and Configuration": [[45, "Supported-Models-and-Configuration"]], "Supported Parsers": [[24, "supported-parsers"]], "Supported TPU Hardware": [[94, "supported-tpu-hardware"]], "Supported Tool Choice Options": [[29, "Supported-Tool-Choice-Options"]], "Supported Transports": [[24, "supported-transports"]], "Supported backends and endpoints": [[53, "supported-backends-and-endpoints"]], "Supported features": [[116, "supported-features"]], "Supported models": [[123, "supported-models"], [125, "supported-models"], [127, "supported-models"]], "Supported rerank models": [[121, "supported-rerank-models"]], "Supporting New Reasoning Model Schemas": [[22, "Supporting-New-Reasoning-Model-Schemas"]], "System Configuration": [[79, "system-configuration"]], "System Design": [[12, "system-design"]], "System Requirements": [[40, "system-requirements"], [94, "system-requirements"]], "System Settings": [[81, "system-settings"]], "TLS (HTTPS) for Gateway Server": [[24, "tls-https-for-gateway-server"]], "TLS Configuration": [[24, "tls-configuration"]], "TODO": [[103, "todo"]], "TPU": [[94, null]], "TPU-Specific Optimizations": [[94, "tpu-specific-optimizations"]], "Table of Contents": [[24, "table-of-contents"]], "Target Models": [[5, "target-models"]], "Targeted Stage Profiling": [[74, "targeted-stage-profiling"]], "TaylorSeer Configuration": [[70, "taylorseer-configuration"]], "TeaCache": [[71, "teacache"], [73, "teacache"]], "TeaCache Acceleration": [[72, null]], "Tensor Checking": [[57, "tensor-checking"]], "Test the accuracy": [[55, "test-the-accuracy"], [80, "test-the-accuracy"]], "Testing": [[24, "testing"], [118, "testing"]], "Testing & Debugging (Internal/CI)": [[97, "testing-debugging-internal-ci"]], "Testing Deployment": [[40, "testing-deployment"]], "Testing and Debugging": [[115, "testing-and-debugging"]], "Testing on TPU": [[94, "testing-on-tpu"]], "Text Generation": [[126, null]], "Text-Only Reranking (backward compatible)": [[121, "text-only-reranking-backward-compatible"]], "The Problem with Tensor Parallelism for MLA Models": [[5, "the-problem-with-tensor-parallelism-for-mla-models"]], "The Root Cause of Non-Determinism": [[4, "the-root-cause-of-non-determinism"]], "The results are not deterministic, even with a temperature of 0": [[98, "the-results-are-not-deterministic-even-with-a-temperature-of-0"]], "The server hangs": [[98, "the-server-hangs"]], "Thinking Budget for DeepSeek R1": [[32, "thinking-budget-for-deepseek-r1"]], "Thinking Budget for GLM-4.5 / GLM-4.6": [[36, "thinking-budget-for-glm-4-5-glm-4-6"]], "Thinking Budget for GLM-4.5V / GLM-4.6V": [[37, "thinking-budget-for-glm-4-5v-glm-4-6v"]], "Throughput Optimization": [[94, "throughput-optimization"]], "Throughput Testing": [[94, "throughput-testing"]], "Tips for newcomers": [[55, "tips-for-newcomers"], [80, "tips-for-newcomers"]], "Token Length Normalized": [[99, "token-length-normalized"]], "Tokenization Endpoints": [[24, "tokenization-endpoints"]], "Tokenize Request": [[24, "tokenize-request"]], "Tokenize Response": [[24, "tokenize-response"]], "Tokenize/Detokenize Example (Round Trip)": [[41, "Tokenize/Detokenize-Example-(Round-Trip)"]], "Tokenizer Caching": [[24, "tokenizer-caching"]], "Tokenizer Loading Failures": [[24, "tokenizer-loading-failures"]], "Tokenizer Management": [[24, "tokenizer-management"]], "Tokenizer Sources": [[24, "tokenizer-sources"]], "Tool & Reasoning Parser": [[38, "tool-reasoning-parser"]], "Tool Call Parsing": [[24, "tool-call-parsing"]], "Tool Choice Mode": [[29, "Tool-Choice-Mode"]], "Tool Parser": [[29, null]], "Top-level fields": [[9, "top-level-fields"]], "TransferEngine as backend": [[21, "transferengine-as-backend"]], "Transformers fallback in SGLang": [[116, null]], "Triton on Ascend": [[81, "triton-on-ascend"]], "Troubleshooting": [[2, "troubleshooting"], [24, "troubleshooting"], [53, "troubleshooting"], [70, "troubleshooting"], [78, "troubleshooting"], [91, "troubleshooting"], [94, "troubleshooting"], [98, "troubleshooting"], [109, "troubleshooting"], [113, "troubleshooting"]], "Troubleshooting and Frequently Asked Questions": [[98, null]], "Try other options": [[14, "try-other-options"]], "Tune --cuda-graph-max-bs": [[14, "tune-cuda-graph-max-bs"]], "Tune --dp-size and --tp-size": [[14, "tune-dp-size-and-tp-size"]], "Tune --mem-fraction-static to increase KV cache pool capacity": [[14, "tune-mem-fraction-static-to-increase-kv-cache-pool-capacity"]], "Tuning the Chunked Prefill Size": [[18, "tuning-the-chunked-prefill-size"]], "Two-Batch Overlap (TBO)": [[8, "two-batch-overlap-tbo"]], "Unconditional Likelihood Normalized": [[99, "unconditional-likelihood-normalized"]], "Understanding the Three Input Formats": [[30, "Understanding-the-Three-Input-Formats"]], "Unified Interfaces and Rich L3 Storage Backends": [[12, "unified-interfaces-and-rich-l3-storage-backends"]], "Update Documentation": [[0, "update-documentation"]], "Update GRUB Settings": [[79, "update-grub-settings"]], "Update Weights From Disk": [[41, "Update-Weights-From-Disk"]], "Update Weights from Disk": [[25, "update-weights-from-disk"]], "Update Weights from Distributed Group": [[25, "update-weights-from-distributed-group"]], "Update Weights from Tensor": [[25, "update-weights-from-tensor"]], "Update the version in code": [[59, "update-the-version-in-code"]], "Upload the PyPI package": [[59, "upload-the-pypi-package"]], "Usage": [[4, "usage"], [7, "usage"], [15, "Usage"], [17, "usage"], [17, "id2"], [17, "id6"], [20, "usage"], [21, "usage"], [22, "Usage"], [24, "usage"], [24, "id2"], [24, "id6"], [28, "Usage"], [45, "Usage"], [45, "id2"], [63, "usage"], [67, "usage"], [69, "usage"], [109, "usage"]], "Usage Examples": [[2, "usage-examples"]], "Usage Notes": [[127, "usage-notes"]], "Use Models From ModelScope": [[114, null]], "User Guide": [[1, "user-guide"]], "Using --enable-layerwise-nvtx-marker with Nsight Systems and /start_profile": [[54, "using-enable-layerwise-nvtx-marker-with-nsight-systems-and-start-profile"]], "Using /end_profile endpoint": [[54, "using-end-profile-endpoint"]], "Using /start_profile endpoint": [[54, "using-start-profile-endpoint"]], "Using AISBench": [[84, "using-aisbench"], [84, "id1"]], "Using Configuration Files": [[61, "using-configuration-files"]], "Using GPTQModel": [[19, "using-gptqmodel"]], "Using Input IDs": [[46, "Using-Input-IDs"]], "Using LLM Compressor": [[19, "using-llm-compressor"]], "Using Language Model Evaluation Harness": [[84, "using-language-model-evaluation-harness"]], "Using LoRA Adapters": [[45, "Using-LoRA-Adapters"]], "Using NVIDIA ModelOpt": [[19, "using-nvidia-modelopt"]], "Using Native Generation APIs": [[52, "Using-Native-Generation-APIs"]], "Using OpenAI Python Client": [[46, "Using-OpenAI-Python-Client"], [47, "Using-OpenAI-Python-Client"], [52, "Using-OpenAI-Python-Client"]], "Using Pre-Quantized Checkpoints": [[19, "using-pre-quantized-checkpoints"]], "Using Python": [[118, "using-python"]], "Using Python Requests": [[46, "Using-Python-Requests"], [47, "Using-Python-Requests"], [52, "Using-Python-Requests"]], "Using Sliding Tile Attention (STA)": [[69, "using-sliding-tile-attention-sta"]], "Using Unsloth": [[19, "using-unsloth"]], "Using auto-round": [[19, "using-auto-round"]], "Using cURL": [[46, "Using-cURL"], [47, "Using-cURL"], [52, "Using-cURL"]], "Using curl": [[118, "using-curl"]], "Using vLLM Benchmark": [[84, "using-vllm-benchmark"]], "VLMs": [[58, "vlms"]], "Verification": [[4, "verification"]], "Verified LoRA Examples": [[64, "verified-lora-examples"]], "Verified LoRAs by Base Model": [[64, "verified-loras-by-base-model"]], "Verifying Traffic Distribution": [[5, "verifying-traffic-distribution"]], "Video Generation": [[62, "video-generation"]], "Video Generation Models": [[64, "video-generation-models"]], "Video Input Support": [[127, "video-input-support"]], "Video Input:": [[37, "video-input"], [50, "video-input"]], "View Traces": [[74, "view-traces"]], "View traces": [[54, "view-traces"]], "WASM Middleware": [[24, "wasm-middleware"]], "Warmup Step": [[79, "warmup-step"]], "Web Rendering (make html)": [[0, "web-rendering-make-html"]], "Web Search Tool": [[38, "web-search-tool"]], "What it does": [[53, "what-it-does"]], "When to Use Each": [[5, "when-to-use-each"]], "Why Deterministic Inference Matters": [[4, "why-deterministic-inference-matters"]], "Why Dynamic Chunking": [[18, "why-dynamic-chunking"]], "Why HiCache Matters": [[11, "why-hicache-matters"]], "Why Pipeline Parallelism?": [[18, "why-pipeline-parallelism"]], "Why SGLang for RL Lifecycle?": [[25, "why-sglang-for-rl-lifecycle"]], "Why and What is EPD Disaggregation?": [[7, "why-and-what-is-epd-disaggregation"]], "Why and What is HiCache?": [[12, "why-and-what-is-hicache"]], "Why and What is PD Disaggregation?": [[17, "why-and-what-is-pd-disaggregation"]], "Worker API Keys": [[24, "worker-api-keys"]], "Worker Management APIs": [[24, "worker-management-apis"]], "Workers Never Ready": [[24, "workers-never-ready"]], "Workload Balancer": [[8, "workload-balancer"]], "Write documentations": [[55, "write-documentations"], [80, "write-documentations"]], "Writing a hook factory": [[9, "writing-a-hook-factory"]], "XPU": [[95, null]], "config (optional)": [[9, "config-optional"]], "gRPC Connection Issues": [[24, "grpc-connection-issues"]], "gRPC Launch": [[24, "grpc-launch"]], "gRPC Routing": [[24, "grpc-routing"]], "hook_factory (required)": [[9, "hook-factory-required"]], "mTLS for Worker Communication": [[24, "mtls-for-worker-communication"]], "name (optional)": [[9, "name-optional"]], "quark_int4fp8_moe online quantization method": [[19, "quark-int4fp8-moe-online-quantization-method"]], "target_modules (required)": [[9, "target-modules-required"]], "test gsm8k": [[83, "test-gsm8k"]], "torchao online quantization method": [[19, "torchao-online-quantization-method"]], "v1/rerank (cross encoder rerank model)": [[41, "v1/rerank-(cross-encoder-rerank-model)"]], "v1/score (decoder-only scoring)": [[41, "v1/score-(decoder-only-scoring)"]]}, "docnames": ["README", "advanced_features/attention_backend", "advanced_features/checkpoint_engine", "advanced_features/cuda_graph_for_multi_modal_encoder", "advanced_features/deterministic_inference", "advanced_features/dp_dpa_smg_guide", "advanced_features/dp_for_multi_modal_encoder", "advanced_features/epd_disaggregation", "advanced_features/expert_parallelism", "advanced_features/forward_hooks", "advanced_features/hicache", "advanced_features/hicache_best_practices", "advanced_features/hicache_design", "advanced_features/hicache_storage_runtime_attach_detach", "advanced_features/hyperparameter_tuning", "advanced_features/lora", "advanced_features/observability", "advanced_features/pd_disaggregation", "advanced_features/pipeline_parallelism", "advanced_features/quantization", "advanced_features/quantized_kv_cache", "advanced_features/rfork", "advanced_features/separate_reasoning", "advanced_features/server_arguments", "advanced_features/sgl_model_gateway", "advanced_features/sglang_for_rl", "advanced_features/speculative_decoding", "advanced_features/structured_outputs", "advanced_features/structured_outputs_for_reasoning_models", "advanced_features/tool_parser", "advanced_features/vlm_query", "basic_usage/deepseek_ocr", "basic_usage/deepseek_v3", "basic_usage/deepseek_v32", "basic_usage/diffusion", "basic_usage/diffusion_llms", "basic_usage/glm45", "basic_usage/glmv", "basic_usage/gpt_oss", "basic_usage/llama4", "basic_usage/minimax_m2", "basic_usage/native_api", "basic_usage/offline_engine_api", "basic_usage/ollama_api", "basic_usage/openai_api", "basic_usage/openai_api_completions", "basic_usage/openai_api_embeddings", "basic_usage/openai_api_vision", "basic_usage/popular_model_usage", "basic_usage/qwen3", "basic_usage/qwen3_vl", "basic_usage/sampling_params", "basic_usage/send_request", "developer_guide/bench_serving", "developer_guide/benchmark_and_profiling", "developer_guide/contribution_guide", "developer_guide/development_guide_using_docker", "developer_guide/development_jit_kernel_guide", "developer_guide/evaluating_new_models", "developer_guide/release_process", "developer_guide/setup_github_runner", "diffusion/api/cli", "diffusion/api/openai_api", "diffusion/ci_perf", "diffusion/compatibility_matrix", "diffusion/contributing", "diffusion/environment_variables", "diffusion/index", "diffusion/installation", "diffusion/performance/attention_backends", "diffusion/performance/cache/cache_dit", "diffusion/performance/cache/index", "diffusion/performance/cache/teacache", "diffusion/performance/index", "diffusion/performance/profiling", "diffusion/support_new_models", "get_started/install", "index", "performance_dashboard/README", "platforms/amd_gpu", "platforms/ascend_contribution_guide", "platforms/ascend_npu", "platforms/ascend_npu_best_practice", "platforms/ascend_npu_deepseek_example", "platforms/ascend_npu_glm5_examples", "platforms/ascend_npu_quantization", "platforms/ascend_npu_qwen3_examples", "platforms/ascend_npu_support", "platforms/ascend_npu_support_features", "platforms/ascend_npu_support_models", "platforms/cpu_server", "platforms/mindspore_backend", "platforms/mthreads_gpu", "platforms/nvidia_jetson", "platforms/tpu", "platforms/xpu", "references/custom_chat_template", "references/environment_variables", "references/faq", "references/frontend/choices_methods", "references/frontend/frontend_index", "references/frontend/frontend_tutorial", "references/learn_more", "references/multi_node_deployment/deploy_on_k8s", "references/multi_node_deployment/lws_pd/lws_pd_deploy", "references/multi_node_deployment/multi_node", "references/multi_node_deployment/multi_node_index", "references/multi_node_deployment/rbg_pd/deepseekv32_pd", "references/post_training_integration", "references/production_metrics", "references/production_request_trace", "references/torch_compile_cache", "supported_models/extending/index", "supported_models/extending/mindspore_models", "supported_models/extending/modelscope", "supported_models/extending/support_new_models", "supported_models/extending/transformers_fallback", "supported_models/index", "supported_models/retrieval_ranking/classify_models", "supported_models/retrieval_ranking/embedding_models", "supported_models/retrieval_ranking/index", "supported_models/retrieval_ranking/rerank_models", "supported_models/specialized/index", "supported_models/specialized/reward_models", "supported_models/text_generation/diffusion_language_models", "supported_models/text_generation/generative_models", "supported_models/text_generation/index", "supported_models/text_generation/multimodal_language_models"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["README.md", "advanced_features/attention_backend.md", "advanced_features/checkpoint_engine.md", "advanced_features/cuda_graph_for_multi_modal_encoder.md", "advanced_features/deterministic_inference.md", "advanced_features/dp_dpa_smg_guide.md", "advanced_features/dp_for_multi_modal_encoder.md", "advanced_features/epd_disaggregation.md", "advanced_features/expert_parallelism.md", "advanced_features/forward_hooks.md", "advanced_features/hicache.rst", "advanced_features/hicache_best_practices.md", "advanced_features/hicache_design.md", "advanced_features/hicache_storage_runtime_attach_detach.md", "advanced_features/hyperparameter_tuning.md", "advanced_features/lora.ipynb", "advanced_features/observability.md", "advanced_features/pd_disaggregation.md", "advanced_features/pipeline_parallelism.md", "advanced_features/quantization.md", "advanced_features/quantized_kv_cache.md", "advanced_features/rfork.md", "advanced_features/separate_reasoning.ipynb", "advanced_features/server_arguments.md", "advanced_features/sgl_model_gateway.md", "advanced_features/sglang_for_rl.md", "advanced_features/speculative_decoding.ipynb", "advanced_features/structured_outputs.ipynb", "advanced_features/structured_outputs_for_reasoning_models.ipynb", "advanced_features/tool_parser.ipynb", "advanced_features/vlm_query.ipynb", "basic_usage/deepseek_ocr.md", "basic_usage/deepseek_v3.md", "basic_usage/deepseek_v32.md", "basic_usage/diffusion.md", "basic_usage/diffusion_llms.md", "basic_usage/glm45.md", "basic_usage/glmv.md", "basic_usage/gpt_oss.md", "basic_usage/llama4.md", "basic_usage/minimax_m2.md", "basic_usage/native_api.ipynb", "basic_usage/offline_engine_api.ipynb", "basic_usage/ollama_api.md", "basic_usage/openai_api.rst", "basic_usage/openai_api_completions.ipynb", "basic_usage/openai_api_embeddings.ipynb", "basic_usage/openai_api_vision.ipynb", "basic_usage/popular_model_usage.rst", "basic_usage/qwen3.md", "basic_usage/qwen3_vl.md", "basic_usage/sampling_params.md", "basic_usage/send_request.ipynb", "developer_guide/bench_serving.md", "developer_guide/benchmark_and_profiling.md", "developer_guide/contribution_guide.md", "developer_guide/development_guide_using_docker.md", "developer_guide/development_jit_kernel_guide.md", "developer_guide/evaluating_new_models.md", "developer_guide/release_process.md", "developer_guide/setup_github_runner.md", "diffusion/api/cli.md", "diffusion/api/openai_api.md", "diffusion/ci_perf.md", "diffusion/compatibility_matrix.md", "diffusion/contributing.md", "diffusion/environment_variables.md", "diffusion/index.md", "diffusion/installation.md", "diffusion/performance/attention_backends.md", "diffusion/performance/cache/cache_dit.md", "diffusion/performance/cache/index.md", "diffusion/performance/cache/teacache.md", "diffusion/performance/index.md", "diffusion/performance/profiling.md", "diffusion/support_new_models.md", "get_started/install.md", "index.rst", "performance_dashboard/README.md", "platforms/amd_gpu.md", "platforms/ascend_contribution_guide.md", "platforms/ascend_npu.md", "platforms/ascend_npu_best_practice.md", "platforms/ascend_npu_deepseek_example.md", "platforms/ascend_npu_glm5_examples.md", "platforms/ascend_npu_quantization.md", "platforms/ascend_npu_qwen3_examples.md", "platforms/ascend_npu_support.rst", "platforms/ascend_npu_support_features.md", "platforms/ascend_npu_support_models.md", "platforms/cpu_server.md", "platforms/mindspore_backend.md", "platforms/mthreads_gpu.md", "platforms/nvidia_jetson.md", "platforms/tpu.md", "platforms/xpu.md", "references/custom_chat_template.md", "references/environment_variables.md", "references/faq.md", "references/frontend/choices_methods.md", "references/frontend/frontend_index.rst", "references/frontend/frontend_tutorial.ipynb", "references/learn_more.md", "references/multi_node_deployment/deploy_on_k8s.md", "references/multi_node_deployment/lws_pd/lws_pd_deploy.md", "references/multi_node_deployment/multi_node.md", "references/multi_node_deployment/multi_node_index.rst", "references/multi_node_deployment/rbg_pd/deepseekv32_pd.md", "references/post_training_integration.md", "references/production_metrics.md", "references/production_request_trace.md", "references/torch_compile_cache.md", "supported_models/extending/index.rst", "supported_models/extending/mindspore_models.md", "supported_models/extending/modelscope.md", "supported_models/extending/support_new_models.md", "supported_models/extending/transformers_fallback.md", "supported_models/index.rst", "supported_models/retrieval_ranking/classify_models.md", "supported_models/retrieval_ranking/embedding_models.md", "supported_models/retrieval_ranking/index.rst", "supported_models/retrieval_ranking/rerank_models.md", "supported_models/specialized/index.rst", "supported_models/specialized/reward_models.md", "supported_models/text_generation/diffusion_language_models.md", "supported_models/text_generation/generative_models.md", "supported_models/text_generation/index.rst", "supported_models/text_generation/multimodal_language_models.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [3, 7, 8, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 38, 39, 40, 41, 42, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 58, 61, 62, 70, 74, 75, 76, 79, 80, 81, 85, 93, 97, 99, 101, 103, 108, 109, 110, 116, 118, 119, 121, 124, 125, 127], "0": [0, 2, 5, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 66, 69, 70, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 93, 94, 95, 97, 101, 103, 105, 109, 110, 113, 114, 115, 116, 118, 119, 121, 123, 124, 125, 127], "00": [15, 22, 26, 27, 28, 29, 30, 33, 41, 42, 45, 46, 47, 52, 78, 101, 103, 105, 121], "000": [28, 33, 55, 77, 80], "0000": [14, 103], "00001": 19, "00002962350845336914": 46, "00004738569259643555": 46, "00005257129669189453": 46, "00006532669067382812": 46, "00008237361907958984": 46, "0000928044319152832": 46, "0000998377799987793": 46, "0001": 103, "00010514259338378906": 46, "0001322031021118164": 46, "00013875961303710938": 46, "00014603137969970703": 46, "0001493692398071289": 46, "0001697540283203125": 46, "00017774105072021484": 46, "00018644332885742188": 46, "0001951456069946289": 46, "0002": 26, "0002028942108154297": 46, "0002053976058959961": 46, "00021159648895263672": 46, "00021409988403320312": 46, "00023102760314941406": [41, 46], "0002351999282836914": 46, "00025582313537597656": 46, "0002701282501220703": 46, "00027441978454589844": 46, "00029540061950683594": 46, "00031065940856933594": 46, "00032067298889160156": 46, "0003418922424316406": 46, "0003495216369628906": 46, "00035071372985839844": 46, "0003693103790283203": 46, "0003848075866699219": 46, "00039005279541015625": 46, "0003972053527832031": 46, "0004031658172607422": 46, "00040984153747558594": 46, "0004382133483886719": 46, "0004413127899169922": 46, "00044417381286621094": 46, "0004513263702392578": 46, "0004620552062988281": 46, "0005130767822265625": 46, "0005335807800292969": 46, "0005621910095214844": 46, "0005698204040527344": 46, "0005784034729003906": 46, "0006489753723144531": 46, "0006608963012695312": 46, "0006771087646484375": 46, "0006952285766601562": 46, "0007076263427734375": 46, "0007262229919433594": 46, "000728607177734375": 46, "0007519721984863281": 46, "0007572174072265625": 46, "0007658004760742188": 46, "0007991790771484375": 46, "0008139610290527344": 46, "0008296966552734375": 46, "0008397102355957031": 46, "0008406639099121094": 46, "0008764266967773438": 46, "0009050369262695312": 46, "0009250640869140625": 46, "0009288787841796875": 46, "0009407997131347656": 46, "0009546279907226562": 46, "0009584426879882812": 46, "0009703636169433594": 46, "000988006591796875": 46, "0009918212890625": 46, "001": [104, 107, 109], "0010013580322265625": 46, "0010061264038085938": 46, "0010251998901367188": 46, "0010318756103515625": 46, "0010385513305664062": 46, "0010423660278320312": 46, "001056671142578125": 46, "0010623931884765625": 46, "0010852813720703125": 46, "0010995864868164062": 46, "0011196136474609375": 46, "0011234283447265625": 46, "0011415481567382812": 46, "0011529922485351562": 46, "0011587142944335938": 46, "001186370849609375": 46, "0011911392211914062": 46, "0011949539184570312": 46, "00119781494140625": 46, "0012035369873046875": 46, "00121307373046875": 46, "0012311935424804688": 46, "0012607574462890625": 46, "0012693405151367188": 46, "0012760162353515625": 46, "0012845993041992188": 46, "0012979507446289062": 46, "0013246536254882812": 46, "001338958740234375": 46, "0013513565063476562": 46, "001354217529296875": 46, "0013570785522460938": 46, "0013742446899414062": 46, "001377105712890625": 46, "0013799667358398438": 46, "0013914108276367188": 46, "0014181137084960938": 46, "001422882080078125": 46, "0014295578002929688": 46, "0014467239379882812": 46, "0014743804931640625": 46, "0014867782592773438": 46, "0014982223510742188": 46, "0015039443969726562": 46, "0015106201171875": 46, "001552581787109375": 46, "0015573501586914062": 46, "0015630722045898438": 46, "0015840530395507812": 46, "00159454345703125": 46, "0016031265258789062": 46, "0016222000122070312": 46, "0016231536865234375": 46, "0016326904296875": 46, "0016994476318359375": 46, "0017156600952148438": 46, "0017194747924804688": 46, "001720428466796875": 46, "0017271041870117188": 46, "0017423629760742188": 46, "0017652511596679688": 46, "0017824172973632812": 46, "00179290771484375": 46, "001811981201171875": 46, "0018157958984375": 46, "0018186569213867188": 46, "0018243789672851562": 46, "0018367767333984375": 46, "0018520355224609375": 46, "0018749237060546875": 46, "0018901824951171875": 46, "0019025802612304688": 46, "0019130706787109375": 46, "0019359588623046875": 46, "0019464492797851562": 46, "001983642578125": 46, "0019989013671875": 46, "002": [15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "00201416015625": 46, "002033233642578125": 46, "0020389556884765625": 46, "0020427703857421875": 46, "002044677734375": 46, "0020751953125": 46, "0020847320556640625": 46, "0021038055419921875": 46, "0021190643310546875": 46, "002124786376953125": 46, "00214385986328125": 46, "0021457672119140625": 46, "00217437744140625": 46, "002193450927734375": 46, "0021953582763671875": 46, "0022068023681640625": 46, "0022106170654296875": 46, "0022411346435546875": 46, "0022487640380859375": 46, "0022735595703125": 46, "002288818359375": 46, "0023021697998046875": 46, "0023040771484375": 46, "002338409423828125": 46, "002349853515625": 46, "0023708343505859375": 46, "0023746490478515625": 46, "00238800048828125": 46, "0024089813232421875": 46, "002460479736328125": 46, "0024623870849609375": 46, "0024738311767578125": 46, "002513885498046875": 46, "0025234222412109375": 46, "0025348663330078125": 46, "0025424957275390625": 46, "0025730133056640625": 46, "0025844573974609375": 46, "0025882720947265625": 46, "00261688232421875": 46, "0026378631591796875": 46, "0026416778564453125": 46, "00264739990234375": 46, "0026607513427734375": 46, "00270843505859375": 46, "002750396728515625": 46, "002765655517578125": 46, "00276947021484375": 46, "0027828216552734375": 46, "0027980804443359375": 46, "002826690673828125": 46, "002838134765625": 46, "0028438568115234375": 46, "002849578857421875": 46, "0028591156005859375": 46, "002864837646484375": 46, "00286865234375": 46, "002918243408203125": 46, "0029296875": 46, "0029582977294921875": 46, "0029697418212890625": 46, "00298309326171875": 46, "0029964447021484375": 46, "0030002593994140625": 46, "00301361083984375": 46, "0030498504638671875": 46, "0030574798583984375": 46, "0030612945556640625": 46, "003070831298828125": 46, "00307464599609375": 46, "0030803680419921875": 46, "003086090087890625": 46, "00308990478515625": 46, "0030918121337890625": 46, "003139495849609375": 46, "0031452178955078125": 46, "0031528472900390625": 46, "003154754638671875": 46, "0031948089599609375": 46, "003215789794921875": 46, "00322723388671875": 46, "0032444000244140625": 46, "0032711029052734375": [41, 46], "00328826904296875": 46, "003307342529296875": 46, "0033359527587890625": 46, "0033473968505859375": 46, "003353118896484375": 46, "0033552646636963": 28, "00336456298828125": 46, "0033740997314453125": 46, "0033931732177734375": 46, "0034122467041015625": 46, "00342559814453125": 46, "0034503936767578125": 46, "0034637451171875": 46, "00347137451171875": 46, "003475189208984375": 46, "00350189208984375": 46, "0035037994384765625": 46, "003520965576171875": 46, "003574371337890625": 46, "003582000732421875": 46, "0036029815673828125": 46, "0036106109619140625": 46, "003631591796875": 46, "0036411285400390625": 46, "0036945343017578125": 46, "003711700439453125": 46, "0037212371826171875": 46, "0037288665771484375": 46, "0037326812744140625": 46, "003742218017578125": 46, "003753662109375": 46, "0037593841552734375": 46, "0037841796875": 46, "0037975311279296875": 46, "0038051605224609375": 46, "0038089752197265625": 46, "00382232666015625": 46, "003833770751953125": 46, "003917694091796875": 46, "00394439697265625": 46, "003948211669921875": 46, "003963470458984375": 46, "003971099853515625": 46, "003978729248046875": 46, "0039825439453125": 46, "003986358642578125": 46, "003993988037109375": 46, "00400543212890625": 46, "004016876220703125": 46, "004024505615234375": 46, "0040435791015625": 46, "00405120849609375": 46, "0040740966796875": 46, "004100799560546875": 46, "004123687744140625": 46, "004150390625": 46, "00415802001953125": 46, "004161834716796875": 46, "00417327880859375": 46, "004184722900390625": 46, "0041961669921875": 46, "004207611083984375": 46, "00424957275390625": 46, "004276275634765625": 46, "004283905029296875": 46, "0042877197265625": 46, "004390716552734375": 46, "00440216064453125": 46, "004413604736328125": 46, "004497528076171875": 46, "004512786865234375": 46, "0045318603515625": 46, "0045623779296875": 46, "00457000732421875": 46, "0045928955078125": 46, "00463104248046875": 46, "004642486572265625": 46, "00466156005859375": 46, "004665374755859375": 46, "004680633544921875": 46, "004688262939453125": 46, "00469207763671875": 46, "004695892333984375": 46, "00469970703125": 46, "0047149658203125": 46, "004726409912109375": 46, "0047607421875": 46, "004810333251953125": 46, "0048370361328125": 46, "00484466552734375": 46, "00487518310546875": 46, "004878997802734375": 46, "00493621826171875": 46, "0049591064453125": 46, "00496673583984375": 46, "004970550537109375": 46, "004974365234375": 46, "004985809326171875": 46, "005": 109, "0050048828125": 46, "005008697509765625": 46, "005023956298828125": 46, "005035400390625": 46, "005039215087890625": 46, "0050811767578125": 46, "005096435546875": 46, "005107879638671875": 46, "00513458251953125": 46, "005161285400390625": 46, "00521087646484375": 46, "005222320556640625": 46, "005237579345703125": 46, "00524139404296875": 46, "00525665283203125": 46, "005260467529296875": 46, "00527191162109375": 46, "00531005859375": 46, "005397796630859375": 46, "005405426025390625": 46, "00540924072265625": 46, "0054168701171875": 46, "00543975830078125": 46, "0054473876953125": 46, "00545501708984375": 46, "0054779052734375": 46, "00551605224609375": 46, "005519866943359375": 46, "005527496337890625": 46, "0055389404296875": 46, "005588531494140625": 46, "0055999755859375": 46, "00560760498046875": 46, "005626678466796875": 46, "005634307861328125": 46, "005657196044921875": 46, "00566864013671875": 46, "00569915771484375": 46, "0057220458984375": 46, "005725860595703125": 46, "005767822265625": 46, "0057830810546875": 46, "005794525146484375": 46, "00579833984375": 46, "00580596923828125": 46, "00583648681640625": 46, "005840301513671875": 46, "005847930908203125": 46, "005855560302734375": 46, "005859375": 46, "005878448486328125": 46, "005886077880859375": 46, "005893707275390625": 46, "0059051513671875": [41, 46], "00594329833984375": 46, "005962371826171875": 46, "005970001220703125": 46, "005992889404296875": 46, "00600433349609375": 46, "0060272216796875": 46, "00604248046875": 46, "00605010986328125": 46, "0060577392578125": 46, "006076812744140625": 46, "00611114501953125": 46, "006134033203125": 46, "006137847900390625": 46, "006145477294921875": 46, "0061492919921875": 46, "006160736083984375": 46, "00616455078125": 46, "006168365478515625": 46, "006175994873046875": 46, "00620269775390625": 46, "0062255859375": 46, "006229400634765625": 46, "0062408447265625": 46, "006256103515625": 46, "006259918212890625": 46, "006275177001953125": 46, "0063323974609375": 46, "00637054443359375": 46, "006374359130859375": 46, "00640106201171875": 46, "006420135498046875": 46, "006435394287109375": 46, "006450653076171875": 46, "0064544677734375": 46, "006465911865234375": 46, "006504058837890625": 46, "0065155029296875": 46, "006534576416015625": 46, "006542205810546875": 46, "0065765380859375": 46, "006580352783203125": 46, "00658416748046875": 46, "006587982177734375": 46, "006595611572265625": 46, "006618499755859375": 46, "006626129150390625": 46, "006633758544921875": 46, "006664276123046875": 46, "006687164306640625": 46, "00669097900390625": 46, "0066986083984375": 46, "006710052490234375": 46, "006717681884765625": 46, "00673675537109375": 46, "006755828857421875": 46, "00676727294921875": 46, "00679779052734375": 46, "006816864013671875": 46, "006908416748046875": 46, "006916046142578125": 46, "006923675537109375": 46, "006969451904296875": 46, "00698089599609375": 46, "006999969482421875": 46, "007007598876953125": 46, "007022857666015625": 46, "0070343017578125": 46, "00704193115234375": 46, "007106781005859375": 46, "007110595703125": 46, "007137298583984375": 46, "00717926025390625": 46, "007228851318359375": 46, "0072479248046875": 46, "00725555419921875": 46, "007289886474609375": 46, "007305145263671875": 46, "0073089599609375": 46, "00731658935546875": 46, "00733184814453125": 46, "00734710693359375": 46, "007373809814453125": 46, "00739288330078125": 46, "0074005126953125": 46, "00740814208984375": 46, "0074310302734375": 46, "007457733154296875": 46, "007465362548828125": 46, "00748443603515625": 46, "0074920654296875": 46, "00749969482421875": 46, "007507552643049313": 109, "007518768310546875": 46, "007534027099609375": 46, "0075531005859375": 46, "00759124755859375": 46, "00763702392578125": 46, "007678985595703125": 46, "007709503173828125": 46, "007720947265625": 46, "0077362060546875": 46, "00775146484375": 46, "007755279541015625": 46, "007778167724609375": 46, "007793426513671875": 46, "0077972412109375": 46, "00782012939453125": 46, "0078277587890625": 46, "00783538818359375": 46, "007843017578125": 46, "0078582763671875": 46, "007904052734375": 46, "0079193115234375": 46, "00794219970703125": 46, "007965087890625": 46, "00799560546875": 46, "00803375244140625": 46, "00807952880859375": 46, "00809478759765625": 46, "00811767578125": 46, "0081329345703125": 46, "0081634521484375": 46, "0081787109375": 46, "00820159912109375": 46, "00821685791015625": 46, "00824737548828125": 46, "0082550048828125": 46, "00826263427734375": 46, "0082855224609375": 46, "00829315185546875": 46, "00833892822265625": 46, "0083465576171875": 46, "00835418701171875": 46, "00836944580078125": 46, "0083770751953125": 46, "00838470458984375": 46, "0084228515625": 46, "00843048095703125": 46, "0084381103515625": 46, "00844573974609375": 46, "008453369140625": 46, "00847625732421875": 46, "008514404296875": 46, "0085296630859375": 46, "008544921875": 46, "00855255126953125": 46, "0085601806640625": 46, "00856781005859375": 46, "008575439453125": 46, "00860595703125": 46, "0086212158203125": 46, "0086669921875": 46, "0086822509765625": 46, "00868988037109375": 46, "008697509765625": 46, "00872039794921875": 46, "00872802734375": 46, "00873565673828125": 46, "0087432861328125": 46, "00878143310546875": 46, "00879669189453125": 46, "00881195068359375": 46, "008819580078125": 46, "00882720947265625": 46, "00884246826171875": 46, "00885772705078125": 46, "0088958740234375": 46, "0089111328125": 46, "0089263916015625": 46, "00893402099609375": 46, "00896453857421875": 46, "00897979736328125": 46, "009002685546875": 46, "0090179443359375": 46, "00902557373046875": 46, "00905609130859375": 46, "009063720703125": 46, "00907135009765625": 46, "0091094970703125": 46, "00911712646484375": 46, "00913238525390625": 46, "00914764404296875": 46, "00916290283203125": 46, "0091705322265625": 46, "00919342041015625": 46, "0092010498046875": 46, "00923919677734375": 46, "009246826171875": 46, "00925445556640625": 46, "00930023193359375": 46, "0093536376953125": 46, "00936126708984375": 46, "00939178466796875": 46, "0093994140625": 46, "00945281982421875": 46, "00946044921875": 46, "00948333740234375": 46, "009490966796875": 46, "00952911376953125": 46, "0095367431640625": 46, "00954437255859375": 46, "0095672607421875": 46, "00958251953125": 46, "00960540771484375": 46, "009613037109375": 46, "009674072265625": 46, "00968170166015625": 46, "0096893310546875": 46, "00970458984375": 46, "00975799560546875": 46, "00978851318359375": 46, "00980377197265625": 46, "00981903076171875": 46, "00982666015625": 46, "00983428955078125": 46, "009857177734375": 46, "00986480712890625": 46, "00988006591796875": 46, "00994110107421875": 46, "00995635986328125": 46, "00it": [26, 29], "01": [14, 15, 22, 26, 27, 28, 29, 30, 41, 46, 47, 78, 101, 103, 109, 121], "0100250244140625": 46, "010040283203125": 46, "010101318359375": 46, "01010894775390625": 46, "0101165771484375": 46, "0101318359375": 46, "01013946533203125": 46, "01015472412109375": 46, "010162353515625": 46, "01018524169921875": 46, "01019287109375": 46, "0102081298828125": 46, "010223388671875": 46, "0102386474609375": 46, "01024": 19, "01025390625": 46, "01026153564453125": 46, "0102691650390625": 46, "01031494140625": 46, "0103302001953125": 46, "010345458984375": 46, "01035308837890625": 46, "01038360595703125": 46, "0104522705078125": 46, "010467529296875": 46, "01052093505859375": 46, "01053619384765625": 46, "0105438232421875": 46, "0105743408203125": 46, "01058197021484375": 46, "01064300537109375": 46, "01065826416015625": 46, "0106658935546875": 46, "01068115234375": 46, "01068878173828125": 46, "010711669921875": 46, "0107269287109375": 46, "0107421875": 46, "01074981689453125": 46, "010772705078125": 46, "01078033447265625": 46, "0107815": 28, "01079559326171875": 46, "01080322265625": 46, "0108184814453125": 46, "01084136962890625": 46, "0108489990234375": 46, "0108795166015625": 46, "010894775390625": 46, "01097869873046875": 46, "01099395751953125": 46, "01100921630859375": 46, "011016845703125": 46, "0110321044921875": 46, "0110626220703125": 46, "011077880859375": [41, 46], "01110076904296875": 46, "0111083984375": 46, "01113128662109375": 46, "01114654541015625": 46, "0111846923828125": 46, "01119232177734375": 46, "01123046875": 46, "01123809814453125": 46, "0112457275390625": 46, "0112762451171875": 46, "01129913330078125": 46, "01131439208984375": 46, "01132965087890625": 46, "0113372802734375": 46, "0113525390625": 46, "01136016845703125": 46, "0113677978515625": 46, "01137542724609375": 46, "011383056640625": 46, "0113983154296875": 46, "01141357421875": 46, "01143646240234375": 46, "011444091796875": 46, "01145172119140625": 46, "011474609375": 46, "0114898681640625": 46, "011505126953125": 46, "01151275634765625": 46, "0115203857421875": 46, "01152801513671875": 46, "01153564453125": 46, "0115814208984375": 46, "01158905029296875": 46, "0115966796875": 46, "0116119384765625": 46, "011627197265625": 46, "01171875": 46, "01175689697265625": 46, "01177978515625": 46, "01178741455078125": 46, "01180267333984375": 46, "01184844970703125": 46, "0118560791015625": 46, "01189422607421875": 46, "01190948486328125": 46, "0119476318359375": 46, "01195526123046875": 46, "011962890625": 46, "01198577880859375": 46, "01200103759765625": 46, "0120391845703125": 46, "01207733154296875": 46, "0120849609375": 46, "01210784912109375": 46, "01212310791015625": 46, "01213836669921875": 46, "01214599609375": 46, "0121612548828125": 46, "01218414306640625": 46, "0121917724609375": 46, "01219940185546875": 46, "01220703125": 46, "01224517822265625": 46, "01226806640625": 46, "012298583984375": 46, "0123291015625": 46, "012359619140625": 46, "0123748779296875": 46, "01241302490234375": 46, "012420654296875": 46, "012451171875": 46, "01247406005859375": 46, "01248931884765625": 46, "0125274658203125": 46, "01253509521484375": 46, "012542724609375": 46, "0125579833984375": 46, "01256561279296875": 46, "01259613037109375": 46, "012603759765625": 46, "01262664794921875": 46, "01263427734375": 46, "01264190673828125": 46, "01276397705078125": 46, "012786865234375": 46, "01280975341796875": 46, "0128326416015625": 46, "01285552978515625": 46, "01287078857421875": 46, "01287841796875": 46, "0128936767578125": 46, "012908935546875": 46, "01300811767578125": 46, "0130157470703125": 46, "01302337646484375": 46, "01303863525390625": 46, "0130462646484375": 46, "01305389404296875": 46, "01308441162109375": 46, "01312255859375": 46, "01317596435546875": 46, "01320648193359375": 46, "01325225830078125": 46, "01326751708984375": 46, "01328277587890625": 46, "0132904052734375": 46, "0133056640625": 46, "01332855224609375": 46, "0133514404296875": 46, "01335906982421875": 46, "01336669921875": 46, "01340484619140625": 46, "01346588134765625": 46, "01348114013671875": 46, "01349639892578125": 46, "0135040283203125": 46, "01355743408203125": 46, "01360321044921875": 46, "01361083984375": 46, "0136260986328125": 46, "01364898681640625": 46, "01367950439453125": 46, "01371002197265625": 46, "0137176513671875": 46, "01372528076171875": 46, "01373291015625": 46, "01374053955078125": 46, "013763427734375": 46, "0137786865234375": 46, "0138092041015625": 46, "01381683349609375": 46, "01384735107421875": 46, "01386260986328125": 46, "01389312744140625": 46, "01392364501953125": 46, "0139312744140625": 46, "013946533203125": 46, "01397705078125": 46, "0140228271484375": 46, "0140533447265625": [41, 46], "0140838623046875": 46, "01409912109375": 46, "01412200927734375": 46, "014129638671875": 46, "0141448974609375": 46, "01415252685546875": 46, "01418304443359375": 46, "0142059326171875": 46, "0142364501953125": 46, "01427459716796875": 46, "014312744140625": 46, "0143280029296875": 46, "0143585205078125": 46, "014373779296875": 46, "01441192626953125": [41, 46], "01442718505859375": 46, "01445770263671875": 46, "0144805908203125": 46, "014495849609375": 46, "0145111083984375": 46, "0145263671875": 46, "01454925537109375": 46, "01456451416015625": 46, "01457977294921875": 46, "014617919921875": 46, "0146484375": 46, "0146636962890625": 46, "014678955078125": 46, "0146942138671875": 46, "01470184326171875": 46, "01471710205078125": 46, "01473236083984375": 46, "0147857666015625": 46, "0148162841796875": 46, "01483154296875": 46, "0148468017578125": 46, "01488494873046875": 46, "01490020751953125": 46, "01491546630859375": 46, "01495361328125": 46, "0149993896484375": 46, "015": 109, "0150146484375": 46, "01505279541015625": 46, "01506805419921875": 46, "01509857177734375": 46, "01513671875": 46, "0151519775390625": 46, "01519012451171875": 46, "01520538330078125": 46, "01522064208984375": 46, "01523590087890625": 46, "01525115966796875": 46, "0152740478515625": 46, "01531982421875": 46, "01535797119140625": 46, "01540374755859375": 46, "01541900634765625": 46, "0154266357421875": 46, "01544189453125": 46, "015472412109375": 46, "0154876708984375": 46, "01551055908203125": 46, "01557159423828125": 46, "01558685302734375": 46, "0156097412109375": 46, "0156707763671875": 46, "01568603515625": 46, "015716552734375": 46, "0157318115234375": 46, "0157470703125": 46, "015777587890625": 46, "0157928466796875": 46, "015838623046875": 46, "0158538818359375": 46, "015869140625": 46, "0158843994140625": 46, "015899658203125": 46, "0159149169921875": 46, "015960693359375": 46, "0159759521484375": 46, "0159912109375": [41, 46], "0160064697265625": 46, "016021728515625": 46, "0160675048828125": 46, "0160980224609375": 46, "016143798828125": 46, "01617431640625": 46, "0161895751953125": 46, "016265869140625": 46, "016326904296875": 46, "016357421875": 46, "016448974609375": 46, "016510009765625": 46, "0165252685546875": 46, "0166015625": 46, "0166168212890625": 46, "016632080078125": 46, "0166778564453125": 46, "016693115234375": 46, "0167236328125": 46, "0167388916015625": 46, "0167694091796875": 46, "01678466796875": 46, "016815185546875": 46, "0168304443359375": 46, "016845703125": 46, "0168609619140625": 46, "016876220703125": 46, "016937255859375": 46, "0169677734375": 46, "016998291015625": 46, "0170745849609375": 46, "01708984375": 46, "0171966552734375": 46, "0172119140625": 46, "0172271728515625": 46, "017242431640625": 46, "0172882080078125": 46, "017333984375": 46, "017364501953125": 46, "0173797607421875": 46, "0174102783203125": 46, "0174560546875": 46, "017486572265625": 46, "0175018310546875": 46, "01751708984375": 46, "0175323486328125": 46, "0175628662109375": 46, "017578125": 46, "0176239013671875": 46, "01763916015625": 46, "0176849365234375": 46, "0177001953125": 46, "017730712890625": 46, "0177764892578125": 46, "0178070068359375": 46, "0178375244140625": 46, "017852783203125": 46, "01788330078125": 46, "0178985595703125": 46, "017913818359375": 46, "0179290771484375": 46, "0180816650390625": 46, "01812744140625": 46, "018157958984375": 46, "0181732177734375": 46, "018218994140625": 46, "0182342529296875": 46, "01824951171875": 46, "018280029296875": 46, "0183258056640625": 46, "01837158203125": 46, "018402099609375": 46, "0184173583984375": 46, "0184326171875": 46, "018463134765625": 46, "0185394287109375": 46, "0185546875": 46, "018585205078125": 46, "0186004638671875": 46, "018707275390625": 46, "01873779296875": 46, "0187530517578125": 46, "018768310546875": 46, "0188446044921875": 46, "018890380859375": 46, "0189208984375": 46, "0189361572265625": 46, "018951416015625": 46, "0189666748046875": 46, "01898193359375": 46, "019012451171875": 46, "01904296875": 46, "019073486328125": 46, "01910400390625": 46, "019134521484375": 46, "0192413330078125": 46, "01934814453125": 46, "0193634033203125": 46, "0193939208984375": 46, "0194854736328125": 46, "01953125": 46, "0196075439453125": 46, "019622802734375": 46, "0196533203125": 46, "019683837890625": 46, "0196990966796875": 46, "01971435546875": 46, "019775390625": 46, "0198211669921875": 46, "0198516845703125": 46, "019927978515625": 46, "019989013671875": 46, "01it": [26, 101], "02": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 78, 101, 103, 109], "0200": 103, "0200042724609375": 46, "020050048828125": 46, "0200653076171875": 46, "020111083984375": 46, "020172119140625": 46, "0202178955078125": 46, "020233154296875": 46, "02032470703125": 46, "0203399658203125": 46, "0204315185546875": 46, "02044677734375": 46, "020477294921875": 46, "0205535888671875": 46, "02056884765625": 46, "0206298828125": 46, "0207061767578125": 46, "020721435546875": 46, "0207977294921875": 46, "02081298828125": 46, "0208282470703125": 46, "020843505859375": 46, "0208587646484375": 46, "0208740234375": 46, "0208892822265625": 46, "0209503173828125": 46, "0210418701171875": 46, "02117919921875": 46, "0211944580078125": 46, "021209716796875": 46, "0212249755859375": 46, "0212860107421875": 46, "0213470458984375": 46, "021392822265625": 46, "02142333984375": 46, "0214385986328125": 46, "021453857421875": 46, "021484375": 46, "021514892578125": 46, "0215301513671875": 46, "021568000316619873": 26, "0215911865234375": 46, "0216": 26, "0216522216796875": 46, "02166748046875": 46, "0216827392578125": 46, "0217132568359375": 46, "0217742919921875": 46, "0218353271484375": 46, "0218658447265625": 46, "021881103515625": 46, "0219573974609375": 46, "0219879150390625": 46, "02203369140625": 46, "02208000048995018": 26, "0221": 26, "0222015380859375": 46, "022216796875": 46, "0222625732421875": 46, "0222930908203125": 46, "0223236083984375": 46, "02239999920129776": 26, "0224": 26, "0224456787109375": 46, "0224761962890625": 46, "022491455078125": 46, "0225": 103, "02264404296875": 46, "022735595703125": 46, "0228424072265625": [41, 46], "022857666015625": 46, "022918701171875": 46, "0229949951171875": 46, "023": 119, "023040771484375": 46, "0230712890625": 46, "0231": 26, "023104000836610794": 26, "0231170654296875": 46, "02313232421875": 46, "0231475830078125": 46, "023162841796875": 46, "0232": 26, "0232391357421875": 46, "0232696533203125": 46, "0233306884765625": 46, "0233612060546875": 46, "0235137939453125": 46, "0235748291015625": 46, "02362060546875": 46, "0237": 41, "0238494873046875": 46, "02386474609375": 46, "0238800048828125": 46, "0239155": 28, "023956298828125": 46, "02398681640625": 46, "024017333984375": 46, "02410888671875": 46, "0241546630859375": 46, "024219751358032227": 27, "02423095703125": 46, "0242462158203125": 46, "024322509765625": 46, "0243988037109375": 46, "024505615234375": 46, "02471923828125": 46, "024749755859375": 46, "0247650146484375": 46, "0247802734375": 46, "0247955322265625": 46, "0248565673828125": 46, "0248870849609375": 46, "0249176025390625": 46, "025": 109, "0251617431640625": 46, "02520751953125": 46, "025238037109375": 46, "0252838134765625": 46, "025299072265625": 46, "0254058837890625": 46, "0255279541015625": 46, "025543212890625": 46, "0255584716796875": 46, "0255889892578125": 46, "0256500244140625": 46, "0256805419921875": 46, "025848388671875": 46, "025970458984375": 46, "0260009765625": 46, "026031494140625": 46, "026092529296875": 46, "0261688232421875": 46, "02618408203125": 46, "026214599609375": 46, "0262451171875": 46, "0262603759765625": 46, "0262908935546875": 46, "02642822265625": 46, "0264739990234375": 46, "0266": 26, "0266265869140625": 46, "0266876220703125": 46, "0267181396484375": 46, "0268402099609375": 46, "0269775390625": 46, "0269927978515625": 46, "02716064453125": 46, "0272064208984375": 46, "0272369384765625": 46, "02728271484375": 46, "0272979736328125": [41, 46], "0273284912109375": 46, "0274200439453125": 46, "0275421142578125": 46, "027618408203125": 46, "027923583984375": 46, "0279693603515625": 46, "028045654296875": 46, "028076171875": 46, "0280914306640625": 46, "0281524658203125": 46, "0282135009765625": 46, "028228759765625": 46, "0282745361328125": 46, "028289794921875": 46, "0283050537109375": 46, "0284": 41, "0284271240234375": 46, "0284423828125": 46, "028472900390625": 46, "0285491943359375": 46, "028656005859375": 46, "0286865234375": 46, "02874755859375": 46, "0288848876953125": 46, "0289154052734375": 46, "0289306640625": 46, "029052734375": 46, "0291595458984375": 46, "0291900634765625": 46, "029296875": 46, "02935791015625": 46, "0294036865234375": 46, "0294342041015625": 46, "0294952392578125": 46, "0295562744140625": 46, "029571533203125": 46, "029632568359375": 46, "0298004150390625": 46, "0298309326171875": 46, "029937744140625": 46, "02e26770173b475e829d4d3a45f6f343": 28, "03": [14, 15, 26, 41, 101, 109, 125], "0300": 26, "030029296875": 46, "0300445556640625": 46, "0301055908203125": 46, "0301361083984375": 46, "0301666259765625": 46, "030242919921875": 46, "030364990234375": 46, "0305023193359375": 46, "030670166015625": 46, "0307": 26, "0307769775390625": 46, "030975341796875": 46, "0310211181640625": 46, "0311431884765625": 46, "0311737060546875": 46, "03143310546875": 46, "03155517578125": 46, "0316": 26, "031646728515625": 46, "032012939453125": 46, "032135009765625": 46, "032318115234375": 46, "0324": [17, 29, 32], "032440185546875": 46, "032470703125": 46, "032501220703125": 46, "03271484375": 46, "032806396484375": 46, "03289794921875": 46, "03314208984375": 46, "03326416015625": 46, "0333251953125": 46, "033447265625": 46, "03375244140625": 46, "0338134765625": 46, "033935546875": 46, "0340576171875": 46, "03411865234375": 46, "03424072265625": 46, "0343017578125": 46, "034454345703125": 46, "03448486328125": 46, "0345458984375": 46, "034637451171875": 46, "03466796875": 46, "034759521484375": 46, "03509521484375": 46, "035247802734375": 46, "035308837890625": 46, "03570556640625": 46, "035888671875": 46, "03607177734375": 46, "03619384765625": 46, "0362548828125": 46, "036346435546875": 46, "036376953125": 46, "036468505859375": 46, "036529541015625": 46, "03668212890625": 46, "03692626953125": 46, "0369873046875": 46, "037078857421875": 46, "0372314453125": 46, "037506103515625": 46, "037841796875": 46, "0380025": 27, "0380859375": 46, "038116455078125": 46, "03826904296875": 46, "038604736328125": 46, "038787841796875": 46, "038818359375": 46, "038848876953125": 46, "0389": 26, "03924560546875": 46, "039276123046875": 46, "0393": 26, "0394": 26, "039435e": 109, "039459228515625": 46, "039703369140625": 46, "03it": [15, 101], "04": [15, 26, 41, 60, 81, 103, 109], "040252685546875": 46, "0404052734375": 46, "0405": 26, "0406": 26, "040618896484375": 46, "0406494140625": 46, "040802001953125": 46, "0411": 26, "041412353515625": 46, "041717529296875": 46, "041961669921875": 46, "0420": 26, "0422": 26, "04248046875": 46, "0425": 26, "0426": 26, "042938232421875": 46, "044219970703125": 46, "045166015625": 46, "045257568359375": 46, "04534912109375": 46, "0458984375": 46, "0467529296875": 46, "047168001532554626": 26, "0472": 26, "047698974609375": 46, "04809600114822388": 26, "0481": 26, "048248291015625": 46, "04825599864125252": 26, "0483": 26, "048370361328125": 46, "0484": 26, "04840087890625": 46, "048492431640625": 46, "0490": 26, "04918399825692177": 26, "0492": 26, "04956800118088722": 26, "0496": 26, "049652099609375": 46, "04986572265625": [41, 46], "049957275390625": 46, "05": [15, 24, 26, 101, 103, 109], "0506": 26, "050624001771211624": 26, "05078125": 46, "0508": 26, "052480001002550125": 26, "0525": 26, "0528": [8, 20, 22, 45, 89, 104], "052978515625": 46, "053497314453125": 46, "05401611328125": 46, "0541": 26, "05446290969848633": 52, "0546875": 41, "0551": 26, "0553": 26, "0554": 26, "0558": 26, "0563": 26, "056488037109375": 46, "0566": 26, "057037353515625": 46, "057373046875": 46, "0577": 26, "0578": 26, "05792236328125": 46, "059112548828125": 46, "05987548828125": 46, "05it": 42, "06": [15, 22, 26, 41, 109], "06072998046875": 46, "0609": 26, "0611572265625": 46, "0625": 46, "062744140625": 46, "0631103515625": 46, "0633544921875": 46, "0637": 41, "0643310546875": 46, "0646": 26, "0660": 26, "0666": 26, "06707763671875": 46, "0672": 26, "068603515625": 46, "0689": 26, "06927490234375": 46, "06it": [29, 30], "07": [26, 41, 101, 103], "0708": 26, "0715487003326416": 27, "0718": 26, "07232666015625": 46, "073486328125": 46, "0749": 26, "07491199672222137": 26, "075": 109, "07500000000000001": 109, "0752": 26, "0755": 26, "0756": 26, "0760": 26, "07603199779987335": 26, "0766": 26, "0772": 26, "0775146484375": 46, "0788": 26, "07919526100158691": 27, "07958984375": 46, "0797": 26, "07977294921875": 46, "079a41525d3c4dd09f8a39dc945382c4": 41, "07it": 47, "08": [14, 15, 26, 41, 103, 109], "0803": 26, "08087158203125": 46, "0829": 26, "0830": 26, "0893": 26, "089599609375": 46, "09": [15, 26, 41, 42, 98, 101], "0900": 26, "090218": 78, "0918": 26, "09197998046875": 46, "0923": 26, "0924": [89, 125], "0932": 26, "0933": 26, "0941": 26, "0942": 26, "0943603515625": 46, "0945": 26, "0946": 26, "0946044921875": 46, "0951": 26, "09521484375": 46, "0961": 26, "09625244140625": 46, "0985": 26, "0988": 26, "0998": 26, "09984000027179718": 26, "0999": 26, "09it": 26, "0b3a18a981654badbd9c6d51abafdaf8": 15, "0dai": 84, "0dd7": 103, "0e9e39f249a16976918f6564b8830bc894c89659": 15, "0x0": 103, "1": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 33, 36, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 61, 62, 64, 66, 69, 70, 71, 72, 73, 74, 75, 80, 84, 88, 89, 91, 93, 95, 97, 101, 103, 109, 110, 111, 113, 115, 118, 121, 123, 124, 125, 127], "10": [0, 14, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 32, 38, 40, 41, 42, 45, 46, 47, 52, 54, 58, 74, 81, 82, 83, 88, 89, 101, 103, 107, 108, 109, 118, 125], "100": [11, 14, 15, 16, 19, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 41, 42, 45, 46, 47, 52, 53, 54, 57, 58, 70, 94, 101, 108, 109], "1000": [8, 15, 22, 23, 24, 27, 28, 29, 30, 41, 42, 53, 54, 58, 82, 84, 97], "10000": [11, 24, 82], "1000000": 39, "10000000": [15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "100000000": 107, "1000000000": 107, "10001": [5, 24], "10011": 94, "1002": [15, 23], "1004": 23, "10078": 20, "1008": [23, 41], "100b": [124, 125], "100m": 24, "100mb": 54, "101": 15, "1010": 26, "1012": 28, "10146": 28, "1015": 26, "1016": 23, "10161": 28, "10168313980102539": 27, "1018": 26, "102": 15, "1020": 26, "1024": [12, 15, 19, 22, 24, 26, 27, 28, 29, 30, 32, 36, 41, 42, 53, 54, 58, 61, 82, 90, 94, 95, 97, 104, 107, 109, 119, 124], "1024x1024": 62, "1026": 26, "1028": 26, "10284800082445145": 26, "102mb": 8, "1030": 28, "1035": [41, 109], "104": [15, 22, 27, 28, 29, 30, 42], "1042": 28, "1043": 26, "1048": 26, "1048576": 127, "1052": 28, "10542": 28, "10696": 28, "106b": [89, 127], "107": 15, "1075": [28, 41], "10774": 41, "108": 82, "1080p": 53, "1080x1920": 53, "1083": [28, 41], "1084": [41, 52], "1087": 26, "1088": 82, "109": [15, 33], "10912": 107, "10948": 41, "1096": [28, 41], "10997": 28, "109b": 39, "10b": [90, 127], "10it": 41, "10m": [24, 39], "11": [14, 15, 23, 24, 26, 27, 28, 29, 38, 41, 42, 52, 54, 62, 81, 101, 103, 109], "110": 15, "11000": 82, "11008": [26, 109], "11008x4096": 26, "1101": 28, "1103": 26, "11050": 41, "111": 15, "11111": 45, "11136": [28, 41], "11141": 28, "1119": 28, "112": [15, 22, 27, 28, 29, 30, 41, 42], "11228": 109, "1124": [28, 89, 125], "11245": 41, "1125": [109, 125], "1128": 28, "114": [15, 82], "1142": 28, "114688": 82, "1152": 82, "1153": 26, "1154": [41, 46], "1156": 26, "11575937271118164": 27, "1158": 26, "11584": 27, "116": [32, 38], "116093850019932e": 109, "11649": 28, "1167": 26, "11685": 109, "1181": [28, 41], "1184": [22, 27, 28, 29, 30, 41, 42], "11852": 18, "1191": 28, "1196": 28, "1199": 26, "11b": [89, 127], "11it": 26, "12": [1, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 38, 41, 42, 54, 60, 69, 70, 76, 82, 83, 88, 90, 94, 95, 101, 105, 125], "120": [5, 15, 22, 24, 26, 27, 28, 29, 30, 42, 55, 80, 82, 97], "1200": [82, 107], "120000": [33, 58], "1205": 41, "12065": 33, "12095": [28, 41, 52], "120b": [20, 29, 38, 89, 125], "12159": 28, "12288": 18, "123": [45, 110], "12345": 45, "123456": 38, "1234567890": 62, "1234567890ab": 24, "123859": 109, "1240": 26, "125": 90, "126": 26, "12612": 20, "1265": 28, "127": [7, 11, 13, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 41, 42, 45, 46, 51, 52, 53, 54, 58, 81, 82, 83, 84, 88, 91, 94, 103, 113, 118, 119, 121, 124], "1273": 28, "128": [1, 4, 15, 17, 18, 19, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 39, 41, 42, 45, 46, 47, 51, 52, 53, 56, 79, 82, 83, 88, 90, 93, 94, 95, 97, 101, 106, 109, 119, 124, 127], "1280": [15, 22, 26, 27, 28, 29, 30, 41, 42, 61, 64], "128000": 33, "128009": [26, 27], "1280x720": 62, "1281": 28, "128902e": 109, "128e": 39, "128g": 60, "128k": [125, 127], "128x11008": 26, "128x128": 32, "128x4096": 26, "129": 15, "1290": 28, "1294": 26, "12994": 28, "12b": 127, "12it": [41, 101], "12k": 18, "12t": 125, "13": [14, 15, 22, 23, 24, 26, 27, 28, 29, 30, 38, 41, 42, 45, 46, 47, 52, 82, 90, 101], "1305": 26, "130859375": 46, "130b": 125, "131072": [15, 26, 33, 41, 82, 84, 107], "13126": 6, "1319": 33, "132": 82, "13216": 28, "13289": 28, "132b": 125, "133": 82, "1330": 109, "1332": 26, "13327": 8, "1335": 41, "13382": 28, "1345": 41, "1349": 28, "13530": 28, "13550": 33, "13580": 28, "135m": 125, "136": [22, 27, 28, 29, 30, 42, 104, 107], "1372": 28, "13724": 6, "1376": 28, "137604": 41, "1378": 41, "138": [32, 38], "1380": 28, "13837": 28, "139": 29, "1391": 26, "13925": 6, "13959": [33, 52], "13b": [89, 125, 127], "14": [15, 26, 27, 28, 29, 38, 41, 82, 83, 101, 104, 107, 109], "140": 109, "14006": 109, "14007": 109, "1401": 28, "1408": 41, "14097": 6, "141": [15, 82], "1414": 28, "14190": 28, "141fc3a09386a8baf0d7495c247ae2d1a565f69f": 15, "1429": [28, 41], "1438": 28, "144": [15, 22, 27, 28, 29, 30, 41, 42, 82], "14422": 3, "1447": 28, "144gb": 40, "14720": 28, "1477": 28, "148": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "1482": 28, "14822": 41, "1483": 41, "149": 15, "1490": 28, "1495": 28, "14975": 41, "14b": [1, 64, 125], "14it": 15, "15": [15, 18, 22, 23, 24, 26, 27, 28, 29, 38, 41, 46, 69, 82, 101, 103, 109], "150": [15, 45, 101], "1500": 82, "15040": 33, "151": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "1513": 109, "1513671875": 46, "151643": 28, "151645": [26, 45, 47, 52], "151649": 28, "152": [15, 22, 27, 28, 29, 30, 42], "1522": 24, "1526": 41, "15320": 3, "15339": 24, "15358": 33, "1536": [15, 22, 27, 28, 29, 30, 41, 42, 82, 83, 86, 119], "15420": 41, "15423": 28, "155": 28, "156": [22, 27, 28, 29, 30, 42, 82], "1576": 28, "158": [5, 26], "159": 15, "15934": 28, "15b": [125, 127], "15b3": 103, "15it": [26, 46, 101], "16": [1, 15, 17, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 38, 41, 42, 45, 46, 47, 52, 53, 58, 83, 84, 86, 88, 90, 94, 101, 103, 104, 105, 107, 124, 125], "160": [14, 15, 22, 27, 28, 29, 30, 41, 42, 82], "1600": [82, 83], "16045": 28, "1616": 28, "162": [15, 109], "1632": 33, "16328": 41, "1633": 28, "16380": 33, "16384": [14, 15, 22, 23, 27, 28, 29, 30, 33, 41, 42, 82, 83, 84, 88, 94, 103], "163840": 103, "164": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "1640": 82, "1650390625": 46, "16622": 41, "1667": 28, "16686": 110, "167": 90, "1673": 33, "168": [22, 23, 27, 28, 29, 30, 42], "1681": 28, "16875": 109, "169": [104, 107], "1692": 26, "16card": 82, "16e": [29, 30, 39, 89, 125], "16g": [79, 81, 84], "16it": [26, 29], "16k": [18, 125], "16x": 23, "17": [14, 15, 26, 27, 28, 29, 41, 82, 101, 103], "17064": 41, "171": 90, "171662e": 109, "17180": 41, "17194": 28, "172": [82, 104, 105, 107], "173": 15, "174": 28, "1741943359375": 46, "1744": 28, "1745383213": 118, "1745993638": 32, "175": 38, "1750252498": [104, 107], "17504": 33, "176": [15, 22, 27, 28, 29, 30, 41, 42], "17601": 41, "1767034308": 24, "1770943618": 26, "1770943685": 26, "1770943728": 26, "1770943769": 26, "1770943797": 26, "1770943832": 26, "1770943861": 26, "1770943895": 26, "1770943931": 27, "1770943932": 27, "1770943933": 27, "1770943998": 28, "1770944000": 28, "1770944013": 28, "1770944014": 28, "1770944092": 29, "1770944093": 29, "1770944158": 29, "1770944227": 45, "1770944228": 45, "1770944295": 47, "1770944296": 47, "1770944298": 47, "1770944331": 52, "1770944332": 52, "1770944371": 41, "1770944492": 41, "1772": 26, "17724609375": 46, "17767": 28, "1779": 28, "178": 82, "1782": 41, "17821": 28, "179": 15, "1792": [15, 22, 27, 28, 29, 30, 41, 42], "17b": [29, 30, 39, 89, 125], "17it": [26, 41], "18": [15, 22, 23, 26, 27, 28, 29, 30, 38, 41, 42, 82, 83, 88, 103, 105], "180": 24, "1800": 82, "18000": 82, "18100": 41, "1813": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "1815": 109, "1817": 41, "182": 15, "1828": 41, "184": [22, 27, 28, 29, 30, 42], "18432": 18, "1855": 28, "18562": 41, "1868896484375": 46, "187": 38, "1879": 52, "189": 15, "1894": 26, "18it": [15, 29, 41], "18k": 18, "19": [15, 22, 26, 27, 28, 29, 41, 46, 47, 78], "19083": 28, "19091": 28, "191": 78, "1917": 24, "1919": 78, "192": [15, 22, 23, 27, 28, 29, 30, 41, 42, 82], "1933694": 28, "193833589553833": 28, "19384980201721191": 28, "19385600090026855": 28, "19482": 28, "1970": 109, "19730": 2, "198": [28, 33, 41, 58], "1990": 28, "1995": 28, "19it": 46, "1_6b": 89, "1b": [19, 29, 56, 89, 116, 125, 127], "1b7d4c3a6e1f": 24, "1card": 82, "1d": 57, "1e9": 12, "1gb": 12, "1m": [1, 24, 39, 125], "1mb": 24, "1p1d": 104, "1stage": 97, "1t": 125, "1v": 127, "1x": 26, "2": [0, 1, 5, 6, 8, 9, 11, 12, 15, 17, 18, 19, 20, 22, 23, 24, 27, 28, 32, 34, 37, 38, 39, 41, 42, 45, 46, 47, 48, 51, 52, 53, 54, 55, 61, 62, 64, 66, 70, 71, 72, 73, 80, 84, 86, 88, 89, 91, 95, 96, 101, 103, 105, 108, 109, 113, 115, 116, 118, 121, 123, 124, 125, 127], "20": [2, 5, 8, 14, 15, 22, 24, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 45, 47, 58, 82, 83, 94, 97, 101, 103, 107, 109], "200": [15, 22, 27, 28, 29, 30, 38, 41, 42, 53, 55, 58, 80, 83, 103, 125], "2000": [14, 53, 56, 82], "20000": [24, 103, 105], "200b": 20, "200k": 125, "20102": [33, 104, 107], "202": [15, 24], "2020": [28, 40], "2021": 28, "2022": [28, 41], "2023": 28, "2023todai": 27, "2024": [5, 125], "2024userpari": 27, "2025": [14, 38, 98, 103, 125], "2026": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 78, 101], "2038": 28, "20474": 41, "2048": [14, 15, 22, 26, 27, 28, 29, 30, 33, 39, 41, 42, 53, 82, 94, 98, 104, 107], "20480": [15, 22, 27, 28, 29, 41, 42], "2055": 28, "206": 38, "2070": 28, "208": [15, 22, 27, 28, 29, 30, 41, 42, 101], "2086": 52, "2097": 41, "20b": [29, 90, 125], "20it": 27, "20m": 15, "21": [15, 26, 27, 28, 29, 41, 45, 46, 109], "210": [38, 90], "2100": 82, "2100000": 28, "2114": 41, "21338741812": 78, "214": 90, "21408": 78, "2141000": 27, "2147000": 27, "2147483648": 107, "21500000": 27, "2154000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 28, "216": [22, 27, 28, 29, 30, 42], "21600000": 28, "2161000": 28, "2163": 28, "2174300": 28, "2176": 28, "2182": 28, "21938": 41, "21b": [89, 125], "21it": [15, 27], "22": [15, 26, 27, 28, 32, 41, 82, 83, 98, 107], "220": [27, 28, 41], "221": [104, 107], "222": 101, "2236": 28, "224": [15, 22, 27, 28, 29, 30, 41, 42], "224gb": 105, "22573": 28, "22707": 28, "2272": 41, "2297": 28, "22it": [27, 29, 47], "22m": [104, 107], "23": [15, 22, 26, 27, 28, 41, 81, 103], "230": 40, "2301439257093": 41, "2304": [15, 22, 27, 28, 29, 30, 41, 42], "2308": 28, "23085": 41, "2309": 26, "231": 78, "232": [22, 27, 28, 29, 30, 42], "2321": 26, "2326": 109, "233": 14, "235": [33, 104, 107], "235b": [11, 20, 22, 50, 89, 90, 127], "238": 41, "2393": 26, "23933": 41, "23949": 28, "24": [15, 22, 24, 26, 27, 28, 29, 30, 41, 42, 61, 66, 70, 78, 83, 101, 103, 104], "240": [15, 20, 22, 24, 27, 28, 29, 30, 41, 42], "2400": 78, "2407": 29, "240gb": 12, "2415": 26, "24155": 33, "2417": 109, "242": [15, 104, 107], "2427": 28, "2432795": 27, "244": 26, "2450": 26, "24576": 82, "24595": 28, "24667": 82, "24669": [82, 83], "247": 109, "2474": 28, "248": [22, 27, 28, 29, 30, 42], "2486572265625": 46, "2494": 28, "24b": [89, 127], "24card": 82, "24it": 15, "25": [12, 15, 26, 27, 28, 29, 33, 41, 45, 46, 69, 70, 81, 101, 103, 109], "25000": 23, "2503": [89, 127], "2504": 28, "2506": 28, "2507": [11, 22, 82, 89], "250m": 24, "2511": 64, "2512": 64, "2513": 109, "253": 90, "2530": 28, "253125": 109, "253b": 125, "255b": 125, "256": [5, 12, 13, 14, 15, 19, 22, 23, 24, 27, 28, 29, 30, 41, 42, 53, 54, 56, 57, 61, 82, 88, 94, 101, 119, 127], "2560": [15, 22, 27, 28, 29, 30, 41, 42], "2567": 26, "256k": 125, "256mb": 24, "2573": 26, "25it": [15, 41], "25m": 24, "25t22": 78, "26": [26, 27, 28, 29, 41, 82, 83, 101, 104, 107], "2606": 41, "262144": [82, 104, 107], "26277": 41, "26306266784668": 109, "264": [28, 41], "264404296875": 46, "26553": 28, "266055e": 109, "2661": 41, "2664": 26, "2670": 28, "26774": 41, "2697": 28, "26it": 15, "27": [26, 38, 41, 45, 103, 109], "2701": 41, "2704": 28, "271": [28, 41], "2719": 28, "272": 82, "275": 5, "2750": 28, "2753": 41, "2762": 26, "277": 38, "27748": 28, "2776": 28, "279": [27, 28, 41, 52], "2791": 26, "2797": 28, "27b": [89, 123, 125, 127], "27it": 26, "28": [15, 22, 27, 28, 29, 30, 41, 42, 52, 82, 83, 109, 125], "280000": 84, "281": 29, "2814453125": 109, "2816": [15, 22, 27, 28, 29, 30, 41, 42], "282": 15, "2821": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "2826": 109, "284171": 15, "28672": 82, "28680": [82, 83], "288": [15, 22, 27, 28, 29, 30, 41, 42, 82], "28804707527160645": 41, "28b": 127, "28it": [15, 27, 41], "28m": 15, "29": [26, 33, 38, 107], "29000": 24, "290416240692139": 28, "290b": 125, "29138749187": 38, "2924": 28, "292ef2c47a3e42e8b00bdb0bf36c3802": 28, "2938": 28, "294930": 41, "29500": [2, 91, 113], "296": 28, "296752e": 109, "29686": 41, "2975": 28, "2989": 41, "2999": 41, "29it": [15, 26], "2_6": [89, 127], "2a": [0, 23], "2b": [19, 23, 89, 119, 121, 125, 127], "2card": 82, "2f": [41, 121], "2f3a0c3": 24, "2k": 18, "2m": [15, 24], "2stage": 97, "2t": 125, "2x": [8, 11, 23, 24, 70, 103, 108], "3": [0, 1, 4, 5, 14, 15, 17, 18, 19, 20, 22, 23, 24, 27, 28, 32, 33, 36, 37, 38, 39, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 62, 65, 66, 70, 78, 79, 81, 82, 83, 88, 89, 91, 93, 95, 96, 101, 103, 104, 107, 109, 111, 115, 116, 121, 123, 124, 125, 127], "30": [5, 12, 15, 22, 23, 24, 26, 27, 28, 29, 30, 33, 41, 42, 46, 55, 61, 74, 78, 80, 82, 101, 104, 107, 109], "300": [15, 17, 22, 23, 24, 27, 28, 29, 30, 37, 41, 42, 47, 50, 88, 107, 125, 127], "3000": [53, 82, 107, 109], "30000": [4, 5, 7, 13, 16, 17, 18, 19, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 45, 50, 51, 52, 53, 54, 56, 58, 62, 68, 76, 79, 88, 90, 94, 96, 104, 105, 107, 109, 114, 116, 119, 121, 123, 124, 125, 127], "30001": [7, 17, 24, 43, 54, 104], "30002": [7, 54], "30003": [7, 54], "3001": 82, "30010": [61, 62, 67], "30011": 24, "30080": 107, "301": 41, "3010": 28, "30296": 41, "3033": 28, "30339": 28, "304": [28, 52], "3042": 28, "306816339492798": 28, "307": 47, "3072": [15, 22, 27, 28, 29, 30, 41, 42, 82], "308": 28, "30800": [104, 107], "3081": 26, "3082": 28, "3090": 109, "3092": 41, "30b": [29, 50, 81, 89, 125, 127], "30gb": 12, "30it": 15, "30min": 97, "31": [27, 29, 33, 41, 76, 97], "31000": 24, "311": [28, 41], "3110": 41, "3118": 28, "312": 82, "312226e": 109, "31378": 24, "314": 109, "3146": 28, "314b": 125, "315": [27, 28, 41, 52], "3156": 41, "316000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 28, "31693": 101, "317": 14, "31886": 15, "32": [1, 5, 15, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 41, 42, 51, 52, 54, 57, 78, 83, 84, 86, 88, 94, 95, 97, 103, 104, 107, 109, 124], "320": [15, 22, 27, 28, 29, 30, 41, 42, 82], "3200": 82, "3202": 20, "3207": 28, "3212802": 52, "3213": 28, "32186": 101, "322": 15, "323": [28, 41, 52], "32313": 28, "3248779296875": 109, "325507398": 22, "326": 28, "32768": [41, 82, 104, 107], "3278": 28, "3283": [28, 41, 52], "32923": 41, "3299": 26, "32b": [89, 90, 94, 125], "32b_eagle3": 94, "32card": 82, "32exp": 107, "32g": [56, 68, 76], "33": [15, 26, 41, 101], "330": [27, 28, 41], "3328": [15, 22, 26, 27, 28, 29, 30, 41, 42], "333123": 27, "33505": 45, "336": [89, 119], "339675e": 109, "33it": [30, 41], "34": [15, 22, 26, 27, 28, 29, 30, 38, 41, 42, 45, 46, 47, 52, 101], "3405": 41, "3410": 41, "3430": 28, "3440": 82, "3460": 28, "34b": [89, 125], "35": [15, 26, 28, 70], "3500": 82, "3500000": 28, "350x": 32, "3518979474117756e": 109, "352": [15, 22, 27, 28, 29, 30, 41, 42, 83], "35212": 28, "3526": 28, "3533": 20, "3561": 28, "35703": 28, "357747e": 109, "358": 28, "3583": 33, "3584": [15, 22, 27, 28, 29, 30, 41, 42, 82], "3598": [28, 41], "36": [29, 30, 38, 41, 52, 82, 101], "3600": [18, 32, 33, 82], "360p": 53, "362": 15, "36342": 41, "3643": 28, "36712": 41, "369": [28, 41], "369873046875": 46, "36a17343026c454dad2c682114c0b8d2": 28, "36b": 125, "37": [26, 41, 45, 52], "370959": 14, "371": 47, "373": [26, 41], "374": [27, 28, 38, 41, 52], "3746": 26, "377": 47, "3772": 28, "3786": 28, "3796875": 109, "38": [15, 26, 28, 41, 47, 101], "380": 30, "382": [28, 41, 109], "3825": 41, "384": [15, 22, 27, 28, 29, 30, 41, 42, 82], "3840": [15, 22, 27, 28, 29, 30, 41, 42], "386": 28, "387": 41, "3880": 28, "3881": 41, "389": [28, 52], "389414e": 109, "389b": 125, "39": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 90, 101], "3900": 82, "3910": 28, "3920": 26, "39430": 41, "3946": 28, "3950": 41, "3953": 28, "39921": 41, "3_1": 125, "3_3": 125, "3a7b": 24, "3b": [29, 30, 53, 61, 62, 64, 89, 95, 125], "3e": 2, "3f": 12, "3m": 40, "3min": 97, "3moe": 125, "3next": 125, "3rd": 45, "3x": [12, 70], "4": [0, 1, 5, 6, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 33, 40, 41, 42, 45, 46, 47, 48, 49, 52, 54, 55, 61, 62, 66, 70, 75, 80, 81, 86, 89, 90, 91, 97, 101, 103, 104, 105, 107, 108, 109, 113, 123, 125, 127], "40": [5, 15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 47, 76, 88, 90, 94, 101, 109, 125], "400": [13, 62, 77, 82, 118], "4000": [20, 79, 82], "40000": 103, "400757e": 109, "400b": [39, 125], "400k": 40, "401": 53, "402": 15, "403": 53, "4041": 28, "405": 28, "407": 29, "408": 24, "4090": 67, "4092": 28, "4096": [3, 14, 15, 18, 22, 23, 26, 27, 28, 29, 30, 33, 41, 42, 58, 78, 82, 88, 94, 97, 98, 107], "4096x12288": 26, "4096x22016": 26, "4096x32000": 26, "4096x4096": 26, "41": [15, 26, 27, 28, 29], "410": 82, "4126": 28, "4129": 26, "4135": 28, "415f4a74c63644b48f25a3fc6edc9e96": 47, "416": [15, 22, 27, 28, 29, 30, 41, 42], "4184": 26, "419": [28, 41], "41d4": 24, "42": [4, 24, 26, 28, 41, 45, 82, 90, 101], "420": 29, "4226": 41, "4241816997528076": 28, "424b": [125, 127], "4257": 28, "427": 29, "42781bd8c9114b22a983a10b98cdfe70": 29, "429": [28, 41], "42it": 26, "43": [4, 15, 26, 27, 30, 52, 78, 90], "4300": 82, "4311": 41, "4317": [15, 22, 23, 24, 27, 28, 29, 30, 41, 42, 88, 110], "4318": 110, "432": [28, 41], "433413": 109, "4337": 41, "4340292513370514": 118, "43464": 41, "43602": 28, "4378": 28, "438": [28, 41], "4396": [28, 41], "44": [4, 28, 41, 52], "4411": 28, "4418": 33, "442": 15, "44292": 28, "44441": 28, "446655440000": 24, "448": [15, 22, 27, 28, 29, 30, 41, 42], "44868": 28, "44it": 26, "45": [4, 15, 24, 27, 29, 30, 41, 61, 101], "4505": 52, "450560": 82, "45541": 27, "458": [28, 41], "4586": 28, "4588": 28, "458880": 82, "4594": 14, "45it": [26, 41, 101], "46": [4, 26, 27, 30, 41, 45, 47], "4608": [15, 22, 27, 28, 29, 30, 41, 42], "4623": 28, "465": 26, "4658": 28, "466": 29, "468": 41, "4695": 28, "46faba3011c84d2f8e80bc2b8d2596a": 26, "46it": [26, 27, 30, 41], "47": [15, 22, 26, 27, 41], "4710": [28, 41], "4718": 28, "4734": 28, "473858574": 15, "4755": 28, "476": [28, 41], "4792": 41, "47b": 125, "47it": 45, "48": [15, 22, 23, 26, 27, 28, 29, 30, 32, 33, 41, 42, 82, 88], "480": [15, 22, 27, 28, 29, 30, 41, 42, 82], "480b": 89, "480p": 64, "48177": 41, "482": [15, 41], "48506": 41, "486": 109, "487316894531251": 109, "48908": 103, "48924": 103, "48b": 125, "48e3d503df7448d0acf21d89173561b5": 52, "48it": 46, "49": [15, 26, 27, 28, 41, 45, 109], "491": 26, "49132": 15, "49152": 82, "4925": 41, "4934": 20, "4936": 26, "497": 28, "4977": 28, "498": [27, 38], "49b": 125, "49bc7099643443f187a6c262e24f425": 45, "49it": [15, 26], "4a": 53, "4b": [34, 45, 53, 64, 89, 119, 125, 127], "4bit": 19, "4c3f": 24, "4card": 82, "4f": [41, 121], "4fa5a7411cd84938956c1ce36e3be772": 47, "4gb": 13, "4k": [18, 53], "4mb": 8, "4th": 90, "4v": [125, 127], "4x": [24, 40, 70], "4xh100": 49, "5": [0, 1, 3, 5, 6, 12, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 39, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 60, 61, 62, 65, 68, 69, 74, 78, 79, 80, 81, 82, 83, 89, 91, 94, 95, 101, 103, 104, 107, 109, 113, 114, 115, 118, 119, 123, 124, 125, 127], "50": [4, 14, 15, 22, 23, 24, 26, 27, 28, 29, 30, 33, 41, 42, 45, 46, 47, 70, 75, 101, 103, 109], "500": [23, 24, 28, 53, 55, 58, 80, 97, 110, 118], "5000": [17, 24, 82, 83], "50000": [23, 82, 83, 84], "500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 28, "5004": 41, "50051": [11, 13], "5008": 28, "500m": 24, "50100": 27, "5018": 27, "502": 24, "503": 24, "504": [24, 28], "5067": 20, "50690": 15, "50702": 15, "50712": 15, "5081": 20, "50814177726902": 109, "5099354": 28, "50it": [15, 27], "50m": 24, "50mb": 24, "51": [15, 22, 26, 27, 41], "5109": 28, "512": [12, 14, 15, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 36, 41, 42, 53, 54, 78, 82, 83, 88, 94, 101, 119, 127], "5120": [15, 22, 27, 28, 29, 30, 41, 42], "512x768": 53, "514771912145079": 109, "515": 28, "5185": 28, "52": [15, 22, 26, 27, 28, 41, 47, 105, 125], "522": 15, "5226": 33, "5236556529998779": 41, "524": 41, "524288": 104, "52428800": 24, "525": 28, "5257": 41, "52576e69b3774d768c111603ec79bb56": 45, "527617": 27, "52844": 28, "52b": 125, "52it": [15, 26, 29], "53": [15, 26, 27, 28, 29, 41, 45], "530677782": 42, "532": 28, "5338": 28, "537": 28, "53it": [30, 101], "54": [15, 26, 29, 45, 47, 82, 101], "54115": 41, "54231": 28, "5432": 24, "5434": 20, "544": 64, "545": 33, "5479": 41, "54it": 26, "55": [15, 22, 26, 29, 30, 41], "550e8400": 24, "5512": 28, "557572e": 109, "558": 29, "55942": 28, "55it": 41, "56": [15, 20, 22, 26, 27, 28, 29, 30, 41, 42, 45, 47, 82], "562": 15, "5632": [15, 22, 27, 28, 29, 30, 41, 42], "5646": 28, "5648": 28, "565970778465271": 118, "56729": 41, "5678": 24, "56953125": 109, "56it": [15, 27], "57": [15, 26, 46, 47], "570": 30, "5707": 41, "5711": 28, "5724": 18, "57344": 20, "576": [15, 22, 27, 28, 29, 30, 41, 42, 82], "5786415f805c432288c12e8f9232fb2b": 27, "5791549598": 109, "57it": [15, 27], "58": [15, 26, 27, 38, 41, 45, 47, 52, 101], "5847": 28, "58it": [15, 22], "59": [15, 26, 41, 101], "593": 109, "594": [28, 41], "5944": 28, "595": 28, "596": 5, "59604": 28, "596463012695313": 109, "59667": 41, "5975": 28, "5976": 41, "5978": 28, "598442311": 41, "59924": 41, "59it": [15, 26, 28], "5_step": 74, "5b": [0, 15, 24, 26, 41, 42, 43, 45, 46, 52, 64, 89, 95, 115, 118, 123, 125], "5cdb391": 78, "5f6baec9587b4e9c8ff357820fb09b1d": 27, "5k": 82, "5m": [24, 39], "5moe": [89, 125], "5t": 125, "5v": [6, 48, 89, 127], "5x": [5, 32], "6": [15, 18, 22, 23, 24, 26, 27, 28, 29, 30, 37, 41, 42, 45, 46, 47, 48, 52, 53, 54, 61, 69, 79, 81, 82, 83, 89, 90, 91, 93, 101, 103, 108, 109, 113, 125, 127], "60": [24, 26, 27, 41, 47, 54, 82, 101, 103, 107, 109, 121, 127], "600": [17, 24, 63, 82, 84], "6000": [20, 82], "6017": 104, "602": 15, "602112": 127, "60390": 41, "60406": 41, "60420": 41, "60432": 41, "60442": 41, "606": 28, "60704": 27, "609": 27, "6099": 28, "60it": 47, "61": [15, 26, 38, 82, 101], "6121": 5, "614": [28, 41], "6144": [15, 18, 22, 27, 28, 29, 30, 41, 42], "6169": 28, "617": 33, "62": [15, 22, 26, 28, 29, 41], "62001": 33, "62166": 28, "6218433380126953": 27, "6218624114990234": 27, "6218678951263428": 27, "624": [28, 41, 82], "62it": 15, "63": [15, 26, 45], "6364": 28, "6379": 24, "64": [1, 11, 15, 18, 19, 22, 23, 24, 26, 27, 28, 29, 30, 33, 37, 41, 42, 45, 46, 47, 50, 51, 52, 53, 54, 58, 78, 82, 88, 94, 95, 97, 101, 104, 107, 110], "640": [15, 22, 27, 28, 29, 30, 41, 42], "64000": [33, 82], "642": 15, "646": [28, 41], "647c7f554502416e962e499243bb4d5": 27, "64g": 84, "64it": [15, 26, 41, 52], "64mb": 24, "64x11008": 26, "64x4096": 26, "65": [1, 15, 18, 26, 37, 42, 50], "650": [82, 83], "6501ef8e2d874006bf555bc80cddc7c5": 32, "6540": 28, "65536": [14, 30, 39, 82], "65it": [15, 27], "66": [15, 29, 82], "665": 5, "6656": [15, 22, 27, 28, 29, 30, 41, 42], "665690": 14, "666397525": 28, "6688": [81, 82, 83], "6690726": 27, "6690829": 27, "6690867": 27, "6699": 82, "66it": [15, 45], "67": [26, 33, 101], "6707": 28, "67108864": [5, 24], "671b": 125, "6722": [28, 41], "6771": 28, "6778": 20, "678": 28, "67890": 45, "67it": [26, 45], "68": [15, 26, 82, 83], "68000": 82, "6801": 28, "682": 15, "685": 82, "6864": 27, "689": 41, "6894": 28, "6896": 28, "6899": 20, "68ba3e8c32c44aacbe2a619f12170c60": 26, "68it": [41, 47], "69": [26, 30], "6980p": [32, 90], "69it": 15, "69x": [70, 71, 73], "6b": [76, 89, 119, 121, 125], "6k": 18, "6lcbd": 104, "6th": 90, "6v": [6, 48], "7": [14, 15, 22, 23, 24, 26, 27, 28, 29, 30, 39, 41, 45, 48, 52, 54, 62, 78, 81, 82, 84, 89, 91, 98, 101, 103, 104, 109, 113, 118, 125, 127], "70": [26, 47, 52, 54], "700": 28, "7007": 27, "7010": 20, "702": [28, 41], "7022946": 27, "7039": 28, "704": [15, 22, 27, 28, 29, 30, 41, 42], "7042": 28, "7071": 28, "70894": 41, "70b": [19, 29, 90], "70it": 27, "71": [26, 33, 82], "712400": 103, "7125738": 28, "7125852": 28, "712589": 28, "713": 41, "714": 28, "715": 41, "7168": [15, 22, 27, 28, 29, 30, 41, 42], "7196": 28, "719af8617f7941cf8857650e01f66a84": 45, "71it": [15, 41], "72": [15, 22, 26, 27, 28, 29, 30, 42, 45, 78, 82], "720": [61, 64, 82, 83], "720p": [53, 64], "722": 15, "7239": 82, "724149616ef84774859748e5f2ea153b": 27, "7273": 20, "728": 28, "7281": 28, "7285857": 41, "72b": [89, 123, 127], "72it": [26, 27], "73": [26, 28, 82, 109], "730975341796876": 109, "7333": 20, "7339": 82, "73594": 28, "73it": [26, 41], "74": [26, 39, 41, 45, 78, 82], "7407": 52, "742": 28, "7439": 82, "7482": 28, "7486296874999999": 30, "749": 38, "74it": 26, "74m": [104, 107], "75": [5, 15, 17, 18, 26, 27, 29, 39, 41, 45, 52, 70, 82, 101, 109, 125], "7512": 41, "752": 28, "7533": 20, "7546": 28, "756": 28, "75b": 125, "75it": 15, "76": [15, 26, 42, 45, 52], "762": 15, "76602": 28, "7667": 20, "768": [14, 15, 22, 27, 28, 29, 30, 41, 42, 82], "7680": [15, 22, 27, 28, 29, 30, 41, 42], "7697": 20, "76it": [41, 47], "77": [15, 26, 28, 41], "7707": 20, "772d3a9a2fd340ccaff6591ad2d8e99": 29, "773": 28, "773171160": 27, "7733": 20, "7772": 52, "77it": [15, 26, 29, 41, 101], "77x": 108, "78": [15, 20, 26, 41, 82, 83], "7826": 28, "783": 33, "785": 41, "78524888": 41, "788": [28, 33], "78it": [15, 22, 26, 101], "79": [15, 26, 82], "793": 33, "794": 27, "7946": 41, "797": 33, "7979": 18, "798": 33, "799": 33, "79it": [28, 29], "7ae557604adf67be50417f59c2c2f167def9a775": 41, "7b": [6, 19, 22, 26, 28, 29, 41, 47, 51, 55, 80, 89, 96, 101, 114, 119, 123, 125, 127], "7bc49e39aaeb46dea490ae29b197616f": 29, "7f": 103, "7fa2af80": 54, "7x": 32, "8": [1, 2, 4, 5, 8, 11, 12, 14, 15, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 33, 36, 37, 39, 40, 41, 42, 45, 50, 51, 52, 53, 54, 56, 58, 60, 62, 69, 70, 78, 79, 81, 83, 84, 86, 88, 91, 93, 94, 98, 101, 103, 104, 105, 107, 109, 113], "80": [15, 22, 24, 26, 27, 28, 29, 30, 39, 41, 42, 47, 58, 82, 94, 101], "800": [32, 84], "8000": [5, 7, 17, 24, 33, 40, 53, 54, 78, 81, 82, 83, 84, 104, 105, 107, 118], "8001": [24, 81, 82, 83, 121], "800i": [32, 81, 82], "802": 15, "803": [28, 33], "807": 28, "808": 33, "8080": [0, 11, 24, 76, 107], "80b": [29, 49, 89, 125], "80gb": 5, "80it": [26, 29, 41, 101], "81": [26, 28, 29, 82, 83], "813": 33, "815": [82, 83], "816043786240": 11, "8173": 41, "8188": [82, 83], "8192": [8, 14, 15, 22, 26, 27, 28, 29, 30, 37, 41, 42, 50, 58, 82, 83, 93, 94, 97, 103], "81it": [26, 41], "82": [5, 14, 26, 90], "821": 28, "824": 33, "825": [29, 41], "82it": [15, 26, 29], "82m": 15, "83": [15, 26, 33, 41, 82], "8304": 41, "8312a342a0ef4b2fabb95bc68fcb2e80": 27, "832": [15, 22, 27, 28, 29, 30, 41, 42, 82, 83], "835": [22, 27, 28, 29, 42], "838": 33, "83it": 29, "84": [15, 26, 82, 103], "840": 33, "841": [15, 41], "842": 15, "8420": 28, "84204177856446": 109, "8443": 24, "84492": 41, "845": 109, "847": 28, "848": 33, "849": [104, 107], "8491": 41, "84a6096a35e24f529324aae34189d23b": 28, "84it": [26, 29, 52, 101], "85": [11, 18, 26, 29, 40], "8542968750000001": 109, "855": 109, "85910": 41, "85it": [26, 101], "86": [26, 41, 82, 90, 109], "860": 82, "862": [28, 41], "8658": 41, "866964": 109, "86it": 47, "87": [15, 26, 33], "879": 33, "87it": [15, 29], "88": [15, 22, 24, 27, 28, 29, 30, 41, 42, 82, 83], "882": 15, "8832519531250003": 109, "8833": 38, "8846": 18, "8884": [55, 80], "8886": 41, "88it": [26, 41], "89": [26, 42, 103], "892": 28, "8926": 28, "894": 28, "89469451904297": 109, "896": [15, 22, 27, 28, 29, 30, 41, 42], "8965": 110, "8995": [81, 82], "8996": 83, "8998": [15, 22, 23, 27, 28, 29, 30, 33, 41, 42, 82, 83, 88], "8999": [82, 83], "89b02de54d2945189b1039fe310d3a7a": 27, "89it": 29, "8b": [1, 2, 3, 5, 7, 15, 17, 19, 23, 24, 26, 27, 29, 35, 41, 51, 53, 54, 76, 79, 81, 89, 90, 91, 93, 95, 109, 111, 113, 115, 121, 123, 125, 127], "8c70": 24, "8card": 82, "8e96d80c3cb64c3eb1ee2586befb0f13": 15, "8t": 125, "8th": 45, "8x": [5, 32, 40], "8xh100": [36, 39], "8xh200": 33, "9": [14, 15, 22, 23, 26, 27, 28, 29, 30, 32, 33, 36, 38, 41, 42, 45, 49, 53, 54, 60, 62, 69, 91, 94, 95, 101, 103, 109, 113], "90": [15, 24, 26, 29, 33, 82], "9000": [82, 83, 86], "9001": 24, "902": 28, "9069": 28, "9080": 41, "9090": 109, "90ab": 24, "90it": 29, "91": [15, 26, 41], "910b": [81, 84], "911": 28, "912": 28, "9120": 2, "9124": 20, "9152": 20, "9154": 20, "9157": 20, "916": 28, "9161": 20, "9163": 20, "9168": 20, "9177122": 27, "9181": 20, "9186": 20, "9186001": 29, "91it": [26, 41, 101], "92": [5, 26, 27, 28, 29, 33], "922": 15, "9220": [55, 80], "9221679687500002": 109, "9292": 28, "92999": 41, "92it": [26, 41], "93": [15, 26, 103], "9363": 41, "94": [15, 26, 33], "941": 109, "9420": 41, "944": 28, "9454": 41, "94it": [26, 41, 101], "95": [19, 22, 24, 26, 27, 28, 29, 33, 42, 45, 98, 124], "950195e": 109, "956": 33, "959889428": 30, "95it": [15, 26, 29, 42, 47], "96": [5, 15, 22, 26, 27, 28, 29, 30, 32, 33, 41, 42, 82, 94, 106], "960": [15, 22, 27, 28, 29, 30, 41, 42, 64], "962": 15, "9625": [28, 41, 52], "9658": 28, "966": 28, "96g": 33, "96gb": 40, "96it": 42, "97": [15, 26], "9716": 41, "9720": 41, "9729": 41, "9733": 28, "9763": 41, "97904": 28, "97it": 26, "97m": [104, 107], "98": [26, 41], "9806": 52, "9822": 27, "983": 54, "984": 23, "99": [24, 26, 121], "990": 28, "992": 23, "996": 23, "998": 23, "9998": 14, "999999": 39, "99it": [15, 26], "9b": [89, 125, 127], "9bf17f2847b046c7b2d5495f4b4f9682": 118, "9c5dbfc57": [104, 107], "9d2f2da9dd2140a0b2468e5b86c7322f": 26, "9dff": 103, "9ea4389e705b4605be26e729bcb5226c": 15, "9k": 82, "9th": 45, "9x": 32, "A": [5, 6, 8, 9, 12, 14, 17, 18, 22, 23, 24, 25, 26, 32, 33, 42, 51, 54, 55, 57, 61, 62, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 80, 90, 93, 95, 103, 110, 116, 119, 121, 123, 125, 127], "And": [18, 28, 38, 108], "As": [12, 14, 15, 18, 26, 42, 47, 54, 127], "At": [12, 33, 72, 75, 103, 104, 107], "Be": 25, "But": [5, 15, 26, 28, 33, 45], "By": [4, 8, 11, 12, 14, 15, 16, 17, 18, 23, 25, 26, 32, 38, 51, 74, 75, 76, 96, 109, 115, 116, 127], "For": [0, 1, 3, 8, 9, 11, 12, 13, 15, 17, 18, 19, 22, 24, 25, 26, 27, 29, 32, 33, 34, 36, 37, 38, 39, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 65, 68, 69, 70, 71, 72, 74, 77, 78, 80, 90, 91, 94, 99, 103, 107, 109, 110, 113, 115, 119, 121, 125, 127], "If": [0, 1, 3, 5, 9, 12, 13, 14, 15, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 42, 43, 45, 50, 51, 53, 54, 55, 56, 57, 61, 62, 72, 74, 76, 79, 80, 81, 82, 88, 90, 92, 94, 96, 97, 98, 103, 108, 109, 110, 111, 115, 118, 119, 121, 125, 127], "In": [0, 3, 5, 6, 7, 8, 9, 12, 15, 17, 18, 22, 24, 25, 26, 27, 28, 29, 32, 36, 37, 38, 41, 42, 45, 46, 47, 52, 55, 56, 64, 79, 80, 90, 91, 94, 97, 98, 101, 103, 104, 110, 113, 115], "It": [1, 3, 5, 6, 8, 12, 13, 14, 15, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 38, 40, 41, 42, 45, 49, 50, 51, 52, 53, 54, 55, 57, 67, 68, 70, 71, 73, 75, 76, 77, 80, 84, 90, 96, 99, 115, 119, 125, 127], "Its": [8, 32, 42, 77], "NOT": [29, 96, 121], "No": [4, 5, 9, 10, 15, 20, 22, 24, 26, 27, 28, 29, 30, 38, 41, 45, 46, 47, 52, 64, 72, 78, 97, 101, 109], "Not": [1, 5, 20, 23, 53, 84, 97], "OFED": 103, "Of": 101, "On": [6, 12, 14, 18, 20, 25, 33, 37, 50, 76, 90, 106, 110], "One": [15, 23, 25, 45, 51, 62], "Or": [3, 17, 19, 24, 26, 29, 30, 53, 61, 67, 93, 114], "Such": 101, "THE": 45, "That": [28, 84, 115, 116], "The": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 60, 61, 62, 64, 66, 68, 69, 70, 72, 74, 75, 76, 78, 79, 81, 84, 85, 88, 90, 91, 93, 94, 95, 97, 99, 101, 102, 103, 104, 107, 109, 110, 111, 113, 115, 116, 118, 121, 125, 127], "Their": 110, "Then": [0, 15, 19, 24, 28, 33, 37, 43, 55, 60, 70, 80, 103, 105, 109, 115], "There": [28, 30, 42, 49, 56, 96], "These": [8, 19, 23, 26, 35, 38, 45, 55, 66, 71, 75, 80, 97, 108, 110, 115, 123, 125, 127], "To": [0, 1, 4, 5, 7, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 32, 33, 36, 38, 39, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 72, 73, 75, 76, 78, 79, 80, 85, 90, 94, 98, 101, 104, 108, 109, 110, 114, 115, 127], "Will": 1, "With": [0, 1, 5, 15, 18, 24, 25, 32, 33, 40, 53, 54, 74, 79, 94, 127], "_": [9, 33, 101], "____": 42, "__call__": [51, 115], "__future__": 57, "__global__": 57, "__init__": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 59, 101, 115], "__main__": [19, 83, 115, 124], "__name__": [9, 19, 83, 115, 124], "__post_init__": 69, "_attn_implement": 116, "_bootstrap_extern": [22, 27, 28, 29, 30, 42], "_build": 0, "_commun": 13, "_dynamo": 26, "_flash_3_hub": [61, 69], "_forward_attn": 8, "_forward_combin": 8, "_forward_dispatch": 8, "_forward_mlp": 8, "_is_idle_for_hicache_storage_op": 13, "_is_no_request": 13, "_jit_add_constant_modul": 57, "_output_": 33, "_pp_commit_comm_work": 18, "_pp_launch_batch": 18, "_pp_process_batch_result": 18, "_pp_send_pyobj_to_next_stag": 18, "_register_config": 75, "_required_config_modul": 75, "_supports_attention_backend": 116, "_work": 41, "a10": 76, "a100": [1, 5, 32, 37, 50, 67, 76, 77], "a14b": [61, 64], "a1b2c3d4": 24, "a2": [33, 41, 81, 84, 88, 89, 103], "a22b": [11, 20, 22, 50, 89, 90, 127], "a292cabb151843b88ae8db7ab2ac134": 47, "a2a": [5, 8, 17, 23, 82, 83, 84, 88, 97, 104, 107], "a2b27aa70a66dc36ce71116f6c6a259dd1b23c17": 15, "a2b69470ad05454da432647a0cf094b7": 52, "a2dc": 103, "a3": [32, 33, 81, 84, 88, 89], "a35b": 89, "a36b": [89, 125], "a3b": [29, 49, 50, 81, 89, 125, 127], "a40": 1, "a716": 24, "a7b9ca17790e4ed0b89d90d4a4b0f915": 26, "a7f62bc7befc401babe9feb82eff53c0": 52, "a800": 32, "a800m": [89, 125], "aarch64": 76, "ab": [5, 24, 69], "abbrevi": [27, 28, 29], "abc": 12, "abi3": 76, "abil": [15, 42, 45, 125], "abl": [15, 30, 109, 115], "abnorm": [19, 74], "abort": [23, 25, 88], "abort_al": 25, "abort_all_request": 25, "abort_on_priority_when_dis": [15, 22, 27, 28, 29, 30, 41, 42], "about": [9, 12, 14, 15, 21, 23, 26, 27, 28, 38, 42, 45, 56, 62, 95, 96, 98, 101, 102, 115, 116, 127], "abov": [8, 11, 23, 26, 29, 32, 43, 45, 51, 53, 54, 55, 76, 80, 90, 95, 98, 99, 101, 103, 110, 115], "absolut": [0, 24], "absorpt": 32, "abstract": 8, "abus": [55, 80], "acc": [23, 78, 88], "acc_length": 78, "acc_typ": 26, "acceler": [2, 8, 14, 23, 26, 32, 61, 73, 76, 77, 83, 94], "accelerator_arg": 94, "accept": [17, 20, 23, 24, 26, 45, 51, 53, 57, 62, 69, 70, 78, 88, 105, 115, 124, 125, 127], "accept_length": 53, "access": [7, 12, 23, 24, 25, 27, 28, 32, 45, 54, 61, 66, 74, 76, 78, 90, 94, 97, 103, 104, 107, 109, 110, 115], "accommod": 110, "accomplish": [42, 45], "accord": [1, 17, 18, 19, 28, 29, 38, 42, 49, 54, 65, 90, 103, 104, 107], "accordingli": [0, 22, 28, 29, 41], "account": [3, 20, 42, 55, 80, 98], "accumul": [20, 71, 72, 73, 97, 98], "accur": [23, 28, 30, 42, 49, 119, 127], "accuraci": [19, 23, 25, 26, 28, 70, 83, 115, 121, 125, 127], "achiev": [4, 5, 8, 12, 15, 18, 25, 26, 32, 33, 45, 70, 71, 73, 84, 94, 98, 103, 108, 125, 127], "across": [2, 4, 5, 6, 8, 11, 12, 13, 15, 18, 20, 23, 24, 25, 32, 33, 54, 57, 69, 71, 72, 73, 74, 75, 77, 78, 94, 97, 98, 99, 105, 108, 110, 125], "act": [29, 38, 43, 75, 101], "action": [19, 24, 41, 42, 78], "activ": [8, 9, 13, 14, 19, 23, 24, 25, 32, 40, 42, 54, 62, 77, 81, 85, 90, 94, 95, 97, 101, 103, 105, 125], "actual": [8, 9, 12, 15, 18, 22, 26, 27, 28, 29, 40, 41, 45, 46, 47, 52, 101, 104, 107, 109, 110, 118], "ad": [0, 4, 5, 15, 16, 18, 23, 24, 29, 38, 45, 55, 57, 65, 67, 75, 76, 77, 80, 84, 109, 110, 112], "ada": 1, "adapt": [8, 15, 23, 33, 61, 62, 70, 75, 81, 94, 103, 115], "adapter_a": [15, 45], "adapter_b": 45, "adb": 24, "add": [0, 2, 5, 8, 11, 19, 22, 23, 25, 26, 27, 28, 29, 32, 36, 38, 39, 42, 46, 49, 51, 53, 54, 56, 58, 65, 74, 75, 76, 78, 79, 81, 85, 90, 98, 104, 107, 109, 127], "add_const": 57, "add_constant_kernel": 57, "add_generation_prompt": [22, 27, 28, 29], "add_link": 110, "add_special_token": 41, "add_stag": 75, "addit": [2, 4, 15, 18, 20, 22, 23, 25, 28, 29, 42, 45, 55, 69, 70, 71, 73, 76, 80, 94, 97, 99, 110, 115, 118], "addition": [7, 26, 32, 33, 42, 54, 90, 95, 103], "addr": [2, 17, 18, 23, 33, 82, 83, 84, 88, 91, 94, 103, 104, 105, 107, 113], "address": [2, 5, 7, 8, 11, 12, 17, 18, 21, 23, 24, 25, 90, 95, 97, 98, 101, 103, 105], "adept": 125, "adject": 41, "adjust": [23, 26, 32, 39, 40, 41, 49, 53, 90, 94, 98, 104, 107, 109, 127], "admin": [11, 23, 88, 109], "admin_api_kei": [15, 22, 23, 27, 28, 29, 30, 41, 42], "administr": [23, 28], "adopt": [23, 24, 77, 84], "adv": 54, "advanc": [5, 8, 15, 33, 38, 40, 51, 54, 57, 71, 73, 110, 125, 127], "advanced_featur": 0, "advantag": 5, "adversari": 15, "advis": 27, "aerob": 101, "affect": [12, 15, 17, 19, 23, 81, 94], "affin": [18, 24, 81, 97], "aflah02": 105, "afm": [89, 125], "aforement": [18, 33], "africa": 45, "after": [0, 3, 5, 6, 8, 12, 13, 15, 17, 19, 22, 23, 24, 25, 26, 32, 37, 40, 42, 50, 52, 53, 54, 57, 61, 74, 84, 88, 93, 98, 104, 110, 115, 124, 127], "afterward": [3, 26, 79], "ag": [42, 103], "again": [12, 15, 19, 26, 29, 30, 45, 55, 62, 79, 80, 85, 115], "against": [0, 12, 15, 19, 23, 53, 99, 121], "agenc": [28, 125], "agent": [22, 24, 40, 52, 53, 125], "aggreg": [12, 13, 53, 63, 110], "aggress": [18, 24, 124], "agnost": 8, "agx": 93, "ahead": 57, "ai": [1, 5, 8, 17, 18, 20, 22, 24, 27, 28, 29, 31, 32, 33, 38, 42, 45, 52, 56, 61, 62, 64, 78, 79, 81, 84, 89, 90, 91, 93, 103, 104, 107, 113, 115, 125, 127], "aibrix": [12, 13, 23], "aid": [15, 42, 57], "aidc": 61, "aig": 104, "ailuropoda": [41, 121], "aim": [26, 32, 97, 101, 103], "aime25": [20, 33], "aiohttp": 53, "aiter": [1, 23, 33, 39, 69, 88, 97], "aiter_attn": 23, "aiv": [82, 84, 86], "ai\u52a9\u624b": [104, 107], "alert": 24, "alexand": 15, "algo": 49, "algoprog": 15, "algorithm": [5, 12, 18, 19, 23, 26, 32, 33, 36, 38, 39, 49, 82, 83, 86, 88, 94, 97, 104, 107, 124], "alia": [24, 79, 81], "alias": 69, "alibaba": [41, 46, 50, 61, 89, 119, 125, 127], "align": [18, 19, 23, 24, 25, 108, 123, 125, 127], "alik": 42, "aliv": [25, 42, 101], "all": [0, 1, 2, 4, 5, 6, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 25, 28, 29, 30, 32, 33, 40, 42, 45, 47, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 67, 68, 70, 72, 73, 74, 75, 76, 80, 81, 88, 94, 97, 99, 104, 110, 114, 115, 118, 121, 124, 127], "all2al": 5, "all_attention_funct": 116, "all_hip": 79, "all_musa": [68, 92], "all_npu": 81, "all_other_model": 115, "all_reduc": 12, "allen": 125, "allenai": [19, 89, 125], "allevi": 12, "allgath": [23, 88], "alloc": [3, 8, 12, 14, 15, 23, 41, 54, 94, 97, 109], "allocator_ascend": [55, 80], "allow": [2, 3, 8, 11, 12, 16, 18, 20, 23, 24, 26, 28, 32, 37, 42, 43, 45, 50, 54, 56, 57, 61, 67, 68, 75, 76, 88, 94, 97, 104, 110, 115, 118, 119, 121, 124, 127], "allow_auto_trunc": [15, 22, 27, 28, 29, 30, 41, 42], "allow_tf32": 26, "allreduc": [23, 88], "almost": [70, 115], "alon": [15, 74], "along": [15, 26, 28, 38, 41, 76, 79, 101, 125, 127], "alongsid": [24, 54, 76, 127], "alpha": [94, 125], "alreadi": [12, 13, 15, 17, 18, 19, 32, 38, 42, 43, 80, 85, 90, 109, 110, 119], "alright": [26, 28], "also": [1, 3, 5, 11, 12, 13, 14, 15, 18, 19, 22, 23, 25, 26, 28, 29, 32, 33, 38, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 74, 76, 79, 80, 93, 96, 98, 101, 103, 104, 105, 108, 110, 115, 116, 121, 127], "altern": [0, 11, 12, 18, 19, 23, 47, 57, 73, 97, 99, 112, 123], "although": 18, "altogeth": 28, "alwai": [0, 1, 4, 14, 15, 20, 22, 23, 24, 27, 28, 29, 42, 45, 51, 55, 65, 66, 69, 70, 80, 94, 118, 121], "am": [42, 45], "amazon": [12, 76], "amazonaw": 76, "ambush": 15, "amd": [8, 19, 33, 39, 60, 67, 76, 77, 97], "america": [27, 28], "among": [11, 12, 26, 32, 97, 108, 110], "amount": [15, 18, 42, 45, 90], "amper": [1, 8], "amplifi": 62, "amx": [1, 23, 90], "amxint4": [15, 23, 41, 88], "an": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 43, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 66, 67, 72, 74, 75, 76, 79, 80, 81, 82, 84, 88, 90, 91, 92, 97, 98, 99, 101, 103, 108, 109, 110, 113, 114, 123, 124, 125, 127], "analysi": [18, 22, 23, 29, 56, 73, 74, 94], "analyst": 38, "analyt": 42, "analyz": [8, 18, 24, 41, 54, 75, 127], "ancient": [5, 15, 45], "angelslim": 94, "ani": [1, 5, 9, 12, 15, 16, 17, 18, 19, 23, 24, 25, 26, 28, 29, 32, 33, 42, 45, 51, 54, 55, 57, 58, 61, 64, 65, 69, 74, 76, 80, 81, 82, 88, 101, 103, 115, 116, 118, 119], "anim": [15, 30], "annot": [23, 24, 26, 29, 45, 52, 54, 57], "annual": 42, "anonym": 110, "anoth": [1, 14, 15, 17, 18, 23, 26, 28, 30, 47, 54, 79, 90, 95, 98, 101, 110], "answer": [22, 24, 26, 27, 28, 29, 41, 42, 45, 99, 101, 121, 127], "ant": 8, "antidisestablishmentarian": 99, "anyth": 45, "aot": 57, "apach": 125, "apart": 41, "apeach": [24, 89, 118, 123], "api": [9, 12, 25, 40, 51, 61, 67, 76, 77, 78, 90, 94, 95, 96, 99, 101, 103, 104, 110, 117, 120, 124, 127], "api_kei": [15, 22, 24, 26, 27, 28, 29, 30, 32, 36, 38, 41, 42, 45, 46, 47, 51, 52, 62], "apigroup": 24, "apivers": [24, 103, 104, 107], "app": [23, 24, 78, 104, 107], "appear": [23, 30, 45, 47, 51, 54, 55, 80, 101], "append": [4, 9, 29, 32, 40, 53, 79, 97], "append_messag": 30, "appli": [0, 5, 7, 8, 13, 15, 19, 23, 24, 26, 30, 32, 40, 41, 42, 45, 53, 55, 56, 61, 62, 64, 69, 70, 75, 76, 80, 81, 90, 97, 103, 104], "applic": [5, 13, 15, 24, 30, 32, 40, 41, 46, 47, 52, 54, 62, 65, 90, 103, 104, 107, 118, 121, 124], "apply_chat_templ": [22, 27, 28, 29, 39, 41], "apply_softmax": 41, "appreci": [55, 80], "approach": [4, 12, 14, 15, 18, 32, 54, 71, 73, 76, 104], "appropri": [0, 12, 18, 19, 26, 29, 45, 53, 75, 118], "approv": [55, 80], "approxim": [5, 20, 28, 90], "april": 25, "apt": [0, 54, 57, 60], "ar": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 61, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 84, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 115, 116, 119, 121, 123, 124, 125, 127], "arbitrari": 9, "arc": 95, "arcane_jinx": 64, "arce": [89, 125], "arch": 60, "architectur": [1, 5, 6, 7, 8, 18, 19, 20, 25, 32, 38, 41, 45, 54, 77, 84, 94, 115, 117, 119, 124, 125, 127], "area": [28, 42, 101], "areal": [77, 108], "aren": 26, "arg": [17, 21, 24, 41, 54, 56, 57, 83, 97, 99, 119, 127], "argument": [1, 5, 8, 19, 20, 21, 24, 27, 28, 29, 32, 33, 36, 37, 39, 41, 45, 49, 50, 51, 53, 54, 55, 57, 65, 69, 76, 77, 80, 85, 88, 91, 93, 110, 113, 115], "arguments_non_stream": 29, "aris": 98, "arm64": 24, "around": [24, 28, 29, 32, 75, 115], "arrai": [45, 51, 53, 74, 118], "arrang": 8, "arriv": [23, 53], "art": [15, 55, 80, 108, 125], "arthriti": 42, "articl": [38, 42], "artifact": [0, 61, 78], "artifici": [42, 115, 121], "ascend": [1, 23, 76, 77, 80, 83, 84, 85, 86, 91, 113], "ascend_attn": [23, 81, 86, 88], "ascend_fuseep": [8, 23, 82, 88], "ascend_home_path": 82, "ascend_instal": [81, 84], "ascend_launch_block": [82, 83, 84], "ascend_mf_store_url": [17, 81, 82, 83], "ascend_mf_transfer_protocol": 81, "ascend_npu_phy_id": 17, "ascend_rt_visible_devic": [91, 113], "asia": 45, "ask": [22, 28, 29, 41, 42, 45, 55, 77, 80, 101], "aspect": [2, 23, 25], "aspect_ratio_id": 30, "aspect_ratio_mask": 30, "assembl": 75, "assert": [25, 41, 51, 54], "asset": [30, 37, 47, 50, 51, 101], "assign": [5, 15, 51], "assist": [12, 26, 27, 28, 29, 30, 32, 38, 40, 41, 42, 45, 47, 51, 52, 96, 99, 101, 104, 107, 124], "assistant_begin": 101, "assistant_end": 101, "associ": [4, 24, 32], "assum": [13, 22, 24, 28, 29], "assumpt": 25, "astral": 90, "astronomi": 42, "async": [11, 23, 25, 42, 88, 115], "async_gener": [42, 115], "async_send": 18, "async_stream_and_merg": 42, "asynchron": [15, 18, 23, 25, 37, 50, 108, 115], "asyncio": 115, "at_least_on": 27, "atb": [82, 83, 84], "atla": [32, 81, 82, 84], "atp": 24, "atp_dsn": 24, "atp_password": 24, "atp_pool_max": 24, "atp_pool_min": 24, "atp_tns_alia": 24, "atp_us": 24, "atp_wallet_path": 24, "attach": [9, 10, 11, 24, 127], "attach_point": 24, "attach_storage_backend": 13, "attachment_ep_statist": 104, "attact": 29, "attain": 14, "attempt": [12, 24, 53], "atten_tp_s": 33, "attent": [4, 8, 12, 14, 15, 17, 18, 19, 20, 22, 25, 26, 27, 28, 29, 30, 33, 37, 39, 41, 42, 45, 46, 47, 50, 52, 61, 67, 75, 76, 77, 81, 82, 83, 84, 86, 91, 93, 95, 97, 101, 103, 104, 107, 113, 115, 116, 119, 121, 125], "attention_backend": [15, 22, 27, 28, 29, 30, 41, 42, 69, 70, 91, 113], "attention_interfac": 116, "attentionbackendenum": 69, "attn": [23, 64, 69, 82, 83, 88], "attn_output": 116, "attn_weight": 116, "attract": [28, 29, 42, 99], "attribut": [9, 110], "attributeerror": 9, "audio": [23, 26, 29, 41, 45, 51, 52, 127], "audio_data": 51, "audiodataitem": 51, "aug": 38, "augment": [125, 127], "august": 38, "augustu": 45, "aura": 15, "auror": 101, "australia": [15, 26, 45, 52, 101], "auth": [24, 53, 78], "authent": 78, "author": [23, 24, 42, 53, 55, 62, 80, 104, 107], "auto": [0, 8, 15, 22, 23, 24, 26, 27, 28, 29, 30, 39, 41, 42, 53, 57, 61, 69, 70, 82, 83, 84, 88, 97, 109, 111, 124], "auto_awq": 19, "auto_gptq": 19, "auto_map": 116, "auto_next_anon": 110, "auto_round": 19, "autoencod": [61, 75], "autoencoder_kl_qwenimag": 75, "autograd": 54, "autom": [42, 79], "automat": [0, 5, 8, 11, 12, 13, 15, 18, 19, 20, 23, 24, 25, 29, 30, 33, 37, 39, 41, 45, 49, 50, 51, 53, 54, 55, 57, 61, 62, 66, 70, 71, 72, 75, 76, 78, 80, 85, 90, 97, 109, 110, 118], "autonom": [24, 42], "autoprocessor": 30, "autoregress": [7, 20, 26, 35, 124], "autoround": 19, "autoroundmllm": 19, "autosc": 76, "autotag": 93, "autotoken": [19, 22, 27, 28, 29, 41, 46], "autotun": [23, 26, 88, 111], "auxiliari": 17, "avail": [1, 5, 12, 15, 17, 18, 21, 23, 25, 26, 27, 28, 32, 33, 38, 41, 43, 45, 46, 47, 52, 53, 57, 61, 67, 68, 69, 72, 73, 76, 77, 79, 90, 94, 97, 98, 103, 109, 116, 118, 125], "avail_mem": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 47, 52, 101], "available_gpu_mem": [14, 15, 41], "available_tool": 29, "averag": [23, 28, 99], "avg": 33, "avg_token": 33, "avinci1": 84, "avoid": [11, 12, 13, 15, 18, 19, 20, 23, 25, 28, 30, 33, 37, 39, 45, 50, 54, 55, 56, 74, 80, 90, 91, 94, 95, 98, 103, 113, 114, 121, 127], "aw": [61, 66], "awai": 61, "await": [42, 115], "awar": [5, 17, 25, 42, 108], "awk": [82, 83, 84], "awq": [19, 23, 32, 77, 85], "awq_marlin": [19, 23], "aws_account": 76, "aws_region": 76, "b": [4, 5, 15, 22, 23, 26, 27, 28, 29, 30, 32, 33, 41, 42, 45, 46, 47, 52, 62, 76, 79, 82, 83, 84, 88, 90, 95, 98, 101, 103, 104, 107, 110], "b0538434881346ba8fed014d4f103a6d": 26, "b200": [1, 32, 33, 37, 39, 50, 67], "b300": [76, 77], "b580": 95, "b64_json": 62, "b64decod": 62, "baai": [41, 89, 119, 121, 125], "back": [1, 5, 8, 23, 24, 25, 30, 33, 47, 62, 63, 69, 75, 97, 116, 118, 127], "backbon": [77, 108, 127], "backend": [5, 7, 10, 18, 20, 22, 25, 26, 27, 28, 30, 32, 33, 37, 38, 39, 41, 42, 43, 45, 46, 47, 50, 51, 52, 54, 55, 58, 67, 76, 77, 79, 80, 81, 82, 83, 84, 86, 90, 91, 93, 95, 99, 101, 104, 105, 107, 108, 109, 112, 113, 115, 116, 119, 121, 127], "backend_nam": [11, 12, 23], "backendfactori": 11, "background": [15, 24, 30, 47, 61, 101, 109, 116], "backoff": 24, "backtrac": 54, "backu": 29, "backup": [13, 23, 88], "backward": [15, 23, 45, 62], "bad": [9, 99, 118], "baichuan": [89, 125], "baichuan2": [89, 125], "baichuanai": 125, "baidu": [89, 125, 127], "bail": 94, "balanc": [7, 11, 12, 17, 18, 23, 32, 38, 45, 47, 70, 72, 82, 83, 88, 94, 101, 104, 108], "balanced": [8, 23], "band": 101, "bandit": 15, "bandwidth": [2, 6, 7, 12, 17], "bank": [28, 52], "bar": [56, 125, 127], "bare": 90, "barex": [17, 97], "base": [0, 1, 6, 7, 8, 11, 12, 15, 17, 19, 20, 23, 24, 26, 28, 30, 32, 33, 37, 38, 39, 40, 42, 45, 50, 51, 53, 54, 62, 70, 71, 72, 73, 75, 77, 78, 81, 82, 84, 88, 89, 90, 94, 97, 99, 103, 105, 106, 110, 111, 119, 121, 123, 125, 127], "base64": [25, 30, 45, 51, 62], "base_config": 115, "base_gpu_id": [15, 22, 27, 28, 29, 30, 41, 42], "base_url": [22, 26, 27, 28, 29, 32, 36, 38, 39, 41, 45, 46, 47, 51, 52, 54, 62], "basedispatch": 8, "baseformatdetector": 29, "baselin": [5, 12, 15, 18, 65, 67, 70, 77, 115], "basemodel": [27, 28], "basemultimodalprocessor": 115, "basereasoningformatdetector": 22, "bash": [0, 33, 54, 59, 60, 76, 82, 84, 90, 93, 94, 105], "bashrc": [54, 90], "basi": 33, "basic": [5, 15, 53, 54, 88, 91, 113, 125], "basic_qa": 101, "batch": [3, 4, 5, 6, 12, 15, 17, 18, 22, 25, 26, 27, 28, 29, 30, 32, 33, 38, 41, 45, 47, 51, 52, 53, 54, 55, 56, 58, 65, 77, 78, 80, 90, 94, 97, 98, 103, 104, 127], "batch_get_v1": 11, "batch_set_v1": 11, "batch_siz": [19, 39, 78], "batchspanprocessor": 97, "bb04702705344749a9192d00ff893625": 27, "bc": 45, "be9dc199044e43519e3c977e142f9bc7": 27, "beach": 121, "beach_dog": 121, "bear": [41, 121], "bearer": [23, 24, 53, 62, 104, 107], "beast": 15, "beauti": [15, 61, 67, 70, 71, 73], "becam": 15, "becaus": [6, 12, 15, 25, 26, 28, 29, 53, 83, 88, 101, 115], "becom": [2, 3, 6, 13, 15, 18, 20, 23, 42, 108], "been": [12, 15, 18, 19, 25, 26, 28, 33, 45, 54, 64, 84, 85, 90, 94, 95, 103], "befor": [0, 1, 2, 8, 12, 13, 14, 15, 16, 17, 19, 20, 23, 24, 25, 28, 29, 32, 53, 54, 55, 57, 58, 62, 66, 69, 70, 74, 75, 80, 88, 93, 94, 110, 115, 127], "beforehand": [32, 90], "began": 15, "begin": [15, 27, 28, 41, 54, 101, 110], "behav": 1, "behavior": [8, 17, 23, 24, 25, 29, 37, 50, 51, 53, 70, 97, 121, 123, 127], "behind": [8, 15, 18, 23, 24, 43, 78], "beij": [27, 28, 32], "being": [1, 5, 6, 14, 15, 17, 18, 23, 42, 45, 110], "believ": [15, 26, 28, 42], "bellatrix": 101, "belong": [12, 15, 41], "below": [1, 13, 15, 23, 26, 29, 30, 33, 37, 41, 50, 51, 56, 60, 64, 68, 69, 71, 72, 73, 76, 79, 81, 90, 92, 101, 110, 115, 117, 119, 124, 125, 127], "bench": [26, 54, 77, 119], "bench_one_batch": [54, 56, 115], "bench_one_batch_serv": [54, 58, 94], "bench_serv": [53, 58, 79, 82, 90, 94, 95, 109], "bench_sglang": [33, 56, 58], "bench_specul": [26, 32, 33], "benchmark": [5, 12, 15, 16, 17, 18, 19, 26, 41, 53, 56, 58, 65, 77, 78, 79, 109, 127], "benchmark_and_profil": 115, "benefici": [14, 101], "benefit": [12, 15, 20, 24, 25, 54, 97], "berlin": [26, 27, 28, 41, 45, 99], "berlin3": 101, "bertforsequenceclassif": [24, 118], "besid": [11, 26, 74, 101], "bespok": 99, "best": [1, 7, 10, 12, 13, 25, 26, 30, 32, 33, 37, 45, 50, 70, 71, 87, 94, 121], "best_effort": [11, 12, 15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "best_kernel": 26, "best_kernel_desc": 26, "best_tim": 26, "best_triton_kernel": 26, "best_triton_kernel_desc": 26, "best_triton_po": 26, "best_triton_tim": 26, "better": [5, 12, 14, 15, 18, 19, 20, 23, 24, 27, 32, 33, 41, 45, 51, 57, 70, 76, 94, 119, 124, 127], "between": [1, 2, 5, 8, 11, 12, 14, 17, 18, 20, 21, 23, 32, 33, 36, 38, 41, 43, 51, 53, 54, 71, 72, 73, 75, 94, 101, 104, 108, 119, 125, 127], "bewar": 90, "beyond": [12, 24, 32, 33, 42], "bf": [15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 88], "bf16": [8, 19, 20, 23, 29, 32, 33, 38, 61, 62, 69, 73, 75, 82, 84, 88, 90, 95, 97, 127], "bfloat16": [15, 19, 23, 26, 41, 49, 82, 83, 88, 93, 94, 97, 127], "bge": [41, 89, 119, 121], "bgererankmodel": 121, "bia": 115, "bias": [42, 115], "bidirect": 24, "big": 28, "bigcod": [89, 125], "biggest": 3, "bilingu": [84, 125], "bill": 24, "billion": [40, 90, 125], "bin": [23, 33, 56, 60, 66, 70, 76, 82, 83, 90, 94, 105], "binari": [57, 91, 113], "bind": [22, 27, 28, 29, 30, 42, 57, 84], "bisheng_toolkit": 82, "bishengir": [82, 83], "bit": [19, 20, 28], "bitsandbyt": [19, 23], "black": [15, 22, 26, 27, 28, 29, 34, 41, 45, 46, 47, 52, 64, 68, 70, 101], "blackwel": [1, 8, 19, 23, 29, 32, 33, 39, 97], "blank": 53, "blend": 26, "blinker": 33, "blob": [30, 37, 47, 50, 51, 69, 101], "block": [1, 3, 8, 12, 15, 18, 20, 24, 25, 28, 55, 66, 70, 71, 73, 80, 97, 101], "block_input": 3, "block_k": 26, "block_m": 26, "block_n": 26, "block_output": 3, "block_siz": 124, "block_w": 3, "blockadapterregist": 70, "blockchain": 42, "blockdim": 57, "blockidx": 57, "blockwis": [23, 97], "blog": [5, 8, 12, 18, 21, 25, 32, 75, 98, 102, 105], "blogpost": 99, "blood": 101, "blossom": [15, 61], "blue": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 101], "bluefield": 103, "bmm": [32, 97], "bn": 70, "bn_compute_block": 70, "bnf": [27, 51], "bodi": [15, 24, 25, 30, 53, 58, 101], "bogart": 101, "bogor": 15, "bold": [68, 74], "bond0": 107, "bone": 101, "book": [42, 47], "bookkeep": 25, "bool": [15, 23, 25, 51, 88, 97, 115], "boolean": [55, 80], "boost": [6, 8, 37], "boot": 21, "bootstrap": [17, 23, 24, 33, 81, 82, 83, 88, 110], "bootstrap_host": 23, "bootstrap_room": [23, 110], "bootstrap_room_list": 110, "bootstrap_room_span": 110, "born": 101, "boston": 29, "bot": [27, 28], "both": [1, 2, 3, 5, 8, 12, 13, 14, 15, 22, 23, 24, 25, 28, 29, 30, 32, 33, 38, 39, 42, 45, 51, 53, 54, 55, 56, 61, 62, 70, 75, 80, 97, 98, 101, 109, 115, 119, 127], "boto3": 61, "bottleneck": [8, 11, 15, 18, 23, 54, 73, 74], "bottom": [38, 56], "bound": [23, 41], "boundari": [12, 18, 24, 29], "box": [22, 37, 50], "brain": 101, "branch": [0, 1, 23, 26, 49, 55, 68, 72, 76, 78, 79, 80, 81, 84, 88, 92, 121], "brasilia": 15, "bras\u00edlia": [15, 26], "brave": 15, "brave_search": [27, 28], "brazil": [15, 26, 28], "breadth": [23, 26, 88], "break": [25, 28, 45, 51, 52, 62, 81, 82, 83, 84], "breakdown": [45, 53, 74], "breaker": 5, "breakpoint": 56, "breakthrough": 42, "brief": 124, "bring": [15, 42], "brittl": 25, "broad": [26, 67, 77, 125], "broadcast": [2, 23, 25, 88], "broader": 28, "brought": 18, "brows": [109, 117], "browser": [0, 38, 54, 78, 109, 110], "browser_serv": 38, "bubbl": 18, "bucket": [23, 61, 66, 88], "bucket_e2e_request_lat": [15, 22, 27, 28, 29, 30, 41, 42], "bucket_inter_token_lat": [15, 22, 27, 28, 29, 30, 41, 42], "bucket_time_to_first_token": [15, 22, 27, 28, 29, 30, 41, 42], "budget": [12, 20], "buffer": [1, 8, 14, 22, 23, 24, 49, 88, 97], "bug": [11, 19, 55, 80, 94, 98], "build": [3, 4, 5, 12, 17, 19, 21, 28, 30, 42, 47, 56, 59, 64, 75, 76, 79, 80, 81, 90, 93, 95, 97, 101, 110, 127], "built": [3, 5, 12, 15, 23, 24, 26, 40, 54, 55, 58, 68, 69, 71, 72, 73, 75, 76, 79, 80, 91, 113, 127], "builtin": 23, "bump": [55, 80], "bumper": 47, "burger": 26, "burst": [24, 53], "busi": [26, 89, 121, 125], "bustl": 42, "bypass": 8, "byte": 12, "bytesio": 30, "c": [4, 5, 15, 29, 41, 42, 45, 52, 68, 76, 79, 94, 103, 107, 110], "c3ec": 103, "c4": 19, "c4ai": [89, 125], "c7": 103, "c79a": 103, "ca": [24, 27, 28, 29], "cab": 101, "cach": [1, 3, 4, 5, 7, 11, 12, 15, 17, 18, 19, 25, 26, 30, 32, 33, 37, 39, 50, 53, 54, 55, 56, 57, 60, 61, 62, 68, 76, 77, 78, 79, 80, 81, 82, 83, 84, 90, 94, 98, 103, 104, 107, 108, 109, 114, 121, 125, 127], "cache_awar": [5, 24, 81, 82, 83], "cache_config": 70, "cache_control": 13, "cache_dit": [70, 71], "cache_hit_r": 109, "cache_onc": 57, "cached_token": [27, 28, 41, 52], "cached_tokens_detail": [27, 28, 41, 52], "caddi": 78, "cadenc": 24, "caesar": 45, "caf\u00e9": 118, "calcul": [8, 17, 19, 20, 22, 23, 30, 38, 51, 75, 101], "calibr": [19, 66, 70, 71, 73], "calibration_dataset": 19, "calico": 62, "california": [27, 28, 29], "call": [1, 9, 13, 18, 22, 23, 25, 26, 27, 28, 36, 37, 38, 40, 41, 42, 45, 50, 53, 54, 57, 62, 74, 78, 88, 99, 101, 104, 110, 115, 121, 125, 127], "call_042ad20b49824325a74f546a": 29, "call_3bc0cef8540c4942bb1e3d6c": 29, "call_48e3fcab9d5542b598c56874": 29, "call_49f989509a824b0fbeecc337": 29, "call_671a6099cda24c9c96f78820": 29, "call_858bb194b06143b1be3dd427": 29, "call_867becc111e449d68b0a5d6a": 29, "call_d6e6ad2d24c14fbc91daf198": 29, "call_e1002114724f49e5ba09b037": 29, "call_fea37321137f41609a6d790": 29, "callabl": [9, 88], "caller": [25, 55, 80], "came": 15, "can": [0, 1, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 81, 84, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 107, 109, 110, 111, 113, 115, 116, 119, 121, 124, 125, 127], "canada": [45, 52, 101], "canberra": [15, 26, 45, 52, 101], "cancel": 24, "candid": 26, "cann": [84, 91, 113], "cann8": [81, 84], "cann_path": 82, "cannot": [1, 5, 9, 15, 18, 22, 26, 27, 28, 29, 30, 33, 41, 45, 46, 47, 52, 54, 57, 90, 94, 101, 103, 108, 121], "cano": 93, "cap": [53, 79], "capabl": [24, 39, 41, 42, 49, 50, 58, 69, 79, 84, 104, 107, 108, 124, 127], "capac": [11, 12, 18, 20, 23, 24, 26, 32, 33, 88], "capit": [15, 19, 26, 27, 28, 29, 32, 36, 41, 42, 45, 51, 52, 91, 99, 101, 113, 115, 119], "capital_info": 27, "capitalinfo": [27, 28], "caption": 127, "captur": [1, 2, 3, 9, 15, 19, 22, 23, 26, 27, 28, 29, 30, 32, 42, 45, 47, 52, 54, 74, 97, 101, 103], "capture_out": 9, "car": [30, 121], "card": 31, "care": 38, "cargo": 24, "carv": 15, "cascad": [15, 24, 26], "case": [0, 1, 5, 8, 12, 14, 15, 19, 23, 24, 28, 32, 33, 34, 40, 42, 53, 54, 55, 63, 80, 91, 94, 98, 113, 117, 124, 125, 127], "cast": [15, 23, 26, 32], "castl": 15, "cat": [23, 62, 81, 121], "categori": [34, 117, 121], "cathedr": [41, 42], "caus": [9, 16, 17, 18, 19, 20, 23, 25, 29, 54, 97, 98], "causal": [75, 125, 127], "causaldmddenoisingstag": 75, "causallm": 23, "cave": 15, "caveat": [15, 54], "cb": 24, "cbm": [104, 107], "ccccdd": [104, 107], "cd": [17, 24, 33, 59, 68, 76, 79, 80, 81, 90, 91, 92, 94, 95, 109, 113], "cdef": 24, "cdn": 78, "cdna3": 19, "cdna4": 19, "celsiu": [27, 28, 29], "censu": 28, "center": [8, 15, 26, 28, 42, 45], "central": [24, 75], "cert": 24, "certain": [5, 18, 26, 28, 61, 75, 79, 110, 127], "certainli": 101, "certif": 24, "cf": 104, "cfg": [71, 73], "chain": [24, 57, 75], "challeng": [7, 15, 17, 20, 42, 55, 80, 98], "champ": 26, "chanc": 29, "chanel": 42, "chang": [0, 8, 18, 25, 26, 28, 33, 38, 41, 51, 54, 55, 56, 60, 77, 78, 79, 80, 81, 90, 98, 103, 107, 109, 115, 119, 127], "channel": [11, 19, 22, 23, 24, 29, 32, 55, 80, 88, 90, 95], "char": 29, "char_count": 24, "charact": [42, 62, 101, 115, 127], "character": 42, "character_gen": 101, "character_lora": 62, "character_regex": 101, "characterist": [3, 12, 18, 42, 73], "charm": 15, "chart": [78, 104], "chat": [15, 19, 22, 23, 24, 26, 27, 28, 31, 32, 33, 36, 37, 39, 40, 41, 43, 47, 50, 51, 52, 53, 77, 88, 89, 93, 94, 104, 107, 115, 119, 121, 125, 127], "chat_exampl": 101, "chat_templ": [15, 22, 27, 28, 29, 30, 32, 33, 41, 42, 96, 121], "chat_template_kwarg": [33, 45], "chatcomplet": [26, 29, 45, 52], "chatcompletionmessag": [26, 29, 45, 52], "chatcompletionmessagefunctiontoolcal": 29, "chatglm": [89, 125], "chatglm2": [89, 125], "chatml": [96, 127], "cheaper": 127, "check": [0, 2, 5, 11, 13, 14, 15, 17, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 42, 43, 45, 46, 47, 51, 52, 53, 55, 76, 78, 80, 81, 88, 90, 94, 97, 101, 103, 116], "check_env": 94, "check_output": [46, 47, 52], "checker": 24, "checklist": 24, "checkout": [26, 90, 95], "checkpoint": [15, 20, 22, 25, 26, 27, 28, 29, 30, 37, 41, 42, 45, 46, 47, 50, 52, 54, 77, 97, 101, 115], "checkpoint_engin": 2, "checkpoint_engine_wait_weights_before_readi": [15, 22, 27, 28, 29, 30, 41, 42], "checksum": 23, "chen": 45, "cherri": 61, "child": 12, "children": [9, 97], "china": [27, 28, 41, 108, 121], "chines": [84, 125], "choic": [22, 23, 26, 27, 28, 32, 33, 45, 47, 49, 52, 100, 101, 104, 107, 108], "choicedeltatoolcal": 29, "choicedeltatoolcallfunct": 29, "choices_method": 99, "choos": [1, 4, 11, 12, 20, 23, 25, 26, 27, 28, 56, 127], "chosen": [1, 15, 20, 23], "chrome": [54, 74], "chunk": [1, 4, 15, 22, 23, 26, 29, 32, 33, 37, 41, 43, 45, 50, 51, 52, 69, 77, 82, 83, 84, 88, 97, 98, 104, 107, 121, 127], "chunked_prefill_s": [14, 15, 22, 27, 28, 29, 30, 41, 42, 103], "chunked_s": 82, "chunkedsgmv": [15, 23], "churn": 15, "ci": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 67, 77, 101], "ci_permiss": [55, 80], "circuit": 5, "circuitbreakeropen": 24, "circular": 23, "circumv": 18, "citi": [15, 24, 26, 27, 28, 29, 30, 32, 41, 42, 47, 52, 101, 115, 121], "cityscap": 70, "civil": 45, "ckpt": [23, 88], "cla": 125, "clangd": 57, "clarif": 45, "clariti": [15, 22, 26, 27, 28, 29, 32, 41, 45, 46, 47, 52, 101], "class": [1, 9, 11, 12, 23, 24, 27, 28, 29, 51, 61, 75, 115, 116], "class_0": 118, "class_1": 118, "class_nam": [11, 12, 23], "classic": [1, 12, 26], "classif": [41, 77, 117, 120, 123], "classifi": [24, 52, 72, 118, 123], "clean": [0, 17, 65], "cleaned_chunk": 42, "cleanup": 23, "clear": [9, 24, 25, 28, 65], "clearli": 28, "cli": [5, 23, 24, 41, 54, 65, 76, 77, 78], "click": 88, "client": [14, 15, 21, 22, 24, 26, 27, 28, 32, 36, 38, 43, 45, 51, 54, 62, 94, 97, 103], "client_tool_choic": 29, "cliff": 15, "climb": 38, "clip": [85, 89, 97, 119, 127], "clone": [17, 33, 68, 76, 79, 81, 90, 91, 92, 93, 94, 95, 113], "close": [19, 20, 24, 33, 38, 49], "closer": 15, "cloth": [47, 101], "cloud": 77, "cloudi": 29, "cloudli": 29, "cluster": [5, 12, 23, 76, 77, 81, 90, 94, 103, 104, 105], "clusterfirstwithhostnet": [103, 104, 107], "clusterip": [104, 107], "cm1": 103, "cnbc": 38, "co": [5, 25, 61, 119], "code": [0, 1, 11, 13, 14, 15, 17, 18, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 41, 42, 45, 46, 47, 50, 51, 52, 54, 56, 61, 79, 81, 82, 83, 84, 86, 88, 90, 94, 95, 98, 101, 103, 104, 107, 110, 115, 118, 119, 121, 123, 125, 127], "code_interpret": 38, "codebas": [0, 55, 80], "codeown": [55, 80], "coder": [29, 89], "coeffici": 72, "coerc": 121, "cofeai": 125, "coffe": 118, "coher": [26, 125], "cohereforai": 89, "coherelab": 125, "collabor": [42, 125], "collect": [6, 8, 19, 23, 25, 33, 78, 88, 97], "collect_tokens_histogram": [15, 22, 27, 28, 29, 30, 41, 42], "collector": [13, 23, 110], "coloc": [7, 108], "color": [6, 15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 54, 101], "colosseum": 45, "column": [1, 29], "com": [0, 3, 17, 24, 30, 31, 33, 37, 41, 47, 50, 51, 54, 55, 56, 59, 60, 61, 64, 68, 69, 76, 79, 80, 81, 84, 90, 91, 92, 93, 94, 95, 101, 102, 103, 104, 107, 110, 113, 121, 127], "combin": [1, 2, 5, 8, 15, 17, 22, 23, 24, 26, 27, 28, 29, 32, 33, 41, 45, 46, 47, 52, 54, 75, 94, 97, 101, 108, 125, 127], "combineinput": 8, "come": [15, 23, 24, 28, 41, 42, 91, 113, 116, 127], "comma": [23, 28, 97], "command": [5, 8, 16, 17, 19, 24, 29, 32, 33, 39, 40, 46, 52, 55, 56, 58, 60, 61, 62, 67, 76, 79, 80, 81, 84, 89, 93, 94, 95, 103, 104, 107, 109, 115], "comment": [55, 80], "commerci": 125, "commit": [0, 23, 42, 58, 67, 77], "commit_sha": 78, "common": [0, 1, 3, 5, 12, 20, 26, 28, 53, 55, 58, 64, 75, 80, 90, 98, 103], "commonli": 29, "commun": [2, 6, 15, 21, 23, 25, 33, 54, 64, 77, 83, 88, 94, 103, 104], "compact": [3, 23, 40, 125, 127], "compani": [42, 102, 104, 108], "companion": 15, "compar": [6, 12, 15, 18, 20, 25, 32, 33, 65, 78, 115, 125], "compare_perf": 65, "comparison": [65, 78, 99, 115], "compat": [4, 8, 11, 12, 18, 19, 20, 23, 24, 26, 32, 38, 40, 41, 45, 46, 47, 49, 51, 53, 57, 61, 62, 66, 67, 69, 77, 84, 88, 94, 96, 103, 104, 107, 110, 127], "compet": 125, "compil": [3, 8, 14, 23, 32, 57, 79, 82, 83, 88, 90, 92, 97, 103], "compile_command": 57, "compile_deep_gemm": 32, "complementari": [70, 71, 73], "complet": [1, 11, 12, 15, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55, 57, 62, 70, 75, 76, 78, 80, 88, 90, 93, 95, 101, 103, 104, 107, 118, 125, 127], "completion_templ": [15, 22, 27, 28, 29, 30, 41, 42], "completion_token": [24, 26, 27, 28, 29, 32, 41, 45, 46, 47, 52, 104, 107, 118], "completion_tokens_detail": [26, 29, 45, 52], "completionchoic": 45, "completionusag": [26, 29, 45, 52], "complex": [0, 12, 18, 20, 25, 28, 42, 43, 45, 55, 75, 80, 125, 127], "complianc": 24, "compon": [2, 5, 6, 8, 12, 14, 19, 24, 43, 55, 69, 77, 80, 88, 101, 104, 115, 127], "compos": [75, 109, 110], "composedpipelin": 75, "composedpipelinebas": 75, "composit": 3, "comprehens": [12, 24, 29, 32, 97, 121, 127], "compress": [23, 85], "compressedtensorsconfig": 19, "compressor": 85, "compris": 17, "comput": [5, 7, 12, 15, 17, 18, 19, 20, 23, 26, 30, 32, 33, 41, 42, 47, 49, 54, 66, 69, 71, 72, 73, 93, 94, 98, 121], "con": [1, 19], "concaten": [13, 32, 41], "concept": [61, 75], "conceptu": 57, "concis": [42, 45, 55, 80, 108, 115], "concret": 25, "concurr": [1, 12, 14, 15, 20, 23, 24, 25, 37, 50, 58, 82, 88, 94, 98, 110], "conda": [76, 81, 95], "condit": [8, 12, 13, 15, 17, 18, 29, 30, 57, 75], "conditioning_stag": 75, "conditioningstag": 75, "confid": [26, 28, 99, 124], "config": [5, 8, 11, 12, 13, 15, 17, 19, 23, 24, 26, 41, 54, 56, 61, 69, 70, 72, 75, 81, 83, 85, 88, 90, 93, 97, 104, 109, 115, 116, 118, 119, 124, 127], "config_file_path": 61, "configur": [0, 1, 5, 12, 13, 15, 18, 19, 25, 30, 32, 40, 41, 53, 55, 56, 57, 58, 62, 64, 67, 68, 71, 73, 75, 77, 78, 80, 90, 103, 104, 107, 110, 115], "configure_log": 16, "confirm": [26, 28, 41, 79, 109], "conflict": [95, 109], "confus": [26, 28], "connect": [2, 3, 5, 15, 17, 22, 26, 27, 28, 29, 30, 38, 41, 42, 43, 45, 46, 47, 52, 53, 56, 101, 105, 109], "connect_data": 24, "connection_mod": 24, "connections_act": 24, "connectx": 103, "consecut": [12, 17, 20, 23, 24, 71, 72, 73, 97], "consecutive_failur": 24, "consecutive_success": 24, "consensu": 12, "consequ": [15, 18, 57], "conserv": [14, 18, 23, 88, 94, 124], "consid": [0, 12, 19, 24, 26, 28, 30, 42, 51, 65, 94], "consider": [3, 24, 30], "consist": [2, 4, 6, 8, 12, 13, 23, 24, 32, 37, 55, 80, 108, 110, 125], "consol": [53, 56, 65, 74, 78], "consolid": 97, "const": 57, "constant": [3, 51, 57], "constantli": 42, "constexpr": 57, "constrain": [23, 27, 88], "constrained_json_disable_any_whitespac": [15, 22, 27, 28, 29, 30, 41, 42], "constrained_json_whitespace_pattern": [15, 22, 27, 28, 29, 30, 41, 42], "constraint": [1, 5, 13, 25, 26, 27, 28, 51, 97, 101, 110, 127], "construct": [53, 75], "constructor": [23, 115], "consult": [23, 28], "consum": [0, 12, 14, 20, 127], "consumpt": 26, "contact": 104, "contain": [0, 2, 12, 15, 17, 23, 24, 32, 41, 45, 51, 54, 57, 70, 74, 75, 76, 81, 84, 90, 99, 103, 104, 107, 109, 110, 121], "container": 103, "container_id": 109, "container_nam": 109, "containerd": 103, "containerport": [24, 103, 104, 107], "content": [3, 5, 13, 15, 16, 22, 23, 26, 27, 28, 29, 30, 31, 36, 37, 40, 41, 43, 45, 46, 47, 50, 51, 52, 53, 54, 62, 70, 90, 104, 107, 118, 121, 123, 124, 127], "context": [11, 12, 20, 23, 24, 25, 26, 30, 37, 39, 40, 42, 50, 53, 77, 82, 83, 88, 93, 95, 97, 104, 107, 110, 125, 127], "context_len": [14, 15, 41, 103], "context_length": [15, 22, 23, 26, 27, 28, 29, 30, 41, 42], "contigu": [8, 12, 57], "continu": [9, 11, 12, 23, 24, 26, 33, 41, 42, 54, 66, 70, 77, 94, 97, 108], "continue_gener": 25, "contract": [22, 45], "contrast": 12, "contribut": [11, 24, 26, 42, 67, 77, 87, 96, 101, 104], "contributor": [0, 55, 80, 94, 125], "control": [1, 5, 8, 11, 12, 15, 16, 17, 18, 23, 25, 26, 29, 33, 37, 45, 50, 51, 53, 54, 70, 75, 97, 103, 108, 121], "conv": [30, 41], "conveni": [19, 54, 79, 101], "convent": [11, 17, 18, 64, 67, 77], "convers": [8, 11, 25, 30, 39, 53, 75, 96, 115, 125, 127], "convert": [0, 12, 19, 24, 27, 28, 31, 45, 76, 110, 115, 127], "convert_dict_to_tool": 29, "cookbook": 48, "cool": [55, 80], "cooldown": [55, 80], "coordin": [5, 94], "copi": [5, 11, 12, 15, 21, 23, 28, 30, 37, 50, 76, 78, 111, 127], "copy_stream": 18, "core": [8, 12, 15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 75, 77, 90, 94, 101, 110], "corner": 23, "corpu": 125, "correct": [0, 15, 24, 25, 28, 29, 41, 45, 54, 75, 115], "correctli": [5, 28, 45, 54, 80, 103, 115, 116], "correl": [8, 24], "correspond": [1, 12, 15, 19, 23, 28, 29, 46, 51, 55, 80, 110, 115], "cost": [23, 24, 25, 40, 54, 62, 94, 119, 125, 127], "cot": [22, 24], "couch": 121, "could": [5, 18, 23, 30, 38, 42, 79, 81, 83, 86, 103], "couldn": 15, "count": [3, 12, 23, 24, 28, 41, 45, 53, 58, 62, 88, 90, 94, 97], "counter": [24, 97, 109], "countri": [15, 26, 27, 28, 42, 45, 51, 52, 101], "coupl": [7, 8], "cours": [5, 101], "cover": [12, 13, 25, 34, 42, 45, 46, 47, 73, 74, 103, 115], "coverag": [55, 80], "cp": [23, 90, 95], "cp310": 76, "cp8": 33, "cp_size": [23, 33], "cpp": 54, "cpp_func": 57, "cpu": [1, 2, 11, 12, 15, 18, 19, 22, 23, 24, 25, 27, 28, 29, 30, 32, 41, 42, 54, 55, 61, 62, 76, 77, 80, 82, 83, 84, 88, 97, 104, 105, 107, 127], "cpu0": 81, "cpu_count": 17, "cpu_offload_gb": [15, 22, 27, 28, 29, 30, 41, 42], "cpufreq": [81, 82, 83, 84], "cpuinfer": [23, 88], "crash": [23, 88, 107], "crash_dump": 16, "crash_dump_fold": [15, 22, 27, 28, 29, 30, 41, 42], "creat": [0, 1, 3, 5, 8, 9, 12, 13, 15, 22, 23, 24, 25, 26, 27, 28, 29, 32, 36, 38, 40, 41, 42, 45, 46, 47, 51, 52, 55, 56, 62, 75, 76, 79, 80, 90, 94, 95, 107, 110, 115, 118], "create_graph": 3, "create_pipeline_stag": 75, "creativ": [42, 45], "credenti": 24, "critic": [1, 4, 12, 24, 54, 55, 62, 80], "croissant": 26, "cron": 78, "cross": [11, 12, 18, 58, 119, 125, 127], "cross_attention_kwarg": 61, "crt": 24, "crucial": [1, 5, 18, 101, 103], "crypto": 24, "crystal": 15, "cseti": 64, "csgmv": [15, 22, 23, 27, 28, 29, 30, 41, 42], "csrc": [54, 57], "cstddef": 57, "cstdint": 57, "csv": [23, 41], "ctrl": [15, 41, 103], "cu13": 76, "cu130": 76, "cu_full_len": 3, "cu_seqlen": 3, "cu_seqlens_kk": 3, "cu_window_len": 3, "cubla": 98, "cuda": [2, 4, 8, 12, 15, 19, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 37, 41, 42, 50, 54, 56, 57, 60, 69, 74, 77, 82, 83, 84, 88, 93, 95, 97, 103, 104, 107, 127], "cuda_fil": 57, "cuda_graph_b": [15, 22, 27, 28, 29, 30, 41, 42], "cuda_graph_max_b": [15, 22, 27, 28, 29, 30, 41, 42], "cuda_hom": 76, "cuda_launch_block": [104, 107], "cuda_profil": 54, "cuda_visible_devic": 60, "cuda_wrapp": 57, "cudaerror_t": 57, "cudagetlasterror": 57, "cudagraph": [23, 88, 111], "cudamemcpyasync": 12, "cudaprofilerapi": 54, "cudaprofilerstart": 54, "cudaprofilerstop": 54, "cudart": [22, 27, 28, 29, 30, 42], "cudastream": 57, "cudastream_t": 57, "cudnn": [23, 93], "cuh": 57, "cuisin": 42, "cultur": [26, 28, 42], "cumul": [18, 51], "curios": 15, "curiou": [61, 70], "curl": [5, 13, 16, 24, 32, 40, 41, 51, 54, 60, 61, 62, 90, 94, 95, 104, 107, 109, 121, 124], "curl_command": [47, 52], "curl_id": 46, "curl_text": 46, "current": [8, 9, 12, 15, 17, 18, 19, 20, 23, 26, 27, 28, 32, 38, 42, 51, 53, 55, 57, 61, 62, 64, 70, 72, 80, 81, 82, 84, 90, 91, 94, 95, 97, 98, 104, 107, 110, 113, 121, 127], "custom": [0, 8, 12, 15, 17, 22, 24, 25, 27, 28, 29, 32, 33, 36, 37, 41, 42, 45, 53, 61, 66, 70, 75, 77, 82, 97, 108, 109], "custom_backend_nam": 11, "custom_logit_processor": [32, 36, 51], "custom_param": [32, 36, 51], "custom_param_list": 51, "custom_serv": 42, "custom_sigquit_handl": [15, 22, 27, 28, 29, 30, 41, 42], "custom_weight_load": [15, 22, 27, 28, 29, 30, 41, 42], "customlogitprocessor": [32, 36, 37, 51], "cut": [19, 32], "cutedsl": 23, "cutlass": [1, 8, 15, 19, 23, 88, 97], "cutlass_mla": [1, 23], "cutlassmla": 32, "cycl": [5, 8, 24, 101], "d": [5, 13, 15, 23, 24, 32, 40, 42, 45, 46, 47, 52, 54, 57, 62, 76, 88, 101, 104, 105, 107, 109, 110, 118, 121, 124], "d2h": [18, 23, 37, 50], "d7ed48dcbc1a43edab3b0cb43bfd302": 26, "d_": 33, "d_ip": [82, 83], "da7e331f997040cc8da1682d45054c3d": 52, "dai": [15, 24, 29, 32, 38, 78, 101], "dame": [41, 42], "dao": 32, "dark": [15, 30], "dashboard": [24, 109], "data": [6, 8, 11, 14, 15, 17, 18, 20, 21, 22, 26, 28, 29, 30, 31, 37, 38, 41, 42, 45, 46, 47, 50, 51, 52, 54, 57, 62, 75, 77, 79, 82, 91, 94, 107, 109, 110, 113, 115, 118, 119, 121, 127], "data0": 82, "data1": [103, 104, 107], "data_fil": 19, "data_path": 83, "data_ptr": 57, "databas": 24, "databrick": [89, 125], "dataclass": [24, 75], "dataload": 23, "dataparallelcontrol": 5, "dataset": [19, 20, 33, 39, 54, 58, 79, 82, 90, 94, 95, 109, 119, 125], "datasourc": 109, "date": [0, 27, 28, 33, 38], "davinci": [24, 81], "davinci0": [81, 84], "davinci1": [81, 84], "davinci10": [81, 84], "davinci11": [81, 84], "davinci12": [81, 84], "davinci13": [81, 84], "davinci14": [81, 84], "davinci15": [81, 84], "davinci2": [81, 84], "davinci3": [81, 84], "davinci4": [81, 84], "davinci5": [81, 84], "davinci6": [81, 84], "davinci7": [81, 84], "davinci8": [81, 84], "davinci9": [81, 84], "davinci_manag": [81, 84], "dbazur": 56, "dbcach": [71, 73], "dbname": 24, "dbrx": [89, 125], "dc8cdfb21993a6cb46199d6b1d79f68a42b06439": 15, "dd": 74, "de": [28, 108], "de4e56c50f3d49479e5aa931d75e4c2": 28, "deactiv": 76, "deadlock": [23, 65], "death": 101, "deb": 54, "debian": 57, "debug": [2, 4, 8, 9, 16, 26, 54, 57, 121], "debug_tensor_dump_inject": [15, 22, 27, 28, 29, 30, 41, 42], "debug_tensor_dump_input_fil": [15, 22, 27, 28, 29, 30, 41, 42], "debug_tensor_dump_lay": [15, 22, 27, 28, 29, 30, 41, 42], "debug_tensor_dump_output_fold": [15, 22, 27, 28, 29, 30, 41, 42], "debugg": 4, "debugpi": 56, "dec": 23, "deceas": 101, "decemb": 27, "decentr": 8, "decid": [15, 23, 28, 70], "decis": [5, 24, 42, 70], "declar": [28, 75, 115], "decod": [5, 6, 7, 11, 12, 14, 15, 32, 33, 35, 47, 52, 53, 61, 74, 75, 77, 78, 81, 82, 83, 90, 97, 98, 107, 110, 116, 124, 125, 127], "decode1": 24, "decode_addr": 33, "decode_attention_backend": [15, 22, 27, 28, 29, 30, 41, 42], "decode_count": 24, "decode_host": 7, "decode_host_ip": 83, "decode_log_interv": [15, 22, 27, 28, 29, 30, 41, 42], "decode_master_ip": 17, "decode_round_robin": [82, 83], "decode_unicod": [51, 52], "decoding_stag": 75, "decodingstag": 75, "decompos": 7, "decord": 127, "decoupl": [7, 8, 18, 25, 127], "decreas": [14, 24, 45, 49, 94, 98], "decrypted_config_fil": [15, 22, 27, 28, 29, 30, 41, 42], "decrypted_draft_config_fil": [15, 22, 27, 28, 29, 30, 41, 42], "dedic": [5, 12, 17, 18, 25, 51, 54, 76, 90, 94, 95, 108, 115, 127], "dee": [104, 107], "deep": [15, 25, 38, 42, 121], "deep_gemm": [5, 8, 23, 88, 97], "deep_normal_mode_use_int8_qu": [82, 83], "deepep": [5, 17, 23, 33, 82, 83, 84, 88, 104, 107], "deepep_config": [15, 22, 27, 28, 29, 30, 41, 42], "deepep_mod": [15, 22, 27, 28, 29, 30, 41, 42], "deepep_normal_combine_enable_long_seq": 8, "deepep_normal_long_seq_per_round_token": [8, 82], "deepep_normal_long_seq_round": [8, 82], "deeper": [25, 26, 55, 80], "deepgemm": [8, 23, 32], "deepli": [24, 41], "deepmind": 25, "deepseek": [1, 2, 8, 11, 12, 14, 19, 20, 22, 23, 24, 26, 28, 29, 56, 58, 76, 77, 78, 81, 84, 87, 88, 89, 91, 93, 103, 104, 106, 107, 113, 125, 127], "deepseek_r1_0528": 104, "deepseek_v3": 56, "deepseek_v3_mo": 103, "deepseekr10528": 104, "deepseekr1thinkingbudgetlogitprocessor": 32, "deepseekv3": [23, 29, 32], "deepseekv31": [23, 29, 33], "deepseekv32": [29, 33, 106], "deepseekv32_pd": 33, "deepspe": 61, "deepstack": 3, "def": [9, 19, 27, 28, 29, 42, 51, 57, 75, 83, 99, 101, 115, 116, 124], "default": [1, 2, 5, 7, 8, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 38, 39, 41, 42, 45, 46, 47, 49, 52, 53, 54, 55, 61, 62, 64, 66, 69, 70, 74, 75, 76, 79, 80, 81, 88, 90, 92, 94, 96, 97, 99, 101, 103, 107, 109, 110, 115, 116, 118, 121, 124, 127], "default_stream": 18, "defeat": 15, "defer": [18, 23, 88, 94], "defici": 88, "defin": [1, 8, 9, 22, 23, 27, 28, 37, 42, 50, 51, 55, 57, 69, 70, 75, 76, 80, 96, 101, 105, 109, 115], "definit": [24, 26, 28, 41, 75, 109], "degrad": [15, 18, 20, 26, 83, 97, 103], "degre": [18, 29, 61, 62, 127], "dejpeg": 64, "delai": [2, 17, 19, 23, 24, 38, 54, 74], "delay": 23, "delet": [13, 23, 24, 61, 76, 88], "delete_ckpt_after_load": [15, 22, 27, 28, 29, 30, 41, 42], "delimit": [22, 23, 29, 88], "deliv": [18, 33, 77, 94, 125], "delta": [22, 23, 29, 32, 45, 52, 125], "demand": [13, 15], "demo": 23, "demonstr": [8, 12, 15, 19, 29, 30, 41, 42, 45, 57, 115, 125], "denois": [35, 61, 63, 70, 71, 72, 73, 75], "denoise_steps_m": 74, "denoising_stag": 75, "denoisingstag": 75, "denot": [18, 23, 28], "dens": [23, 33, 82, 83, 88, 90, 91, 104, 107, 113, 125], "densiti": 101, "dep": [53, 76, 95], "depart": 28, "depend": [1, 12, 17, 18, 20, 23, 28, 53, 55, 68, 69, 73, 76, 80, 81, 84, 88, 90, 95, 107, 110, 124], "depict": 30, "deploi": [11, 17, 25, 32, 76, 78, 82, 84, 94, 106, 108, 111], "deploy": [2, 5, 7, 8, 17, 18, 19, 23, 25, 32, 33, 37, 42, 50, 76, 77, 90, 94, 103, 107, 119, 121, 125, 127], "deploy_and_serve_endpoint": 76, "deploymod": 82, "deprec": [22, 27, 28, 29, 30, 41, 42, 97, 101], "depth": [23, 24, 26, 42, 88, 125], "dequant": 20, "deregistrations_tot": 24, "deriv": [20, 26, 123], "descend": 121, "describ": [8, 9, 41, 42, 45, 47, 51, 55, 69, 76, 79, 80, 82, 88, 89, 92, 99, 109, 110, 118], "descript": [4, 5, 8, 9, 17, 23, 24, 25, 27, 28, 29, 32, 36, 39, 43, 49, 51, 54, 55, 61, 65, 66, 69, 70, 72, 73, 75, 80, 90, 94, 97, 115, 119, 121, 123, 124, 125, 127], "descriptor": [24, 53], "design": [1, 7, 8, 10, 11, 17, 22, 24, 32, 45, 47, 75, 77, 94, 108, 110, 118, 121, 125, 127], "desir": [27, 90, 95], "desktop": 109, "destin": [15, 17, 42], "destini": 15, "destroi": [13, 15, 25], "destroy_weights_update_group": 25, "detach": [10, 11, 30], "detach_storage_backend": 13, "detail": [0, 1, 3, 5, 8, 11, 12, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 32, 33, 38, 39, 41, 42, 45, 49, 51, 53, 54, 55, 61, 66, 68, 71, 73, 74, 78, 80, 84, 90, 93, 94, 95, 98, 103, 108, 115, 124, 127], "detailed_tip": 101, "detect": [5, 15, 22, 23, 24, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 70, 71, 72, 73, 88, 97, 101], "detector": 29, "determin": [12, 14, 15, 18, 23, 25, 29, 42, 90, 99, 110], "determinist": [23, 55, 77, 80, 108], "deterministiclogitprocessor": 51, "detoken": [51, 97], "detokenization_result": 41, "detokenize_payload": 41, "detokenize_respons": 41, "detokenize_url": 41, "detokenizermanag": [15, 41], "dev": [23, 54, 57, 60, 64, 68, 70, 74, 76, 79, 81, 84, 90, 103, 104, 107], "dev1": 41, "devcontain": 56, "devel": 60, "develop": [4, 8, 12, 15, 23, 24, 29, 33, 42, 43, 45, 54, 55, 75, 76, 80, 84, 94, 95, 102, 108, 110, 125], "developer_guid": 115, "devic": [8, 11, 12, 15, 17, 19, 22, 23, 27, 28, 29, 30, 32, 33, 37, 41, 42, 50, 55, 57, 60, 68, 76, 79, 80, 81, 82, 83, 84, 86, 88, 90, 93, 94, 95, 97, 103, 104, 107, 125, 127], "device_": 57, "device_config": 19, "device_list": 11, "device_map": 19, "device_nam": [17, 41], "device_rdma": 81, "deviceconfig": 19, "devkit": 93, "devtool": 54, "df": 23, "dgx": 76, "diagnos": [73, 103], "diagnost": 73, "diagram": 56, "dialogu": [11, 125], "dict": [3, 9, 23, 27, 28, 29, 30, 51, 88], "dictionari": [23, 28, 29, 45], "did": [15, 41, 74], "didn": [15, 28, 29], "diet": 101, "differ": [3, 4, 5, 6, 8, 12, 15, 17, 18, 19, 23, 24, 25, 26, 28, 30, 32, 33, 34, 37, 41, 42, 47, 50, 52, 53, 56, 62, 66, 70, 71, 72, 73, 74, 75, 78, 79, 90, 94, 97, 98, 103, 104, 107, 109, 110, 111, 114, 115, 117, 121, 124], "differenti": [8, 12], "difficult": [15, 25], "diffus": [63, 64, 66, 69, 72, 73, 74, 79, 117, 119, 126], "diffusers_kwarg": 61, "dim": 15, "dimens": [23, 54, 57, 69, 75], "dip": 82, "dip1": 82, "dip2": 82, "dir": [19, 23, 24, 54, 88, 94, 103], "direct": [2, 11, 12, 23, 24, 25, 42, 88, 90], "directli": [0, 2, 3, 9, 12, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 45, 54, 55, 57, 64, 80, 84, 104, 115], "directori": [0, 2, 23, 24, 33, 54, 56, 57, 61, 74, 75, 84, 90, 97, 109, 110, 114, 115], "directoryorcr": [104, 107], "disabl": [4, 5, 8, 11, 15, 18, 19, 22, 23, 24, 26, 28, 32, 33, 41, 53, 54, 55, 56, 71, 72, 80, 82, 83, 84, 88, 90, 94, 95, 97, 98, 104, 107, 121, 127], "disable_chunked_prefix_cach": [15, 22, 27, 28, 29, 30, 41, 42], "disable_cuda_graph": [15, 22, 27, 28, 29, 30, 41, 42], "disable_cuda_graph_pad": [15, 22, 27, 28, 29, 30, 41, 42], "disable_custom_all_reduc": [15, 22, 27, 28, 29, 30, 41, 42], "disable_fast_image_processor": [15, 22, 27, 28, 29, 30, 41, 42], "disable_flashinfer_autotun": [15, 22, 27, 28, 29, 30, 41, 42], "disable_flashinfer_cutlass_moe_fp4_allgath": [15, 22, 27, 28, 29, 30, 41, 42], "disable_hicache_numa_detect": [15, 22, 27, 28, 29, 30, 41, 42], "disable_hybrid_swa_memori": [15, 22, 27, 28, 29, 30, 41, 42], "disable_outlines_disk_cach": [15, 22, 27, 28, 29, 30, 41, 42], "disable_overlap_schedul": [15, 22, 27, 28, 29, 30, 41, 42], "disable_radix_cach": [15, 22, 27, 28, 29, 30, 41, 42], "disable_shared_experts_fus": [15, 22, 27, 28, 29, 30, 41, 42], "disable_tokenizer_batch_decod": [15, 22, 27, 28, 29, 30, 41, 42], "disagg": 13, "disaggreg": [5, 8, 25, 32, 77, 81, 82, 104, 106, 107, 108, 110], "disaggregation_bootstrap_port": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_decode_dp": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_decode_enable_fake_auto": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_decode_enable_offload_kvcach": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_decode_polling_interv": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_decode_tp": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_ib_devic": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_mod": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_prefill_pp": [15, 22, 27, 28, 29, 30, 41, 42], "disaggregation_transfer_backend": [15, 22, 27, 28, 29, 30, 41, 42], "disast": 25, "discard": [1, 25], "discourag": [45, 51], "discov": [15, 24, 45], "discoveri": 107, "discrep": 25, "discuss": [5, 11, 32, 42, 55, 80, 94], "dish": [26, 42], "disjoint": 23, "disk": [2, 23, 61, 88, 97, 114, 115], "dispatch": [1, 5, 8, 13, 23, 25, 88, 97, 98, 104, 107], "dispatchoutput": 8, "displai": [0, 15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 56, 78, 79, 101], "dist": [2, 15, 17, 18, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 41, 45, 46, 47, 52, 82, 83, 84, 88, 91, 94, 101, 103, 104, 105, 107, 113], "dist_init_addr": [15, 22, 27, 28, 29, 30, 41, 42], "dist_port": 33, "dist_timeout": [15, 22, 27, 28, 29, 30, 41, 42], "distanc": [71, 73], "distil": [22, 28, 45, 64, 70, 90, 93], "distinct": [3, 7, 17, 75], "distinguish": 110, "distract": 15, "distrib_releas": 54, "distribut": [0, 2, 8, 12, 15, 17, 24, 33, 51, 76, 77, 84, 91, 103, 113], "distro": 79, "dit": [61, 69, 75, 77], "dit_precis": 62, "div_ceil": 57, "dive": 25, "diverg": 108, "divers": [4, 8, 12, 25, 26, 42, 45, 51, 108], "divid": [20, 24, 53], "divis": [18, 23], "dkr": 76, "dlami": 56, "dlc": 76, "dldevic": 57, "dllm": [23, 77, 124], "dllm_algorithm": [15, 22, 27, 28, 29, 30, 41, 42, 124], "dllm_algorithm_config": [15, 22, 27, 28, 29, 30, 41, 42], "dlpack": 57, "dmd": 70, "dmddenoisingstag": 75, "dn": 101, "dnspolici": [103, 104, 107], "do": [0, 1, 15, 19, 23, 29, 32, 42, 45, 54, 55, 57, 60, 76, 80, 82, 83, 84, 90, 94, 98, 101, 105, 115, 121], "doc": [5, 12, 26, 27, 51, 52, 54, 55, 56, 65, 76, 78, 79, 80, 91, 93, 99, 113, 115, 125], "doc_patch": [15, 22, 26, 27, 28, 29, 41, 42, 45, 46, 47, 52, 101], "docker": [23, 32, 38, 54, 67, 77, 80, 84, 93, 97, 103, 109, 110, 114], "dockerfil": [68, 76, 79, 81, 90], "dockerhub": 81, "dockerx": 79, "document": [1, 5, 11, 12, 13, 15, 23, 24, 25, 26, 29, 31, 32, 33, 38, 41, 42, 43, 45, 52, 56, 57, 58, 61, 66, 69, 71, 73, 75, 76, 79, 90, 91, 92, 93, 95, 96, 97, 103, 105, 113, 118, 127], "doe": [0, 5, 8, 9, 12, 13, 15, 16, 18, 23, 26, 28, 33, 54, 55, 56, 64, 80, 115], "doesn": [24, 33, 97, 103], "dog": 121, "domain": [2, 24], "domin": [7, 15, 74], "don": [1, 9, 18, 26, 28, 29, 30, 39, 43, 45, 51, 54, 55, 56, 72, 79, 80, 81, 115, 127], "donald": 99, "done": [32, 42, 51, 52, 54, 60, 82, 83, 84, 94, 105], "dot": [9, 73, 89, 127], "dotsvlm": [89, 127], "doubl": [26, 28, 45, 88], "down": [14, 15, 24, 28, 38, 45, 55, 61, 80, 97, 98, 99], "down_mo": 41, "down_proj": [15, 23], "downcast": [41, 46], "download": [15, 19, 23, 26, 30, 41, 51, 53, 54, 56, 57, 62, 76, 78, 81, 84, 85, 90, 91, 94, 95, 113, 115], "download_cont": 62, "download_dir": [15, 22, 27, 28, 29, 30, 41, 42], "downstream": [0, 24], "downward": [18, 103], "dp": [17, 23, 24, 26, 32, 33, 37, 54, 77, 82, 83, 88, 91, 104, 107, 113], "dp_attent": 23, "dp_rank": 110, "dp_size": [5, 13, 14, 15, 22, 27, 28, 29, 30, 33, 41, 42, 83, 91, 113], "dpa": 77, "dpbudget": 97, "dpkg": 54, "dpo": 108, "dr": 45, "draft": [1, 8, 23, 32, 33, 36, 38, 39, 49, 82, 83, 86, 88, 94, 97], "drain": 13, "dramat": [3, 11], "drastic": [55, 80], "drawn": 15, "dream": 42, "drench": 121, "dress": 61, "dri": [60, 68, 79], "drift": 25, "driven": 53, "driver": [81, 82, 84, 103], "drop": [15, 20, 81, 94, 97], "drun": [79, 81], "dry": [30, 101], "ds_channel_config_path": [15, 22, 27, 28, 29, 30, 41, 42], "ds_heavy_channel_num": [15, 22, 27, 28, 29, 30, 41, 42], "ds_heavy_channel_typ": [15, 22, 27, 28, 29, 30, 41, 42], "ds_heavy_token_num": [15, 22, 27, 28, 29, 30, 41, 42], "ds_sparse_decode_threshold": [15, 22, 27, 28, 29, 30, 41, 42], "dsa": [1, 84], "dshm": [103, 104, 107], "dsl": 8, "dst": 57, "dsv32": [33, 107], "dtype": [1, 15, 20, 22, 23, 25, 26, 27, 28, 29, 30, 33, 41, 42, 49, 57, 61, 69, 82, 83, 88, 93, 94, 127], "dual": [1, 70, 90], "dual_chunk_flash_attn": [1, 23], "dublin": 27, "duck": 99, "ducx_path": 17, "due": [4, 5, 14, 17, 18, 19, 23, 54, 55, 56, 80, 93, 94, 97, 99, 108, 110], "dummi": [2, 23, 51, 54], "dummy_hook_factori": 9, "dump": [27, 28, 46, 51, 65, 107, 118], "dump_expert_distribution_record": 41, "duplic": [5, 32, 55, 80], "durat": [32, 37, 50, 53, 54, 74, 101], "duration_m": 74, "dure": [1, 3, 5, 7, 8, 9, 12, 14, 15, 17, 18, 19, 20, 23, 25, 30, 37, 40, 41, 50, 51, 54, 69, 90, 97, 98, 108, 110, 121, 127], "dusti": 93, "dustin": 93, "dv": 56, "dvyio": 64, "dwell": 15, "dynam": [4, 5, 8, 12, 13, 17, 19, 20, 24, 25, 26, 54, 62, 66, 70, 71, 73, 75, 85, 94, 98, 104, 107, 127], "dynamic_batch_tokenizer_batch_s": [15, 22, 27, 28, 29, 30, 41, 42], "dynamic_batch_tokenizer_batch_timeout": [15, 22, 27, 28, 29, 30, 41, 42], "dynamic_smem": 57, "dynamo": [17, 23, 26], "e": [0, 1, 3, 4, 5, 8, 9, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 32, 33, 37, 38, 41, 45, 50, 53, 54, 55, 56, 57, 58, 60, 61, 65, 68, 69, 70, 75, 76, 79, 80, 81, 90, 91, 92, 94, 95, 105, 109, 110, 113, 115, 121, 125, 127], "e2": [23, 37, 50, 63, 88], "e29b": 24, "e2e_lat": [27, 28, 41, 52], "e2e_request_latency_second": 109, "e2e_request_latency_seconds_bucket": 109, "e2e_request_latency_seconds_count": 109, "e2e_request_latency_seconds_sum": 109, "e2m1": 20, "e4m3": [20, 32], "e5": [77, 89, 119], "e569b8498c7f4f86a80cd9850db8c8a7": 28, "e5c459be70a8487d92703ed058f70e90": 41, "e5m2": 20, "each": [0, 1, 2, 3, 4, 8, 9, 12, 15, 17, 18, 20, 23, 24, 25, 28, 30, 32, 33, 37, 41, 42, 45, 49, 50, 51, 53, 54, 55, 58, 64, 72, 74, 75, 80, 88, 90, 97, 101, 103, 105, 110, 115, 118, 121, 127], "eager": [3, 15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "eagl": [1, 32, 33, 82, 83, 86, 88, 94], "eagle2": 23, "eagle3": [23, 26, 38, 39, 82, 88], "eagleworkerv2": 26, "ear": 15, "earli": [14, 25, 125], "earlier": 99, "earn": 38, "earth": 42, "eas": [67, 75], "easi": [5, 8, 15, 19, 28, 55, 77, 80, 101, 108], "easier": [24, 40, 56, 115], "easiest": 5, "easili": [28, 42, 75, 115], "east": 66, "eat": 101, "eater": 101, "ebnf": 29, "ebnf_grammar": [27, 28], "ec": [104, 107], "echo": [33, 54, 60, 68, 76, 79, 81, 82, 83, 84, 94, 105], "econom": [26, 42], "ecosystem": 95, "ecr": 76, "ecr_registri": 76, "edg": [19, 125, 127], "edit": [55, 56, 60, 62, 64, 67, 70, 76, 77, 80, 124], "edit_threshold": 124, "efdf0fc44f274048aeb1aca215a13e33": 26, "effect": [1, 2, 12, 18, 20, 25, 26, 28, 40, 42, 45, 62, 70, 94, 97, 103], "effective_max_running_requests_per_dp": 41, "effici": [2, 5, 8, 11, 12, 15, 17, 18, 19, 21, 23, 24, 25, 26, 30, 32, 33, 37, 40, 41, 42, 50, 51, 55, 57, 67, 73, 77, 80, 90, 93, 94, 108, 119, 121, 125, 127], "effort": [1, 11, 13], "eg": [15, 23, 37, 50], "eic": [13, 23], "eiffel": [26, 28, 41, 42], "eight": [103, 127], "eighth": 45, "either": [9, 12, 23, 28, 33, 38, 51, 62, 76], "elabor": 19, "elaps": [15, 41, 103], "elast": [5, 8, 23, 25, 88], "elastic_ep_backend": [15, 22, 27, 28, 29, 30, 41, 42], "element": [9, 15, 20, 23, 30, 45, 57], "eleutherai": [99, 125], "elif": 101, "elimin": [5, 18, 25], "elit": [15, 40], "els": [9, 15, 27, 28, 41, 55, 80, 121], "elsiu": 29, "embed": [15, 23, 24, 44, 45, 51, 52, 75, 77, 88, 115, 117, 120, 123, 127], "embed_token": 15, "embedding_process": [41, 46], "embrac": 25, "emerg": 42, "emit": 54, "emot": 42, "empathet": 42, "empathi": 42, "emphasi": 42, "empir": [45, 124], "emploi": [8, 12, 26, 51, 127], "empow": 25, "empti": [13, 23, 25, 29, 41, 45, 54, 57], "empty_lik": 57, "emptydir": [103, 104, 107], "emul": 1, "en": [19, 89, 119], "enabl": [1, 3, 4, 5, 6, 7, 8, 12, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 28, 32, 33, 36, 37, 38, 39, 42, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 61, 62, 66, 68, 70, 71, 72, 74, 75, 78, 79, 81, 82, 83, 84, 86, 88, 89, 90, 91, 93, 94, 95, 97, 98, 104, 107, 108, 109, 110, 113, 119, 121, 125, 127], "enable_ascend_transfer_with_mooncak": 17, "enable_attn_tp_input_scatt": [15, 22, 27, 28, 29, 30, 41, 42], "enable_broadcast_mm_inputs_process": [15, 22, 27, 28, 29, 30, 41, 42], "enable_cache_report": [15, 22, 27, 28, 29, 30, 41, 42], "enable_cudagraph_gc": [15, 22, 27, 28, 29, 30, 41, 42], "enable_custom_logit_processor": [15, 22, 27, 28, 29, 30, 41, 42], "enable_deterministic_infer": [15, 22, 27, 28, 29, 30, 41, 42], "enable_double_spars": [15, 22, 27, 28, 29, 30, 41, 42], "enable_dp_attent": [15, 22, 27, 28, 29, 30, 41, 42], "enable_dp_lm_head": [15, 22, 27, 28, 29, 30, 41, 42], "enable_draft_weights_cpu_backup": [15, 22, 27, 28, 29, 30, 41, 42], "enable_dynamic_batch_token": [15, 22, 27, 28, 29, 30, 41, 42], "enable_dynamic_chunk": [15, 22, 27, 28, 29, 30, 41, 42], "enable_eplb": [15, 22, 27, 28, 29, 30, 41, 42], "enable_expert_distribution_metr": [15, 22, 27, 28, 29, 30, 41, 42], "enable_flashinfer_allreduce_fus": [15, 22, 27, 28, 29, 30, 41, 42], "enable_fp32_lm_head": [15, 22, 27, 28, 29, 30, 41, 42], "enable_fused_qk_norm_rop": [15, 22, 27, 28, 29, 30, 41, 42], "enable_hierarchical_cach": [15, 22, 27, 28, 29, 30, 41, 42], "enable_layerwise_nvtx_mark": [15, 22, 27, 28, 29, 30, 41, 42], "enable_lmcach": [15, 22, 27, 28, 29, 30, 41, 42], "enable_lora": [15, 22, 27, 28, 29, 30, 41, 42], "enable_lora_overlap_load": [15, 22, 27, 28, 29, 30, 41, 42], "enable_memory_sav": [15, 22, 27, 28, 29, 30, 41, 42], "enable_metr": [15, 22, 27, 28, 29, 30, 41, 42, 107], "enable_metrics_for_all_schedul": [15, 22, 27, 28, 29, 30, 41, 42], "enable_mixed_chunk": [15, 22, 27, 28, 29, 30, 41, 42], "enable_moe_nz": [82, 83], "enable_mscclpp": [15, 22, 27, 28, 29, 30, 41, 42], "enable_multi_layer_eagl": [15, 22, 27, 28, 29, 30, 41, 42], "enable_multimod": [15, 22, 27, 28, 29, 30, 41, 42], "enable_nan_detect": [15, 22, 27, 28, 29, 30, 41, 42], "enable_nccl_nvl": [15, 22, 27, 28, 29, 30, 41, 42], "enable_nsa_prefill_context_parallel": [15, 22, 27, 28, 29, 30, 41, 42], "enable_p2p_check": [15, 22, 27, 28, 29, 30, 41, 42], "enable_pdmux": [15, 22, 27, 28, 29, 30, 41, 42], "enable_piecewise_cuda_graph": [15, 22, 27, 28, 29, 30, 41, 42], "enable_precise_embedding_interpol": [15, 22, 27, 28, 29, 30, 41, 42], "enable_prefill_delay": [15, 22, 27, 28, 29, 30, 41, 42], "enable_prefix_mm_cach": [15, 22, 27, 28, 29, 30, 41, 42], "enable_priority_schedul": [15, 22, 27, 28, 29, 30, 41, 42], "enable_profile_cuda_graph": [15, 22, 27, 28, 29, 30, 41, 42], "enable_refresh": 24, "enable_request_time_stats_log": [15, 22, 27, 28, 29, 30, 41, 42], "enable_return_hidden_st": [15, 22, 27, 28, 29, 30, 41, 42], "enable_return_routed_expert": [15, 22, 27, 28, 29, 30, 41, 42], "enable_single_batch_overlap": [15, 22, 27, 28, 29, 30, 41, 42], "enable_symm_mem": [15, 22, 27, 28, 29, 30, 41, 42], "enable_taylors": 70, "enable_think": [22, 45], "enable_tokenizer_batch_encod": [15, 22, 27, 28, 29, 30, 41, 42], "enable_torch_compil": [15, 22, 27, 28, 29, 30, 41, 42, 61], "enable_torch_compile_debug_mod": [15, 22, 27, 28, 29, 30, 41, 42], "enable_torch_symm_mem": [15, 22, 27, 28, 29, 30, 41, 42], "enable_trac": [15, 22, 27, 28, 29, 30, 41, 42], "enable_two_batch_overlap": [15, 22, 27, 28, 29, 30, 41, 42], "enable_weights_cpu_backup": [15, 22, 27, 28, 29, 30, 41, 42], "enable_x": 69, "encapsul": [12, 25, 75], "encod": [7, 30, 37, 45, 46, 51, 52, 61, 62, 69, 74, 75, 77, 127], "encoder_onli": [15, 22, 27, 28, 29, 30, 41, 42], "encoder_transfer_backend": [15, 22, 27, 28, 29, 30, 41, 42], "encoder_url": [15, 22, 27, 28, 29, 30, 41, 42], "encoding_for_model": 45, "encoding_format": 119, "encount": [14, 15, 18, 19, 32, 54, 76, 79, 81, 82, 88, 90, 92, 94, 103, 109], "encourag": [14, 45, 51, 55, 80], "end": [3, 6, 8, 15, 18, 22, 23, 24, 27, 28, 37, 40, 41, 42, 43, 45, 51, 52, 54, 57, 67, 74, 78, 101, 103, 109, 110, 115, 127], "end_tag": [27, 28], "endem": [41, 121], "endpoint": [2, 7, 11, 23, 25, 27, 28, 41, 52, 61, 66, 76, 77, 78, 88, 101, 109, 110, 115], "endur": 101, "energi": 101, "enforc": [15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 57, 97, 101], "engag": [42, 101], "engin": [7, 12, 15, 17, 19, 21, 23, 24, 26, 32, 43, 47, 54, 55, 70, 75, 77, 79, 80, 81, 85, 88, 91, 93, 98, 101, 104, 108, 113, 124], "engine_metr": 24, "england": [27, 28, 51], "english": [28, 125], "enhanc": [8, 26, 42, 125, 127], "enjoi": [42, 121], "enough": [5, 9, 14, 23, 25, 71, 72, 73], "enp48s3u1u1": 84, "ensembl": 53, "ensur": [0, 2, 4, 8, 11, 12, 15, 17, 18, 23, 24, 25, 26, 28, 29, 32, 33, 38, 42, 53, 54, 55, 56, 75, 78, 79, 80, 81, 90, 93, 94, 105, 107, 108, 109, 115, 121], "enter": [56, 90, 110], "enterpris": [12, 19, 24, 76, 108, 125], "entir": [5, 6, 9, 17, 19, 24, 25, 27, 28, 54, 71, 72, 73, 74, 79], "entri": [5, 8, 9, 14, 24, 64, 75], "entryclass": 115, "entrypoint": [2, 5, 13, 84, 115, 118], "enum": [27, 28, 29, 69], "enumer": [19, 51, 101], "env": [3, 17, 24, 26, 61, 68, 70, 76, 79, 81, 90, 103, 104, 107, 110, 114], "env_fold": 105, "envelop": 23, "environ": [8, 11, 12, 15, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 36, 38, 41, 42, 45, 46, 47, 52, 53, 54, 55, 58, 60, 61, 66, 67, 69, 76, 77, 78, 90, 95, 101, 103, 104, 105, 107, 109, 110, 114], "environment": 18, "eo": [14, 51, 53, 94], "eof": 23, "eom": 29, "ep": [7, 23, 32, 33, 37, 40, 50, 54, 82, 88, 97, 104, 107], "ep_dispatch_algorithm": [15, 22, 27, 28, 29, 30, 41, 42], "ep_num_redundant_expert": [15, 22, 27, 28, 29, 30, 41, 42], "ep_siz": [8, 15, 22, 27, 28, 29, 30, 41, 42], "epd": 77, "eplb": [5, 8, 23, 88, 104, 107], "eplb_algorithm": [15, 22, 27, 28, 29, 30, 41, 42], "eplb_min_rebalancing_utilization_threshold": [15, 22, 27, 28, 29, 30, 41, 42], "eplb_rebalance_layers_per_chunk": [15, 22, 27, 28, 29, 30, 41, 42], "eplb_rebalance_num_iter": [15, 22, 27, 28, 29, 30, 41, 42], "equal": [15, 22, 23, 33, 53, 57, 101], "equat": 42, "equip": [33, 90], "equival": [24, 52, 79, 98], "erni": [89, 125, 127], "ernie4": 127, "err": 105, "error": [0, 2, 9, 13, 15, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 41, 42, 45, 46, 47, 52, 53, 54, 55, 57, 62, 78, 80, 81, 90, 101, 103, 105, 109, 121], "error_messag": 15, "error_typ": 118, "errors_tot": 24, "esc": 90, "escap": 15, "especi": [2, 5, 8, 12, 14, 15, 18, 20, 23, 29, 38, 42, 55, 56, 64, 65, 80], "essenti": [11, 15, 24, 101, 103, 108, 109, 115], "establish": [22, 108], "estim": [18, 28, 97], "et": 38, "etc": [1, 3, 5, 6, 9, 11, 13, 19, 23, 24, 29, 53, 54, 61, 65, 66, 67, 73, 74, 75, 77, 79, 81, 84, 88, 115, 118, 125], "eth": 103, "ethernet": 103, "ethic": 42, "europ": [26, 28, 45, 52], "ev": 127, "eva": 64, "eval": [30, 33, 55, 58, 80, 115], "evalu": [4, 18, 20, 23, 25, 26, 33, 41, 53, 55, 77, 80, 94, 123], "evaluation_mod": 33, "even": [4, 13, 18, 25, 28, 42, 56, 97, 99, 125, 127], "even_k": 26, "evenli": 18, "event": [18, 23, 24, 29, 54, 88], "eventu": 115, "ever": 40, "everi": [0, 6, 8, 9, 12, 15, 16, 23, 54, 55, 56, 57, 64, 80, 90, 110], "everyon": 15, "everyth": 3, "evict": [5, 12, 15, 23, 24, 88], "evolut": 42, "evolv": [8, 18, 24, 42], "exa": 38, "exa_api_kei": 38, "exact": [12, 24, 28, 38, 74], "exactli": [9, 15, 24, 28, 43, 54, 115], "examin": 75, "exampl": [0, 1, 5, 9, 11, 12, 13, 15, 17, 18, 23, 25, 26, 27, 28, 30, 33, 34, 35, 36, 38, 39, 40, 42, 46, 47, 48, 49, 55, 56, 57, 58, 60, 65, 74, 76, 77, 80, 87, 91, 95, 99, 101, 105, 109, 110, 113, 114], "example_function_nam": [27, 28], "example_imag": [30, 37, 47, 50, 51, 101], "example_nam": [27, 28], "example_valu": [27, 28], "exampleoutput": 45, "exaon": [89, 125], "exce": [8, 12, 23, 24, 37, 50, 51, 55, 80, 90, 97, 115], "exceed": 83, "excel": [1, 55, 80, 125, 127], "except": [1, 9, 23, 29, 33, 41, 94, 116], "excess": [15, 18, 24], "excit": 42, "exclud": [0, 23, 76], "exclus": [54, 62], "exec": [0, 54, 56, 74], "execut": [7, 8, 12, 18, 19, 23, 24, 25, 27, 28, 38, 54, 74, 75, 76, 84, 90, 103, 104, 110, 119, 123], "executor": 97, "exercis": 101, "exhaust": 24, "exhibit": 125, "exist": [0, 1, 7, 11, 12, 19, 23, 30, 55, 56, 74, 80, 104, 107, 110, 115], "exit": [90, 105], "exp": [29, 33, 89, 106], "expand": [1, 5, 12, 101, 115], "expandable_seg": [82, 83, 84, 86], "expans": [8, 26, 70, 71, 73], "expect": [3, 4, 9, 15, 19, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 38, 40, 41, 42, 45, 46, 47, 52, 54, 57, 64, 70, 90, 94, 101], "expens": [55, 80], "experi": [4, 18, 19, 20, 84, 104], "experienc": 32, "experiment": [18, 20, 23, 26, 32, 36, 38, 88, 97], "expert": [14, 23, 32, 51, 77, 82, 83, 90, 97, 104, 106, 107, 124, 125], "expert_distribution_recorder_buffer_s": [15, 22, 27, 28, 29, 30, 41, 42], "expert_distribution_recorder_mod": [15, 22, 27, 28, 29, 30, 41, 42], "expert_record_server_process": 41, "expir": 24, "explain": [5, 13, 38, 42, 75, 94, 110, 115, 119], "explan": [1, 5, 29, 93, 95], "explicit": [9, 24, 25, 29], "explicitli": [5, 15, 19, 26, 27, 39, 41, 64, 90, 109, 110], "exploit": 12, "explor": [1, 15, 42, 45, 127], "expon": 20, "exponenti": [20, 23, 24], "export": [9, 11, 17, 18, 23, 24, 33, 38, 53, 54, 56, 57, 60, 61, 70, 76, 78, 79, 80, 81, 82, 83, 84, 86, 88, 90, 91, 94, 110, 113, 114, 115], "export_metrics_to_fil": [15, 22, 27, 28, 29, 30, 41, 42], "export_metrics_to_file_dir": [15, 22, 27, 28, 29, 30, 41, 42], "exported_model": 19, "expos": [12, 13, 16, 24, 25, 38, 45, 53, 54, 57, 61, 104, 109], "expr": [24, 82], "express": [51, 57, 101, 125, 127], "extend": [11, 12, 23, 24, 26, 29, 32, 33, 45, 53, 58, 74, 77, 99, 115, 117, 121, 125], "extens": [56, 57, 69, 77, 127], "extent": 5, "extern": [9, 11, 20, 23, 24, 38, 41], "extra": [11, 12, 19, 23, 26, 28, 33, 49, 53, 57, 58, 70, 88, 124], "extra_bodi": [22, 27, 28, 32, 36, 45, 51], "extra_buff": [23, 49, 88], "extra_metric_label": [15, 22, 27, 28, 29, 30, 41, 42], "extra_parallel_modul": 70, "extract": [6, 42, 55, 57, 75, 80, 115, 127], "extractor": 75, "extrem": [3, 5, 12, 15, 18, 19, 20, 29, 55, 80], "ey": [15, 42], "f": [9, 15, 19, 22, 26, 27, 28, 29, 30, 37, 41, 42, 45, 46, 47, 50, 51, 52, 57, 62, 68, 76, 79, 81, 82, 83, 84, 90, 91, 92, 101, 103, 104, 110, 113, 115, 121], "f1": 56, "f26c6f7accfa4c2cb3320152bffbcaa": 26, "f5": 56, "f7ff": 103, "f_": 26, "f_1": 26, "f_k": 26, "fa": [61, 69, 94], "fa1d1ea84f824d3b9c9402d10e2e5856": 28, "fa3": [1, 3, 4, 11, 15, 18, 22, 23, 26, 27, 28, 29, 30, 32, 33, 37, 39, 41, 42, 45, 46, 47, 50, 52, 69, 88, 101], "fa4": [1, 23, 69], "fabdb6a30b49f79a7aba0f2ad9df9b399473380f": 56, "face": [15, 19, 23, 45, 62, 64, 77, 96, 115, 125], "facil": 101, "facilit": [18, 25, 32, 90, 108, 119], "fact": [15, 41], "facto": 108, "factor": [19, 23, 24, 26, 40, 42, 53, 98], "factori": [23, 108], "factory_nam": 9, "factual": [42, 115], "fahrenheit": [27, 28, 29], "fail": [0, 9, 13, 15, 19, 24, 25, 29, 41, 53, 54, 55, 57, 61, 80, 99, 105], "failur": [0, 9, 13, 17, 19, 55, 76, 80], "failurethreshold": 107, "fair": [42, 55, 80], "fairi": 15, "fake": [19, 23, 88], "fal": 61, "falcon": 125, "fall": [1, 5, 8, 23, 24, 33, 69, 116, 118, 121, 127], "fallback": [23, 24, 27, 28, 39, 51, 61, 77, 112, 117], "fals": [15, 22, 23, 24, 25, 26, 27, 28, 29, 30, 41, 42, 45, 46, 51, 52, 54, 56, 61, 66, 70, 88, 97, 104, 107, 115, 121], "famili": [1, 5, 22, 24, 33, 45, 50, 70, 72, 84, 89, 94, 119, 121, 123, 124, 125, 127], "familiar": [26, 43], "famou": [26, 28, 41, 42], "faq": 77, "far": [5, 15, 51], "fascin": [42, 45], "fashion": 42, "fast": [1, 5, 9, 12, 13, 19, 23, 24, 25, 38, 40, 43, 55, 66, 67, 70, 77, 80, 88, 125, 127], "fastapi": [23, 88], "fastapi_root_path": [15, 22, 27, 28, 29, 30, 41, 42], "faster": [12, 15, 26, 55, 61, 68, 70, 72, 76, 80, 94, 97, 108, 119, 124, 125, 127], "fastest": [26, 73], "fasthunyuan": [61, 64], "fastsafetensor": 23, "fastvideo": [61, 64, 67], "fastwan": 67, "fastwan2": 64, "fat": 101, "fatal": [9, 76], "father": 15, "fault": [5, 17, 24, 25], "favor": [14, 45], "favorit": 42, "fcf": [15, 17, 22, 23, 27, 28, 29, 30, 41, 42, 88], "fe36": 103, "fe64": 103, "fe6e": 103, "fe73": 103, "fe80": 103, "feasibl": 23, "featur": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 15, 18, 23, 26, 28, 29, 30, 32, 33, 36, 37, 39, 45, 47, 49, 50, 51, 54, 55, 61, 65, 73, 75, 80, 87, 97, 102, 103, 108, 110, 115, 124, 125, 127], "feed": [24, 115], "feedback": 11, "feel": [45, 55, 80, 81, 90], "felt": 15, "feroci": 15, "ferret": 101, "fetch": [12, 27, 28, 29, 53, 54], "fetch_metr": 78, "few": [3, 15, 55, 79, 80], "few_shot_gsm8k": [55, 58, 80, 83], "fewer": [18, 90], "ffi": [24, 57], "ffn": 23, "fi": [82, 83, 84, 105], "fiber": 101, "fiction": [42, 115], "field": [15, 23, 25, 27, 28, 30, 41, 42, 45, 53, 74, 84, 115], "fieldpath": [104, 107], "fieldref": [104, 107], "fifo": [15, 23, 24, 88], "fight": 15, "figur": [28, 56], "file": [0, 2, 12, 13, 16, 20, 30, 37, 41, 50, 51, 53, 55, 57, 62, 63, 69, 70, 74, 78, 80, 90, 94, 95, 96, 98, 103, 115, 118, 127], "file_path": 24, "file_storage_path": [15, 22, 27, 28, 29, 30, 41, 42], "filenam": 23, "filesystem": 24, "fill": [1, 15, 26, 101], "fillmor": 99, "filter": [24, 29, 78], "final": [13, 22, 23, 26, 29, 57, 75, 98, 115], "final_hidden_st": 8, "final_respons": 29, "financ": 42, "find": [0, 15, 18, 22, 23, 26, 27, 28, 29, 33, 42, 45, 51, 55, 74, 76, 80, 84, 94, 98, 103, 109, 110, 115, 117, 121], "fine": [8, 12, 17, 18, 29, 33, 37, 50, 54, 70, 108, 125, 127], "finer": 110, "finetun": 29, "finish": [15, 32, 54, 61], "finish_reason": [26, 27, 28, 29, 32, 41, 45, 47, 52, 104, 107], "finit": 15, "finn": 15, "fire": [15, 41, 79, 90, 103], "firewal": [24, 43, 94], "firm": 38, "firmwar": [81, 84], "first": [0, 1, 2, 3, 5, 9, 11, 12, 14, 15, 18, 19, 22, 23, 24, 26, 28, 32, 33, 41, 42, 45, 46, 47, 53, 54, 55, 56, 58, 62, 64, 66, 70, 76, 78, 80, 81, 88, 90, 91, 94, 97, 105, 109, 110, 113, 115], "first_answ": 101, "first_full_lay": 69, "first_full_step": 69, "firstli": 54, "fit": [5, 12, 18, 23, 33, 76, 127], "five": [25, 55, 80], "fix": [0, 1, 3, 13, 18, 55, 64, 65, 70, 80, 94], "fla": 23, "flag": [2, 4, 8, 11, 19, 23, 24, 28, 30, 32, 33, 36, 45, 51, 53, 54, 56, 58, 61, 69, 88, 90, 97, 110, 119, 127], "flagship": 90, "flaki": [0, 55, 80], "flash": [23, 37, 50, 61, 69, 97, 124], "flash_attn": 33, "flash_attn_with_kvcach": 33, "flash_mla": 33, "flash_mla_sparse_fwd": 33, "flash_mla_with_kvcach": 33, "flash_rl": 23, "flashattent": [1, 4, 33, 67, 69, 73, 94], "flashattention3": 32, "flashattention_backend": 1, "flashinf": [1, 4, 8, 15, 22, 23, 26, 27, 28, 29, 30, 32, 41, 42, 76, 88, 93, 97], "flashinfer_cudnn": 23, "flashinfer_cutedsl": [8, 23, 33, 97], "flashinfer_cutlass": [8, 15, 22, 23, 27, 28, 29, 30, 33, 41, 42, 97], "flashinfer_mla_disable_rag": [15, 22, 27, 28, 29, 30, 41, 42], "flashinfer_mxfp4": [8, 23], "flashinfer_mxfp4_moe_precis": [15, 22, 27, 28, 29, 30, 41, 42], "flashinfer_trtllm": [1, 8, 23, 33, 88, 97], "flashmla": [1, 23, 32], "flashmla_auto": [23, 33], "flashmla_decod": [23, 88], "flashmla_kv": [23, 33, 88], "flashmla_prefil": [23, 88], "flashmla_spars": [23, 33, 88], "flashrl": 23, "flatten": [3, 30, 45, 51], "flattened_bucket": 25, "fleet": 24, "flex_attent": [1, 23], "flexattent": 1, "flexibl": [8, 15, 19, 25, 52, 75, 94, 119, 121], "flexibli": 32, "flight": [18, 53], "flm": 125, "float": [4, 20, 23, 45, 51, 62, 69, 72, 88, 119, 121], "float16": [19, 23, 26, 41, 46, 88], "float32": [19, 23, 26, 41, 46, 49, 88], "float8": 19, "float8_e4m3fn": 20, "flow": [8, 25, 70, 75, 110], "flower": 30, "fluenci": 45, "flush": [23, 25, 42, 43, 51, 52, 53, 101], "flush_cach": [24, 25, 41, 53], "flux": [34, 61, 64, 67, 68, 70, 71, 72], "fly": [19, 20], "flymi": 64, "fn": 70, "fn_compute_block": 70, "fn_name": 9, "fnmatch": 9, "focal": 38, "focu": [25, 42, 74], "focus": [8, 25, 42, 45, 127], "folder": [0, 16, 23, 54, 56, 60, 88, 90, 107, 109, 111], "follow": [0, 1, 3, 4, 5, 8, 9, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 32, 33, 37, 40, 41, 42, 45, 50, 51, 52, 54, 55, 56, 57, 60, 61, 64, 65, 72, 75, 76, 79, 80, 81, 84, 88, 90, 91, 93, 94, 98, 101, 102, 103, 104, 105, 109, 110, 113, 115, 116, 118, 125, 127], "follow_bootstrap_room": 23, "foo": [27, 28], "food": 101, "fool": 38, "footprint": [1, 20], "forc": [0, 24, 26, 51, 58, 61, 72, 74, 76, 97], "foreign": 57, "forest": [15, 34, 64, 68, 70], "forev": 60, "fork": [54, 74, 77, 101], "form": [7, 9, 15, 28, 29, 40, 42, 51, 54, 62, 95], "format": [2, 6, 8, 9, 15, 19, 21, 23, 25, 27, 28, 32, 41, 42, 51, 54, 61, 65, 74, 88, 90, 94, 104, 109, 110, 127], "former": [14, 17, 23, 83], "formerli": [5, 102], "formula": 8, "forum": 45, "forward": [1, 5, 8, 9, 18, 24, 42, 55, 80, 88, 97, 115, 116], "forward_batch": 115, "forward_batch_info": 115, "forward_decod": [1, 115], "forward_extend": [1, 115], "forward_hook": [9, 15, 22, 27, 28, 29, 30, 41, 42], "forward_stream": 18, "forwardbatch": 115, "foster": 42, "fought": 15, "found": [0, 4, 5, 12, 15, 17, 18, 20, 23, 41, 42, 45, 83, 86, 93, 103], "foundat": 125, "four": [5, 15, 32, 42, 110], "fp": [61, 127], "fp16": [19, 23, 61, 62, 69, 73, 75, 105], "fp32": [23, 61, 88, 127], "fp4": [1, 8, 19, 23, 77, 88, 97], "fp4_e2m1": [20, 23], "fp4_gemm_runner_backend": [15, 22, 27, 28, 29, 30, 41, 42], "fp8": [1, 8, 14, 19, 23, 33, 36, 77, 88, 90, 97, 105], "fp8_dynam": 19, "fp8_e4m3": [1, 20, 23, 33], "fp8_e5m2": [20, 23], "fp8_gemm_runner_backend": [15, 22, 27, 28, 29, 30, 41, 42], "fp8_kernel": 19, "fp8dq": [19, 23], "fp8wo": [19, 23], "fr": 26, "frac": 54, "fraction": [0, 11, 17, 18, 23, 26, 32, 33, 36, 37, 39, 40, 50, 82, 83, 84, 86, 88, 93, 94, 98, 103, 104, 107], "fragment": [3, 29, 32, 97], "frame": [61, 127], "framework": [5, 12, 25, 42, 55, 67, 77, 80, 84, 91, 107, 108, 113, 121], "franc": [15, 19, 26, 27, 28, 29, 32, 36, 41, 42, 45, 51, 52, 91, 99, 101, 113, 115, 119], "francisco": [27, 28, 29], "franklin": 93, "free": [15, 24, 28, 31, 42, 45, 55, 72, 80, 81, 90], "freeli": 110, "french": [28, 42], "freq_32768": 26, "frequenc": [12, 37, 50, 51, 97, 101], "frequency_penalti": [45, 51], "frequent": [3, 12, 14, 15, 17, 18, 23, 77], "fridai": 38, "friendli": 108, "friendship": 15, "from": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 38, 40, 42, 45, 46, 47, 51, 52, 53, 54, 57, 61, 62, 63, 67, 70, 72, 75, 77, 78, 83, 85, 91, 93, 96, 97, 98, 101, 107, 108, 109, 110, 112, 113, 116, 117, 118, 121, 123, 124, 125, 126, 127], "from_arg": 24, "from_pretrain": [19, 22, 27, 28, 29, 30, 41, 46, 64], "from_stat": 24, "front": [6, 12, 15], "frontend": [77, 78, 96], "frontier": 108, "frozen": [3, 22, 23, 27, 28, 29, 30, 42], "fruit": 101, "fsdp": [23, 88], "full": [5, 7, 8, 11, 14, 15, 23, 25, 32, 34, 35, 39, 41, 42, 49, 54, 64, 69, 72, 88, 103, 108, 119, 124, 125, 127], "full_argu": 29, "full_siz": 23, "fullattn": 64, "fulli": [0, 4, 7, 12, 19, 24, 29, 32, 33, 45, 55, 70, 79, 80, 104, 107, 108, 125], "func": 57, "func_latency_second": 109, "func_latency_seconds_bucket": 109, "func_latency_seconds_count": 109, "func_latency_seconds_sum": 109, "func_name1": 29, "func_name2": 29, "function": [0, 1, 8, 9, 12, 18, 23, 26, 27, 28, 45, 55, 57, 75, 80, 88, 94, 99, 101, 108, 109, 115], "function_cal": [24, 26, 29, 45, 52], "function_call_input": 29, "function_call_pars": 29, "function_call_respons": 29, "function_call_response_json": 29, "function_dict": 29, "function_nam": [27, 28], "functioncallpars": 29, "functool": [26, 57, 115], "fundament": 11, "furri": 64, "further": [5, 7, 12, 18, 25, 26, 28, 42, 76, 110], "furthermor": 26, "fuse": [8, 19, 20, 23, 33, 88, 97], "fused_moe_triton": [41, 104], "fusedmo": [8, 33], "fusion": [19, 23, 82, 83, 88, 97], "futur": [12, 19, 22, 23, 27, 28, 29, 30, 41, 42, 55, 80, 91, 97, 101, 104, 113, 115], "futurewarn": [22, 27, 28, 29, 30, 42], "futurist": 70, "fuzzi": 28, "g": [0, 1, 3, 4, 5, 8, 9, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 32, 37, 38, 41, 50, 53, 54, 55, 56, 57, 58, 60, 61, 65, 68, 69, 70, 75, 76, 80, 90, 95, 109, 115, 121, 125, 127], "gain": [5, 6, 8, 12, 30, 125], "garbag": 23, "garden": [15, 61], "gate": [5, 19, 55, 80], "gate_proj": [15, 23], "gate_up_proj": 23, "gatewai": [14, 17, 23, 25, 77, 83, 118], "gather": [5, 8, 23, 25, 33, 97, 127], "gaudi": 19, "gaug": 109, "gb": [11, 14, 15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 47, 52, 88, 94, 97, 101, 103], "gb200": [32, 39, 77, 97], "gb300": 76, "gc": [23, 88, 94], "gc_warning_threshold_sec": [15, 22, 27, 28, 29, 30, 41, 42], "gcc": 90, "gcp": 94, "gd": 12, "gdd77bd465": 41, "gem": 15, "gemm": [8, 15, 97], "gemma": [77, 89, 94, 123, 125, 127], "gemma2forsequenceclassif": [118, 123], "gemma3": 47, "gen": [14, 15, 90, 99, 101, 125], "gen_data": [22, 29], "gen_perf_baselin": 63, "gen_respons": [22, 29], "gen_second": 33, "gen_throughput": 109, "gen_url": [22, 29], "gender": 42, "gener": [6, 7, 8, 12, 15, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 33, 35, 38, 39, 40, 43, 45, 53, 54, 57, 66, 68, 69, 70, 71, 73, 75, 77, 78, 84, 88, 90, 91, 94, 103, 108, 109, 110, 111, 113, 115, 117, 118, 124, 125, 127], "general_inform": 28, "generate_request": 109, "generate_stream": 53, "generated_text": [22, 29, 53], "generatereqinput": 51, "generation_config": [23, 51], "generation_duration_second": 24, "generation_tokens_bucket": [15, 22, 27, 28, 29, 30, 41, 42], "generation_tokens_tot": 109, "generative_model": 115, "gentl": 15, "geographi": [27, 28], "geq": 42, "germani": [26, 27, 28, 45, 101], "get": [0, 5, 9, 11, 13, 15, 23, 24, 25, 26, 27, 28, 29, 30, 32, 43, 46, 49, 53, 54, 55, 62, 76, 80, 81, 82, 84, 90, 95, 103, 104, 107, 115, 119, 121], "get_current_d": [27, 28], "get_current_weath": [27, 28, 29], "get_embed": 115, "get_image_featur": 115, "get_load": [5, 24], "get_max_total_num_token": 41, "get_memory_pool_s": 41, "get_messag": [27, 28, 29], "get_model_info": [23, 24, 41, 101, 103], "get_model_load": 19, "get_prompt": 30, "get_server_arg": 41, "get_server_info": [23, 24, 41, 53], "get_start": 0, "get_tourist_attract": 29, "get_weath": [24, 29], "getattr": 9, "gf_auth_anonymous_en": 109, "gf_server_http_port": 109, "ggml": [27, 51], "gguf": [19, 23, 116], "gh": 78, "ghp_xxxxx": 24, "giant": [41, 121], "gibberish": 53, "gid": 103, "gigabyt": [12, 23], "gigachat3": 23, "git": [17, 33, 55, 60, 64, 68, 76, 79, 80, 81, 84, 90, 91, 92, 93, 94, 95, 113], "github": [0, 3, 11, 17, 24, 30, 33, 37, 41, 47, 50, 51, 55, 64, 67, 68, 69, 76, 79, 80, 81, 84, 90, 91, 92, 93, 94, 95, 98, 101, 107, 110, 113, 125, 127], "github_token": 78, "githubusercont": 47, "give": [15, 27, 28, 29, 42, 60, 101, 115], "given": [9, 12, 18, 24, 26, 27, 28, 29, 32, 33, 41, 42, 51, 121], "glitter": 15, "glm": [6, 23, 24, 25, 29, 64, 67, 77, 89, 108, 125, 127], "glm45": [23, 24, 36, 37], "glm47": [23, 36], "glm4moethinkingbudgetlogitprocessor": [36, 37], "glm4v": [30, 47, 101], "glm5_w4a8": 84, "glm_ocr": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 101], "glm_ocr_nextn": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 101], "glmasr": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 101], "glmasrconfig": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 101], "glob": [9, 23], "global": [12, 24, 27, 28, 74, 110], "global_force_attn_backend": 69, "global_force_attn_backend_context_manag": 69, "global_segment_s": 13, "glog_v": [91, 113], "gloo": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 97, 101], "gloo_socket_ifnam": [82, 83, 84, 103, 107], "gme": [89, 119], "gnu": [0, 90], "gnupg": 54, "go": [28, 38, 45, 79, 81, 109], "goal": 115, "golang": 24, "gold": 24, "golden": [15, 121], "good": [14, 15, 32, 55, 70, 79, 80, 101], "googl": [77, 89, 94, 101, 108, 125, 127], "got": 57, "govern": 28, "gpqa": 58, "gpqa_diamond": 20, "gpt": [20, 22, 23, 24, 29, 45, 77, 89, 125], "gptoss": 89, "gptq": [19, 23, 77], "gptq_marlin": [19, 23], "gpu": [3, 4, 5, 6, 8, 11, 12, 14, 17, 18, 19, 20, 21, 23, 25, 26, 30, 32, 33, 36, 37, 39, 40, 43, 49, 50, 54, 55, 56, 58, 60, 61, 62, 64, 67, 73, 74, 76, 77, 78, 80, 81, 82, 88, 95, 97, 103, 104, 105, 106, 107, 108, 114, 127], "gpu_config": 78, "gpu_id_step": [15, 22, 27, 28, 29, 30, 41, 42], "gqa": 5, "grade": [5, 19, 76, 108], "gradual": [18, 94], "grafana": 109, "grain": [8, 12, 17, 33, 54, 70, 101, 108, 110, 127], "gram": 124, "grammar": [13, 27, 28, 29, 51, 105], "grammar_backend": [15, 22, 27, 28, 29, 30, 41, 42], "grammar_queu": 13, "grandeur": 45, "grandmoth": 42, "granit": [89, 125], "granular": [12, 18, 54, 58], "graph": [1, 2, 4, 8, 15, 19, 23, 25, 26, 32, 33, 41, 54, 56, 74, 77, 82, 83, 84, 88, 98, 103, 104, 107, 127], "graph_kei": 3, "graphic": 95, "gre": 105, "great": [118, 124], "greater": [2, 5, 8, 12, 15, 17, 18, 23, 26, 42, 121], "greedi": [26, 51], "greedy_token_select": 99, "greek": 45, "greenctx": 23, "greet": 51, "grep": [103, 104, 107], "grew": 15, "grid": 23, "grid_siz": 57, "grok": [89, 94, 125], "ground": 31, "group": [1, 4, 5, 8, 12, 15, 21, 23, 24, 32, 33, 53, 60, 79, 88, 93, 97], "group_m": 26, "group_nam": 25, "group_siz": [19, 23], "grouped_gemm": 8, "grow": [18, 28, 42, 51], "growth": [28, 101], "grpc": [23, 25, 88, 110], "grpc_mode": [15, 22, 27, 28, 29, 30, 41, 42], "grpo": [4, 108], "grub_cmdline_linux": 79, "gryffindor": 101, "gsai": 35, "gserver": 53, "gsm8k": [20, 55, 56, 58, 80, 115], "gsp": 53, "gt": [22, 27, 28, 29, 30, 42, 101], "gte": [41, 46, 77, 89, 119], "gte_qwen2": 89, "guarante": [12, 25, 27, 51, 121], "guard": [15, 19], "gui": 54, "guid": [5, 11, 17, 19, 23, 25, 27, 29, 32, 40, 51, 52, 54, 61, 65, 67, 73, 74, 76, 79, 81, 87, 91, 94, 103, 113, 123], "guidanc": [24, 72, 73, 90, 94, 98, 108, 115], "guidance_scal": 75, "guidelin": [42, 55, 67, 80, 115], "gz": [19, 54, 56, 74], "h": [5, 13, 24, 32, 33, 40, 46, 47, 52, 54, 57, 62, 69, 90, 95, 104, 107, 118, 121, 124], "h1": 125, "h100": [1, 26, 32, 37, 39, 50, 64, 67, 76, 77, 106], "h20": [1, 2, 32, 33, 103], "h200": [1, 33, 36, 37, 39, 49, 50, 67, 78, 106], "h2d": [15, 23], "ha": [1, 3, 5, 9, 12, 14, 15, 18, 19, 20, 23, 24, 25, 28, 29, 32, 33, 36, 38, 39, 41, 42, 49, 54, 55, 58, 61, 62, 64, 74, 75, 78, 80, 84, 85, 90, 103, 107, 108, 110, 116, 125], "had": [15, 18, 28, 45], "hadn": 54, "hair": [15, 101], "half": [23, 24, 93, 101], "halt": 15, "hand": [6, 14, 18], "handl": [5, 8, 9, 11, 17, 18, 20, 22, 23, 24, 25, 26, 30, 32, 41, 51, 52, 54, 75, 94, 103, 104, 115, 119, 127], "handler": [23, 55, 80, 88], "handoff": 25, "handsom": 15, "hang": [23, 30], "happen": [13, 14, 19, 23, 25, 37, 50, 116, 127], "happi": [15, 42, 55, 80, 108], "hard": [11, 103], "hardwar": [1, 8, 15, 18, 19, 23, 33, 39, 55, 58, 73, 79, 80, 81, 82], "harm": 56, "harmoni": 42, "harri": 101, "has_audio_understand": 41, "has_image_understand": 41, "hash": [24, 58, 97, 115], "hasn": 103, "hat": 125, "hatch": 15, "have": [5, 15, 17, 18, 19, 23, 26, 27, 28, 32, 38, 41, 42, 45, 47, 54, 55, 62, 64, 72, 74, 76, 79, 80, 81, 82, 84, 88, 90, 92, 94, 95, 97, 99, 103, 104, 108, 110, 115, 121, 124, 125, 127], "hazard": 18, "hbm": 94, "hccl_algo": 82, "hccl_buffsiz": [8, 82, 83, 84, 86], "hccl_op_expansion_mod": [82, 84, 86], "hccl_socket_ifnam": [82, 83, 84], "hdk": 81, "he": [15, 101], "head": [1, 5, 12, 23, 26, 33, 37, 43, 50, 54, 82, 83, 88, 104, 105, 107, 115, 127], "head_nod": 105, "head_node_ip": 33, "header": [23, 24, 88, 97, 110, 118], "headlin": 38, "headshotx": 64, "heal": 15, "health": [5, 17, 43, 94, 97, 101, 107], "health_checks_tot": 24, "health_gener": [24, 41], "healthcar": 42, "healthi": [14, 24, 25, 101], "hear": 28, "heard": [15, 28], "heart": 101, "heartbeat": 17, "heartbroken": 15, "heavi": [7, 15, 23, 88], "heavili": 29, "hei": 51, "height": [61, 75], "heightxwidth": 53, "hellaswag": 58, "hello": [19, 24, 29, 42, 43, 51, 91, 113, 115], "helm": 104, "help": [0, 12, 14, 15, 18, 23, 27, 28, 29, 30, 38, 40, 42, 45, 51, 53, 54, 55, 61, 76, 79, 80, 94, 98, 101, 104, 107, 108, 109, 127], "henc": 18, "her": [15, 45, 121], "here": [11, 12, 14, 15, 19, 25, 26, 27, 28, 29, 30, 32, 41, 42, 45, 51, 52, 55, 61, 64, 76, 79, 80, 81, 83, 84, 86, 101, 103, 104, 108, 109, 116], "heritag": 42, "heterogen": 24, "heurist": [14, 33], "hf": [15, 19, 23, 26, 41, 53, 96, 115, 123, 124, 125, 127], "hf3f": [12, 13, 23], "hf_chat_template_nam": [15, 22, 27, 28, 29, 30, 41, 42], "hf_home": 60, "hf_ptq": 19, "hf_token": [24, 60, 68, 76, 79, 81, 90, 115], "hf_xxx": 60, "hh": 74, "hi": [15, 41, 42, 51, 101, 105, 121], "hicach": [23, 77, 88], "hicache_io_backend": [15, 22, 27, 28, 29, 30, 41, 42], "hicache_mem_layout": [15, 22, 27, 28, 29, 30, 41, 42], "hicache_ratio": [12, 15, 22, 23, 27, 28, 29, 30, 41, 42], "hicache_s": [12, 15, 22, 27, 28, 29, 30, 41, 42], "hicache_storage_backend": [13, 15, 22, 27, 28, 29, 30, 41, 42], "hicache_storage_backend_extra_config": [12, 13, 15, 22, 27, 28, 29, 30, 41, 42], "hicache_storage_backend_extra_config_json": 13, "hicache_storage_pass_prefix_kei": 13, "hicache_storage_prefetch_polici": [13, 15, 22, 27, 28, 29, 30, 41, 42], "hicache_write_polici": [15, 22, 27, 28, 29, 30, 41, 42], "hicachecontrol": 13, "hicachefil": 12, "hicachestorag": 12, "hidden": [8, 9, 15, 23, 26, 42, 51, 88], "hidden_s": 8, "hidden_st": [115, 116], "hide": [8, 12, 15], "hierarch": [11, 12, 77], "hierarchi": [12, 54, 110], "hierarchical_sparse_attention_extra_config": [15, 22, 27, 28, 29, 30, 41, 42], "high": [5, 8, 12, 15, 19, 23, 25, 26, 28, 29, 30, 32, 34, 37, 38, 43, 50, 51, 58, 61, 62, 70, 77, 84, 91, 93, 99, 108, 113, 119, 121, 125, 127], "higher": [1, 5, 8, 11, 12, 14, 15, 18, 19, 20, 23, 25, 26, 28, 38, 42, 45, 51, 55, 70, 71, 78, 80, 81, 94, 121, 124, 127], "higherrorr": 24, "highest": [5, 24, 51, 99], "highest_token_prob": 51, "highlat": 24, "highli": [5, 7, 8, 25, 45, 51], "highlight": [15, 22, 27, 28, 29, 41, 45, 46, 47, 52, 75, 101], "hilab": [89, 127], "him": 15, "hint": 8, "hiradix_cach": 13, "hiradixcach": 13, "hisi_hdc": [81, 84], "histogram": [23, 24, 33, 88, 109], "histogram_quantil": 24, "histor": [26, 97], "histori": [5, 29, 41, 42, 65, 78], "historian": 45, "hit": [5, 11, 12, 14, 24, 51, 103, 109], "hmm": [26, 28, 45], "hobbi": 42, "hold": [12, 75], "holist": 127, "home": [24, 26, 41, 42, 56, 79, 90, 104], "honest": 15, "hood": [25, 98], "hook": 8, "hook_cal": 9, "hook_factori": 23, "hook_factory_path": 9, "hook_spec": 9, "hope": [15, 42], "hopper": [1, 8, 19, 23, 32, 33, 39, 64, 97], "horizon": 125, "horizont": [7, 24], "hormon": 101, "host": [0, 2, 5, 11, 12, 13, 15, 17, 18, 19, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 57, 58, 68, 76, 79, 81, 82, 83, 84, 88, 90, 91, 93, 94, 95, 97, 101, 103, 104, 107, 109, 113, 114, 115, 116, 119, 121, 123, 124, 125, 127], "hostipc": [103, 104, 107], "hostnam": [23, 82, 83, 84, 105], "hostnetwork": [103, 104, 107], "hostpath": [103, 104, 107], "hot": [5, 12], "hottest": 12, "hour": [15, 32], "hous": [42, 101], "hover": 78, "how": [0, 1, 12, 14, 15, 18, 19, 23, 24, 25, 26, 28, 30, 32, 41, 42, 45, 53, 54, 69, 77, 79, 90, 92, 95, 99, 105, 109, 112, 117, 127], "howee": 89, "howev": [5, 6, 7, 12, 14, 15, 24, 29, 30, 42, 49, 98, 103, 108, 110, 115, 116, 127], "hpu": [23, 33], "html": [27, 54, 78, 111, 115], "http": [0, 2, 3, 4, 5, 7, 11, 15, 16, 17, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 68, 69, 74, 76, 78, 79, 80, 81, 82, 83, 84, 90, 91, 92, 93, 94, 95, 97, 98, 101, 102, 103, 104, 107, 109, 110, 111, 113, 115, 118, 119, 121, 124, 127], "http_proxi": [82, 84], "http_server": [13, 41, 115, 118], "http_worker_ipc": 15, "httpget": 107, "https_proxi": [82, 84], "huawei": 8, "hub": [15, 23, 24, 28, 33, 41, 42, 68, 76, 79, 116], "hufflepuff": 101, "hug": [19, 23, 45, 62, 64, 77, 96, 115, 125], "huge": [26, 42], "huggingfac": [15, 19, 23, 24, 30, 41, 51, 56, 60, 61, 64, 68, 76, 79, 84, 90, 114, 115, 119, 121, 123, 125, 127], "huggingface_hub": 115, "huggingfacetb": [89, 125], "huihui": 89, "human": [9, 23, 42, 123, 124, 127], "human_ev": 58, "humanev": 58, "humor": [30, 47], "hundr": 90, "hunyuan": [67, 70, 71, 72, 73, 125], "hunyuanvideo": [34, 64, 70, 71, 72, 73], "hybrid": [6, 8, 17, 22, 23, 39, 45, 49, 88, 125, 127], "hybrid_attn_backend": 1, "hyperparamet": [18, 23, 77], "i": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 36, 37, 38, 39, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 103, 105, 108, 109, 110, 111, 113, 115, 116, 118, 119, 121, 123, 124, 125, 127], "i2v": 64, "ib": [11, 17, 23, 25, 33, 88, 103, 104, 107], "ibdev2netdev": 103, "ibm": [89, 125], "ibstatu": 103, "ibv_devic": 103, "ibv_devinfo": 103, "icon": [26, 41, 42, 47], "id": [17, 22, 23, 25, 26, 27, 28, 29, 32, 41, 47, 51, 52, 53, 54, 57, 61, 62, 64, 66, 78, 81, 82, 88, 104, 107, 118], "id2label": [24, 118], "idea": [12, 42, 55, 80], "ideal": [11, 18, 24, 121], "idempot": 13, "ident": [3, 4, 12, 13, 18, 25, 79], "identif": 54, "identifi": [2, 11, 23, 28, 54, 62, 74, 75, 90, 95, 118, 121, 123, 125, 127], "idl": [5, 8, 12, 23, 25, 32, 88], "idle_timeout": 24, "idx": 57, "ifconfig": 84, "ifnam": 82, "ignor": [15, 19, 22, 23, 26, 27, 28, 29, 30, 33, 41, 45, 46, 47, 52, 53, 61, 94, 101], "ignore_eo": 51, "igw": 24, "ii": [32, 41], "iic": 89, "illustr": [64, 75, 90], "im_end": [30, 51, 96, 101], "im_start": [30, 51, 96, 101], "imag": [3, 7, 23, 24, 31, 33, 41, 51, 53, 56, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 79, 84, 88, 90, 93, 101, 103, 109, 115, 119, 125, 127], "image_byt": [62, 101], "image_data": [30, 51], "image_encod": 75, "image_encoding_stage_primari": 75, "image_featur": 30, "image_fil": 101, "image_grid_thw": 30, "image_id": [62, 76], "image_nam": [81, 93], "image_output": 30, "image_pad": 30, "image_path": 119, "image_qa": 101, "image_tag": 76, "image_token": 30, "image_uri": 76, "image_url": [31, 37, 47, 50, 62, 101, 121], "imagedataitem": 51, "imageencodingstag": 75, "imagevaeencodingstag": 75, "imbal": [8, 17, 97], "imbalanc": 5, "img": 62, "imit": 115, "immedi": [12, 13, 15, 23, 24, 25, 53, 54, 55, 61, 80], "impact": [12, 24, 42, 54, 65, 127], "imper": 65, "impl": [23, 88, 91, 113, 116], "implement": [1, 9, 11, 12, 20, 22, 23, 24, 25, 26, 29, 32, 33, 36, 37, 45, 53, 61, 62, 69, 73, 77, 81, 91, 94, 97, 98, 99, 104, 110, 113, 116, 125, 127], "impli": 38, "implic": 42, "import": [0, 4, 5, 9, 14, 15, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 41, 42, 43, 45, 46, 47, 51, 52, 57, 62, 64, 65, 72, 83, 91, 94, 101, 113, 115, 116, 118, 119, 121, 124, 127], "import_model_class": 115, "import_modul": 9, "import_new_model_class": 115, "importlib": [9, 22, 27, 28, 29, 30, 42], "impos": 110, "improv": [3, 4, 5, 7, 8, 11, 12, 15, 18, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 37, 38, 41, 42, 45, 46, 47, 49, 50, 52, 65, 70, 94, 101, 121, 125, 127], "in_plac": 25, "inaccur": 54, "inc": [89, 125], "includ": [3, 7, 8, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 41, 42, 45, 53, 54, 57, 58, 61, 62, 75, 77, 84, 89, 90, 94, 98, 101, 109, 115, 118, 119, 121, 125], "inclus": 54, "inclusionai": [89, 124, 125], "incom": [12, 17, 23], "incompat": [1, 64, 127], "incomplet": 25, "inconsist": [12, 29, 53], "incorpor": [15, 26, 107, 121, 125], "incorrect": [26, 42, 99], "incorrectli": 3, "increas": [2, 3, 8, 12, 15, 17, 18, 19, 23, 24, 26, 28, 29, 32, 33, 42, 45, 49, 74, 94, 101, 125, 127], "increasingli": 42, "incred": 42, "incredibli": 42, "increment": [12, 14, 24, 97], "incur": [6, 99], "inde": 28, "indent": [28, 57, 118], "independ": [5, 7, 24, 25, 32, 91, 113], "indetermin": 98, "index": [0, 15, 24, 26, 29, 32, 33, 41, 45, 46, 47, 52, 54, 74, 76, 78, 81, 82, 90, 95, 104, 107, 118, 121], "indic": [1, 8, 14, 17, 20, 28, 97, 103], "individu": [42, 54, 71, 115], "inductor": [23, 88], "inductor_root_cach": 111, "industri": [24, 39, 42, 77, 108], "ineffici": [7, 17, 54], "inequ": 42, "inet": 84, "inexplic": 15, "inf": [51, 53, 90, 95, 109], "infer": [2, 5, 7, 8, 12, 15, 17, 19, 23, 30, 32, 33, 37, 43, 49, 50, 53, 55, 67, 71, 72, 73, 74, 75, 76, 77, 79, 80, 84, 90, 94, 95, 98, 103, 107, 108, 115, 125, 127], "inference_mod": 97, "infiniband": [23, 103, 104, 107], "infinit": [18, 23, 53, 124], "influenc": [42, 45], "info": [9, 11, 15, 22, 23, 24, 26, 27, 28, 29, 30, 37, 42, 45, 46, 47, 50, 52, 81, 84, 88, 91, 101, 103, 105, 113, 121], "inform": [17, 23, 24, 27, 28, 29, 33, 38, 41, 42, 43, 45, 51, 54, 57, 62, 76, 90, 94, 101, 116, 118], "infra": [76, 94], "infrastructur": [17, 18, 24, 25, 55, 61, 80, 108], "ing": 32, "inher": [12, 18], "inherit": [1, 29, 75, 115], "init": [2, 15, 17, 18, 23, 24, 33, 41, 82, 83, 84, 88, 91, 94, 103, 104, 105, 107, 113], "init_cuda_graph_st": 1, "init_expert_loc": [15, 22, 27, 28, 29, 30, 41, 42], "init_forward_metadata": 1, "init_forward_metadata_capture_cuda_graph": 1, "init_forward_metadata_replay_cuda_graph": 1, "init_weights_update_group": 25, "initi": [1, 2, 7, 9, 12, 15, 17, 18, 19, 22, 23, 24, 25, 26, 41, 42, 45, 46, 47, 51, 57, 64, 69, 74, 75, 90, 91, 98, 99, 101, 105, 110, 113], "initialdelaysecond": [103, 107], "inject": [23, 24, 75], "inner": [9, 20], "innov": [25, 32, 45], "inorgan": 30, "inplac": 0, "input": [4, 7, 8, 9, 12, 15, 17, 22, 23, 24, 26, 29, 33, 38, 41, 51, 53, 54, 55, 56, 57, 58, 62, 63, 71, 72, 73, 75, 76, 78, 79, 80, 82, 83, 88, 90, 94, 95, 98, 109, 115, 118, 119, 121, 125, 126], "input_emb": [23, 51, 115], "input_hidden_st": 8, "input_id": [23, 29, 30, 46, 51, 115], "input_ids_embed": 46, "input_item": 24, "input_len": [53, 78], "input_seq_len": 94, "input_text": 41, "input_throughput": 78, "input_validation_stag": 75, "inputvalidationstag": 75, "inquiri": 42, "insepar": 15, "insert": [26, 90, 110], "insid": [3, 24, 54, 56, 60, 76], "inspect": [14, 24, 54], "inspir": [12, 42], "inst": 127, "instal": [5, 17, 23, 38, 43, 52, 53, 54, 56, 57, 58, 59, 60, 61, 64, 69, 77, 78, 87, 97, 103, 104, 107, 109, 110], "installationguid": 54, "instanc": [5, 8, 11, 12, 13, 15, 17, 19, 21, 23, 24, 25, 45, 51, 54, 82, 88, 90, 94, 99, 109], "instanti": [24, 75], "instantli": 54, "instead": [9, 12, 15, 18, 20, 22, 23, 26, 27, 28, 29, 30, 35, 38, 41, 42, 51, 53, 55, 61, 74, 80, 97, 98, 101, 109, 115, 118, 127], "instinct": [68, 79], "instruct": [0, 1, 3, 4, 5, 6, 7, 11, 15, 17, 19, 23, 24, 26, 27, 28, 29, 30, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 65, 67, 69, 73, 74, 76, 79, 80, 81, 89, 90, 93, 95, 101, 103, 105, 109, 111, 114, 115, 116, 119, 125, 127], "instruct_lora_4_alpha_16": 15, "instrument": 110, "insuffici": 19, "int": [3, 17, 23, 24, 25, 27, 28, 51, 57, 69, 88], "int32": [45, 51, 57], "int32_t": 57, "int4": [19, 77, 93, 97, 125], "int4_awq": 23, "int4wo": [19, 23, 93], "int64_t": 57, "int8": [19, 32, 82, 90], "int8_kernel": 19, "int8dq": [19, 23], "int8wo": [19, 23], "integ": [23, 27, 28, 51, 53, 70, 118], "integr": [5, 7, 8, 19, 23, 25, 30, 38, 42, 55, 57, 70, 75, 77, 80, 84, 97, 103, 115, 119, 125, 127], "integratedtermin": 56, "intel": [1, 19, 39, 76, 77, 90, 95], "intel_amx": 23, "intel_xpu": [1, 39, 95], "intellectu": 42, "intellig": [11, 40, 42, 43, 70, 115, 121, 125, 127], "intend": 13, "intens": [7, 17, 25], "intention": 15, "inter": [5, 21, 23, 53, 88, 94], "interact": [0, 23, 25, 42, 43, 54, 61, 78], "interconnect": 6, "interest": [42, 55, 80, 104, 108], "interfac": [8, 24, 67, 69, 84, 109, 115, 118, 119, 121], "interface_v1": 11, "interleav": [8, 47], "intermedi": [9, 23], "intern": [9, 24, 45, 54, 56, 58, 103, 109, 115, 118], "internal_st": 41, "internlm": [89, 123, 125], "internlm2": [89, 123, 125], "internlm2forrewardmod": 123, "internlm2forrewardmodel": 118, "internvl": 6, "interpol": 23, "interpret": [22, 29, 38], "interrupt": [17, 25], "interv": [5, 17, 23, 24, 55, 80, 88, 97], "intervent": 8, "intervitensinc": 90, "intfloat": [89, 119], "intra": 18, "intra_node_nvlink": [17, 97], "introduc": [5, 7, 8, 12, 14, 15, 17, 18, 20, 23, 25, 32, 41, 55, 80, 95, 98, 103], "introduct": [42, 55, 80, 115, 124], "introductori": 115, "invalid": [9, 33, 118], "invari": [4, 23], "inventori": 24, "investig": 98, "invoc": 33, "invok": [9, 19, 29], "involv": [6, 12, 32, 41, 42, 101, 110, 115], "io": [0, 11, 12, 23, 24, 30, 81, 84, 88, 102, 103, 104, 107, 115], "io_struct": [29, 51], "iommu": 79, "ip": [2, 21, 23, 38, 81, 82, 84, 88, 97, 101, 105, 109], "ip1": [82, 83, 84], "ip2": [82, 83, 84], "ipc": [37, 50, 56, 68, 76, 79, 81, 90, 114], "ipc_lock": [104, 107], "ipostyellow": 64, "ipynb": [0, 15], "ipython": 42, "irang": 57, "ireland": [27, 28], "iron": [47, 101], "is_async": 25, "is_embed": [15, 22, 27, 28, 29, 30, 41, 42], "is_gener": 41, "is_healthi": 24, "is_matryoshka": 119, "is_multimodal_model": 115, "isl": 94, "isn": 103, "iso": 41, "isol": [19, 24, 64, 103], "issu": [4, 11, 12, 13, 15, 18, 19, 20, 23, 25, 32, 33, 39, 55, 63, 64, 74, 76, 79, 80, 81, 82, 88, 90, 92, 95, 98, 101, 109, 110, 121], "istanbul": 42, "itali": [27, 28, 45, 101], "itd": [56, 84], "item": [9, 24, 30, 41, 55, 62, 80, 121], "item1": 23, "item2": 23, "item_first": 41, "item_id": 24, "items_stor": 24, "iter": [2, 18, 23, 41, 54, 75], "iter_lin": [51, 52], "itl": 53, "its": [3, 5, 8, 12, 15, 18, 23, 24, 26, 27, 28, 38, 41, 42, 45, 51, 54, 55, 62, 75, 80, 84, 97, 99, 110, 115, 119, 125], "itself": 25, "j": [78, 105, 125], "j_master": 105, "j_node": 105, "jaeger": 110, "jamesliu1": 26, "janeiro": 28, "janu": [89, 127], "japan": [15, 26, 45, 101], "japanes": [61, 125], "jason9693": [24, 118, 123], "javascript": 78, "jax": [23, 94, 108], "jax_compilation_cache_dir": 94, "jean": 47, "jet": [125, 127], "jetpack": 93, "jetson": [76, 77], "jetvlm": 127, "jinja": [24, 29, 32, 33, 121], "jit": [8, 23, 77, 94, 97], "jit_cach": 94, "jit_kernel": 57, "jitter": 24, "job": [24, 42, 55, 78, 80, 105], "jobs_presenting_ipod": [37, 50, 127], "jog": 101, "johnni": 93, "joi": 15, "join": [9, 11, 29, 77, 94], "jointli": [84, 125], "jointthreshold": 124, "joke": 4, "joy": 121, "jpeg": [53, 121], "jpg": [31, 62, 119], "json": [4, 5, 9, 11, 12, 13, 15, 19, 20, 22, 23, 24, 26, 29, 31, 32, 37, 40, 41, 46, 47, 50, 52, 53, 54, 55, 56, 57, 61, 62, 63, 65, 69, 70, 74, 75, 78, 80, 85, 88, 101, 104, 107, 109, 110, 115, 118, 119, 121, 124, 127], "json_data": 15, "json_model_override_arg": [15, 22, 27, 28, 29, 30, 41, 42], "json_output": 101, "json_schema": [27, 28, 51], "judg": 43, "judgment": 12, "jul": 27, "jump": [22, 38], "jupyt": 0, "just": [12, 14, 15, 23, 28, 40, 57, 60, 74, 94, 96, 97, 115, 116, 124], "justmycod": 56, "k": [15, 26, 28, 41, 51, 61, 69, 90], "k2": [5, 22, 24, 29, 61, 89, 106, 125], "k8": [5, 24, 76, 103, 107], "k_cach": [33, 57], "k_proj": [15, 23], "k_scale": 20, "kblocksiz": 57, "kconstant": 57, "kda": 125, "kdlcpu": 57, "kdlcuda": 57, "keen": 42, "keep": [0, 6, 13, 23, 24, 25, 28, 30, 37, 38, 45, 50, 55, 56, 61, 80, 88, 105, 115, 127], "keep_mm_feature_on_devic": [15, 22, 27, 28, 29, 30, 41, 42], "keep_paus": 25, "keepal": 24, "keg": 84, "kei": [1, 7, 8, 9, 12, 17, 18, 19, 20, 23, 25, 27, 28, 30, 32, 38, 41, 42, 45, 51, 54, 61, 63, 66, 69, 73, 74, 77, 79, 88, 94, 97, 101, 104, 107, 115, 127], "kept": 38, "kernel": [1, 3, 4, 8, 11, 12, 15, 19, 20, 22, 25, 26, 27, 28, 29, 30, 32, 33, 41, 42, 54, 67, 69, 73, 74, 76, 77, 79, 82, 83, 84, 90, 92, 94, 97, 98, 108], "kernel_ascend": [23, 88], "key_stat": 116, "keyword": 115, "kfd": [60, 68, 79], "kill": 54, "kimi": [5, 22, 23, 24, 29, 45, 77, 89, 106, 125, 127], "kimi_k2": [22, 23, 29], "kind": [15, 24, 42, 103, 104, 107], "king": 15, "kingdom": [15, 45, 101], "kit": 93, "kk": 3, "kl": 108, "klein": [34, 64], "knew": 15, "knob": 13, "know": [26, 28, 42, 43, 45, 88, 115], "knowledg": [27, 28, 42, 45], "known": [5, 19, 26, 28, 41, 42, 45, 77, 125], "korean": 125, "kt": [23, 88], "kt_cpuinfer": [15, 22, 27, 28, 29, 30, 41, 42], "kt_max_deferred_experts_per_token": [15, 22, 27, 28, 29, 30, 41, 42], "kt_method": [15, 22, 27, 28, 29, 30, 41, 42], "kt_num_gpu_expert": [15, 22, 27, 28, 29, 30, 41, 42], "kt_threadpool_count": [15, 22, 27, 28, 29, 30, 41, 42], "kt_weight_path": [15, 22, 27, 28, 29, 30, 41, 42], "ktransform": 88, "kubectl": [76, 103, 104, 107], "kubernet": [12, 23, 106], "kv": [1, 5, 7, 11, 12, 13, 15, 17, 18, 19, 23, 25, 32, 33, 39, 41, 49, 54, 77, 81, 88, 94, 98, 125], "kv16": 20, "kv4": [1, 20], "kv8": 20, "kv_cach": [20, 25], "kv_cache_dtyp": [15, 22, 27, 28, 29, 30, 33, 41, 42], "kv_cache_qformat": 19, "kv_events_config": [15, 22, 27, 28, 29, 30, 41, 42], "kvcach": [11, 12, 17, 18, 23, 39, 41, 53, 57, 88], "kwarg": 116, "l": [18, 28, 43, 51, 62, 105], "l0": 24, "l1": [12, 24, 71, 73], "l12": 38, "l15": 38, "l2": 12, "l27": 38, "l3": 13, "l31": 38, "l34": 38, "l38": 38, "l4": [24, 76], "l40": [32, 76], "l53": 38, "l57": 38, "l7": 24, "lab": [4, 34, 51, 64, 68, 70, 89, 91, 108, 113, 127], "label": [15, 22, 23, 24, 25, 27, 28, 29, 30, 41, 42, 54, 55, 60, 80, 88, 103, 104, 107, 109, 110, 118, 121], "label1": 23, "label2": 23, "label_0": [24, 118], "label_1": [24, 118], "label_n": 24, "label_token_id": 41, "laboratori": 84, "lack": [19, 53], "landmark": [26, 28, 41, 42], "landscap": 61, "lang": 101, "languag": [6, 7, 12, 15, 17, 18, 23, 40, 42, 45, 47, 50, 52, 57, 76, 77, 88, 90, 94, 96, 108, 116, 117, 126], "language_onli": [15, 22, 27, 28, 29, 30, 41, 42], "larg": [1, 2, 3, 5, 8, 12, 14, 15, 17, 18, 20, 23, 24, 25, 28, 32, 35, 37, 40, 50, 53, 54, 61, 68, 74, 76, 77, 84, 90, 94, 106, 108, 117, 119, 121, 126, 127], "larger": [3, 5, 12, 14, 15, 17, 18, 20, 23, 28, 30, 32, 33, 51, 61, 90, 94, 95, 97, 125, 127], "largest": [26, 28, 42, 45, 52, 125], "last": [9, 22, 23, 26, 57, 60, 66, 70, 76, 78, 79, 81, 110, 118], "last_gen_throughput": 41, "last_hidden_st": 30, "lastli": 115, "late": 38, "latenc": [3, 5, 8, 12, 15, 17, 19, 23, 24, 25, 32, 33, 37, 50, 53, 54, 55, 58, 65, 74, 77, 78, 80, 88, 109, 119, 121, 127], "latency_m": 78, "latent": [1, 5, 23, 75], "latent_preparation_stag": 75, "latentpreparationstag": 75, "later": [3, 5, 9, 14, 16, 25, 29, 60, 93, 99], "latest": [18, 24, 27, 28, 33, 38, 39, 50, 68, 76, 82, 90, 94, 102, 103, 107, 108, 109, 114, 119, 125], "latter": 12, "launch": [0, 2, 3, 5, 7, 8, 11, 16, 19, 20, 25, 27, 28, 34, 35, 38, 42, 48, 51, 54, 55, 56, 58, 61, 62, 76, 79, 80, 81, 91, 93, 96, 97, 105, 109, 110, 111, 113, 114, 115], "launch_rout": [5, 7, 17, 24, 33, 54, 81, 82, 83, 104, 107, 110], "launch_serv": [1, 2, 3, 4, 5, 6, 7, 8, 11, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 76, 79, 80, 81, 82, 83, 84, 86, 90, 91, 93, 94, 95, 96, 101, 103, 104, 105, 107, 109, 110, 111, 113, 114, 115, 116, 119, 121, 123, 124, 125, 127], "launch_server_cmd": [15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 101], "launcher": 24, "launchkernel": 57, "laundri": 101, "law": [32, 45], "layer": [1, 3, 5, 6, 8, 9, 11, 12, 15, 18, 19, 20, 24, 26, 32, 39, 41, 55, 61, 62, 69, 80, 88, 97, 98, 104, 107, 115, 121, 125], "layer_first": [11, 12, 15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "layer_id": 115, "layerwis": [23, 88], "layerwise_profil": 54, "layout": [6, 8, 12, 13, 23, 88, 94], "lb": [82, 83, 110], "lccl": [91, 113], "ld_library_path": [82, 90], "ld_preload": 90, "le": [24, 109], "lead": [3, 4, 5, 7, 12, 15, 17, 18, 19, 25, 26, 39, 40, 51, 53, 98, 108], "leader": [15, 103, 104, 107], "leadercr": 104, "leadertempl": [103, 104], "leaderworkerset": [103, 104, 107], "leaderworkertempl": [103, 104], "leaf": 12, "leak": 24, "lean": 101, "learn": [0, 1, 4, 5, 15, 21, 23, 28, 42, 45, 77, 79, 108, 115, 119, 121, 123, 125, 127], "least": [1, 15, 18, 23, 29, 42, 51, 84, 101, 103], "leav": [51, 81], "led": [3, 15], "left": [15, 56], "legal": 45, "len": [9, 51, 52, 53, 54, 58, 82, 90, 94, 95], "length": [3, 4, 8, 12, 15, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 37, 39, 40, 41, 45, 46, 47, 50, 51, 52, 53, 54, 57, 62, 78, 82, 83, 88, 93, 97, 101, 104, 107], "less": [14, 17, 53, 54, 97, 108], "lestor": 101, "let": [9, 23, 24, 25, 26, 28, 29, 42, 45, 75, 101, 115], "letter": [27, 28, 29, 45, 47], "level": [1, 5, 6, 11, 12, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 41, 45, 46, 47, 50, 51, 52, 54, 70, 71, 73, 74, 79, 88, 91, 97, 101, 110, 113, 125], "level0": 82, "level1": 82, "leverag": [8, 12, 21, 41, 79, 108, 116, 125], "lfu": [23, 88], "lg": 125, "lgai": [89, 125], "li": 110, "lib": [15, 22, 24, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 82, 90, 95, 101], "lib64": 90, "libfabr": 17, "libiomp5": 90, "librari": [8, 23, 24, 25, 32, 33, 76, 90, 108, 115], "libtbbmalloc": 90, "libtcmalloc": 90, "licens": 125, "lid": 103, "life": [1, 15, 41, 42], "lifecycl": 24, "lift": 38, "light": [15, 28, 41], "lighter": [5, 24], "lightn": [33, 64], "lightweight": [6, 74, 127], "lightx2v": 64, "like": [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 18, 19, 22, 25, 26, 28, 29, 30, 32, 34, 41, 42, 49, 54, 55, 57, 61, 62, 71, 75, 80, 81, 88, 90, 97, 101, 103, 109, 119, 121, 122, 124, 125, 127], "likelihood": 45, "lill": 42, "limit": [5, 7, 11, 12, 14, 15, 17, 19, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 37, 41, 42, 45, 46, 47, 50, 52, 53, 54, 77, 78, 88, 93, 97, 98, 99, 101, 103, 104, 107], "limit_mm_data_per_request": [15, 22, 27, 28, 29, 30, 41, 42], "line": [8, 15, 17, 19, 23, 26, 27, 28, 29, 37, 38, 41, 42, 50, 55, 61, 67, 80, 90, 95, 109], "linear": [12, 19, 49, 64, 85, 125], "linearli": [5, 51], "ling": [89, 125], "linguist": 127, "link": [0, 17, 78, 81, 103, 115], "link_lay": 103, "link_up": 103, "linkedin": 102, "linkup": 103, "lint": [0, 55, 80], "linux": [56, 60, 90], "linux64cli": 56, "list": [4, 9, 15, 21, 22, 23, 25, 26, 29, 32, 34, 35, 38, 41, 43, 45, 46, 51, 52, 54, 55, 62, 64, 69, 70, 72, 80, 88, 97, 98, 101, 108, 110, 115, 118, 121], "list_lora": 62, "listen": [21, 23, 61, 62], "lite": [89, 125, 127], "liter": 29, "littl": [6, 62], "liuhaotian": [119, 127], "live": [15, 24, 41, 42, 54, 78], "livenessprob": 107, "ll": [28, 29, 42, 45, 54, 103], "llada": 35, "llada2": 124, "llada2moemodellm": 124, "llama": [1, 5, 15, 19, 23, 24, 26, 27, 41, 47, 51, 53, 54, 56, 76, 77, 79, 81, 88, 89, 93, 94, 95, 96, 108, 109, 111, 116, 119, 123, 125, 127], "llama2": [26, 127], "llama3": [23, 24, 26, 29, 89, 127], "llama4": [29, 48], "llama4forconditionalgener": 30, "llama_ckpt": 115, "llama_dir": 115, "llama_wrapp": 115, "llamaattent": 115, "llamaconfig": 115, "llamaforcausallm": [15, 115], "llamaforsequenceclassif": [118, 123], "llamaforsequenceclassificationwithnormal_weight": 118, "llamamlp": 115, "llamawrapp": 115, "llava": [47, 51, 89, 119, 127], "llavavid": 127, "llguidanc": [23, 27], "llm": [4, 6, 8, 12, 17, 18, 20, 22, 24, 26, 27, 28, 29, 30, 33, 34, 37, 39, 42, 43, 53, 76, 79, 82, 85, 89, 90, 91, 94, 95, 99, 108, 113, 115, 124, 125, 127], "llmcompressor": 19, "llvm": 57, "lm": [23, 82, 83, 88, 104, 107], "lm_head": [15, 19, 26, 115], "lmcach": 12, "lmdeploi": 53, "lmhead": 26, "lmm": [51, 89, 127], "lmsy": [26, 29, 38, 98, 102, 105, 108], "lmsysorg": [24, 33, 56, 60, 68, 76, 79, 81, 102, 104, 107, 114], "ln": 3, "lo": [82, 83], "load": [2, 7, 8, 9, 12, 14, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 41, 42, 45, 46, 47, 51, 52, 53, 54, 57, 61, 62, 70, 74, 75, 78, 82, 83, 85, 88, 90, 96, 101, 104, 108, 109, 116], "load_balance_method": [15, 22, 27, 28, 29, 30, 41, 42], "load_config": [19, 70], "load_dataset": 19, "load_decod": 61, "load_encod": 61, "load_format": [15, 22, 23, 25, 27, 28, 29, 30, 41, 42], "load_imag": [51, 101], "load_jit": 57, "load_lora_adapt": 15, "load_model": 19, "loadconfig": 19, "loaded_adapt": [15, 62], "loader": [19, 21, 25, 75, 115], "local": [0, 5, 15, 22, 23, 24, 25, 26, 27, 28, 29, 30, 38, 39, 41, 42, 43, 45, 46, 47, 52, 53, 55, 56, 61, 63, 76, 80, 81, 82, 83, 84, 90, 91, 94, 101, 113, 115, 123, 124, 125, 127], "local_attention_s": 23, "local_dir": 115, "local_host": 82, "local_host1": [82, 83, 84], "local_host2": [82, 83, 84], "local_input_imag": 62, "local_ip": [17, 33], "localattent": 69, "localhost": [2, 4, 5, 15, 16, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 62, 78, 88, 94, 101, 109, 127], "locat": [0, 12, 23, 24, 25, 27, 28, 29, 51, 52, 54, 56, 57, 88, 90, 104, 107], "lock": 24, "lof": 23, "log": [0, 2, 9, 11, 14, 15, 22, 26, 27, 28, 29, 37, 41, 45, 46, 47, 50, 51, 52, 63, 74, 76, 90, 91, 97, 101, 103, 107, 109, 113], "log_level": [15, 22, 27, 28, 29, 30, 41, 42], "log_level_http": [15, 22, 27, 28, 29, 30, 41, 42], "log_request": [15, 22, 27, 28, 29, 30, 41, 42], "log_requests_format": [15, 22, 27, 28, 29, 30, 41, 42], "log_requests_level": [15, 22, 27, 28, 29, 30, 41, 42], "log_requests_target": [15, 22, 27, 28, 29, 30, 41, 42], "logger": [9, 23], "logic": [3, 8, 9, 18, 24, 25, 29, 45, 51, 75, 118], "login": [76, 78, 109], "logit": [0, 23, 24, 32, 36, 37, 88, 97, 115], "logit_bia": 45, "logits_processor": 115, "logitsprocessor": 115, "logitsprocessoroutput": 115, "logo": [47, 68, 74], "logprob": [4, 23, 26, 29, 32, 45, 47, 51, 52, 98, 99, 104, 107, 121], "logprob_start_len": [51, 98], "london": [27, 28, 41, 45, 99, 101], "long": [0, 3, 5, 8, 11, 12, 14, 15, 19, 20, 23, 24, 25, 26, 32, 53, 54, 77, 98, 125, 127], "longer": [12, 17, 18, 20, 23, 45, 55, 56, 80, 97, 99], "longest": 14, "longev": 101, "look": [3, 9, 14, 27, 28, 30, 33, 42, 53, 55, 57, 75, 80, 95, 96, 115], "loop": [18, 24, 25, 42, 67, 70, 75, 101, 124], "lora": [0, 51, 53, 61, 67, 77, 94, 108, 127], "lora0": 15, "lora0_new": 15, "lora1": [15, 62], "lora2": [15, 62], "lora3": 15, "lora_1": 62, "lora_2": 62, "lora_a": 62, "lora_b": 62, "lora_backend": [15, 22, 27, 28, 29, 30, 41, 42], "lora_eviction_polici": [15, 22, 27, 28, 29, 30, 41, 42], "lora_id": 15, "lora_nam": [15, 23, 62], "lora_nicknam": 62, "lora_path": [15, 22, 23, 27, 28, 29, 30, 41, 42, 45, 51, 53, 61, 62], "lora_target_modul": [15, 22, 27, 28, 29, 30, 41, 42], "loraref": 15, "lose": 17, "loss": [15, 19, 70, 127], "lot": [55, 80], "loui": 42, "louvr": [26, 41, 42], "love": [15, 24, 42, 118], "low": [3, 5, 8, 12, 14, 23, 26, 28, 32, 38, 45, 51, 53, 54, 58, 62, 74, 77, 84, 88, 98, 121], "low_lat": [8, 23, 82, 83, 88, 107], "lowconfid": [23, 124], "lower": [1, 6, 12, 14, 19, 20, 23, 24, 26, 32, 37, 42, 45, 55, 61, 70, 72, 80, 94, 97, 98, 115, 124], "lowercas": 69, "lpm": [14, 23, 88], "lru": [15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "lru_cach": [26, 57, 115], "lsb": 54, "lscpu": 90, "lsof": 109, "lspci": 103, "lssf": 90, "lt": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "lustr": 54, "lw": [33, 103, 106, 107], "lws_group_siz": [103, 104, 107], "lws_leader_address": [103, 104, 107], "lws_worker_index": [103, 104, 107], "lyon": [26, 28, 42], "m": [1, 2, 3, 4, 5, 6, 7, 8, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 76, 79, 80, 81, 82, 83, 84, 86, 90, 91, 93, 94, 95, 96, 97, 101, 103, 104, 105, 107, 109, 110, 111, 113, 114, 115, 116, 119, 121, 123, 124, 125, 127], "m2": [48, 58, 89, 125], "m2t": 124, "m3": [41, 89, 121], "ma": 29, "maas_hosted_model": 104, "machin": [1, 4, 5, 23, 33, 42, 55, 56, 76, 79, 80, 81, 109, 111, 115, 121], "made": [0, 15, 18], "madrid": 45, "madrid2": 101, "magic": [15, 101], "magnific": 15, "mai": [5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 33, 38, 42, 53, 54, 55, 56, 58, 64, 72, 75, 79, 80, 90, 98, 101, 103, 104, 107, 110, 114, 119, 121, 123, 127], "main": [0, 2, 4, 6, 18, 19, 26, 28, 30, 37, 41, 42, 47, 50, 51, 53, 55, 61, 69, 75, 78, 80, 81, 84, 90, 95, 101, 104, 107, 110, 115, 119, 124, 127], "main_doc": [104, 107], "mainli": [12, 23, 41], "mainstream": [82, 84, 89], "maintain": [4, 5, 12, 18, 20, 23, 40, 55, 65, 72, 80, 94, 101, 110, 115], "mainten": 23, "major": [12, 26, 27, 28, 30, 33, 41, 45, 55, 80, 103, 108, 115], "make": [1, 3, 4, 13, 14, 23, 24, 25, 26, 27, 28, 29, 32, 40, 42, 45, 54, 55, 80, 81, 103, 108, 115, 118, 121, 124], "make_cpp_arg": 57, "make_hook": 23, "makefil": 0, "makeshift": 101, "malform": 9, "mamba": [125, 127], "mamba_full_memory_ratio": [15, 22, 27, 28, 29, 30, 41, 42], "mamba_scheduler_strategi": [15, 22, 27, 28, 29, 30, 41, 42], "mamba_ssm_dtyp": [15, 22, 27, 28, 29, 30, 41, 42], "mamba_track_interv": [15, 22, 27, 28, 29, 30, 41, 42], "mambaradixcach": 49, "man": [15, 47, 101], "manag": [2, 8, 11, 13, 15, 16, 17, 18, 19, 23, 25, 29, 61, 67, 75, 76, 90, 94], "mani": [1, 3, 12, 14, 15, 18, 23, 24, 25, 26, 32, 34, 42, 45, 53, 54, 55, 80, 90, 98, 99, 111, 115, 121], "manifest": 23, "manner": [26, 42, 51], "mantissa": 20, "manual": [0, 25, 32, 39, 54, 55, 62, 64, 80, 93, 110, 114], "manylinux2014_aarch64": 76, "manylinux2014_x86_64": 76, "map": [23, 24, 25, 26, 56, 75, 88, 109, 118], "marbl": 15, "margin": 12, "mark": [17, 23, 28, 110], "markdown": [31, 65], "marker": [23, 88], "market": 38, "marlin": [19, 23, 97], "marri": 15, "marseil": [26, 28, 42], "mask": [8, 35, 51, 69, 71, 73, 97, 124], "mask_strategi": 69, "mask_strategy_file_path": [61, 69], "massachusett": 29, "master": [2, 13, 25], "master_address": 25, "master_node_ip": 18, "master_port": 25, "master_server_address": 13, "match": [1, 3, 5, 9, 14, 23, 24, 25, 26, 27, 28, 29, 33, 39, 41, 43, 51, 57, 58, 61, 62, 63, 75, 88, 94, 97, 109, 115], "matched_stop": [26, 29, 32, 45, 47, 52, 104, 107], "matchlabel": [24, 104], "materi": [5, 102], "math": [53, 89, 101, 123, 125], "mathemat": 98, "matrix": [8, 32, 67, 77, 97], "matryoshka_dimens": 119, "matter": [20, 41, 70], "maturin": 24, "maverick": 39, "max": [3, 5, 8, 15, 17, 18, 23, 24, 26, 32, 33, 37, 41, 49, 50, 53, 58, 66, 81, 82, 83, 84, 88, 90, 94, 97, 98, 103, 104, 107, 111, 124, 127], "max_cached_step": 70, "max_concurr": [53, 94], "max_connect": 24, "max_content_len": 3, "max_continuous_cached_step": 70, "max_delay_pass": 23, "max_execution_time_m": 24, "max_export_batch_s": 97, "max_fram": 127, "max_gen_tok": 39, "max_len": 3, "max_loaded_lora": [15, 22, 27, 28, 29, 30, 41, 42], "max_lora_chunk_s": [15, 22, 27, 28, 29, 30, 41, 42], "max_lora_rank": [15, 22, 27, 28, 29, 30, 41, 42], "max_loras_per_batch": [15, 22, 27, 28, 29, 30, 41, 42], "max_mamba_cache_s": [15, 22, 27, 28, 29, 30, 41, 42], "max_memory_pag": 24, "max_model_len": 41, "max_new_token": [4, 14, 15, 19, 22, 27, 28, 29, 51, 52, 83, 124], "max_pixel": 127, "max_position_embed": 26, "max_post_edit_step": 124, "max_prefill_token": [14, 15, 22, 27, 28, 29, 30, 41, 42, 103], "max_queued_request": [15, 22, 27, 28, 29, 30, 41, 42], "max_req_input_len": 41, "max_running_request": [14, 15, 22, 27, 28, 29, 30, 41, 42, 103, 124], "max_stack_s": 24, "max_token": [26, 27, 28, 29, 31, 32, 36, 37, 45, 47, 50, 51, 52, 58, 101, 104, 107, 127], "max_total_num_token": [14, 15, 41, 103], "max_total_token": [15, 22, 27, 28, 29, 30, 41, 42], "max_warmup_step": 70, "maxim": [1, 8, 12, 14, 15, 24, 25, 26, 94], "maximum": [1, 3, 14, 15, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 41, 42, 45, 46, 47, 50, 51, 52, 58, 70, 90, 94, 97, 98, 101, 108, 121], "maxsurg": 104, "maxunavail": 104, "mayb": [26, 28], "mb": [8, 97], "mc": 70, "mc_force_mnnvl": 17, "mc_te_metr": [104, 107], "mcdse": 77, "mcp": 38, "md": [0, 33, 37, 55, 71, 80, 115], "me": [4, 24, 26, 27, 28, 42, 43, 45, 101], "mean": [8, 12, 13, 14, 17, 18, 23, 24, 27, 28, 29, 33, 53, 64, 70, 72, 79, 88, 90, 97, 116, 121, 127], "meaning": 118, "measur": [42, 51, 53, 58, 94], "mechan": [8, 12, 18, 19, 25, 32, 33, 71, 75, 119, 123], "medatada": 1, "median": [15, 53], "medium": [38, 58, 66, 70, 103, 104, 107], "meet": [12, 15, 23, 28, 42, 102, 115], "megatron": [108, 125], "meituan": 90, "melanoleuca": [41, 121], "mellanox": 103, "mem": [0, 11, 12, 15, 17, 18, 23, 26, 32, 33, 36, 37, 39, 40, 41, 50, 54, 82, 83, 84, 86, 88, 93, 94, 97, 98, 103, 104, 105, 107], "mem_cach": 13, "mem_fraction_stat": [14, 15, 22, 27, 28, 29, 30, 41, 42], "member": [15, 104, 115], "memfabr": [17, 83], "memfabric_hybrid": 17, "memori": [1, 3, 5, 7, 8, 12, 13, 15, 17, 18, 19, 26, 32, 37, 39, 41, 49, 50, 54, 61, 62, 65, 73, 74, 90, 93, 103, 104, 107, 127], "memory_usag": 41, "mention": [28, 127], "mere": [15, 21], "merg": [24, 32, 41, 53, 54, 62, 127], "merge_lora_weight": 62, "merge_profil": 54, "merged_output": 42, "merger": 3, "messag": [9, 13, 22, 23, 24, 25, 26, 27, 28, 31, 32, 36, 37, 40, 41, 43, 45, 47, 50, 51, 52, 53, 67, 77, 104, 107, 118, 127], "messages_requir": 29, "messages_specif": 29, "met": [13, 15], "meta": [1, 2, 4, 5, 15, 17, 19, 23, 24, 26, 27, 29, 30, 39, 51, 53, 54, 56, 76, 79, 81, 89, 90, 93, 95, 96, 105, 109, 111, 115, 116, 125, 127], "meta_info": [27, 28, 41, 52, 121], "metadata": [1, 2, 9, 11, 13, 18, 23, 24, 26, 29, 45, 47, 52, 54, 78, 97, 103, 104, 107, 127], "metal": 90, "method": [2, 5, 8, 11, 18, 23, 24, 25, 32, 33, 43, 45, 51, 54, 57, 64, 67, 79, 82, 83, 84, 85, 88, 92, 100, 108, 115, 127], "methodologi": [21, 125], "metric": [5, 11, 13, 23, 33, 37, 50, 58, 74, 77, 83, 88, 97], "metrics_data": 78, "metropoli": 42, "metropolitan": 28, "mha": [12, 20, 33], "mha_one_shot": 33, "mi300": [33, 77], "mi300x": [32, 67, 68, 79], "mi30x": [33, 60, 68], "mi325x": 67, "mi350": 33, "mi355": [33, 77], "mi355x": 32, "mi35x": 33, "michael": 42, "micro": [8, 18, 23, 88], "microsc": 20, "microservic": 24, "microsoft": [56, 89, 125, 127], "mid": [26, 38], "might": [5, 15, 16, 19, 23, 26, 28, 30, 41, 51, 56, 95, 97, 98, 109], "migrat": 118, "mild": [45, 121], "mile": [25, 77, 108], "millard": 99, "million": [28, 42], "mimo": [26, 89, 125, 127], "min": [0, 12, 23, 26, 38, 51, 55, 80, 88], "min_new_token": 51, "min_p": 51, "mind": [0, 42, 55, 80], "mindspor": [77, 87, 112, 117], "miner": 101, "mini": [82, 83, 89, 110, 124, 125, 127], "minicpm": [89, 125, 127], "minicpm3": [89, 125], "minim": [8, 9, 12, 18, 20, 26, 55, 70, 80, 94, 127], "minimax": [5, 24, 58, 77, 89, 125], "minimaxai": 40, "minimum": [19, 23, 24, 32, 33, 55, 70, 80], "minio": [61, 66], "minist": 28, "ministri": 101, "minor": [15, 23, 45, 55, 80], "minut": [14, 15, 16, 17, 21, 24, 32, 41, 55, 78, 80, 101], "mirror": 24, "misalign": 18, "misconfigur": 9, "mislead": 99, "mismatch": [25, 41, 91, 113], "miss": [9, 53, 96, 118], "misti": 15, "mistral": [23, 24, 29, 77, 89, 119, 125, 127], "mistralai": [29, 89, 125, 127], "mitig": [12, 15, 18, 25, 39, 124], "mix": [1, 8, 19, 23, 26, 30, 88, 94], "mix_ip": 82, "mixtral": 125, "mixtur": [8, 32, 90, 124, 125], "ml": [35, 64, 69, 76, 103], "mla": [12, 20, 23, 88, 94, 125], "mlc": 27, "mllm": [23, 115], "mlp": [3, 9, 19, 23, 97, 127], "mlx5_0": [11, 23, 104, 107], "mlx5_1": [23, 107], "mlx5_2": 107, "mlx5_3": 107, "mlx5_4": 107, "mlx5_5": [104, 107], "mlx5_6": [104, 107], "mlx5_7": 107, "mlx5_bond_0": [33, 103, 104], "mlx5_bond_1": [33, 103, 104], "mlx5_bond_2": [33, 103, 104], "mlx5_bond_3": [33, 103, 104], "mlx5_roce0": 17, "mm": [1, 6, 23, 26, 37, 50, 74, 81, 86, 88, 127], "mm_attention_backend": [15, 22, 27, 28, 29, 30, 41, 42], "mm_enable_dp_encod": [15, 22, 27, 28, 29, 30, 41, 42], "mm_fp4": 97, "mm_item": 30, "mm_max_concurrent_cal": [15, 22, 27, 28, 29, 30, 41, 42], "mm_per_request_timeout": [15, 22, 27, 28, 29, 30, 41, 42], "mm_process_config": [15, 22, 27, 28, 29, 30, 41, 42], "mmap": [23, 88], "mmlu": [39, 58, 115], "mmlu_pro": 39, "mmmu": [53, 58, 115], "moba": 69, "moba_select_mod": 69, "moba_threshold": 69, "moba_threshold_typ": 69, "mobil": [125, 127], "mocked_fake_id_for_offline_gener": 74, "mod_part": 9, "modal": [37, 39, 50, 53, 77, 97, 119, 127], "mode": [1, 2, 4, 7, 8, 9, 11, 18, 19, 22, 23, 25, 33, 39, 41, 42, 45, 53, 56, 58, 69, 81, 84, 88, 90, 93, 97, 98, 103, 104, 107, 111], "model": [0, 1, 2, 7, 8, 11, 12, 14, 15, 17, 18, 20, 21, 25, 27, 31, 33, 36, 37, 38, 39, 42, 43, 47, 49, 50, 51, 52, 54, 55, 56, 60, 61, 62, 65, 66, 67, 68, 69, 73, 74, 76, 78, 79, 80, 83, 85, 86, 87, 93, 96, 99, 101, 103, 104, 105, 107, 108, 109, 111, 112, 116, 120, 126], "model_arch_name_to_cl": 115, "model_arg": 39, "model_checksum": [15, 22, 27, 28, 29, 30, 41, 42], "model_class": 115, "model_config": [19, 26, 41, 46, 115], "model_dump_json": 27, "model_executor": 115, "model_id": [19, 24], "model_id_or_path": [90, 95], "model_impl": [15, 22, 27, 28, 29, 30, 41, 42, 91, 113], "model_index": 75, "model_info": [15, 41, 101], "model_json_schema": [27, 28], "model_load": [19, 115], "model_loader_extra_config": [15, 22, 27, 28, 29, 30, 41, 42], "model_nam": [19, 22, 29, 33, 41, 109, 115, 118], "model_name_tool_choic": 29, "model_path": [11, 15, 19, 22, 25, 27, 28, 29, 30, 41, 42, 61, 62, 82, 83, 84, 91, 94, 105, 113, 115, 124], "model_path_or_id": [69, 74], "model_typ": 41, "model_valid": 27, "model_validate_json": 27, "modelconfig": 19, "modelcontextprotocol": 24, "modelopt": [8, 20, 23, 88], "modelopt_checkpoint_restore_path": [15, 19, 22, 27, 28, 29, 30, 41, 42], "modelopt_checkpoint_save_path": [15, 19, 22, 27, 28, 29, 30, 41, 42], "modelopt_export_path": [15, 19, 22, 27, 28, 29, 30, 41, 42], "modelopt_fp4": [1, 19, 23, 33], "modelopt_fp8": [19, 23], "modelopt_qu": [15, 22, 27, 28, 29, 30, 41, 42], "modelopt_quantize_and_export": 19, "modelregistri": 115, "modelrunn": [9, 115], "modelscop": [53, 77, 89, 97, 112, 117], "modelslim": [23, 82, 83, 84, 85, 88], "moder": [45, 101, 123], "modern": [7, 12, 26, 108], "modesti": 30, "modif": [24, 55, 80, 103], "modifi": [0, 3, 8, 9, 13, 19, 24, 25, 45, 54, 55, 56, 65, 76, 78, 80, 81, 84, 103, 104, 109, 115], "modul": [8, 9, 11, 12, 15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 54, 56, 57, 62, 65, 71, 72, 73, 75, 88, 101, 115, 116], "modular": [8, 75, 108], "module_cache_s": 24, "module_nam": 9, "module_path": [11, 12, 23], "module_typ": [9, 24], "module_uuid": 24, "moe": [1, 17, 19, 25, 32, 33, 40, 51, 82, 83, 84, 85, 88, 89, 90, 91, 94, 97, 104, 107, 108, 113, 124, 125, 127], "moe_a2a_backend": [15, 22, 27, 28, 29, 30, 33, 41, 42], "moe_dense_tp_s": [15, 22, 27, 28, 29, 30, 33, 41, 42], "moe_runn": 8, "moe_runner_backend": [15, 22, 27, 28, 29, 30, 41, 42], "moe_wna16": 23, "moerunn": 8, "moerunnercor": 8, "moment": 121, "monitor": [2, 5, 25, 107, 109, 110], "mood": 65, "moon": [42, 45], "mooncak": [7, 8, 12, 13, 15, 22, 23, 27, 28, 29, 30, 41, 42, 53, 81, 88, 97], "mooncake_devic": 11, "mooncake_global_segment_s": 11, "mooncake_ib_devic": [15, 22, 27, 28, 29, 30, 41, 42], "mooncake_mast": 11, "mooncake_protocol": 11, "mooncake_te_meta_data_serv": 11, "moonshot": 125, "moonshotai": [29, 125, 127], "moor": 77, "more": [2, 3, 4, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 45, 47, 49, 51, 52, 53, 54, 55, 56, 58, 61, 62, 67, 70, 72, 75, 76, 77, 80, 84, 90, 91, 95, 97, 98, 101, 103, 110, 113, 115, 116, 119, 121, 124, 127], "morgan": 38, "mori": 8, "mortal": 15, "moscow": 42, "most": [0, 1, 5, 6, 12, 14, 15, 26, 28, 29, 32, 38, 41, 42, 45, 54, 55, 64, 69, 70, 77, 80, 90, 96, 101, 103, 115, 116, 124], "mostli": 98, "mother": 42, "motiv": 42, "motlei": 38, "motor": 42, "mount": [56, 60], "mountain": [67, 70, 71, 73], "mountpath": [103, 104, 107], "move": [8, 11, 12, 18, 25, 97, 127], "movement": [12, 15], "mp4": [37, 50, 61, 62, 127], "mrl": 119, "ms_enable_lccl": [91, 113], "mscclpp": [23, 88], "msg": 26, "msmodelslim": 84, "mt": 26, "mt43244": 103, "mtgpu": 68, "mtp": [8, 26, 32, 33, 78, 84, 97], "much": [0, 12, 14, 18, 28, 45, 55, 80, 115], "muggl": 101, "mul": 97, "multi": [1, 5, 11, 15, 18, 25, 30, 37, 39, 50, 67, 76, 77, 91, 95, 97, 103, 113, 115, 127], "multi_item_scoring_delimit": [15, 22, 27, 28, 29, 30, 41, 42], "multi_modal_item": 30, "multi_modal_projector": 30, "multi_node_deploy": 33, "multi_turn_qa": 101, "multiformatpars": 29, "multilingu": [119, 123, 125, 127], "multimod": [1, 3, 7, 23, 30, 31, 37, 39, 47, 50, 77, 86, 88, 101, 117, 125, 126], "multimodal_gen": [63, 65, 69, 72], "multimodal_language_model": 115, "multimodal_processor": 115, "multimodaldataitem": 97, "multipart": 62, "multipl": [1, 2, 5, 6, 7, 8, 12, 17, 18, 23, 24, 26, 29, 32, 33, 38, 45, 51, 53, 54, 55, 62, 66, 71, 73, 74, 80, 84, 91, 94, 97, 101, 105, 110, 113, 115, 125, 127], "multipli": [5, 18, 24], "multiprocessingseri": 25, "mundan": 15, "municip": 28, "musa": 77, "muscl": 101, "museum": [26, 28, 41, 42], "must": [1, 5, 7, 9, 12, 13, 15, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 33, 43, 51, 54, 55, 57, 61, 62, 80, 103, 110, 115], "mutual": [24, 54, 62], "mv": [68, 79, 81, 92], "mvbench": 58, "mxfp4": [8, 19, 20, 23, 32, 88], "mxfp8": 23, "my": [2, 23, 28, 42, 45, 55, 61, 80, 91, 113, 115], "my_checkpoint": 19, "my_middlewar": 24, "my_model": 96, "my_model_templ": 96, "my_packag": 23, "my_project": 9, "myattent": 116, "mymodel": 116, "mystic": 15, "n": [1, 4, 5, 12, 15, 22, 23, 24, 26, 27, 28, 29, 31, 33, 41, 42, 43, 45, 51, 52, 53, 57, 62, 66, 70, 74, 90, 95, 101, 104, 105, 107, 119, 121], "n1": [26, 45, 52], "n10": 45, "n2": [26, 45, 52], "n3": [26, 45, 52], "n4": 45, "n5": 45, "n6": 45, "n7": 45, "n8": 45, "n9": 45, "na": [41, 81, 82], "naiv": [5, 84], "name": [0, 2, 5, 11, 12, 15, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 36, 40, 41, 42, 43, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 66, 69, 76, 79, 80, 81, 82, 84, 88, 90, 91, 94, 95, 96, 99, 101, 103, 104, 107, 109, 110, 113, 115, 118], "name1": 53, "name2": 53, "name_non_stream": 29, "name_to_modul": 9, "named_modul": [9, 23], "named_tensor": 25, "namespac": [24, 57, 62, 107], "nan": [23, 41, 88], "nano": [89, 125, 127], "narr": 42, "narrow": 15, "nation": [26, 42], "nativ": [1, 8, 12, 15, 24, 25, 38, 51, 53, 61, 69, 70, 73, 77, 94, 103, 108, 125, 127], "natur": [7, 12, 15, 25, 30, 42, 45, 55, 80], "naur": 29, "navig": [45, 109], "navit": 127, "nb": 41, "nbconvert": 0, "nbstripout": 0, "nc": [41, 105], "ncapit": 26, "nccl": [15, 22, 23, 25, 27, 28, 29, 30, 32, 41, 42, 88, 97, 98, 103, 104, 105, 107], "nccl_debug": 103, "nccl_ib_gid_index": [56, 79, 103, 107], "nccl_ib_hca": [104, 107], "nccl_ib_qps_per_connect": [104, 107], "nccl_ib_sl": [104, 107], "nccl_ib_split_data_on_qp": [104, 107], "nccl_ib_tc": [104, 107], "nccl_ib_timeout": 107, "nccl_init_addr": 105, "nccl_min_nchannel": [104, 107], "nccl_net_plugin": [104, 107], "nccl_port": [15, 22, 27, 28, 29, 30, 41, 42], "nccl_socket_ifnam": [103, 107], "ncontent": 28, "ndescrib": 51, "ndetoken": 41, "ndr": 103, "ndv5": 79, "nearbi": 30, "nearest": [18, 42], "nearli": [5, 79], "neatli": 28, "necessari": [12, 28, 75, 76, 80, 98, 101, 103, 115], "necessarili": [28, 64], "necessit": 18, "need": [1, 2, 3, 4, 5, 8, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 39, 40, 41, 42, 43, 45, 53, 54, 55, 56, 57, 60, 62, 75, 78, 79, 80, 81, 84, 85, 90, 91, 94, 96, 98, 101, 103, 104, 107, 108, 109, 110, 113, 114, 115, 116, 117, 119, 127], "neg": [45, 51, 61, 71, 72, 73, 97], "negat": 20, "negative_prompt": 75, "neighbor": [15, 42], "nemo": [29, 33, 125], "nemo_skills_aime25_": 33, "nemo_skills_disable_uncommitted_changes_check": 33, "nemotron": [125, 127], "nest": 110, "nest_asyncio": [30, 42], "net": 84, "netdev": 103, "network": [2, 24, 41, 56, 75, 79, 81, 90, 93, 98, 103, 104, 107, 109, 121], "networkconfig": 104, "neural": [41, 121], "neuralmag": 19, "neutral": [42, 115], "never": [5, 15, 42], "new": [0, 3, 11, 12, 14, 15, 19, 21, 23, 24, 25, 27, 28, 38, 41, 42, 45, 51, 55, 59, 60, 62, 65, 67, 77, 78, 80, 90, 94, 97, 103, 104, 110, 112, 117, 118, 125, 127], "new2": 65, "new_token_ratio": 14, "new_york": [27, 28], "newer": [76, 90], "newest": 33, "newli": [12, 33, 115], "newmodeldetector": 29, "next": [12, 18, 22, 25, 26, 28, 29, 48, 51, 57, 62, 89, 110, 115, 121, 125, 127], "next_token_logit": 115, "nextn": [23, 49, 82, 83, 88, 97], "nf": 54, "nfinal": 28, "nfirst": 28, "ngener": [27, 28, 42], "nginx": 78, "nhere": 28, "nhttp": 41, "ni": 28, "nic": [12, 103], "nice": 26, "nicknam": [61, 62], "night": 15, "nightli": [65, 76, 78, 81], "nimag": 30, "ninth": 45, "nixl": [12, 13, 23], "nlet": 26, "nlp": [41, 46, 84, 89, 119, 125], "nn": [9, 103, 116], "nnal": [81, 82, 83, 84], "nnext": 28, "nnode": [2, 15, 17, 18, 22, 23, 27, 28, 29, 30, 33, 41, 42, 82, 83, 84, 88, 91, 94, 103, 104, 105, 107, 113], "nnow": 28, "no_answ": 33, "no_buff": [15, 22, 23, 27, 28, 29, 30, 41, 42, 49, 88], "no_grad": 115, "no_proxi": 24, "no_stop_trim": [29, 51], "node": [5, 11, 12, 18, 21, 24, 25, 26, 33, 41, 74, 76, 77, 82, 83, 91, 97, 103, 104, 107, 110, 113], "node0_ip": 94, "node1": [5, 103], "node2": 5, "node_rank": [15, 22, 27, 28, 29, 30, 41, 42, 82, 83, 84], "nodeport": [104, 107], "nodeselector": [104, 107], "nohealthywork": 24, "nois": [4, 24, 62], "noisi": 75, "nokai": 26, "non": [1, 9, 18, 23, 24, 25, 43, 45, 53, 55, 57, 80, 97, 101, 115, 118, 124], "nondeterminist": 98, "none": [8, 9, 15, 22, 23, 24, 25, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 51, 52, 62, 66, 70, 83, 88, 97, 104, 107, 115], "norm": [23, 88], "normal": [1, 8, 22, 23, 24, 29, 41, 42, 69, 82, 83, 88, 94, 107, 110], "normal_text": [24, 29], "north": 45, "notabl": 90, "note": [5, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 33, 36, 39, 41, 42, 43, 45, 46, 47, 52, 55, 56, 57, 60, 61, 62, 64, 72, 77, 79, 80, 84, 90, 91, 94, 95, 96, 97, 101, 103, 104, 105, 107, 110, 113, 114, 115, 118, 121], "notebook": [15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 101], "noth": 23, "notic": [18, 81, 98, 103, 104], "notr": [41, 42], "nousresearch": 79, "novel": [21, 45], "now": [1, 5, 8, 15, 23, 26, 28, 38, 41, 42, 45, 54, 56, 57, 79, 101, 115, 118], "nowadai": [55, 80], "npcach": 23, "nproc": 2, "nprompt": [42, 115], "npu": [1, 23, 33, 76, 77, 83, 84, 86, 91, 113], "nput": 28, "npx": 24, "nround": 41, "nsa": [1, 23, 33, 82, 88], "nsa_decode_backend": [15, 22, 27, 28, 29, 30, 41, 42], "nsa_prefill_backend": [15, 22, 27, 28, 29, 30, 41, 42], "nsa_prefill_cp_mod": [15, 22, 27, 28, 29, 30, 41, 42], "nsight": [23, 67, 73, 77], "nstep": 41, "nsy": [54, 56, 74], "ntask": 105, "nthat": 41, "nthe": [26, 41], "ntoken": 41, "null": [15, 22, 23, 27, 28, 29, 30, 32, 41, 42, 46, 47, 61, 76, 88, 104, 107, 118], "num": [23, 26, 32, 33, 36, 39, 49, 53, 54, 55, 56, 58, 61, 62, 74, 79, 80, 82, 83, 86, 88, 90, 94, 95, 104, 107, 109], "num_block": 57, "num_choic": 26, "num_class": [24, 118], "num_concurr": 39, "num_continuous_decode_step": [15, 22, 27, 28, 29, 30, 41, 42], "num_draft_token": 26, "num_el": 57, "num_entri": 33, "num_fewshot": 39, "num_fram": [61, 75, 127], "num_gpu": [61, 62], "num_hidden_lay": 54, "num_inference_step": [61, 75], "num_key_value_head": 54, "num_lay": [45, 51], "num_lora_layers_with_weight": 62, "num_paused_request": [25, 41], "num_prompt": 94, "num_prompts_per_concurr": 94, "num_quest": 83, "num_queue_req": 109, "num_reserved_decode_token": [15, 22, 27, 28, 29, 30, 41, 42], "num_running_req": 109, "num_shot": 83, "num_stag": 26, "num_step": 54, "num_thread": 57, "num_token": [45, 51], "num_token_to_fetch": 12, "num_triton_choic": 26, "num_used_token": 109, "num_warp": 26, "numa": [23, 88, 90], "numa_balanc": [79, 81, 82, 83, 84], "numa_nod": [15, 22, 27, 28, 29, 30, 41, 42], "number": [1, 2, 3, 8, 12, 14, 15, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 39, 41, 42, 45, 46, 47, 50, 51, 52, 53, 54, 55, 58, 61, 69, 70, 74, 80, 90, 94, 97, 101, 109, 110, 118, 121, 124], "numer": [32, 41, 42, 98], "numexpr": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "numexpr_max_thread": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "numpi": [23, 53], "nurgaliyev": 93, "nurs": 42, "nutanix": 15, "nutrient": 101, "nv": 93, "nvda": 38, "nvfp4": [8, 19, 20, 23, 32, 97], "nvfp4_awq": 23, "nvfp4_mlp_onli": 19, "nvidia": [1, 8, 20, 23, 32, 33, 38, 39, 54, 55, 60, 67, 73, 76, 77, 80, 97, 103, 104, 107, 125, 127], "nvidia_h100_80gb_hbm3": 41, "nvidia_h100_80gb_hbm3_down": 41, "nvila": 127, "nvl": [23, 88], "nvl72": [17, 32], "nvlink": 97, "nvme": 56, "nvpmodel": 93, "nvrtc": [22, 27, 28, 29, 30, 42, 97], "nvshmem_bootstrap_uid_sock_ifnam": 107, "nvshmem_disable_p2p": 107, "nvshmem_enable_nic_pe_map": 104, "nvshmem_hca_list": 104, "nvshmem_hca_pe_map": 104, "nvshmem_ib_gid_index": [104, 107], "nvshmem_ib_sl": 107, "nvshmem_ib_traffic_class": [104, 107], "nvtx": [23, 88], "nwait": [26, 28], "nwhich": 41, "ny": [27, 28, 29], "nyc": 24, "nyou": 51, "n\u00fa\u00f1ez": 93, "n\u4f60\u597d\u5440": [104, 107], "n\u55ef": [104, 107], "n\u6211\u7684\u4efb\u52a1\u5c31\u662f\u966a\u4f60\u804a\u5929": [104, 107], "n\u7528\u6237\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u80cc\u666f\u4fe1\u606f": [104, 107], "n\u7528\u6ce2\u6d6a\u7ebf\u7ed3\u5c3e\u53ef\u4ee5\u8f6f\u5316\u8bed\u6c14": [104, 107], "n\u8003\u8651\u5230\u4e2d\u6587\u7528\u6237": [104, 107], "o": [11, 12, 17, 24, 25, 26, 27, 28, 46, 51, 54, 56, 60, 62, 74, 81, 89, 105, 127], "o_proj": [15, 23], "oai": [53, 82], "oai_serv": 24, "object": [6, 9, 12, 23, 24, 26, 27, 28, 29, 30, 32, 45, 46, 47, 51, 52, 53, 57, 61, 74, 88, 104, 107, 118, 121], "observ": [5, 13, 20, 26, 77, 110], "obstacl": [3, 15], "obtain": [12, 18, 26, 29, 41, 99, 103, 110], "occasion": [14, 121], "occup": [42, 54, 101], "occupi": 8, "occur": [14, 15, 41, 51, 98], "ocp": 20, "ocr": [48, 89, 127], "odd": 53, "odel": 22, "ofassistantgener": 27, "ofed_info": 103, "off": [8, 15, 24, 26, 32, 49, 61, 79, 91, 97, 113, 119, 124], "offer": [8, 18, 28, 51, 73, 121, 123, 125, 127], "offic": 28, "offici": [23, 24, 28, 32, 33, 39, 41, 55, 56, 79, 80, 90, 91, 96, 104, 113], "offlin": [17, 20, 47, 54, 58, 77, 81, 85], "offload": [11, 12, 19, 25, 61, 62], "offload_group_s": [15, 22, 27, 28, 29, 30, 41, 42], "offload_mod": [15, 22, 27, 28, 29, 30, 41, 42], "offload_num_in_group": [15, 22, 27, 28, 29, 30, 41, 42], "offload_prefetch_step": [15, 22, 27, 28, 29, 30, 41, 42], "offset": 25, "often": [5, 8, 12, 15, 24, 25, 26, 28, 32, 41, 75, 97, 123, 124], "ok": [15, 24, 41, 103], "okai": [14, 28, 45], "old": [5, 42, 45], "older": 103, "ollama": 77, "ollama_host": 43, "olmo": [89, 125], "oltp": 88, "om": 76, "omit": [25, 26, 45, 57, 99, 119], "omni": 127, "onboard": 24, "onc": [1, 9, 12, 15, 19, 25, 29, 41, 45, 46, 47, 52, 55, 56, 61, 80, 90, 99, 103, 111], "oncal": [55, 80], "ondemand": 81, "one": [1, 5, 9, 12, 15, 17, 18, 19, 22, 23, 24, 27, 28, 29, 30, 33, 38, 39, 41, 42, 45, 47, 51, 52, 53, 54, 55, 61, 62, 68, 72, 75, 76, 79, 80, 81, 90, 92, 97, 98, 99, 109, 116, 119], "oneshot": [19, 97], "onevis": [47, 51, 89, 127], "ongo": [17, 25, 39, 54], "onli": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 39, 40, 43, 51, 53, 54, 55, 56, 57, 58, 61, 62, 64, 69, 70, 74, 76, 78, 79, 80, 81, 88, 91, 93, 95, 97, 98, 99, 101, 103, 113, 115, 125, 127], "onlin": [0, 32, 53, 54, 84, 105], "only_run": 115, "onrequest": 24, "onrespons": 24, "onto": 76, "oom": [14, 19, 39, 98, 127], "op": [6, 12, 23], "op_api": 82, "open": [0, 20, 24, 26, 30, 39, 54, 55, 56, 58, 62, 76, 77, 79, 80, 82, 84, 88, 90, 92, 108, 109, 125, 127], "openai": [23, 26, 32, 36, 38, 40, 41, 51, 53, 61, 67, 77, 88, 89, 90, 94, 95, 96, 99, 101, 118, 119, 125, 127], "openai_api_complet": 15, "openai_api_kei": [53, 60], "openapi": 52, "openbmb": [89, 125, 127], "openssl": 24, "opentelemetri": [5, 23, 110], "oper": [1, 3, 4, 8, 11, 12, 13, 17, 20, 23, 24, 25, 26, 32, 33, 41, 54, 55, 75, 76, 80, 81, 83, 90, 94, 97, 104, 107, 119], "operation": 13, "operation_duration_second": 24, "operations_tot": 24, "opinion": 41, "opp": 82, "opportun": [42, 94], "oppos": 15, "opt": [19, 56, 76, 79, 90], "optic": 127, "optim": [1, 2, 4, 8, 10, 14, 15, 17, 18, 19, 20, 21, 24, 25, 26, 30, 39, 41, 49, 55, 61, 70, 71, 72, 76, 77, 79, 80, 91, 104, 108, 113, 121, 125], "option": [3, 5, 11, 15, 17, 19, 22, 24, 25, 26, 28, 32, 38, 41, 45, 54, 57, 61, 62, 65, 72, 73, 76, 77, 94, 99, 109, 110, 115, 118, 124], "oraclecloud": 24, "orang": 47, "orchestr": [8, 24, 75], "order": [3, 4, 5, 15, 23, 24, 41, 62, 66, 69, 70, 75, 101, 121, 127], "org": [29, 36, 37, 57, 64, 76, 81, 90, 95, 98, 105, 108, 111, 125, 127], "organ": [11, 24], "organiz": 24, "orient": 12, "orig_logit": 115, "origin": [1, 5, 15, 18, 19, 22, 26, 27, 28, 29, 32, 33, 41, 45, 46, 47, 52, 62, 70, 101, 118, 121], "orin": 77, "orion": 125, "orionstarai": 125, "oserror": 76, "osl": 94, "oss": [20, 22, 23, 29, 45, 61, 66, 77, 89, 125], "ostri": 64, "otel_exporter_otlp_traces_protocol": 110, "otel_trac": 110, "other": [0, 1, 2, 5, 6, 13, 15, 16, 18, 19, 23, 26, 28, 29, 32, 33, 39, 41, 42, 45, 47, 49, 55, 58, 75, 76, 79, 80, 81, 94, 97, 98, 99, 101, 105, 109, 110, 111, 115, 124, 125, 127], "otherwis": [1, 3, 13, 23, 33, 53, 54, 69, 70, 110, 116, 119], "otlp": [23, 24, 110], "otlp_traces_endpoint": [15, 22, 27, 28, 29, 30, 41, 42, 110], "ottawa": [45, 52, 101], "ottawa3": 101, "our": [0, 15, 19, 26, 33, 38, 42, 51, 55, 75, 80, 81, 98, 104, 108, 118], "out": [15, 22, 23, 24, 26, 28, 29, 30, 37, 39, 41, 45, 50, 54, 55, 63, 76, 80, 84, 90, 101, 105, 108, 114], "outcomes_tot": 24, "outdat": [5, 90], "outer": [9, 20], "outer_linear_hook": 9, "outlin": [23, 27, 29, 32, 51, 65, 88, 97], "output": [0, 4, 6, 8, 9, 12, 15, 19, 22, 23, 24, 26, 32, 33, 38, 41, 42, 46, 47, 52, 55, 56, 57, 58, 61, 62, 63, 67, 68, 75, 77, 78, 79, 80, 82, 88, 90, 91, 94, 95, 97, 98, 101, 103, 104, 105, 109, 113, 115, 123, 124, 125, 127], "output_dir": [19, 33, 54], "output_hidden_st": 30, "output_id": [27, 28, 41, 52], "output_len": [53, 78], "output_path": 61, "output_seq_len": 94, "output_text": 38, "output_throughput": 78, "outstandingli": 84, "outweigh": 23, "ov": [51, 89, 127], "over": [0, 5, 8, 9, 12, 15, 17, 19, 23, 24, 28, 33, 42, 54, 57, 61, 67, 70, 71, 72, 73, 77, 78, 97], "overal": [8, 13, 32, 78, 94, 101], "overall_throughput": 78, "overcom": 15, "overflow": 5, "overgrown": 15, "overhead": [3, 5, 6, 12, 14, 15, 20, 23, 24, 25, 26, 30, 33, 42, 54, 55, 74, 77, 80, 97, 127], "overlap": [2, 5, 12, 13, 18, 23, 32, 33, 36, 38, 42, 49, 54, 83, 88, 90, 94, 95, 97, 99, 104], "overload": 24, "overrid": [11, 12, 24, 26, 39, 51, 53, 54, 55, 61, 76, 80, 96, 119, 127], "overview": [12, 27, 32, 46, 55, 66, 67, 77, 80], "overweight": 38, "overwrit": [74, 97], "ovis_garden": 61, "own": [5, 23, 24, 26, 28, 33, 41, 42, 55, 75, 76, 80, 81, 90, 95, 105], "p": [23, 33, 38, 51, 68, 76, 79, 90, 104, 109, 114], "p2p": [2, 18, 23, 88, 97], "p2pwork": 18, "p50": 24, "p95": [24, 53], "p99": [24, 53], "p_": 26, "p_ip": [82, 83, 84], "p_master": 84, "packag": [2, 9, 15, 22, 26, 27, 28, 29, 30, 38, 41, 45, 46, 47, 52, 55, 68, 69, 76, 79, 80, 81, 90, 91, 92, 94, 95, 97, 101, 104, 110, 113], "pad": [1, 23, 88, 97, 115], "pad_input_id": 115, "padding_buffs": 8, "page": [0, 1, 11, 12, 15, 18, 23, 33, 34, 38, 46, 49, 62, 76, 77, 88, 94, 95, 97, 98, 104, 107, 116], "page_first": [11, 12, 13, 23], "page_first_direct": [11, 12, 13, 23, 88], "page_first_kv_split": [23, 88], "page_head": [13, 23], "page_s": [1, 12, 15, 22, 23, 27, 28, 29, 30, 41, 42], "pai": 103, "pain": 25, "pair": [5, 11, 12, 20, 28, 47, 53, 61, 69, 97], "pairwis": 41, "palac": [28, 41], "pan": 78, "panda": [41, 121], "pandoc": 0, "pantheon": 45, "paper": [1, 15, 26, 71, 73], "paragraph": 101, "parallel": [0, 6, 12, 14, 15, 17, 20, 26, 29, 30, 37, 50, 54, 56, 61, 77, 82, 83, 84, 90, 91, 94, 97, 103, 104, 106, 107, 113, 123, 124], "parallel_config": 70, "parallel_kwarg": 70, "parallelism_config": 70, "param": [15, 20, 23, 29, 41, 53, 72, 125], "param1": 29, "param2": 29, "param_dict": 51, "paramet": [2, 3, 5, 8, 14, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 41, 52, 54, 55, 56, 57, 58, 62, 64, 74, 75, 76, 77, 80, 81, 88, 90, 94, 95, 97, 98, 104, 105, 107, 115, 124, 125, 127], "parameter": 9, "pari": [15, 26, 27, 28, 29, 32, 36, 41, 42, 45, 51, 52, 99, 101, 121], "paris2": 101, "paris3": 101, "park": [30, 47], "pars": [13, 19, 22, 29, 38, 45, 69, 76, 85, 97, 118], "parse_function_cal": 29, "parse_non_stream": [22, 29], "parse_streaming_incr": 29, "parse_url": [22, 29], "parser": [23, 28, 30, 32, 36, 40, 45, 76, 77, 88, 125], "part": [1, 3, 9, 12, 28, 30, 32, 41, 47, 75, 98, 104, 121], "parti": 88, "partial": [13, 23, 24, 25, 29, 108], "particip": 2, "particular": [28, 29], "particularli": [4, 8, 20, 28, 54], "partit": [18, 23, 25, 32, 78, 97, 105], "partli": 29, "partner": 108, "partnership": 108, "pass": [0, 8, 9, 12, 15, 18, 23, 25, 26, 30, 33, 43, 45, 53, 55, 57, 58, 61, 64, 69, 70, 80, 97, 115, 127], "passag": 121, "passion": 42, "password": [24, 76, 109], "past": [65, 90], "patch": [3, 76, 110], "patch14": [89, 119], "patchleadertempl": 107, "patchworkertempl": 107, "path": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 58, 61, 62, 63, 65, 67, 68, 69, 70, 71, 73, 75, 76, 79, 80, 81, 82, 83, 84, 86, 88, 90, 91, 93, 94, 96, 97, 99, 101, 103, 104, 105, 107, 109, 113, 114, 115, 116, 119, 121, 123, 124, 125, 127], "patronu": 101, "pattern": [3, 9, 12, 17, 23, 25, 27, 28, 51, 54, 55, 70, 74, 75, 80, 88, 103], "pattern1": 9, "pattern2": 9, "paus": [8, 56, 94], "pause_gener": 25, "payload": [24, 25, 27, 28, 53, 107, 119, 121], "pci": 79, "pcie": 15, "pd": [5, 7, 8, 32, 77, 82, 106, 110], "pd_role": 107, "pdmux": [23, 88], "pdmux_config_path": [15, 22, 27, 28, 29, 30, 41, 42], "peac": 15, "peak": [8, 14, 18, 23, 32, 98], "pedestrian": 121, "peer": [2, 15, 18, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 97, 101], "pem": 24, "penalti": [45, 124], "penalty_lambda": 124, "pend": [24, 25], "peopl": [15, 26, 28, 42, 55, 80], "per": [1, 2, 8, 12, 14, 15, 17, 19, 20, 23, 24, 25, 26, 32, 37, 41, 50, 51, 53, 54, 55, 61, 62, 69, 72, 74, 78, 80, 88, 94, 97, 105, 107, 109, 127], "per_row": [19, 23], "per_tensor": [19, 23], "percept": 127, "perf": [65, 77], "perf_baselin": [63, 65], "perfect": 18, "perfectli": 4, "perfetto": [54, 74, 110], "perform": [1, 3, 6, 7, 8, 11, 12, 13, 15, 18, 19, 22, 23, 25, 27, 28, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 52, 54, 55, 62, 64, 69, 75, 77, 79, 80, 82, 83, 90, 91, 93, 95, 99, 101, 103, 108, 110, 113, 115, 119, 121, 125], "performance_dashboard": 78, "perhap": [28, 30], "period": [8, 24, 55, 78, 80, 97], "periodsecond": [103, 104, 107], "perman": [15, 109], "permiss": [24, 55, 80], "permut": 8, "permutemethodpool": 8, "persimmon": [89, 125], "persist": [24, 61], "person": [15, 30, 42], "petit_nvfp4": 23, "phase": [1, 8, 12, 17, 18, 23, 26, 32, 42, 94, 97, 110, 124, 127], "phenomenon": 18, "phi": [89, 125, 127], "philosophi": 25, "philschmid": 15, "phoenix": 101, "phrase": 45, "phy": 103, "physic": [25, 97, 101], "physical_st": 103, "piano": 62, "pick": [5, 24, 26, 53, 55, 80, 97], "pickl": 16, "piec": [15, 47], "piecewis": [3, 23, 88], "piecewise_cuda_graph_compil": [15, 22, 27, 28, 29, 30, 41, 42], "piecewise_cuda_graph_max_token": [15, 22, 27, 28, 29, 30, 41, 42], "piecewise_cuda_graph_token": [15, 22, 27, 28, 29, 30, 41, 42], "pil": [30, 51], "pile": 125, "pillow": 53, "pin": [23, 61, 62], "ping": 49, "pip": [0, 2, 5, 17, 19, 23, 24, 33, 43, 54, 58, 59, 60, 61, 64, 67, 78, 79, 81, 82, 84, 90, 91, 92, 94, 95, 110, 113], "pip1": 82, "pip3": [33, 55, 76, 80, 95], "pipelin": [0, 23, 24, 26, 30, 61, 62, 64, 65, 67, 69, 70, 77, 88, 97, 123], "pipeline_class": 62, "pipeline_nam": [62, 75], "pipelineconfig": 75, "pipelinestag": 75, "piqu": 15, "pixel": [30, 75], "pixel_art_style_lora_z_image_turbo": [62, 64], "pixel_valu": 30, "place": [6, 8, 12, 15, 28, 29, 37, 42, 55, 57, 80], "plai": [42, 62, 121], "plain": 24, "plan": [1, 15, 24, 29, 41, 56, 62, 76, 88, 94, 97], "plane": 25, "planet": [42, 45], "plant": 30, "platform": [1, 39, 67, 73, 76, 84, 90, 91, 113], "playground": [16, 115], "pleas": [1, 5, 8, 15, 17, 19, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 46, 47, 51, 54, 55, 56, 58, 61, 65, 76, 79, 80, 81, 82, 88, 90, 91, 92, 93, 94, 95, 97, 98, 101, 103, 105, 107, 110, 113, 115, 127], "plu": [22, 37, 50, 61, 101, 125], "plugin": [12, 17, 29, 94, 103], "png": [30, 37, 47, 50, 51, 53, 61, 62, 101], "po": [104, 107], "pod": 24, "point": [4, 5, 8, 9, 20, 23, 24, 25, 38, 75, 101, 104, 107, 109, 110, 115], "poisson": 53, "poli": 72, "polici": [4, 12, 14, 15, 17, 23, 25, 26, 66, 70, 81, 82, 83, 88, 107], "polit": [26, 42], "poll": [23, 62, 88, 97], "polynomi": 72, "pong": 49, "pool": [3, 12, 15, 17, 23, 24, 37, 41, 50, 97, 98], "pool_siz": 24, "poorli": 99, "popul": [26, 27, 28, 42, 51, 115], "popular": [19, 42, 45, 77, 90], "port": [0, 2, 5, 7, 11, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 56, 58, 61, 62, 67, 76, 79, 81, 82, 83, 84, 88, 94, 96, 97, 101, 103, 104, 105, 107, 109, 110, 114, 116, 119, 121, 123, 124, 125, 127], "port_tool_choic": 29, "portion": [2, 3, 20, 29, 98], "posit": [5, 18, 24, 42, 45, 49, 51, 71, 72, 73, 97, 115, 127], "possibl": [0, 12, 14, 18, 23, 26, 42, 55, 80, 115], "possibli": 110, "post": [4, 5, 8, 15, 19, 22, 24, 25, 26, 27, 28, 29, 31, 37, 41, 43, 46, 47, 50, 51, 52, 53, 54, 62, 75, 77, 97, 98, 103, 104, 105, 107, 110, 118, 119, 121, 124, 127], "post2": [68, 76, 79], "postgr": 24, "postgres_db_url": 24, "postpon": 108, "potenti": [5, 18, 20, 23, 26, 42, 72, 95, 110, 124], "potter": 101, "power": [5, 15, 24, 25, 33, 40, 42, 43, 45, 54, 77, 79, 108, 127], "power_of_two": [5, 24], "pp": [13, 18, 23, 54, 88], "pp_async_batch_depth": [15, 22, 27, 28, 29, 30, 41, 42], "pp_max_micro_batch_s": [15, 22, 27, 28, 29, 30, 41, 42], "pp_proxy_tensor": 115, "pp_size": [15, 22, 27, 28, 29, 30, 41, 42], "ppo": 108, "ppproxytensor": 115, "pprint": [32, 36], "pr": [0, 5, 8, 15, 20, 33, 39, 49, 55, 65, 80, 107, 115], "practic": [10, 15, 25, 32, 54, 55, 64, 80, 87], "pre": [0, 1, 8, 20, 23, 24, 30, 51, 79, 81, 84, 109], "prealloc": 97, "preced": [45, 55, 61, 80], "preciou": 15, "precis": [3, 8, 12, 19, 20, 23, 32, 61, 62, 75, 88, 90, 94], "precompil": [26, 32, 97], "precomput": [51, 97], "precomputed_embed": [30, 51], "predefin": [23, 115], "predetermin": 41, "predict": [5, 18, 24, 42, 53, 84, 99, 118, 124, 125], "predictor": 18, "preempt": [23, 55, 80], "preemption": [23, 88], "prefer": [0, 5, 12, 13, 20, 23, 24, 28, 29, 33, 41, 53, 55, 56, 57, 61, 69, 80, 88, 90, 123], "preferred_sampling_param": [15, 22, 27, 28, 29, 30, 41, 42], "prefetch": [13, 23, 61, 88], "prefetch_threshold": [12, 13], "prefetch_timeout_bas": [12, 13], "prefetch_timeout_per_ki_token": [12, 13], "prefil": [4, 5, 7, 8, 11, 12, 15, 22, 26, 27, 28, 29, 30, 32, 33, 37, 41, 42, 50, 77, 78, 81, 82, 83, 97, 98, 103, 107, 109, 110, 115, 121, 127], "prefill1": 24, "prefill_addr": 33, "prefill_attention_backend": [15, 22, 27, 28, 29, 30, 41, 42], "prefill_count": 24, "prefill_delayer_forward_passes_bucket": [15, 22, 27, 28, 29, 30, 41, 42], "prefill_delayer_max_delay_pass": [15, 22, 27, 28, 29, 30, 41, 42], "prefill_delayer_token_usage_low_watermark": [15, 22, 27, 28, 29, 30, 41, 42], "prefill_delayer_wait_seconds_bucket": [15, 22, 27, 28, 29, 30, 41, 42], "prefill_head_ip": 33, "prefill_host": 7, "prefill_host_ip": 83, "prefill_in1024": 104, "prefill_ip": 82, "prefill_master_ip": 17, "prefill_max_request": [15, 22, 27, 28, 29, 30, 41, 42], "prefix": [1, 4, 5, 12, 14, 18, 23, 24, 32, 33, 49, 53, 54, 65, 76, 77, 88, 94, 97, 98, 115], "preliminari": [2, 20], "prepar": [4, 15, 18, 19, 23, 28, 33, 57, 75, 97, 103], "prepare_data": 33, "prepend": 12, "preprocess": [7, 23, 75], "prereleas": [67, 68], "prerequisit": [54, 77], "presence_penalti": [45, 51], "present": [12, 28, 90, 121, 127], "preserv": [25, 29], "preset": [53, 66, 70, 104], "presid": [28, 42, 99], "press": [15, 41, 56, 90, 103], "pressur": [12, 25], "pretrain": 125, "pretrainedmodel": 116, "pretti": [26, 28, 32, 36], "prev": [51, 52], "preval": 42, "prevent": [5, 12, 13, 14, 15, 17, 18, 23, 24, 45, 55, 56, 80, 95, 98, 103, 124], "preview": 0, "previou": [18, 26, 32, 38, 72, 109, 110, 125], "previous": [20, 23, 26, 42, 51, 62], "previous_modulated_input": 72, "previous_modulated_input_neg": 72, "previous_residu": 72, "previous_residual_neg": 72, "price": 38, "primari": [24, 42, 62, 95], "primarili": [20, 55, 75, 76, 80, 97, 125], "prime": 28, "primit": [24, 99], "princ": 15, "princess": 15, "principl": [25, 110], "print": [4, 15, 19, 28, 29, 30, 31, 37, 38, 41, 42, 43, 45, 46, 50, 51, 52, 53, 54, 62, 65, 82, 83, 84, 91, 101, 113, 115, 118, 119, 121, 124, 127], "print_highlight": [22, 26, 27, 28, 29, 41, 45, 46, 47, 51, 52, 101], "prior": [8, 81, 90], "priorit": [55, 80], "prioriti": [23, 24, 55, 77, 80, 88, 118], "priority_scheduling_preemption_threshold": [15, 22, 27, 28, 29, 30, 41, 42], "prithivmlmod": 64, "privaci": [42, 45, 108], "privat": [3, 12, 23, 24], "privileg": [56, 79, 81, 84, 90, 103, 104, 107], "pro": [1, 19, 39, 89, 95, 115, 127], "proactiv": 12, "prob": [23, 24, 88, 118], "probabl": [23, 24, 25, 26, 28, 41, 51, 118], "probe": 24, "problem": [17, 19, 22, 25, 42, 81, 101, 103], "proc": [79, 81], "proce": 24, "proceed": 12, "process": [2, 5, 6, 7, 12, 13, 15, 17, 18, 23, 24, 25, 26, 30, 32, 33, 37, 41, 42, 45, 50, 53, 54, 55, 58, 65, 75, 76, 78, 80, 88, 90, 94, 97, 103, 109, 110, 118, 121, 125, 127], "process_tracing_init": 110, "processor": [23, 32, 36, 37, 45, 47, 75, 88, 90, 101, 115, 127], "processor_output": [30, 51], "produc": [4, 29, 53, 109, 125], "product": [4, 5, 12, 18, 19, 23, 25, 33, 38, 73, 76, 77, 94, 101, 108, 116], "profici": 15, "profil": [18, 23, 25, 53, 55, 67, 77, 80, 88, 94], "profile_id": 54, "profile_log": 54, "profiler_python": 54, "program": [45, 56, 119, 121, 127], "programmat": [19, 24, 54], "progress": [18, 24], "progress_bar": 101, "prohibit": 18, "proj": 62, "project": [0, 3, 6, 19, 20, 24, 28, 30, 33, 37, 38, 41, 47, 50, 51, 59, 60, 68, 76, 79, 81, 90, 92, 94, 95, 96, 101, 102, 107, 110, 125, 127], "projector": [30, 127], "prometheu": [5, 16, 23, 109], "promis": [18, 42, 124], "prompt": [1, 4, 14, 19, 22, 23, 24, 27, 28, 29, 30, 32, 34, 38, 41, 42, 45, 51, 53, 54, 58, 61, 62, 65, 67, 68, 69, 70, 71, 73, 74, 75, 79, 82, 88, 90, 91, 94, 95, 98, 109, 113, 115, 124, 127], "prompt_encoding_stage_primari": 75, "prompt_token": [24, 26, 27, 28, 29, 32, 41, 45, 46, 47, 52, 104, 107, 118], "prompt_tokens_bucket": [15, 22, 27, 28, 29, 30, 41, 42], "prompt_tokens_detail": [23, 26, 29, 32, 45, 46, 47, 52, 104, 107, 118], "prompt_tokens_tot": 109, "pronounc": 20, "propag": [18, 110], "proper": [5, 28, 53, 55, 57, 80, 90, 103, 127], "properli": [20, 28, 57, 79, 94, 101, 103, 110], "properti": [27, 28, 29, 32, 45, 51, 57], "propos": [12, 18, 29], "prosper": 15, "protect": [24, 42, 77], "protein": 101, "proto": [24, 110], "protobuf": 110, "protocol": [13, 24, 103, 104, 107, 118], "protocol_buffers_python_implement": [91, 113], "prototyp": [23, 30], "proven": [25, 41, 77], "provid": [2, 4, 5, 8, 12, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 40, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 55, 57, 58, 61, 65, 67, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 90, 91, 94, 97, 101, 105, 109, 110, 113, 115, 118, 119, 123, 125, 127], "provinc": 41, "proxi": [23, 81], "prss": 56, "prune": [24, 127], "pt": [23, 26, 30, 79, 89, 125, 127], "pth": 19, "ptq": 19, "ptxa": 76, "pub": 54, "public": [61, 78, 84, 102], "publish": 23, "pull": [0, 3, 24, 33, 38, 55, 56, 60, 80, 81, 84], "punica": 15, "pure": [23, 33, 55, 80, 101], "purpos": [8, 12, 15, 16, 18, 23, 43, 57], "push": [0, 55, 76, 80], "put": [13, 18, 24, 25, 27, 28, 78], "pwd": [19, 80], "py": [1, 2, 8, 13, 15, 16, 19, 22, 23, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 45, 46, 47, 51, 52, 54, 55, 56, 57, 58, 59, 63, 65, 69, 75, 76, 78, 79, 80, 92, 96, 101, 115, 118], "py3": 81, "pybase64": 53, "pydant": [27, 28], "pyo3": 24, "pypi": [24, 55, 80], "pyproject": [55, 59, 68, 79, 80, 81, 90, 92, 95], "pyproject_cpu": 90, "pyproject_npu": 81, "pyproject_oth": [68, 79, 92], "pyproject_xpu": 95, "python": [1, 2, 5, 7, 8, 9, 11, 12, 13, 17, 21, 22, 23, 25, 27, 28, 31, 33, 37, 39, 41, 42, 45, 50, 51, 53, 54, 55, 56, 58, 59, 62, 63, 65, 67, 68, 73, 76, 78, 79, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 95, 96, 101, 104, 105, 109, 110, 113, 114, 115, 116, 124, 125, 127], "python3": [1, 3, 4, 6, 11, 15, 16, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 60, 76, 79, 80, 81, 82, 83, 84, 91, 94, 101, 103, 104, 105, 107, 109, 111, 113, 114, 115, 116, 119, 121, 123, 124, 125, 127], "python_execution_backend": 38, "python_serv": 38, "python_tag": 29, "pythonpath": 80, "pytorch": [1, 9, 19, 23, 57, 67, 69, 73, 76, 77, 88, 90, 95, 97, 98, 111], "pytorch_npu_alloc_conf": [82, 83, 84, 86], "pytorch_vers": 81, "p\u8282\u70b9": 82, "q": [32, 33, 127], "q2": 38, "q4_k_m": 19, "q_b_proj": 97, "q_proj": [15, 23], "qa": 12, "qdrep": 54, "qformat": 19, "qingdao": 32, "qk": [15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "qkv": [3, 19, 23], "qkv_proj": [23, 54], "qlora": 108, "qoq": 23, "qp": 97, "qperf": 103, "quadrat": 18, "quai": [81, 84], "qualiti": [19, 26, 27, 34, 41, 61, 64, 70, 72, 94, 119, 124, 125], "quant": [19, 23, 88], "quant_config": [19, 115], "quant_method": 8, "quant_model_descript": 85, "quant_path": 19, "quantifi": 84, "quantiz": [1, 8, 14, 15, 22, 27, 28, 29, 30, 32, 33, 41, 42, 77, 82, 83, 84, 85, 90, 94, 115, 125], "quantization_param_path": [15, 22, 27, 28, 29, 30, 41, 42], "quantizationconfig": 115, "quantizationmodifi": 19, "quantize_and_sav": 19, "quantize_and_serv": [15, 22, 27, 28, 29, 30, 41, 42], "quantizeconfig": 19, "quantized_model": 19, "quantized_tinyllama_fp4": 19, "quantized_tinyllama_fp8": 19, "quantum": 42, "quark_int4fp8_mo": 23, "quarot": 89, "queri": [0, 12, 16, 23, 27, 28, 29, 41, 53, 77, 127], "query_head": 69, "query_st": 116, "query_weath": 32, "quest": 15, "question": [26, 28, 32, 33, 36, 41, 42, 45, 53, 55, 56, 58, 77, 79, 80, 82, 88, 92, 101, 121, 127], "queu": [5, 13, 23, 88], "queue": [5, 13, 15, 17, 25, 41, 97, 103, 109], "queue_schedul": [81, 84], "quick": [30, 52, 54, 55, 61, 68, 73, 77, 80, 94], "quickli": [0, 15, 54, 55, 74, 80], "quit": [15, 28, 41, 103], "quot": [28, 38], "quotat": 28, "qwen": [0, 1, 2, 3, 4, 5, 6, 15, 18, 19, 22, 23, 24, 26, 28, 29, 30, 34, 41, 42, 43, 45, 47, 49, 50, 52, 53, 54, 55, 64, 67, 70, 71, 72, 73, 74, 76, 77, 80, 86, 89, 90, 95, 101, 114, 115, 119, 121, 123, 125, 127], "qwen1": 41, "qwen2": [0, 1, 3, 6, 15, 19, 24, 26, 29, 41, 42, 43, 45, 46, 47, 51, 52, 53, 55, 80, 89, 95, 101, 104, 107, 114, 115, 118, 119, 123, 127], "qwen25": [23, 29], "qwen2_5_vlforconditionalgener": [30, 127], "qwen2_5vl": 75, "qwen2forcausallm": 41, "qwen2forrewardmodel": [118, 123], "qwen2forsequenceclassif": [24, 118, 123], "qwen2vl": 115, "qwen3": [2, 3, 6, 7, 11, 20, 22, 23, 24, 29, 48, 58, 76, 81, 87, 89, 90, 91, 108, 113, 119, 125, 127], "qwen3_cod": [23, 29], "qwen3_rerank": 121, "qwen3_vl_rerank": 121, "qwen3forcausallm": 125, "qwen3forsequenceclassif": 118, "qwen_imag": 75, "qwen_image_": 63, "qwen_image_edit_inpaint": 64, "qwen_image_t2i": 63, "qwen_vl": 127, "qwenimag": 74, "qwenimage_denois": 74, "qwenimageeditpipelin": 75, "qwenimageeditpipelineconfig": 75, "qwenimagesamplingparam": 75, "qwq": [28, 89, 90], "r": [0, 24, 27, 28, 45, 70, 89, 101, 118, 125], "r1": [1, 2, 5, 8, 11, 19, 20, 22, 23, 24, 28, 45, 48, 58, 76, 79, 88, 89, 90, 91, 93, 103, 104, 113, 125], "r7b": 125, "raccoon": [61, 70], "race": [17, 42], "rack": 30, "radix": [4, 5, 18, 23, 24, 33, 41, 53, 54, 81, 82, 83, 84, 88, 94, 98, 104, 107, 121], "radix_cach": 4, "radix_eviction_polici": [15, 22, 27, 28, 29, 30, 41, 42], "radixattent": [11, 12, 23, 77, 115], "radixtre": 12, "rag": [23, 33, 88], "rai": 108, "rain": 121, "rais": [9, 23, 38, 41, 53, 110], "raise_for_statu": 41, "ralli": 38, "ram": 23, "ran": 115, "random": [5, 23, 24, 26, 53, 54, 58, 61, 79, 82, 88, 90, 94, 95, 107, 109], "random_se": [15, 22, 27, 28, 29, 30, 41, 42], "randomli": [51, 53], "rang": [12, 14, 15, 18, 19, 20, 23, 26, 39, 41, 42, 45, 51, 53, 54, 77, 82, 90, 94, 95, 109, 124], "rank": [2, 8, 13, 15, 17, 18, 20, 22, 23, 25, 27, 28, 29, 30, 32, 33, 41, 42, 45, 46, 47, 52, 54, 77, 82, 83, 84, 88, 90, 91, 94, 97, 101, 103, 104, 105, 107, 113, 117, 121, 123], "rank0": 74, "rank_offset": 25, "rapid": [12, 42], "rapidli": 42, "rate": [5, 9, 11, 12, 26, 38, 78, 82, 90, 95, 103, 109], "rate_limit": 24, "rate_limit_tot": 24, "rather": [14, 19, 24], "ratio": [8, 11, 12, 20, 23, 24, 39, 49, 53, 70, 82, 88, 90, 94, 95, 109], "ravenclaw": 101, "raw": [18, 20, 37, 47, 50, 51, 61, 75, 101, 115, 127], "raw_tool": 29, "rbac": 24, "rbg": [33, 106], "rbg_pd": 33, "rc1": 81, "rc2": [81, 91], "rc_rdma_write_bw": 103, "rdma": [8, 11, 12, 56, 79, 81, 97, 104, 107], "re": [0, 23, 28, 32, 55, 56, 62, 76, 80, 94, 103, 108, 115], "reach": [12, 38, 42, 97, 108], "reachabl": 53, "react": [55, 80], "reaction": [55, 80], "read": [0, 12, 23, 28, 42, 51, 56, 62, 79, 94, 127], "readabl": [9, 23, 28, 41, 57], "readi": [2, 5, 12, 14, 15, 19, 23, 33, 41, 54, 79, 88, 90, 103, 105, 115, 125], "readinessprob": [103, 104, 107], "readm": [55, 80, 115], "real": [12, 19, 23, 27, 28, 29, 54, 125], "realism": 64, "realismlora": 64, "realloc": [3, 79], "rear": 47, "reasoing_cont": 28, "reason": [3, 5, 16, 18, 20, 23, 25, 29, 36, 40, 42, 49, 50, 58, 76, 77, 88, 97, 125, 127], "reasoning_cont": [22, 26, 28, 29, 32, 45, 47, 52, 104, 107], "reasoning_effort": 38, "reasoning_pars": [15, 22, 27, 28, 29, 30, 41, 42], "reasoning_text": [22, 24], "reasoning_token": [26, 29, 45, 46, 47, 52], "reasoningpars": 22, "rebal": [23, 88, 107], "rebalanc": [8, 23, 24, 88], "reboot": 79, "rebuild": [0, 25], "recal": [26, 28], "recaptur": 25, "recapture_cuda_graph": 25, "receiv": [12, 17, 24, 32, 110, 115], "recent": [15, 23, 26, 28, 38, 55, 78, 80, 98], "recip": [19, 48, 111], "recogn": [22, 39, 41, 57, 115, 125], "recognit": 127, "recommend": [0, 1, 2, 8, 11, 12, 15, 17, 18, 19, 20, 23, 25, 26, 29, 31, 32, 33, 38, 39, 40, 45, 54, 55, 57, 58, 68, 74, 76, 80, 81, 84, 90, 91, 124], "recompil": 24, "recomput": 25, "reconstruct": [32, 41], "reconstructed_text": 41, "record": [0, 12, 23, 41, 88, 97, 110], "record_shap": 97, "recoveri": [24, 25, 42, 76], "recreategrouponpodrestart": [103, 104], "recv": [23, 88, 97], "recycl": 25, "red": [61, 125], "redefin": 40, "redesign": 18, "redhatai": 90, "redirect": 25, "redis_pool_max": 24, "redis_retention_dai": 24, "redis_url": 24, "rednot": [89, 127], "redoc": 52, "reduc": [0, 1, 2, 3, 4, 5, 6, 8, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 41, 45, 46, 47, 51, 52, 54, 55, 62, 71, 74, 78, 80, 88, 94, 97, 98, 101, 110, 119, 127], "reduct": [4, 15, 20, 24, 32, 76, 125], "redund": [12, 18, 19, 20, 23, 30, 70, 71, 88, 104, 107, 127], "redundantli": 12, "ref": [37, 50, 127], "refactor": 8, "refer": [8, 11, 12, 14, 17, 20, 23, 28, 29, 32, 33, 38, 45, 46, 47, 51, 52, 54, 55, 57, 58, 61, 75, 76, 79, 80, 84, 90, 91, 95, 98, 103, 105, 107, 113, 115, 127], "referenc": 75, "reference_hf": 115, "reference_imag": 121, "refin": [75, 121, 123], "refit": 108, "reflect": 64, "refresh": 78, "refresh_interv": 24, "refus": [26, 29, 45, 52], "regard": 110, "regardless": [23, 53], "regex": [23, 27, 28, 63, 101], "region": [24, 25, 54, 66, 76], "regist": [5, 8, 9, 11, 23, 24, 54, 70, 74, 75], "register_forward_hook": 9, "register_fused_func": 8, "register_post_permut": 8, "register_pre_permut": 8, "registr": [5, 9, 24], "registrations_tot": 24, "registri": [24, 75, 115], "regress": [19, 55, 80, 124], "regul": 24, "regular": [9, 15, 26, 51, 57, 101], "regular_count": 24, "regular_expression_gen": 101, "reinforc": [4, 108, 123, 125, 127], "reiniti": 15, "reinstal": [24, 76, 84], "reject": [13, 24, 26], "rel": [0, 4, 5, 6, 20, 24, 62, 72], "rel_l1": 72, "relat": [5, 15, 33, 42, 47, 55, 57, 61, 76, 80, 90, 96, 103, 104, 107], "relationship": [12, 15, 42, 110], "relaunch": 121, "relax": 17, "releas": [22, 24, 27, 28, 29, 30, 38, 42, 54, 55, 68, 76, 79, 80, 81, 104], "release_memory_occup": [23, 25], "release_weights_occup": 23, "relev": [0, 15, 26, 27, 28, 58, 121], "reli": [25, 55, 80, 115], "reliabl": [4, 5, 28, 29, 125], "religion": 42, "reload": 15, "remain": [1, 15, 18, 98, 110, 127], "remax": 108, "rememb": [0, 26, 28, 46], "remind": [27, 28], "remot": [1, 13, 15, 17, 18, 21, 23, 26, 31, 32, 33, 37, 39, 40, 41, 43, 50, 61, 79, 81, 82, 83, 84, 86, 88, 90, 94, 95, 103, 104, 107, 119, 121, 123, 127], "remote_inst": [21, 23], "remote_instance_weight_loader_backend": [15, 22, 27, 28, 29, 30, 41, 42], "remote_instance_weight_loader_seed_instance_ip": [15, 22, 27, 28, 29, 30, 41, 42], "remote_instance_weight_loader_seed_instance_service_port": [15, 22, 27, 28, 29, 30, 41, 42], "remote_instance_weight_loader_send_weights_group_port": [15, 22, 27, 28, 29, 30, 41, 42], "remote_instance_weight_loader_start_seed_via_transfer_engin": [15, 22, 27, 28, 29, 30, 41, 42], "remov": [0, 5, 9, 22, 24, 26, 27, 28, 29, 30, 41, 42, 51, 56, 79, 101, 115, 124, 127], "render": [61, 78], "renderd176": 60, "renderd184": 60, "renown": 45, "reorder": [14, 32], "rep": 54, "repair": 101, "repeat": [15, 24, 25, 30, 33, 37, 42, 50, 51, 56, 58], "repetit": [45, 51, 124], "repetition_penalti": [15, 41, 51], "replac": [15, 19, 23, 31, 42, 52, 68, 76, 79, 81, 90, 94, 105, 109, 110, 115], "replai": [1, 3, 25, 54], "replay_request_dump": 16, "repli": [27, 28], "replic": [5, 6, 8], "replica": [5, 24, 103, 104, 107], "repo": [0, 23, 26, 54, 55, 56, 62, 80, 125, 127], "repo_id": 115, "report": [11, 23, 28, 33, 37, 50, 53, 54, 57, 74, 77, 88, 94, 98, 115], "repositori": [2, 8, 11, 41, 56, 68, 71, 73, 75, 78, 81, 90, 93, 94], "repository_nam": 76, "repres": [12, 15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 57, 101, 110, 119], "represent": [23, 119], "reproduc": [18, 45, 61], "reput": 15, "req": [13, 15, 23, 41, 53, 103, 110], "req_id": 110, "req_root_span": 110, "request": [0, 4, 5, 6, 7, 8, 11, 12, 13, 15, 17, 18, 20, 23, 25, 26, 27, 28, 30, 32, 33, 36, 41, 45, 49, 51, 53, 54, 56, 58, 63, 75, 77, 78, 79, 82, 83, 88, 97, 98, 103, 104, 105, 107, 109, 115, 124, 127], "request_duration_second": 24, "request_errors_tot": 24, "request_r": 53, "requestexcept": 41, "requests_act": 24, "requests_tot": 24, "requir": [0, 1, 3, 5, 7, 8, 11, 12, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 38, 45, 49, 51, 53, 56, 57, 58, 61, 62, 65, 69, 70, 75, 76, 77, 78, 79, 81, 84, 89, 90, 98, 103, 110, 115, 116, 118, 119, 121, 123, 124, 127], "require_reason": 28, "rerank": [24, 26, 77, 117, 120], "reranker_process": 41, "rerun": [55, 80], "rescal": 72, "research": [42, 89, 125], "reserv": [6, 14, 15, 23, 88], "reset": 72, "resid": [12, 15, 24], "residu": [3, 23, 66, 70, 71, 72, 73], "residual_diff_threshold": 70, "resist": 101, "resist\u987d\u5f3a": 30, "resiz": 23, "resolut": [3, 53, 64, 74, 127], "resolv": [0, 9, 17, 19, 24, 32, 55, 57, 74, 80, 98, 103, 119], "resolve_cal": 9, "resolve_devic": 57, "resort": 118, "resourc": [7, 12, 15, 17, 18, 19, 24, 30, 54, 55, 76, 80, 93, 103, 104, 107, 108, 115, 119], "resp": 62, "respect": [26, 32, 45, 52, 110], "respond": [24, 29], "respons": [0, 6, 12, 13, 15, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 41, 42, 43, 45, 46, 47, 50, 51, 52, 61, 62, 75, 99, 119, 123, 127], "response1": 41, "response2": 41, "response_cont": 27, "response_data": 27, "response_format": [27, 28, 62], "response_json": [41, 121], "response_non_stream": [22, 29], "response_requir": 29, "response_sent_to_client_t": [27, 28, 41, 52], "response_specif": 29, "response_stream": [22, 29], "responses_tot": 24, "rest": [28, 61, 124], "restart": [10, 11, 25, 32, 41, 56, 57, 60, 103], "restartpolici": [103, 104, 107], "restor": [19, 23, 62, 88], "restrict": [15, 24, 28, 33, 53, 57], "restructuredtext": 0, "result": [0, 3, 4, 5, 12, 15, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 32, 38, 41, 45, 46, 49, 53, 54, 55, 63, 70, 78, 80, 84, 90, 94, 99, 115, 118, 121, 123, 125, 127], "resume_memory_occup": [23, 25], "resume_weights_occup": 23, "retain": [37, 50], "retent": 24, "reth0": 103, "reth2": 103, "reth4": 103, "reth6": 103, "retoken": 53, "retract": [14, 23, 25, 97], "retracted_req": 14, "retri": [0, 5, 13], "retries_exhausted_tot": 24, "retries_tot": 24, "retriev": [11, 12, 24, 26, 57, 77, 117, 119, 121, 125], "retry_backoff_second": 24, "retryabl": 24, "return": [9, 12, 13, 18, 23, 24, 25, 27, 28, 29, 41, 51, 57, 61, 62, 88, 101, 115, 118, 119, 121], "return_dict": [22, 27, 28, 29, 41], "return_hidden_st": 51, "return_logprob": [27, 28, 51], "return_routed_expert": [45, 51], "return_tensor": 30, "return_text_in_logprob": 51, "reus": [0, 1, 5, 11, 12, 19, 23, 24, 33, 49, 55, 71, 72, 73, 75, 80, 115], "reusabl": [12, 57, 75], "reuter": 38, "rev": 103, "revel": 15, "reveng": 15, "revert": 18, "revis": [15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "revolv": 75, "reward": [25, 52, 77, 117, 122], "reward_process": 41, "rf": [76, 79], "rheumatoid": 42, "rich": [32, 36, 41, 42, 101], "rid": [15, 51, 104, 107, 110, 118], "right": [5, 20, 26, 28, 42, 45, 98], "rigid": 25, "rigor": [55, 80], "ring": [24, 61, 62, 82], "ring_degre": 61, "rio": 28, "risen": 38, "risk": [14, 15, 19, 26], "river": 41, "rl": [4, 5, 23, 26, 77, 88, 89, 108, 125, 127], "rl2": 108, "rl_on_policy_target": [15, 22, 27, 28, 29, 30, 41, 42], "rl_quant_profil": [15, 22, 27, 28, 29, 30, 41, 42], "rl_team": 108, "rlhf": [108, 123], "rlimit_nofil": 53, "rm": [60, 68, 76, 79, 81, 89, 92, 93, 123], "rmsnorm": [23, 115], "roadmap": [4, 8, 15, 32, 33, 39, 94, 102], "roar": 81, "robin": [15, 22, 23, 27, 28, 29, 30, 41, 42, 82, 83, 88], "robot": 42, "robust": [25, 53, 119], "roce": [56, 79], "rocki": 15, "rocm": [1, 8, 23, 33, 67, 77, 79], "rocm700": [33, 60, 68], "role": [22, 24, 26, 27, 28, 29, 30, 31, 32, 36, 37, 40, 41, 42, 43, 45, 47, 50, 51, 52, 103, 104, 107, 124, 127], "role_end": 124, "rolebasedgroup": 107, "rolebind": 24, "roleref": 24, "roll": [15, 41, 79, 90, 103, 108], "rollback": 13, "rollingupd": 104, "rollingupdateconfigur": 104, "rollout": [5, 25, 77, 108], "rolloutstrategi": 104, "roman": 45, "romanc": 15, "rome": [27, 28, 42, 45, 101], "rooflin": 18, "room": [18, 110], "root": [12, 15, 23, 27, 28, 33, 41, 51, 54, 56, 68, 76, 79, 81, 84, 88, 90, 103, 104, 107, 110, 111, 114, 115], "rope": [23, 88, 97], "rotari": [23, 127], "rotat": 24, "roughli": [38, 98], "round": [8, 15, 22, 23, 27, 28, 29, 30, 42, 53, 82, 83, 88], "round_robin": [5, 15, 22, 23, 24, 27, 28, 29, 30, 41, 42, 82, 83, 88], "rout": [5, 8, 17, 23, 25, 43, 51, 53, 88, 97, 118, 125, 127], "routed_expert": 45, "router": [7, 8, 14, 23, 33, 54, 77, 81, 83, 107, 108, 110], "router_api_kei": 24, "router_log": 24, "routerarg": 24, "routin": [15, 76], "rst": 0, "rule": [14, 23, 24, 30, 41, 65, 94], "run": [0, 1, 2, 3, 4, 9, 13, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 37, 38, 41, 42, 43, 45, 46, 47, 49, 50, 52, 53, 54, 56, 57, 58, 63, 65, 68, 74, 77, 82, 84, 88, 92, 94, 95, 97, 98, 101, 103, 104, 105, 107, 109, 111, 114, 115, 121, 127], "run_batch": 101, "run_dat": 78, "run_ev": [33, 58, 83], "run_id": 78, "run_llm": 115, "runnabl": [0, 57], "runner": [1, 3, 5, 8, 23, 33, 41, 88, 97], "runner_allow_runasroot": 60, "runnerinput": 8, "runneroutput": 8, "running_queu": 25, "runtim": [8, 10, 11, 15, 18, 19, 22, 25, 30, 41, 42, 51, 54, 55, 69, 74, 75, 76, 77, 80, 84, 93, 94, 95, 97, 115, 127], "runtime_vers": 94, "runtimecheck": 57, "runtimedevicecheck": 57, "runtimeendpoint": [99, 101], "runtimeerror": 54, "rust": [5, 104, 118], "rustc": 24, "rustl": 24, "rustup": 24, "ruthless": 15, "s3": [12, 61, 66], "safe": [15, 22, 24, 25, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "safeguard": 65, "safest": 25, "safetensor": [15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 62, 88, 101], "safeti": 13, "sage": [61, 64, 69], "sage_attn": [61, 69], "sage_attn_3": 69, "sageattent": [67, 69, 73], "sageattention3": 69, "sagesla": 64, "sai": [15, 45, 101], "same": [3, 4, 5, 11, 12, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 33, 41, 45, 51, 54, 55, 57, 61, 62, 65, 80, 81, 84, 94, 98, 101, 110, 115, 118, 121], "sampl": [1, 5, 9, 15, 24, 32, 33, 36, 41, 52, 53, 72, 74, 76, 77, 81, 98, 115, 127], "sampler": 127, "sampling_arg": 61, "sampling_backend": [15, 22, 27, 28, 29, 30, 41, 42], "sampling_default": [15, 22, 27, 28, 29, 30, 41, 42], "sampling_param": [4, 15, 19, 22, 27, 28, 29, 42, 51, 52, 65, 91, 113, 115, 124], "sampling_se": 4, "samplingparam": [51, 75], "san": [27, 28, 29], "sandbox": [24, 38], "saniti": [55, 80], "sarah": 45, "sat": 15, "satisfi": [5, 13, 18, 28], "satur": [18, 25], "save": [2, 5, 14, 19, 23, 25, 41, 49, 54, 56, 61, 67, 68, 74, 88, 90, 94, 97, 98, 127], "save_dir": 19, "save_pretrain": 19, "saver": [23, 25, 88], "saw": 15, "sbatch": 105, "sbin": [81, 84], "scalabl": [7, 8, 90, 127], "scalar": [20, 123], "scale": [5, 7, 8, 12, 17, 18, 19, 23, 24, 25, 32, 33, 40, 51, 53, 61, 73, 76, 106, 108, 121, 125], "scaled_dot_product_attent": 69, "scaling_factor": 20, "scaling_governor": [81, 82, 83, 84], "scan": 0, "scarc": [6, 15], "scatter": [5, 23, 82, 83, 88, 110], "scenario": [1, 4, 5, 8, 11, 12, 15, 18, 20, 23, 30, 32, 33, 58, 63, 104, 107, 127], "scene": [30, 42, 47, 121, 127], "sceneri": 30, "sched_migration_cost_n": [82, 83, 84], "schedul": [3, 7, 11, 12, 13, 14, 15, 18, 24, 25, 32, 33, 36, 38, 42, 49, 53, 55, 65, 67, 75, 77, 78, 80, 90, 94, 95, 97, 107, 110], "schedule_conserv": [15, 22, 27, 28, 29, 30, 41, 42], "schedule_delay_milli": 97, "schedule_low_priority_values_first": [15, 22, 27, 28, 29, 30, 41, 42], "schedule_polici": [15, 22, 27, 28, 29, 30, 41, 42], "scheduler_output_processor_mixin": [55, 80], "scheduler_recv_interv": [15, 22, 27, 28, 29, 30, 41, 42], "schema": [15, 23, 25, 27, 28, 51, 101], "schema_get_current_d": [27, 28], "schema_get_current_weath": [27, 28], "scheme": [8, 12, 19], "school": 28, "scienc": 125, "scm": [66, 71, 73], "scontrol": 105, "scope": [5, 24, 65, 71], "score": [25, 33, 58, 115, 121, 123], "score_process": 41, "scout": [29, 30, 39, 89, 125], "scrape": [24, 109], "scratch": 127, "screenshot": 110, "script": [16, 19, 32, 33, 38, 42, 53, 54, 55, 56, 58, 65, 67, 76, 77, 78, 79, 80, 84, 90, 91, 93, 95, 97, 105, 113, 115, 118], "sd": 64, "sdk": [24, 61, 62, 67, 76, 110], "sdpa": [1, 23, 69, 73], "seamless": [7, 8, 19, 84, 118], "seamlessli": [11, 26, 108], "search": [12, 15, 23, 27, 28, 32, 33, 101, 119, 121, 125, 127], "seat": 28, "sec": [5, 23, 24, 88, 103, 107], "seccomp": 79, "second": [2, 15, 17, 21, 23, 24, 26, 37, 47, 50, 52, 53, 55, 58, 61, 74, 78, 80, 94, 97, 109, 125], "second_answ": 101, "secondari": 42, "secret": [15, 24, 61, 66, 68, 76, 79, 81, 90], "section": [8, 15, 17, 19, 24, 25, 28, 30, 45, 51, 57, 63, 64, 73, 81, 82, 88, 89, 98, 103, 104, 107, 109, 110, 115, 127], "secur": [23, 42, 54, 76, 79, 103], "securitycontext": [103, 104, 107], "see": [1, 3, 5, 8, 11, 12, 13, 14, 15, 16, 17, 19, 23, 24, 25, 26, 27, 28, 32, 34, 42, 43, 45, 46, 51, 52, 54, 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 90, 94, 95, 98, 101, 103, 109, 115, 116, 121, 125, 127], "seed": [4, 21, 23, 45, 61, 74, 75, 88, 94], "seed_instance_ip": 21, "seed_instance_service_port": 21, "seek": [3, 15], "seem": [15, 28, 29, 30, 45, 53], "seen": [15, 39, 49], "segment": [3, 23, 110], "sein": 41, "seldom": 18, "select": [5, 7, 9, 12, 18, 19, 23, 24, 25, 26, 33, 39, 45, 51, 53, 63, 76, 77, 97, 104, 107, 124], "select_expert": 8, "selection_tot": 24, "selector": [24, 25, 69, 103, 104, 107], "self": [8, 9, 42, 45, 46, 47, 51, 75, 115, 116], "self_attn": 54, "semant": [119, 121], "send": [0, 13, 14, 16, 21, 23, 24, 27, 28, 47, 51, 53, 54, 77, 79, 88, 98, 105, 110, 127], "send_on": 54, "send_weights_nccl_group_ports_list": 21, "sender": 110, "sens": [15, 26], "sensetim": 125, "sensit": [12, 15, 24, 58], "sent": [24, 53, 90, 95], "sentenc": [28, 38, 45, 47, 51], "sep": 96, "sep_styl": 96, "separ": [2, 5, 7, 15, 17, 18, 22, 23, 26, 27, 28, 29, 41, 45, 46, 47, 52, 54, 55, 61, 71, 72, 73, 80, 94, 97, 101, 104, 110, 127], "separate_reason": [22, 45], "separate_reasoning_data": 22, "separate_reasoning_response_json": 22, "septemb": 5, "seq": [15, 23, 33, 41, 103], "seq_len": 3, "seqlen": 3, "sequenc": [3, 7, 8, 12, 15, 17, 18, 20, 23, 24, 25, 26, 32, 45, 51, 54, 61, 89, 94, 123], "sequenti": [75, 104, 125], "seren": 61, "seri": [18, 22, 28, 29, 32, 40, 67, 75, 84, 89, 90, 95, 123, 125], "serial": [24, 25, 51], "serialized_named_tensor": 25, "serv": [0, 5, 8, 12, 13, 18, 19, 24, 25, 30, 32, 33, 36, 39, 45, 49, 54, 70, 76, 77, 84, 103, 105, 108, 119, 121], "served_model_nam": [15, 22, 27, 28, 29, 30, 41, 42], "server": [0, 3, 5, 7, 11, 12, 13, 14, 15, 16, 19, 20, 21, 26, 27, 28, 32, 33, 36, 38, 42, 49, 51, 53, 55, 56, 57, 58, 63, 76, 77, 79, 80, 81, 93, 94, 96, 97, 103, 105, 109, 110, 111, 114, 115, 118, 124], "server_address": 33, "server_arg": [9, 13, 15, 22, 23, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 61, 62, 65, 75, 101, 115], "server_info": 41, "server_ip": 103, "server_nam": 110, "server_process": [15, 22, 26, 27, 28, 29, 41, 45, 52, 101], "server_process_tool_choic": 29, "server_typ": 33, "serverarg": [9, 15, 22, 27, 28, 29, 30, 41, 42, 69, 75], "servers_act": 24, "servic": [3, 7, 13, 21, 23, 38, 45, 46, 47, 54, 76, 88, 90, 103, 107, 109, 118], "service_nam": 24, "service_ti": [26, 29, 45, 52], "serviceaccount": 24, "servicenow": 125, "serving_classifi": 118, "session": [24, 29, 54, 110], "set": [1, 3, 5, 6, 8, 11, 12, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 36, 38, 39, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 61, 62, 66, 70, 75, 76, 78, 80, 83, 88, 90, 91, 93, 94, 95, 96, 97, 98, 101, 103, 105, 109, 110, 111, 113, 114, 115, 116, 119, 123, 124, 127], "set_attention_backend": 69, "set_default_backend": 101, "set_env": [82, 83, 84], "set_lora": 62, "setenv": 82, "setup": [8, 17, 23, 25, 45, 54, 69, 76, 77, 90, 94, 103, 121], "setup_musa": 92, "setup_rocm": 79, "setuptool": [90, 95], "sever": [12, 15, 19, 21, 24, 26, 41, 42, 51, 54, 90, 115], "sft": 108, "sgl": [0, 3, 6, 11, 19, 22, 23, 24, 27, 28, 29, 30, 33, 37, 38, 41, 42, 47, 50, 51, 56, 57, 59, 60, 68, 74, 76, 79, 81, 90, 91, 92, 94, 95, 99, 101, 102, 104, 105, 107, 110, 113, 115, 118, 124, 125, 127], "sgl_": 97, "sgl_cach": 104, "sgl_cache1": 104, "sgl_cache4": 107, "sgl_enable_jit_deepgemm": 107, "sgl_ext": 45, "sgl_grpc_endpoint": 24, "sgl_jax": 94, "sgl_kernel": [57, 76], "sgl_tokenizer_path": 24, "sglang": [1, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 26, 30, 31, 34, 35, 38, 40, 42, 45, 46, 47, 48, 51, 52, 53, 57, 59, 60, 63, 64, 66, 69, 70, 71, 72, 73, 74, 75, 82, 83, 84, 86, 87, 88, 90, 91, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 121, 123, 124, 125, 127], "sglang_": 97, "sglang_allow_overwrite_longer_context_len": 97, "sglang_blackwell_overlap_shared_experts_outside_sbo": 97, "sglang_block_nonzero_rank_children": 97, "sglang_cache_dit_bn": [66, 70], "sglang_cache_dit_en": [61, 66, 67, 70, 71, 73], "sglang_cache_dit_fn": [66, 70], "sglang_cache_dit_mc": [66, 70], "sglang_cache_dit_rdt": [66, 70], "sglang_cache_dit_scm_cache_bin": [66, 70], "sglang_cache_dit_scm_compute_bin": [66, 70], "sglang_cache_dit_scm_polici": [66, 70], "sglang_cache_dit_scm_preset": [66, 70], "sglang_cache_dit_taylors": [66, 70], "sglang_cache_dit_ts_ord": [66, 70], "sglang_cache_dit_warmup": [66, 70], "sglang_cache_hit_r": 5, "sglang_chunked_prefix_cache_threshold": [97, 104], "sglang_clip_max_new_tokens_estim": 97, "sglang_cloud_storage_typ": [61, 66], "sglang_cpu_omp_threads_bind": 90, "sglang_custom_allreduce_algo": 97, "sglang_cutlass_mo": 97, "sglang_data_parallel_budget_interv": 97, "sglang_debug_memory_pool": 97, "sglang_deepep_bf16_dispatch": [86, 97], "sglang_deepep_ll_combine_send_num_sm": 97, "sglang_deepep_num_max_dispatch_tokens_per_rank": [82, 83, 86, 97], "sglang_detokenizer_max_st": 97, "sglang_dev": 56, "sglang_dg_cache_dir": 97, "sglang_dg_use_nvrtc": 97, "sglang_disable_consecutive_prefill_overlap": 97, "sglang_disable_fa4_warmup": 97, "sglang_disable_outlines_disk_cach": 97, "sglang_disable_request_log": 97, "sglang_disaggregation_bootstrap_timeout": [17, 82, 84, 107], "sglang_disaggregation_heartbeat_interv": 17, "sglang_disaggregation_heartbeat_max_failur": 17, "sglang_disaggregation_nixl_backend": 17, "sglang_disaggregation_queue_s": 17, "sglang_disaggregation_thread_pool_s": 17, "sglang_disaggregation_waiting_timeout": [17, 107], "sglang_dp_round_robin": [82, 83], "sglang_dynamic_chunking_smooth_factor": 18, "sglang_enable_flashinfer_fp8_gemm": [23, 97], "sglang_enable_jit_deepgemm": [32, 97, 104], "sglang_enable_overlap_plan_stream": [82, 83, 84, 86], "sglang_enable_spec_v2": [26, 32, 33, 36, 38, 82, 83, 84, 86], "sglang_enable_torch_compil": 97, "sglang_enable_torch_inference_mod": 97, "sglang_enable_tp_memory_inbalance_check": 97, "sglang_eplb_heatmap_collection_interv": 97, "sglang_flashinfer_fp4_gemm_backend": [23, 97], "sglang_flashinfer_num_max_dispatch_tokens_per_rank": 97, "sglang_force_fp8_marlin": 97, "sglang_forward_timeout_m": 97, "sglang_forward_unknown_tool": 97, "sglang_fused_mla_enable_rope_fus": 97, "sglang_hack_deepep_new_mod": 104, "sglang_hack_deepep_num_sm": 104, "sglang_health_check_timeout": 97, "sglang_host_ip": 97, "sglang_imag": 79, "sglang_in_deepgemm_precompile_stag": 97, "sglang_int4_weight": 97, "sglang_is_first_rank_on_nod": 97, "sglang_is_flashinfer_avail": 97, "sglang_is_in_ci": [60, 97], "sglang_is_in_ci_amd": 97, "sglang_jit_deepgemm_compile_work": 97, "sglang_jit_deepgemm_fast_warmup": 97, "sglang_jit_deepgemm_precompil": 97, "sglang_log_request_head": 97, "sglang_logging_config_path": 97, "sglang_mm_buffer_size_mb": 97, "sglang_mm_precompute_hash": 97, "sglang_moe_nvfp4_dispatch": 97, "sglang_moe_pad": 97, "sglang_mooncake_custom_mem_pool": [17, 97], "sglang_mooncake_trans_thread": 104, "sglang_mori_fp8_disp": 97, "sglang_mori_num_max_dispatch_tokens_per_rank": 97, "sglang_mori_num_work": 97, "sglang_mori_post_batch_s": 97, "sglang_mori_qp_per_transf": 97, "sglang_nccl_all_gather_in_overlap_scheduler_sync_batch": 97, "sglang_ngram_force_greedy_verifi": 26, "sglang_npu": 81, "sglang_npu_use_mlapo": [82, 83], "sglang_npu_use_multi_stream": [82, 84], "sglang_nsa_enable_mtp_precompute_metadata": 97, "sglang_nsa_fuse_topk": 97, "sglang_nvfp4_ckpt_fp8_gemm_in_attn": 97, "sglang_nvfp4_ckpt_fp8_nextn_mo": 97, "sglang_one_visible_device_per_process": 97, "sglang_otlp_exporter_max_export_batch_s": [97, 110], "sglang_otlp_exporter_schedule_delay_milli": [97, 110], "sglang_per_token_group_quant_8bit_v2": 97, "sglang_port": 97, "sglang_pp_layer_partit": [18, 33, 97], "sglang_profile_record_shap": 97, "sglang_profile_with_stack": [54, 97], "sglang_queued_timeout_m": 97, "sglang_random": 53, "sglang_record_step_tim": 97, "sglang_request_dump": 16, "sglang_rout": [5, 7, 17, 23, 24, 33, 54, 81, 82, 83, 104, 107, 110], "sglang_s3_access_key_id": [61, 66], "sglang_s3_bucket_nam": [61, 66], "sglang_s3_endpoint_url": [61, 66], "sglang_s3_region_nam": 66, "sglang_s3_secret_access_kei": [61, 66], "sglang_scheduler_decrease_prefill_idl": 82, "sglang_scheduler_max_recv_per_pol": 97, "sglang_scheduler_recv_skipper_weight_decod": 97, "sglang_scheduler_recv_skipper_weight_default": 97, "sglang_scheduler_recv_skipper_weight_non": 97, "sglang_scheduler_recv_skipper_weight_verifi": 97, "sglang_scheduler_skip_all_gath": [82, 83], "sglang_server_host": 109, "sglang_set_cpu_affin": [81, 82, 83, 84, 86, 97, 104, 107], "sglang_skip_p2p_check": 97, "sglang_skip_sgl_kernel_version_check": 107, "sglang_storag": [15, 22, 23, 27, 28, 29, 30, 41, 42], "sglang_support_cutlass_block_fp8": [23, 97], "sglang_symm_mem_prealloc_gb_s": 97, "sglang_test_request_time_stat": 97, "sglang_test_retract": 97, "sglang_test_retract_no_prefill_b": 97, "sglang_tool_strict_level": 97, "sglang_torch_profiler_dir": [53, 54, 97], "sglang_use_ait": 97, "sglang_use_cpu_engin": 90, "sglang_use_cuda_ipc_transport": [37, 50], "sglang_use_custom_triton_kernel_cach": 97, "sglang_use_deepgemm_bmm": 97, "sglang_use_fia_nz": [82, 83], "sglang_use_modelscop": [53, 97, 114], "sglang_vit_enable_cuda_graph": 3, "sglang_vlm_cache_size_mb": [37, 50], "sglang_wait_weights_ready_timeout": 97, "sglang_zhync": 56, "sglangtracepropagatecontext": 110, "sglangtracereqcontext": 110, "sglangtracethreadcontext": 110, "sglroutertestatp_high": 24, "sgmv": 15, "sh": [0, 24, 59, 76, 79, 82, 83, 84, 90, 93, 107], "shadow": 15, "shakhizat": 93, "shanghai_ai_laboratori": 89, "shape": [3, 9, 15, 19, 25, 30, 45, 51, 54, 57, 75, 97], "shard": [5, 15, 17, 22, 25, 26, 27, 28, 29, 30, 33, 41, 42, 45, 46, 47, 52, 101], "sharded_st": 23, "share": [1, 5, 8, 11, 12, 14, 15, 17, 20, 23, 24, 25, 27, 28, 37, 38, 50, 53, 55, 60, 69, 80, 82, 83, 84, 88, 94, 97, 102, 103, 104, 108, 110, 121], "sharegpt": [53, 54], "sharpli": 38, "she": [15, 45], "sheet": 101, "shell": [46, 47, 52, 54, 56], "ship": 111, "shm": [23, 56, 60, 68, 76, 79, 81, 84, 90, 103, 104, 107], "shone": 15, "short": [23, 33, 38, 42, 45, 51, 53, 65, 115], "shorter": 99, "shortest": 5, "shorthand": 23, "shot": [29, 33, 55, 56, 58, 80, 97], "should": [0, 4, 12, 14, 15, 18, 20, 23, 25, 26, 28, 29, 32, 33, 36, 38, 40, 45, 54, 56, 57, 61, 65, 84, 90, 96, 103, 104, 109, 110, 115, 121], "show": [2, 4, 15, 18, 20, 23, 29, 30, 33, 38, 43, 45, 47, 64, 76, 78, 79, 81, 101, 103, 105, 127], "show_time_cost": [15, 22, 27, 28, 29, 30, 41, 42], "showcas": 105, "shown": [1, 15, 29, 30, 54, 74, 79, 124], "shrub": 15, "shuffl": [8, 23], "shut": 61, "shutdown": [22, 23, 27, 28, 29, 30, 42, 115], "sick": 15, "side": [3, 13, 15, 23, 42, 54, 118, 127], "sig": [103, 104, 107], "sigmoid": 41, "sign": 20, "signal": 38, "signatur": [9, 115], "signific": [2, 5, 6, 8, 17, 18, 20, 26, 32, 42, 45, 55, 80, 98, 125], "significantli": [2, 5, 12, 18, 21, 33, 37, 38, 50, 65, 71, 76, 83, 94, 101], "sigquit": [23, 88], "silent": [13, 25, 26], "silu": 97, "siluandmul": 115, "similar": [1, 37, 41, 45, 51, 57, 71, 72, 73, 115, 121], "similar_imag": 121, "similarli": [12, 90, 98, 115, 125], "simpl": [5, 12, 14, 19, 20, 24, 30, 33, 43, 57, 64, 71, 101, 103, 115], "simplenamespac": 83, "simpler": [20, 54], "simplest": [5, 25], "simpli": [19, 27, 41, 64, 76, 85, 99, 119, 121], "simplic": 25, "simplifi": [8, 32, 54, 94], "simul": [8, 58], "simultan": [17, 18, 70, 94], "sin_cos_w": 3, "sinc": [5, 6, 12, 15, 18, 22, 26, 27, 28, 29, 30, 38, 39, 41, 42, 45, 46, 47, 49, 52, 55, 76, 80, 101], "singl": [4, 5, 12, 20, 23, 24, 29, 30, 32, 33, 45, 51, 54, 55, 58, 62, 63, 65, 76, 77, 79, 80, 88, 90, 94, 97, 105, 115], "single_run": 78, "singleprocess": 26, "sink": 24, "site": 42, "situat": 30, "size": [1, 2, 3, 4, 5, 6, 8, 11, 12, 15, 17, 19, 20, 23, 24, 25, 26, 30, 32, 33, 36, 37, 38, 40, 41, 49, 50, 53, 54, 56, 57, 58, 60, 61, 62, 68, 69, 74, 76, 78, 79, 81, 82, 83, 84, 86, 88, 90, 91, 93, 94, 95, 97, 98, 103, 104, 105, 107, 113, 119, 121, 123, 125, 127], "size_t": 57, "sk": [38, 53, 60, 62], "skew": 51, "skill": [15, 33, 42], "skip": [0, 9, 15, 19, 23, 41, 53, 54, 56, 58, 70, 71, 72, 73, 74, 79, 88, 94, 97, 111], "skip_server_warmup": [15, 22, 27, 28, 29, 30, 41, 42], "skip_special_token": [22, 24, 29, 41, 51], "skip_time_step": 69, "skip_tokenizer_init": [15, 22, 27, 28, 29, 30, 41, 42], "skipper": 97, "sky": [15, 76, 94], "skyserv": 76, "skywork": [41, 77, 89, 123], "sla": 64, "slack": [11, 55, 80, 94, 102], "slash": [55, 80], "sleep": [2, 23, 60, 62, 88, 105, 108, 121], "sleep_on_idl": [15, 22, 27, 28, 29, 30, 41, 42], "slice": 61, "slice_span": 110, "slide": [1, 32, 94, 102, 108], "sliding_tile_attn": 69, "slight": 98, "slightli": [45, 98], "slime": [77, 108], "slo": 12, "slot": 15, "slow": [14, 20, 23, 25, 66, 70, 88, 98, 111], "slowdown": 53, "slower": [12, 23, 124], "slowli": 14, "slurm_log": 105, "slurm_nodeid": 105, "slurm_nodelist": 105, "slurm_procid": 105, "slytherin": 101, "sm": [23, 88, 97, 103], "sm10": 23, "sm100": [23, 33, 97], "sm103": 76, "sm120": 69, "sm75": 76, "sm80": 69, "sm86": 69, "sm89": 69, "sm90": [23, 33, 69, 97], "sm_103a": 76, "sm_group_num": [15, 22, 27, 28, 29, 30, 41, 42], "sm_sglang_": 76, "sm_sglang_input_argu": 76, "sm_sglang_model_path": 76, "sm_sglang_reasoning_pars": 76, "small": [0, 3, 6, 12, 14, 15, 18, 23, 25, 32, 33, 38, 54, 55, 80, 89, 98, 125, 127], "small3": 125, "smaller": [12, 14, 15, 18, 19, 20, 23, 24, 26, 55, 74, 76, 80, 94, 98, 123], "smallest": 51, "smg": [24, 97], "smg_db_": 24, "smg_discovery_": 24, "smg_http_": 24, "smg_http_rate_limit_tot": 24, "smg_http_request_duration_seconds_bucket": 24, "smg_http_requests_tot": 24, "smg_http_responses_tot": 24, "smg_mcp_": 24, "smg_mcp_servers_act": 24, "smg_mcp_tool_calls_tot": 24, "smg_mcp_tool_duration_seconds_bucket": 24, "smg_router_": 24, "smg_router_generation_duration_second": 24, "smg_router_generation_duration_seconds_bucket": 24, "smg_router_requests_tot": [5, 24], "smg_router_tokens_tot": 24, "smg_router_tpot_second": 24, "smg_router_tpot_seconds_bucket": 24, "smg_router_ttft_second": 24, "smg_router_ttft_seconds_bucket": 24, "smg_worker_": 24, "smg_worker_cb_": 24, "smg_worker_cb_st": 24, "smg_worker_cb_transitions_tot": 24, "smg_worker_connections_act": 24, "smg_worker_health_checks_tot": 24, "smg_worker_pool_s": 24, "smg_worker_requests_act": [5, 24], "smg_worker_retries_exhausted_tot": 24, "smg_worker_retries_tot": 24, "smollm": [89, 125], "smooth": [45, 46, 47, 55, 80], "smoother": 23, "smoothli": 54, "snapshot": [15, 37, 41, 50, 115], "snapshot_download": 115, "snc": 90, "sneak": 15, "snippet": [29, 38, 54, 55, 80], "so": [0, 1, 3, 9, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 41, 42, 45, 46, 47, 51, 52, 54, 55, 62, 80, 90, 101, 115], "societ": 42, "societi": 42, "socket": [2, 90, 103], "soft": [15, 23, 53, 88], "soft_watchdog_timeout": [15, 22, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 101], "softmax": [24, 41], "softwar": [68, 91, 113], "solar": [42, 89, 125], "solut": [3, 12, 18, 22, 23, 25, 76], "solv": [3, 18, 101], "some": [0, 1, 5, 13, 14, 18, 19, 25, 26, 28, 29, 30, 32, 42, 45, 53, 54, 55, 56, 57, 60, 64, 69, 80, 88, 101, 103, 104, 109, 110, 115, 119, 121, 123, 125], "somehow": 15, "someon": [26, 30], "someth": [15, 26, 28, 57], "sometim": [3, 16, 26, 28, 41, 98, 103, 121], "somewhat": 47, "somewher": 28, "soon": [15, 19, 91, 113, 116, 127], "sophia": 15, "sophist": 40, "sorri": 42, "sort": [15, 51, 121], "sota": 125, "sound": [15, 26], "sourc": [0, 4, 5, 17, 25, 26, 27, 28, 38, 39, 41, 51, 54, 57, 58, 67, 77, 82, 83, 84, 105, 109, 115, 125, 127], "south": 52, "sp": [61, 70], "sp_size": 61, "space": [12, 45, 49, 51, 53, 75, 114, 119, 125], "spaces_between_special_token": 51, "spain": [45, 101], "spam": [55, 80], "span": [12, 24, 45, 54, 110, 125], "spargeattn": 64, "spark": [76, 77], "sparkl": 15, "spars": [33, 64, 69, 84, 88, 125], "sparseautomodelforcausallm": 19, "sparsiti": [69, 88], "spatial": 69, "spatial_chunk_s": 69, "spatial_lay": 69, "spatial_topk": 69, "spatiotempor": 69, "speak": 98, "spec": [1, 23, 24, 26, 52, 83, 94, 103, 104, 107, 118], "spec_nam": 9, "speci": [41, 121], "special": [8, 22, 25, 28, 29, 33, 51, 58, 75, 77, 88, 91, 113, 117, 118, 123, 125, 127], "specif": [1, 5, 8, 9, 11, 12, 18, 19, 20, 23, 24, 26, 28, 30, 32, 42, 45, 51, 54, 55, 61, 67, 70, 74, 75, 76, 77, 78, 80, 81, 91, 95, 113, 125, 127], "specifi": [1, 4, 7, 8, 12, 15, 19, 20, 22, 23, 26, 27, 28, 29, 30, 32, 33, 37, 39, 41, 42, 45, 46, 47, 50, 51, 52, 54, 60, 61, 63, 76, 79, 81, 90, 94, 96, 99, 101, 109, 110, 119, 121], "specific_funct": 29, "specul": [8, 32, 33, 53, 77, 78, 82, 83, 86, 108], "speculative_accept_threshold_acc": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_accept_threshold_singl": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_algorithm": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_attention_mod": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_draft_attention_backend": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_draft_load_format": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_draft_model_path": [15, 22, 26, 27, 28, 29, 30, 41, 42], "speculative_draft_model_quant": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_draft_model_revis": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_eagle_topk": [15, 22, 26, 27, 28, 29, 30, 41, 42], "speculative_moe_a2a_backend": [15, 22, 26, 27, 28, 29, 30, 41, 42], "speculative_moe_runner_backend": [15, 22, 26, 27, 28, 29, 30, 41, 42], "speculative_ngram_branch_length": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_capac": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_match_typ": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_max_bfs_breadth": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_max_match_window_s": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_min_bfs_breadth": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_ngram_min_match_window_s": [15, 22, 27, 28, 29, 30, 41, 42], "speculative_num_draft_token": [15, 22, 23, 26, 27, 28, 29, 30, 41, 42], "speculative_num_step": [15, 22, 26, 27, 28, 29, 30, 41, 42], "speculative_token_map": [15, 22, 27, 28, 29, 30, 41, 42], "specv2": 26, "speech": 125, "speed": [12, 23, 25, 26, 32, 33, 38, 49, 53, 70, 72, 78, 98, 103, 127], "speedup": [30, 32, 33, 70, 71, 73, 108], "spell": 45, "spent": 15, "sphinx": 0, "spike": [8, 74], "split": [1, 4, 8, 9, 12, 15, 19, 22, 23, 24, 27, 28, 29, 30, 41, 42, 53, 55, 80, 88], "split_kv": 1, "spoke": 15, "spontan": 42, "sport": 30, "spot": 94, "spread": 15, "sql": [15, 45], "sqrt": 115, "squar": 115, "src": [24, 56, 57, 107, 118], "srt": [1, 2, 13, 15, 16, 19, 22, 24, 26, 30, 32, 36, 41, 45, 46, 47, 51, 52, 101, 104, 115, 116, 118, 125, 127], "srun": 105, "ss": [62, 74], "sse": [24, 38], "ssf": 24, "ssh": [43, 56], "ssl": 78, "ssm": [23, 49, 88], "st": 76, "st_attn": 69, "st_chunk_siz": 69, "st_layer": 69, "st_topk": 69, "sta_infer": 69, "sta_mod": 69, "stabil": [8, 18, 25, 32, 33, 108], "stabilityai": [89, 125], "stabl": [4, 45, 56, 65, 70, 76, 79, 125], "stablelm": [89, 125], "stack": [24, 25, 26, 54, 68, 74, 97, 107, 108, 109, 127], "stag": 101, "stage": [7, 8, 17, 18, 23, 24, 32, 33, 36, 38, 55, 62, 63, 77, 80], "stage_duration_second": 24, "stage_nam": 75, "stai": [0, 18, 95, 97, 101], "stall": 25, "stand": [14, 15, 23, 30, 47, 101], "standalon": 23, "standaloneworkerv2": 26, "standard": [1, 4, 8, 9, 12, 19, 22, 24, 45, 64, 75, 77, 94, 103, 115, 118], "stanlei": 38, "star": [15, 45, 77], "starcod": 125, "starcoder2": [89, 125], "starsfridai": 64, "start": [0, 13, 15, 16, 18, 19, 21, 22, 23, 28, 29, 32, 33, 38, 41, 42, 45, 51, 52, 54, 55, 63, 65, 68, 70, 73, 74, 75, 76, 79, 80, 81, 84, 85, 88, 90, 93, 94, 95, 101, 103, 109, 110, 114, 115], "start_expert_distribution_record": 41, "start_profil": 53, "start_step": 54, "start_tag": [27, 28], "startswith": [51, 52], "startup": [9, 11, 15, 19, 23, 24, 26, 33, 40, 41, 56, 79, 91, 94, 103, 104, 107, 113], "startuppolici": 104, "starvat": 15, "stat": [23, 24, 26, 41, 88], "state": [9, 12, 14, 15, 23, 24, 25, 26, 27, 28, 29, 32, 42, 45, 49, 51, 52, 55, 62, 80, 88, 97, 101, 103, 108, 125], "statefulset": 76, "statement": [42, 115], "static": [0, 8, 11, 17, 18, 23, 25, 26, 32, 33, 36, 37, 39, 40, 50, 54, 57, 70, 75, 82, 83, 84, 85, 86, 88, 93, 94, 98, 103, 104, 107], "static_cast": 57, "static_config": 109, "stationari": 30, "statist": [8, 19, 24, 53, 97], "statu": [5, 24, 25, 27, 28, 41, 42, 56, 57, 62, 76, 94, 101, 103, 109, 118], "status_cod": 15, "std": 53, "stdin": 76, "stdio": 24, "stdout": 23, "steadi": 14, "steadili": 28, "step": [0, 12, 15, 18, 19, 23, 24, 25, 26, 28, 29, 32, 33, 36, 39, 41, 49, 54, 55, 56, 61, 63, 66, 69, 71, 72, 73, 76, 80, 82, 83, 86, 88, 90, 94, 97, 103, 111, 115, 124], "step3": [23, 24, 29, 127], "stepfun": 127, "still": [7, 13, 14, 15, 17, 23, 26, 28, 29, 33, 38, 41, 45, 70, 104, 110], "stochast": 4, "stock": 38, "stop": [12, 13, 14, 23, 26, 27, 28, 45, 47, 51, 52, 54, 101, 109], "stop_after_first": 27, "stop_expert_distribution_record": 41, "stop_profil": 53, "stop_regex": 51, "stop_str": 96, "stop_token_id": 51, "storag": [10, 20, 23, 77, 88], "storagebackendfactori": 13, "store": [5, 9, 11, 12, 13, 23, 24, 49, 54, 57, 83, 110], "stori": [43, 45], "storytel": 42, "str": [9, 15, 23, 24, 25, 27, 28, 29, 51, 69, 88, 115], "straightforward": [14, 24, 28], "strain": 101, "strateg": 8, "strategi": [5, 12, 14, 15, 17, 18, 23, 24, 25, 49, 66, 67, 69, 70, 71, 72, 77, 88, 124], "strawberri": 45, "stream": [8, 18, 23, 24, 27, 28, 32, 43, 45, 57, 88, 97, 115, 124], "stream_and_merg": 42, "stream_interv": [15, 22, 27, 28, 29, 30, 41, 42], "stream_output": [15, 22, 27, 28, 29, 30, 41, 42], "stream_reason": 22, "streamabl": 24, "streamlin": [19, 40, 119], "streams_per_devic": [82, 83, 84, 86], "street": [30, 47, 61, 101, 121], "strength": [62, 101], "strict": [53, 97], "stricter": 13, "strictli": [13, 15, 18, 23], "stride": [26, 57], "string": [4, 9, 12, 14, 15, 23, 24, 25, 27, 28, 29, 30, 32, 41, 45, 51, 61, 62, 69, 118, 121], "strip": [51, 52], "stripe": 30, "strive": 42, "strong": [8, 12, 15, 26, 38, 50, 99, 125, 127], "strongest": 12, "strongli": [5, 8, 19, 45, 57, 58, 79], "struct": 57, "structur": [8, 12, 18, 23, 24, 25, 29, 65, 75, 77, 97, 101, 110, 127], "structural_tag": [27, 28, 51], "stuck": [24, 103], "student": 101, "studi": [15, 75], "studio": 56, "stumbl": 15, "style": [23, 24, 25, 26, 53, 61, 62, 64, 116], "style_lora": 62, "styliz": 47, "sub": [5, 32, 41, 90], "subclass": [8, 22, 75], "subcommand": 61, "subdirectori": 0, "subdomainpolici": 104, "subject": [24, 65], "submit": [14, 53, 55, 58, 80, 105], "submodul": 9, "suboptim": 7, "subprocess": [23, 46, 47, 52], "subsequ": [3, 12, 18, 25, 94], "subset": [26, 62, 99, 121], "substanti": [12, 17], "succe": 104, "succeed": [13, 25, 41], "success": [13, 15, 24, 25, 41, 56, 61, 79], "successfulli": [12, 15, 76, 81, 103, 109], "successor": 125, "successthreshold": 107, "sudo": [79, 81, 93], "suffer": 25, "suffici": [12, 14, 28, 57, 94, 124, 127], "suffix": [55, 80], "suggest": [11, 14, 19, 27, 30, 37, 50, 58, 83, 93], "suit": [65, 117], "suitabl": [5, 12, 18, 23, 121], "sum": [22, 24, 38, 41], "summar": [101, 124, 125, 127], "summari": [24, 53, 101], "sun": 121, "sunni": 45, "sunset": [67, 70, 71, 73, 121], "super": [115, 125], "supercharg": 79, "superior": [94, 125], "suppli": [20, 23, 24, 32, 42, 99], "support": [0, 2, 5, 7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 25, 26, 27, 30, 32, 33, 34, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 51, 54, 55, 57, 62, 64, 65, 66, 67, 73, 76, 78, 79, 80, 84, 85, 87, 93, 95, 97, 99, 101, 103, 108, 112], "suppos": [5, 15, 57], "sure": [0, 3, 26, 28, 29, 45, 52, 54, 55, 80, 81, 103, 115], "surfboard": 30, "surg": 38, "surpass": 125, "surprisingli": 125, "surround": 15, "sustain": 101, "svc": [104, 107], "swa": [23, 39, 88], "swa_full_tokens_ratio": [15, 22, 27, 28, 29, 30, 41, 42], "swa_siz": 23, "swagger": 52, "swap": 3, "swappi": [81, 82, 83, 84], "swim": 101, "switch": [8, 11, 13, 18, 22, 23, 27, 28, 29, 30, 42, 53, 69, 76, 103, 116], "sy": [79, 81, 82, 83, 84, 107], "symbol": [28, 57, 64], "symbolic_correct": 33, "symbolicdevic": 57, "symbolicdtyp": 57, "symbolics": 57, "symm": [23, 88, 97], "symmetr": [23, 97], "sync": [18, 25, 56, 97], "sync_duration_second": 24, "synchron": [11, 15, 18, 24, 32, 55, 80], "syntact": 23, "syntax": [15, 24, 28, 45], "synthet": 53, "sys_ptrac": 79, "sysctl": [81, 82, 83, 84], "system": [2, 5, 8, 10, 11, 15, 17, 19, 23, 27, 28, 29, 30, 38, 42, 45, 51, 53, 57, 58, 67, 68, 73, 77, 82, 83, 84, 90, 96, 97, 101, 103, 104, 107, 108, 109, 115, 121, 124, 125], "system_fingerprint": [26, 29, 45, 52], "systemat": 94, "systemcut": 27, "systemd": 78, "systemprompt": 11, "t": [1, 9, 15, 18, 23, 24, 26, 28, 29, 30, 33, 38, 39, 43, 45, 51, 54, 55, 56, 69, 72, 76, 79, 80, 81, 90, 97, 103, 115, 127], "t2t": 124, "t2v": [61, 62, 64], "t4": 76, "t_": 26, "t_2": 26, "tabl": [1, 4, 23, 64, 65, 69, 90, 95, 97, 115, 124, 125, 127], "tackl": 26, "tag": [9, 22, 23, 24, 25, 29, 33, 43, 51, 55, 80, 81, 84, 97], "tail": [18, 25], "tailor": [17, 37, 50], "taint": [104, 107], "take": [0, 1, 9, 14, 15, 17, 18, 19, 23, 24, 26, 32, 41, 45, 54, 55, 56, 61, 79, 80, 90, 94, 103, 114, 115], "tale": 15, "talk": 15, "talker": 127, "tall": 15, "taller": 15, "tar": 56, "target": [0, 1, 8, 9, 15, 18, 19, 23, 24, 26, 38, 53, 54, 62, 69, 75, 88, 97, 109], "target_modul": 23, "target_pattern": 9, "targetport": [103, 104, 107], "tarn59": [62, 64], "task": [2, 20, 25, 39, 40, 41, 42, 43, 55, 61, 62, 65, 75, 80, 105, 118, 119, 121, 122, 123, 125, 127], "task_queue_en": [82, 83], "task_typ": 62, "taxi": [30, 47, 101], "taylor": [70, 71, 73], "taylors": [66, 71, 73], "taylorseer_ord": 70, "tbo": [23, 88], "tbo_token_distribution_threshold": [15, 22, 27, 28, 29, 30, 41, 42], "tcp": [13, 17, 24, 81, 82, 83, 103, 104, 107], "tcpsocket": [103, 104], "teacach": [64, 67, 77], "teacache_thresh": 72, "teacacheparam": 72, "teach": 15, "teacher": 101, "team": [19, 25, 32, 56, 64], "tech": 33, "technic": [15, 27, 33, 108], "techniqu": [8, 12, 15, 18, 19, 20, 23, 67, 74, 94, 119], "technologi": [24, 42, 103], "tee": [54, 81, 82, 83, 84], "tele": 125, "teleai": 125, "tell": [4, 38, 42, 43, 45, 54, 109], "temp": 4, "temperatur": [15, 19, 22, 23, 26, 27, 28, 29, 32, 33, 41, 42, 45, 47, 51, 52, 53, 91, 101, 113, 115, 124], "templat": [15, 22, 23, 24, 32, 33, 39, 41, 45, 51, 53, 57, 77, 88, 104, 107, 115, 119, 121, 127], "tempor": [69, 71, 72, 73, 127], "temporal_chunk_s": 69, "temporal_lay": 69, "temporal_topk": 69, "temporari": [17, 57, 61], "temporarili": [24, 97], "tenant": 24, "tencent": [61, 125], "tend": 103, "tensor": [3, 6, 9, 12, 14, 15, 18, 20, 21, 37, 50, 54, 55, 61, 75, 77, 80, 85, 90, 91, 94, 97, 103, 104, 107, 113, 115, 123, 127], "tensormatch": 57, "tensorrt": [8, 23, 53], "tensorview": 57, "term": [12, 23], "termin": [2, 11, 12, 15, 22, 24, 25, 26, 27, 28, 29, 37, 41, 45, 46, 47, 50, 52, 54, 56, 76, 79, 90, 95, 101], "terminate_process": [15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 101], "terminu": 33, "terrain": 15, "terrifi": 15, "test": [1, 2, 4, 5, 15, 20, 22, 23, 26, 27, 28, 29, 37, 38, 41, 42, 45, 46, 47, 50, 52, 54, 57, 58, 60, 63, 64, 65, 68, 78, 82, 84, 85, 90, 93, 101, 103, 105, 121, 127], "test_add_const": 57, "test_classify_api": 118, "test_determinist": 4, "test_eagle_infer_a": [55, 80], "test_eagle_infer_b": [55, 80], "test_eval_accuracy_larg": [55, 80], "test_generation_model": 115, "test_gpt_oss_1gpu": 55, "test_moe_eval_accuracy_larg": 80, "test_oth": 115, "test_vision_openai_server_": 115, "test_vision_openai_server_a": 115, "test_vision_openai_server_b": 115, "testament": 42, "testcas": 65, "testcase_config": 65, "testgenerationmodel": 115, "text": [4, 6, 15, 19, 22, 23, 24, 26, 27, 28, 29, 30, 31, 34, 35, 37, 40, 42, 43, 45, 46, 47, 50, 51, 52, 53, 61, 62, 68, 74, 75, 77, 88, 91, 113, 115, 117, 118, 119, 124, 125, 127], "text_complet": 45, "text_embed": 46, "text_encod": [70, 75], "text_encoder_precis": 61, "text_input": 119, "text_it": 101, "text_qa": 101, "textencodingstag": 75, "textual": [6, 115], "textur": 6, "th": 23, "than": [5, 12, 14, 15, 17, 18, 19, 20, 23, 24, 26, 28, 33, 40, 42, 51, 55, 61, 76, 80, 90, 97, 101, 114, 115, 121], "thank": [26, 42, 55, 80, 93, 103, 105], "thei": [0, 8, 9, 15, 17, 18, 26, 28, 47, 51, 75, 90, 97, 103, 109, 115, 123, 125, 127], "them": [0, 1, 6, 8, 16, 19, 25, 26, 28, 32, 38, 41, 42, 53, 55, 56, 64, 69, 79, 80, 90, 97, 98, 104, 109, 110, 115, 127], "theme": 30, "themselv": 15, "therebi": 12, "therefor": [12, 14, 15, 18, 22, 41, 45, 69], "thi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 64, 65, 69, 70, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 115, 116, 118, 119, 121, 123, 125, 127], "thing": [14, 26, 42, 115, 116], "think": [4, 5, 22, 23, 24, 25, 26, 28, 29, 33, 40, 49, 58, 89, 104, 107, 124, 125, 127], "think_end_token": 28, "thinker": 127, "thinking_budget": [32, 36], "third": [38, 45, 88], "thorough": 28, "thoroughli": 115, "those": [5, 15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 64, 101], "though": [13, 18, 28], "thought": [24, 42], "thousand": 12, "thread": [13, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 52, 61, 77, 97, 101, 110], "thread_finish_flag": 110, "thread_label": 110, "thread_span": 110, "threadidx": 57, "threadpool": [23, 88], "three": [1, 4, 7, 11, 12, 25, 26, 27, 45, 51, 52, 101], "threshold": [5, 12, 16, 23, 24, 33, 66, 69, 70, 71, 72, 73, 88, 97, 124], "threshold_acc": 23, "thrill": 15, "thrive": 42, "throne": 15, "through": [5, 8, 12, 15, 18, 19, 24, 29, 30, 32, 33, 41, 42, 45, 53, 54, 55, 57, 61, 69, 79, 80, 81, 90, 94, 102, 127], "throughout": [24, 75], "throughput": [5, 6, 8, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 37, 41, 45, 46, 47, 50, 52, 53, 55, 58, 65, 77, 78, 80, 98, 101, 108, 109, 115, 121, 125, 127], "thu": [15, 18, 33, 45, 56, 64, 69, 115, 116, 127], "thudm": 125, "thumb": 14, "thunlp": 26, "ti2v": 64, "tier": [7, 11, 12, 24], "tightli": 7, "tii": 125, "tiiuae": 125, "tiktoken": [24, 45], "tile": [23, 61, 88], "tile_sample_min_height": 61, "tile_sample_min_width": 61, "tilelang": [23, 33, 88], "time": [0, 1, 2, 3, 8, 12, 14, 15, 17, 18, 19, 21, 23, 24, 26, 27, 28, 32, 33, 37, 41, 42, 45, 46, 50, 51, 53, 54, 55, 56, 57, 58, 62, 63, 71, 78, 80, 88, 90, 97, 98, 103, 105, 109, 115], "time_per_output_token_second": 109, "time_per_output_token_seconds_bucket": 109, "time_per_output_token_seconds_count": 109, "time_per_output_token_seconds_sum": 109, "time_to_first_token_second": 109, "time_to_first_token_seconds_bucket": 109, "time_to_first_token_seconds_count": 109, "time_to_first_token_seconds_sum": 109, "timelin": 54, "timeout": [11, 12, 13, 17, 18, 23, 24, 32, 33, 37, 39, 50, 63, 82, 83, 86, 88, 97, 107], "timeoutsecond": 107, "timer": 78, "timestamp": [53, 118], "timestep": [26, 71, 72, 73, 74, 75], "timestep_preparation_stag": 75, "timesteppreparationstag": 75, "timezon": [27, 28], "tini": 61, "tinyllama": 19, "tip": [0, 13, 18, 57, 77, 98, 101], "tip_suggest": 101, "tire": 15, "titl": [42, 115], "tl": 26, "tlsv1": 24, "tmp": [16, 23, 24, 54, 60, 63, 94, 97, 110], "tmp_autoround": 19, "tn": 24, "to_stat": 24, "to_str": [32, 36, 51], "todai": [29, 32, 40, 42, 45], "todo": 13, "togeth": [3, 5, 12, 15, 17, 19, 22, 23, 24, 26, 27, 28, 29, 33, 41, 45, 46, 47, 52, 70, 75, 97, 101, 127], "tok": [53, 58], "token": [1, 3, 5, 7, 8, 12, 13, 15, 17, 19, 20, 22, 25, 27, 28, 29, 36, 39, 40, 46, 49, 51, 58, 68, 69, 75, 76, 79, 82, 83, 84, 86, 90, 94, 96, 97, 103, 104, 107, 109, 110, 115, 118, 121, 124, 125, 127], "token_capac": 41, "token_id": [41, 45, 51], "token_ids_logprob": 51, "token_idx": [23, 33], "token_length_norm": 99, "token_step": 25, "token_usag": 109, "tokenization_result": 41, "tokenize_payload": 41, "tokenize_respons": 41, "tokenize_url": 41, "tokenizer_communicator_mixin": 13, "tokenizer_free_server_process": 41, "tokenizer_manag": 29, "tokenizer_metrics_allowed_custom_label": [15, 22, 27, 28, 29, 30, 41, 42], "tokenizer_metrics_custom_labels_head": [15, 22, 27, 28, 29, 30, 41, 42], "tokenizer_mod": [15, 22, 27, 28, 29, 30, 41, 42], "tokenizer_path": [15, 22, 27, 28, 29, 30, 41, 42], "tokenizer_worker_num": [15, 22, 27, 28, 29, 30, 41, 42], "tokenizermanag": [13, 15, 41], "tokenizers_parallel": [27, 28, 46], "tokens_to_gener": 33, "tokens_tot": 24, "tokyo": [15, 26, 29, 45, 101], "tokyo2": 101, "told": 15, "toler": [5, 17, 20, 24, 25, 104, 107], "tolist": 30, "toml": [12, 23, 55, 59, 68, 79, 80, 81, 90, 92, 95], "tongyi": 64, "too": [14, 15, 18, 24, 28, 32, 53, 55, 80, 94], "tool": [9, 22, 23, 25, 27, 28, 32, 33, 36, 40, 54, 73, 76, 77, 88, 101, 110, 125, 127], "tool_cal": [26, 29, 32, 45, 47, 52, 104, 107], "tool_call_id": 29, "tool_call_pars": [15, 22, 27, 28, 29, 30, 41, 42], "tool_calls_tot": 24, "tool_chat_template_deepseekv3": [29, 32], "tool_chat_template_deepseekv31": 29, "tool_chat_template_deepseekv32": 33, "tool_chat_template_llama4_python": 29, "tool_choic": 29, "tool_dict": 29, "tool_duration_second": 24, "tool_get_current_d": [27, 28], "tool_get_current_weath": [27, 28], "tool_iterations_tot": 24, "tool_nam": 29, "tool_serv": [15, 22, 27, 28, 29, 30, 41, 42], "tool_to_cal": 29, "tool_ttl": 24, "tool_us": [23, 101], "toolcallitem": 29, "toolchain": 24, "toolkit": [81, 82, 83, 84, 93], "tools_tag_list": 29, "top": [12, 26, 29, 33, 42, 51, 55, 69, 80, 108, 125], "top_k": [15, 41, 45, 51, 115], "top_logprobs_num": 51, "top_p": [15, 19, 22, 23, 27, 28, 29, 33, 41, 42, 45, 51, 53, 91, 113], "topic": 42, "topk": [1, 8, 23, 26, 32, 33, 36, 39, 49, 82, 83, 86, 88, 94, 97], "topkoutput": 8, "topo": 107, "topologi": [24, 107], "torch": [1, 8, 14, 15, 17, 23, 25, 32, 41, 46, 54, 57, 76, 81, 88, 90, 95, 97, 103, 115, 116], "torch_compile_caching_tutori": 111, "torch_compile_max_b": [15, 22, 27, 28, 29, 30, 41, 42], "torch_dtyp": [19, 30], "torch_empty_cach": 25, "torch_log": 26, "torch_memory_sav": 25, "torch_n": [1, 23, 41, 119, 121], "torch_npu": 81, "torch_npu_vers": 81, "torch_sdpa": [61, 69], "torchao": [23, 88, 95], "torchao_config": [15, 22, 27, 28, 29, 30, 41, 42], "torchaudio": [76, 90, 95], "torchinductor_cache_dir": [23, 111], "torchinductor_root": 23, "torchrun": 2, "torchvis": [76, 81, 90, 95], "torchvision_vers": 81, "total": [12, 14, 15, 17, 18, 22, 23, 24, 25, 33, 40, 45, 53, 54, 78, 82, 88, 90, 118, 121, 125], "total_input_token": 53, "total_kv_token": 33, "total_output_token": 53, "total_q_token": 33, "total_request": [5, 23, 88], "total_retract": [27, 28, 41, 52], "total_seq_len": 8, "total_token": [5, 23, 24, 26, 29, 32, 45, 46, 47, 52, 88, 104, 107, 118], "toulous": 28, "tourism": 26, "tourist": [28, 29, 42], "toward": [18, 38, 51, 123, 127], "tower": [26, 28, 41, 42], "tp": [1, 5, 6, 8, 11, 12, 17, 18, 23, 24, 25, 29, 32, 33, 36, 37, 38, 39, 40, 45, 49, 50, 54, 56, 58, 61, 70, 79, 81, 82, 83, 84, 86, 88, 90, 91, 94, 95, 103, 104, 105, 107, 113, 123], "tp0": 103, "tp1": 103, "tp16": 105, "tp2": 103, "tp3": 103, "tp4": 103, "tp5": 103, "tp6": [90, 103], "tp7": 103, "tp8": [32, 78], "tp_rank": 110, "tp_size": [5, 8, 12, 15, 22, 27, 28, 29, 30, 33, 41, 42, 61, 82, 91, 105, 113], "tpot": [53, 82], "tpot_second": 24, "tpu": [76, 77], "tpu_vm": 94, "tpuv6": 94, "tqdm": 53, "tr": 54, "trace": [16, 23, 26, 53, 77, 88, 97, 103], "trace_context": 110, "trace_get_proc_propagate_context": 110, "trace_get_remote_propagate_context": 110, "trace_req_finish": 110, "trace_req_start": 110, "trace_set_proc_propagate_context": 110, "trace_set_remote_propagate_context": 110, "trace_set_thread_info": 110, "trace_slice_end": 110, "trace_slice_start": 110, "tracing_compos": 110, "track": [12, 23, 24, 25, 33, 39, 41, 54, 71, 73, 88, 110, 118], "trade": [8, 24, 25, 38, 49, 119], "tradeoff": 23, "tradit": [11, 18, 42], "tradition": 17, "traffic": [13, 24, 25, 58, 94, 109], "trail": 28, "train": [4, 19, 23, 25, 26, 29, 33, 41, 54, 77, 84, 101, 119, 125, 127], "trainer": 25, "trait": 3, "trajectori": 38, "transfer": [2, 7, 8, 11, 15, 17, 18, 21, 23, 56, 81, 82, 83, 88, 97, 110], "transfer_engin": [21, 23, 88], "transferengin": 12, "transform": [3, 6, 15, 18, 19, 22, 23, 26, 27, 28, 29, 30, 38, 41, 42, 45, 46, 47, 52, 53, 61, 62, 66, 69, 70, 71, 75, 77, 84, 88, 96, 101, 112, 115, 117, 125, 127], "transformer_2": 62, "transformersmodel": 116, "transit": [24, 45, 46, 47], "transitions_tot": 24, "transmiss": 8, "transmit": 8, "transpar": 28, "transport": [37, 42, 50], "travel": 29, "travers": 12, "treacher": 15, "treat": [41, 97], "tree": [5, 15, 23, 24, 26, 30, 41, 94], "tree_cach": 13, "trend": [42, 78, 115], "trial": 4, "tricki": 28, "trigger": [12, 23, 27, 28, 41, 54, 90, 97], "triggered_tag": 27, "trillion": [18, 125], "trim": [29, 51], "triniti": [89, 125], "trip": 29, "triton": [1, 4, 8, 15, 23, 32, 39, 41, 76, 88, 90, 95, 97, 119, 121, 127], "triton_3_5_1": 41, "triton_attention_num_kv_split": [15, 22, 27, 28, 29, 30, 41, 42], "triton_attention_reduce_in_fp32": [15, 22, 27, 28, 29, 30, 41, 42], "triton_attention_split_tile_s": [15, 22, 27, 28, 29, 30, 41, 42], "triton_attn": 23, "triton_backend": 1, "triton_kernel": [8, 23], "triton_mm_10": 26, "triton_mm_102": 26, "triton_mm_103": 26, "triton_mm_106": 26, "triton_mm_107": 26, "triton_mm_11": 26, "triton_mm_111": 26, "triton_mm_113": 26, "triton_mm_114": 26, "triton_mm_115": 26, "triton_mm_116": 26, "triton_mm_119": 26, "triton_mm_12": 26, "triton_mm_120": 26, "triton_mm_123": 26, "triton_mm_124": 26, "triton_mm_128": 26, "triton_mm_130": 26, "triton_mm_133": 26, "triton_mm_136": 26, "triton_mm_137": 26, "triton_mm_139": 26, "triton_mm_14": 26, "triton_mm_140": 26, "triton_mm_141": 26, "triton_mm_142": 26, "triton_mm_145": 26, "triton_mm_147": 26, "triton_mm_148": 26, "triton_mm_149": 26, "triton_mm_150": 26, "triton_mm_153": 26, "triton_mm_154": 26, "triton_mm_157": 26, "triton_mm_158": 26, "triton_mm_162": 26, "triton_mm_167": 26, "triton_mm_17": 26, "triton_mm_170": 26, "triton_mm_171": 26, "triton_mm_172": 26, "triton_mm_173": 26, "triton_mm_174": 26, "triton_mm_175": 26, "triton_mm_176": 26, "triton_mm_179": 26, "triton_mm_18": 26, "triton_mm_20": 26, "triton_mm_22": 26, "triton_mm_23": 26, "triton_mm_26": 26, "triton_mm_27": 26, "triton_mm_30": 26, "triton_mm_31": 26, "triton_mm_36": 26, "triton_mm_37": 26, "triton_mm_4": 26, "triton_mm_45": 26, "triton_mm_46": 26, "triton_mm_47": 26, "triton_mm_48": 26, "triton_mm_49": 26, "triton_mm_50": 26, "triton_mm_54": 26, "triton_mm_55": 26, "triton_mm_56": 26, "triton_mm_58": 26, "triton_mm_60": 26, "triton_mm_61": 26, "triton_mm_64": 26, "triton_mm_65": 26, "triton_mm_68": 26, "triton_mm_69": 26, "triton_mm_7": 26, "triton_mm_74": 26, "triton_mm_75": 26, "triton_mm_8": 26, "triton_mm_83": 26, "triton_mm_84": 26, "triton_mm_85": 26, "triton_mm_87": 26, "triton_mm_88": 26, "triton_mm_89": 26, "triton_mm_92": 26, "triton_mm_93": 26, "triton_mm_94": 26, "triton_mm_96": 26, "triton_mm_97": 26, "triton_mm_98": 26, "triton_mm_99": 26, "triton_ptxas_path": 76, "tritonattn": 3, "tritonattnbackend": 127, "tritonrunnercor": 8, "trivial": [15, 22, 23, 25, 27, 28, 29, 30, 41, 42, 88], "troubleshoot": [5, 77, 103], "trt": [8, 33, 53], "trtllm": [1, 23, 32], "trtllm_mha": [1, 23, 39], "trtllm_mla": [1, 23], "true": [1, 13, 14, 15, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 60, 61, 62, 67, 69, 70, 71, 73, 74, 82, 83, 84, 86, 94, 97, 101, 103, 104, 107, 109, 110, 114, 115, 116, 119, 121, 124], "truncat": [23, 26, 54, 88, 119], "trunk": 101, "truss": 53, "trust": [1, 15, 17, 18, 23, 24, 26, 31, 32, 33, 37, 39, 40, 50, 55, 56, 61, 79, 80, 81, 82, 83, 84, 86, 88, 90, 94, 95, 103, 104, 107, 108, 119, 121, 123, 127], "trust_remote_cod": [15, 19, 22, 27, 28, 29, 30, 41, 42, 116, 124], "trustworthi": 28, "truth": 25, "try": [9, 12, 19, 23, 28, 32, 41, 42, 55, 76, 78, 80, 81, 98, 103], "tse": 23, "tsinghua": 84, "ttft": [6, 15, 17, 18, 33, 37, 53, 58, 78, 94, 115], "ttft_m": 78, "ttft_second": 24, "tune": [8, 12, 15, 23, 26, 29, 33, 37, 50, 70, 72, 73, 77, 79, 95, 104, 108, 111, 123, 125], "tuned_8sm": 104, "tunix": [77, 108], "tunnel": [43, 56], "tupl": 9, "turbo": [45, 64, 70], "turbowan2": 64, "turn": [9, 11, 24, 25, 26, 32, 82], "tutori": [27, 30, 45, 46, 47, 111], "tvm": 57, "tvm_ffi": 57, "twice": [12, 98], "twine": 59, "twitter": 102, "two": [1, 2, 5, 6, 9, 11, 12, 14, 15, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 41, 42, 47, 49, 51, 56, 71, 72, 73, 75, 76, 84, 88, 96, 97, 98, 101, 103, 104, 105, 110, 115, 116, 121], "twoshot": 97, "txt": 0, "type": [4, 5, 8, 9, 13, 15, 20, 24, 25, 27, 28, 29, 31, 32, 37, 38, 40, 41, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 69, 72, 73, 78, 80, 83, 94, 97, 104, 107, 109, 115, 118, 121, 124, 127], "type_check": 57, "typic": [3, 5, 6, 7, 14, 15, 18, 20, 22, 23, 25, 26, 27, 28, 29, 32, 39, 41, 45, 46, 47, 52, 53, 55, 57, 61, 62, 70, 72, 75, 76, 80, 81, 90, 94, 101, 103], "typo": 28, "u": [3, 15, 29, 38, 66, 94, 99, 104, 108, 115], "ubuntu": [54, 57, 81, 90, 103], "ubuntu1804": 54, "ubuntu22": [60, 81], "ucx": 17, "ud": 2, "ui": [52, 54, 74, 78, 109, 110], "ultra": [12, 66, 70, 125], "ulyss": [61, 62], "ulysses_degre": 61, "ulysses_s": 70, "ulyssesattent": 69, "unabl": 115, "unavail": [23, 61], "uncach": 4, "unchang": 51, "unconditional_likelihood_norm": 99, "unconfin": 79, "undaunt": 15, "undeni": 42, "under": [0, 5, 7, 9, 12, 15, 23, 25, 29, 54, 55, 62, 80, 94, 95, 97, 98, 109, 115, 125], "underli": [3, 18], "understand": [0, 5, 12, 15, 31, 41, 42, 55, 80, 94, 110, 125, 127], "understood": 6, "underutil": 18, "unesco": 42, "unet": 75, "unexpect": 15, "unhealthi": 5, "unicod": 24, "unifi": [7, 8, 15, 24, 32, 45, 67, 84, 108], "uniform": [18, 23, 24, 74], "uniformli": 33, "unintend": 51, "union": [15, 23, 51], "uniqu": [4, 42, 62, 84, 118], "unit": [15, 24, 27, 28, 29, 42, 45, 52, 101], "unittest": [55, 80, 115], "univers": 84, "unix": [2, 118], "unknown": [45, 97], "unless": [1, 26, 28, 53], "unlik": [20, 25, 26, 57, 124], "unload": 15, "unload_lora_adapt": 15, "unlock": [8, 24], "unmerg": 62, "unmerge_lora_weight": 62, "unnecessari": 42, "unpermut": 8, "unpin": 15, "unquant": [82, 88], "unrel": 12, "unrestrict": 51, "unset": [23, 82, 83, 84], "unsloth": 108, "unspecifi": [1, 23, 53], "unstabl": 3, "unsuccess": 25, "unsupport": 26, "unsur": [125, 127], "until": [14, 15, 18, 32, 51, 54, 78, 94, 105], "untrust": 24, "unus": 107, "unusu": [30, 47, 101], "unwant": 5, "unwrap": 57, "up": [0, 5, 8, 12, 14, 15, 17, 18, 21, 23, 26, 28, 30, 32, 38, 39, 40, 41, 42, 47, 54, 55, 70, 71, 73, 75, 76, 78, 79, 80, 90, 93, 95, 103, 108, 109, 110, 125], "up_proj": [15, 23], "upcast": [19, 32], "upcom": [33, 38], "updat": [2, 3, 11, 13, 15, 18, 19, 23, 24, 29, 40, 54, 60, 63, 65, 78, 84, 97, 98, 102, 109, 115], "update_weight": 41, "update_weights_from_disk": [25, 41], "update_weights_from_distribut": 25, "update_weights_from_tensor": 25, "upgrad": [33, 60, 68, 76, 79, 90, 92, 95, 121], "upload": [24, 61, 62, 66, 84], "upload_pypi": 59, "upon": [12, 15, 41, 45, 46, 61, 75, 91, 109, 110, 113, 127], "upper": 12, "upsid": 38, "upstag": [89, 125], "upstream": [13, 24, 69], "upstream_responses_tot": 24, "upward": 38, "urban": [47, 101], "urgent": [55, 80], "url": [5, 7, 15, 16, 23, 24, 26, 30, 31, 37, 38, 41, 47, 50, 51, 52, 53, 54, 61, 62, 66, 76, 81, 88, 90, 94, 95, 109, 110, 119, 121, 127], "us": [0, 1, 2, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 40, 41, 42, 49, 50, 51, 53, 55, 60, 62, 64, 67, 70, 72, 73, 74, 75, 77, 78, 80, 91, 92, 96, 99, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 121, 123, 124, 125, 127], "us_president_exampl": 99, "usabl": [19, 93, 125], "usag": [3, 5, 11, 23, 25, 26, 29, 30, 36, 41, 43, 46, 47, 51, 52, 55, 57, 61, 65, 74, 80, 88, 93, 94, 98, 99, 103, 104, 107, 121], "use_fast": 30, "use_fast_accum": 26, "use_mla_backend": 41, "user": [4, 8, 12, 14, 15, 18, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 40, 41, 43, 45, 47, 50, 51, 52, 54, 55, 58, 61, 75, 80, 91, 96, 99, 101, 104, 107, 108, 113, 118, 119, 121, 127], "usernam": [76, 109], "userwarn": 26, "usp": 61, "uspattent": 69, "usr": [15, 22, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 76, 81, 82, 83, 84, 90, 101], "usual": [0, 18, 45, 76, 90, 109, 121], "utf": [51, 52], "util": [6, 7, 8, 12, 14, 15, 18, 22, 23, 25, 26, 27, 28, 29, 30, 41, 42, 45, 46, 47, 51, 52, 74, 79, 88, 90, 94, 101, 103, 108, 119], "uuid": 24, "uv": [17, 38, 67, 90, 94], "uv_config_fil": 90, "uvicorn": [15, 23, 41, 103], "uvicorn_access_log_exclude_prefix": [15, 22, 27, 28, 29, 30, 41, 42], "v": [4, 5, 8, 15, 19, 24, 25, 41, 56, 57, 60, 61, 62, 68, 69, 70, 76, 79, 84, 89, 90, 95, 114, 115, 118, 125, 127], "v0": [5, 29, 33, 39, 41, 60, 68, 76, 79, 81, 89, 103, 123, 125], "v01": [89, 125], "v1": [15, 19, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 45, 46, 47, 50, 51, 52, 53, 62, 64, 89, 103, 104, 107, 110, 118, 119, 121, 125, 127], "v1_5": 125, "v1alpha1": 107, "v2": [5, 8, 23, 41, 53, 61, 89, 94, 121, 125, 127], "v3": [1, 5, 8, 17, 19, 22, 23, 29, 48, 56, 58, 78, 84, 89, 91, 107, 113, 125, 127], "v32": [33, 107], "v6e": 94, "v7": 94, "v_cach": 57, "v_proj": [15, 23], "v_scale": 20, "vae": [61, 70, 74, 75], "vae_config": 61, "vae_path": 61, "vae_precis": [61, 62], "vae_sp": 61, "vae_til": 61, "valid": [0, 2, 4, 19, 23, 27, 28, 29, 33, 51, 54, 55, 57, 62, 64, 69, 70, 75, 79, 80, 94, 97, 119, 121], "valu": [3, 7, 8, 11, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 39, 45, 50, 51, 54, 55, 57, 61, 62, 69, 70, 74, 76, 80, 83, 88, 90, 97, 98, 103, 104, 107, 121, 124, 127], "valuabl": 115, "value1": [23, 29], "value2": [23, 29], "value_st": 116, "valueerror": [9, 41], "valuefrom": [104, 107], "vanilla": [5, 61], "var": [81, 84, 107], "vari": [3, 4, 8, 20, 25, 28, 53, 73, 124], "variabl": [3, 8, 11, 15, 17, 18, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 38, 41, 42, 45, 46, 47, 52, 53, 54, 57, 60, 61, 66, 67, 76, 77, 78, 90, 91, 94, 101, 103, 109, 110, 113, 114, 115], "varianc": [8, 25, 55, 80], "variant": [3, 8, 22, 26, 54, 76, 78, 89, 123, 125, 127], "variat": [18, 75], "varieti": [1, 42, 101, 117], "variou": [1, 12, 17, 19, 41, 45, 47, 75, 89, 97], "varlen": 33, "vast": [45, 125], "vc_task_index": 82, "ve": [28, 103], "vector": [26, 32, 55, 80, 119], "veget": 101, "vehicl": [30, 42], "veil": 15, "vendetta": 15, "vendor": [24, 82], "venv": [90, 94], "verb": 24, "verbos": [16, 23], "veri": [3, 6, 14, 15, 18, 28, 33, 37, 47, 50, 51, 55, 80, 98, 115], "verif": [1, 23, 26, 32, 33, 36, 38, 57, 58, 97], "verifi": [1, 2, 4, 15, 20, 23, 24, 26, 28, 33, 41, 53, 57, 58, 77, 78, 79, 90, 93, 94, 95, 97, 109, 118], "verl": [25, 77, 108], "versatil": [42, 125, 127], "version": [2, 8, 23, 24, 25, 32, 41, 42, 49, 55, 56, 76, 80, 84, 88, 90, 91, 94, 95, 97, 101, 103, 113, 121, 127], "versu": 25, "vertic": 24, "via": [0, 5, 7, 8, 9, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24, 25, 33, 38, 41, 51, 53, 54, 55, 61, 67, 70, 72, 75, 80, 88, 90, 94, 95, 109, 110, 124, 125, 127], "vibrant": [26, 42, 77], "victor": 15, "vicuna": 127, "video": [3, 23, 58, 60, 61, 66, 67, 69, 75, 79, 102, 121], "video_data": 127, "video_id": 62, "video_pruning_r": 127, "video_sparse_attn": 69, "video_url": [37, 50, 121, 127], "videomm": 58, "view": [0, 29, 30, 78, 103, 109, 110], "vigor": 101, "vim": 90, "vine": 15, "virtual": [15, 22, 25, 26, 27, 28, 29, 30, 33, 41, 42, 45, 46, 47, 52, 90, 101], "virtualenv": 24, "visibl": [54, 97, 101], "vision": [3, 6, 7, 44, 45, 50, 51, 52, 53, 89, 115, 116, 125, 127], "vision_end": 30, "vision_flat": 30, "vision_model": 30, "vision_process": 47, "vision_start": 30, "visionattent": 115, "visit": [19, 42, 48, 78, 94], "visitor": 42, "visual": [3, 6, 30, 51, 54, 56, 74, 78, 110, 127], "visualstudio": 56, "vit": [3, 6, 7, 37, 89, 115, 119, 127], "vital": [8, 42], "vitamin": 101, "vitcudagraphrunn": 3, "vl": [3, 6, 19, 29, 47, 48, 53, 54, 81, 89, 101, 119, 127], "vl2": [89, 127], "vllm": [19, 53, 54, 89, 118], "vlm": [6, 7, 19, 23, 25, 42, 53, 77, 108, 115, 127], "vlm1": 127, "vm": [79, 81, 82, 83, 84, 94], "vmoba": 69, "vmoba_attn": 69, "vocab": [23, 26], "vocabulari": [23, 26], "voic": 15, "void": 57, "volum": [56, 81, 103, 104, 107], "volumemount": [103, 104, 107], "vram": [3, 19], "vsa": [64, 69], "vscode_cli_alpine_x64_cli": 56, "vuitton": 42, "vx": 76, "w": [26, 27, 28, 45, 51, 69, 70, 81, 82, 83, 84, 101], "w2a16": 19, "w3a16": 19, "w3c": 24, "w4a16": [19, 85], "w4a4": 85, "w4a8": [32, 82, 83, 84, 85], "w4a8_awq": 23, "w4afp8": 23, "w8a16": [19, 85], "w8a8": [32, 82, 83, 85, 89, 90], "w8a8_fp8": [19, 23], "w8a8_int8": [19, 23, 90], "w8a8fp8config": 19, "wa": [5, 15, 18, 26, 29, 38, 45, 54, 101, 103, 118], "wai": [0, 2, 3, 5, 15, 18, 28, 29, 30, 42, 54, 57, 61, 81, 95, 101, 115], "wait": [2, 11, 12, 13, 15, 18, 23, 24, 25, 26, 28, 41, 45, 46, 47, 54, 55, 74, 80, 88, 97, 101, 103, 104, 105, 109], "wait_complet": [11, 12, 23, 88], "wait_for_serv": [15, 22, 26, 27, 28, 29, 41, 45, 46, 47, 52, 101], "waiting_queu": [13, 25], "wake": 108, "walk": [15, 55, 57, 61, 80, 101], "walkthrough": 115, "wall": [53, 124], "wallet": 24, "wan": [34, 61, 62, 64, 67, 70, 71, 72, 73, 77], "wan2": [61, 62, 64, 70, 71, 72, 73], "wan_pipelin": 62, "wand": 101, "wanpipelin": 62, "want": [5, 9, 15, 16, 19, 23, 26, 28, 29, 41, 42, 45, 51, 54, 55, 61, 62, 76, 80, 81, 88, 90, 103, 110, 111, 115, 127], "war": [15, 41], "warmup": [15, 22, 23, 27, 28, 29, 30, 41, 42, 53, 54, 66, 70, 74, 88, 90, 94, 97], "warmup_interv": 70, "warmup_name1": 23, "warmup_name2": 23, "warn": [9, 14, 15, 20, 22, 23, 24, 26, 27, 28, 29, 30, 41, 45, 46, 47, 52, 53, 88, 101], "warn_onc": 26, "warrior": 15, "washington": [15, 45, 52], "wasip2": 24, "wasm32": 24, "watch": [23, 24], "watchdog": [15, 18, 23, 33, 41, 82, 83, 86, 88], "watchdog_timeout": [15, 22, 27, 28, 29, 30, 41, 42], "water": 15, "waterfal": 15, "watermark": 23, "watsonx": 125, "wave": [1, 23], "wb": 62, "wcde": 64, "we": [0, 3, 5, 7, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 30, 32, 33, 36, 37, 38, 39, 41, 42, 45, 46, 47, 52, 54, 55, 56, 57, 58, 64, 65, 76, 79, 80, 81, 82, 84, 90, 94, 98, 101, 103, 104, 108, 110, 114, 115, 116], "weather": [27, 28, 29, 32, 45, 121], "web": [76, 78, 109, 110, 121], "web_search_preview": 38, "webassembli": 24, "websit": [0, 28, 91, 113], "week": [29, 55, 80, 101], "weekli": 102, "weight": [2, 5, 8, 14, 15, 19, 21, 26, 53, 54, 56, 60, 62, 83, 85, 86, 93, 97, 101, 115, 125], "weight_load_func": 23, "weight_loader_disable_mmap": [15, 22, 27, 28, 29, 30, 41, 42], "weight_update_group": 25, "weight_vers": [15, 22, 25, 26, 27, 28, 29, 30, 41, 42, 45, 47, 52], "weilin": 26, "welcom": [11, 55, 80, 84, 89, 94, 96, 127], "well": [12, 18, 25, 26, 28, 38, 42, 62, 70, 77, 101, 115, 125], "went": 15, "were": [15, 42, 45], "wet": 30, "wget": 56, "what": [9, 15, 19, 22, 25, 26, 27, 28, 29, 30, 32, 37, 38, 41, 42, 43, 45, 47, 50, 52, 69, 99, 101, 108, 115, 116, 119, 121, 127], "wheel": [55, 76, 80], "when": [0, 1, 2, 3, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 39, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 61, 62, 64, 69, 70, 71, 72, 73, 76, 79, 80, 83, 85, 88, 90, 96, 97, 98, 101, 109, 110, 115, 118, 121, 127], "whenev": [24, 54, 55, 80], "where": [4, 5, 8, 12, 15, 17, 18, 20, 23, 25, 27, 28, 29, 30, 32, 33, 37, 42, 45, 50, 51, 54, 75, 99, 115, 121], "wherea": 12, "wherein": 8, "wherev": 15, "whether": [1, 12, 23, 25, 28, 41, 51, 54, 55, 58, 61, 74, 80, 97, 110, 121], "which": [0, 3, 4, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 32, 33, 42, 45, 47, 49, 51, 52, 53, 54, 55, 57, 61, 62, 65, 70, 74, 76, 80, 81, 84, 90, 94, 95, 96, 97, 98, 103, 110, 115, 116, 118, 125], "while": [3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 40, 41, 45, 46, 47, 52, 54, 60, 61, 62, 97, 98, 101, 105, 125, 127], "whisper": 15, "white": 30, "whitespac": [23, 88], "whl": [24, 76, 81, 90, 95], "who": [15, 21, 40, 45, 94], "whole": [24, 33, 101], "whose": [15, 23, 51], "why": [15, 19, 28], "wide": [12, 23, 32, 42, 77, 117], "widespread": 77, "width": [19, 20, 61, 75], "wield": 15, "wild": 119, "willing": [15, 42], "willow": 101, "window": [1, 3, 18, 23, 24, 26, 55, 80, 88, 94, 125], "wise": [8, 61], "wish": 110, "with_devic": 57, "with_dtyp": 57, "with_stack": [54, 97], "with_strid": 57, "with_xxx": 57, "within": [5, 7, 8, 12, 15, 17, 19, 20, 23, 24, 26, 28, 30, 33, 45, 55, 56, 75, 76, 80, 84, 95, 101, 103, 109, 110], "without": [1, 5, 8, 12, 13, 20, 23, 24, 25, 26, 33, 41, 42, 45, 54, 55, 61, 62, 65, 78, 80, 84, 85, 94, 97, 115, 121], "woman": [42, 61, 121], "won": [1, 15, 18, 40, 115], "wonder": [15, 28], "wood": 101, "word": [0, 42, 45, 51, 101], "work": [1, 11, 18, 19, 24, 25, 28, 29, 42, 51, 55, 60, 61, 64, 70, 77, 80, 81, 96, 97, 103, 104, 107, 108, 116, 118, 121], "workaround": [17, 54], "worker": [2, 5, 17, 23, 25, 26, 32, 33, 42, 82, 83, 88, 94, 97, 103, 104, 107], "worker1": [5, 24], "worker2": [5, 24], "worker_id": 24, "worker_typ": 24, "workers_discov": 24, "workertempl": [103, 104], "workflow": [24, 26, 41, 53, 55, 61, 80, 108, 125], "workload": [5, 7, 12, 14, 15, 18, 20, 23, 24, 25, 26, 32, 37, 49, 50, 53, 54, 74, 79, 94, 103, 107, 125], "workspac": [56, 74, 104, 107], "world": [15, 23, 24, 25, 28, 40, 41, 42, 45, 52, 77, 125], "world_siz": [25, 70], "worldwid": 77, "worst": 15, "would": [15, 26, 27, 28, 29, 41, 42, 54, 90, 110], "wouldn": 15, "wrap": [0, 26, 28, 53], "wrapper": [1, 23, 24, 26, 57], "write": [0, 1, 11, 15, 23, 28, 42, 45, 51, 62, 63, 88, 115, 124], "write_back": [12, 23, 88], "write_through": [11, 12, 15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "write_through_select": [12, 23, 88], "written": [12, 33, 104], "wrong": 41, "www": 102, "x": [5, 13, 15, 22, 23, 24, 27, 28, 29, 30, 41, 42, 54, 57, 62, 70, 76, 77, 85, 88, 90, 97, 102, 103, 104, 107, 115, 119, 121, 124, 125], "x1": [104, 107], "x64": 60, "x86_64": [24, 54, 76, 90], "x_": 105, "xai": [24, 125], "xdit": 67, "xeon": [32, 76, 77, 90], "xf": 56, "xformer": [61, 69, 73], "xgrammar": [15, 22, 23, 27, 28, 29, 30, 41, 42, 51, 88, 95, 105], "xiaomi": [26, 125, 127], "xiaomimimo": [26, 89, 125, 127], "xlab": 64, "xml": 24, "xpu": [1, 23, 39, 76, 77], "xvers": [89, 125], "xx": 17, "xxx": [11, 17, 60, 82, 83], "xxxx": 17, "xxxxx": 54, "xxxxxx": 29, "y": [0, 24, 33, 45, 54, 60, 76, 95], "yaml": [12, 23, 24, 61, 69, 70, 76, 94, 103, 104, 109, 110, 124], "ye": [4, 5, 26, 41, 45, 72, 97, 104, 107], "yeah": [26, 45], "year": [15, 28, 38, 42], "yearli": 28, "yellow": [47, 101], "yet": [15, 53, 70, 84, 103, 127], "yield": [8, 12, 18], "yieldoper": 8, "yml": [55, 76, 80, 107], "york": [27, 28, 29], "you": [0, 1, 3, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 65, 68, 69, 70, 74, 75, 76, 78, 79, 80, 81, 82, 84, 88, 89, 90, 92, 93, 94, 95, 96, 98, 101, 103, 104, 105, 107, 108, 109, 111, 114, 115, 116, 118, 119, 121, 125, 127], "young": 15, "your": [0, 1, 4, 5, 11, 13, 14, 15, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 39, 40, 42, 45, 46, 47, 52, 53, 54, 55, 56, 58, 61, 65, 68, 69, 73, 75, 76, 79, 80, 82, 83, 84, 89, 90, 91, 94, 95, 98, 101, 103, 104, 105, 107, 108, 109, 110, 113, 115, 117, 127], "your_aws_account": 76, "your_aws_region": 76, "your_exa_kei": 38, "your_imag": 31, "your_image_tag": 76, "your_model_path": 109, "your_module_path": 11, "your_repository_nam": 76, "your_token_her": 78, "your_user_nam": [55, 80], "yourhicacheclassnam": 11, "yourkei": 53, "yourself": 42, "yuanxiang": 125, "yum": 103, "z": [64, 67, 70, 71, 72, 73, 76, 105], "zai": [29, 36, 37, 64, 127], "zealand": 45, "zero": [11, 12, 19, 21, 25, 29, 77, 97, 108], "zhao": 26, "zhipu": [84, 125], "zhipuai": [89, 125], "zhousx": 26, "zip": [27, 28, 41, 42, 91, 113, 115], "zmq": 110, "zmq_to_schedul": [7, 15, 22, 23, 27, 28, 29, 30, 41, 42, 88], "zmq_to_token": [7, 23, 88], "zoom": 78, "zsh": [56, 68], "\u00e9lys\u00e9": 26, "\u0432\u0435\u0440ich": 41, "\u4e0d\u8fc7\u8981\u63a7\u5236\u8868\u60c5\u7b26\u53f7\u6570\u91cf": [104, 107], "\u4e5f\u53ef\u80fd\u662f\u60f3\u786e\u8ba4\u6211\u7684\u8eab\u4efd\u548c\u529f\u80fd\u8303\u56f4": [104, 107], "\u4f60\u53ef\u4ee5\u628a\u6211\u5f53\u6210\u4e00\u4e2a\u77e5\u8bc6\u4e30\u5bcc": [104, 107], "\u4f60\u662f\u8c01": [104, 107], "\u521a\u597d\u80fd\u4e2d\u548cai\u7684\u673a\u68b0\u611f": [104, 107], "\u529f\u80fd\u5b9a\u4f4d": [104, 107], "\u53c8\u80fd\u907f\u514d\u8ba9\u7528\u6237\u9762\u5bf9\u7a7a\u767d\u8f93\u5165\u6846\u65f6\u4e0d\u77e5\u6240\u63aa": [104, 107], "\u540c\u65f6\u7a81\u51fa\u5b9e\u7528\u4ef7\u503c\u6765\u964d\u4f4e\u964c\u751f\u611f": [104, 107], "\u540d\u5b57\u53eb": [104, 107], "\u5b66\u4e60": [104, 107], "\u5de5\u4f5c": [104, 107], "\u5e94\u8be5\u7528\u7b80\u4f53\u4e2d\u6587\u56de\u590d": [104, 107], "\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b": [104, 107], "\u5fb7\u56fd\u7684\u9996\u90fd\u662f\u67cf\u6797": 121, "\u6211\u662f\u4f60\u7684ai\u52a9\u624b": [104, 107], "\u65e2\u80fd\u4e86\u89e3\u9700\u6c42": [104, 107], "\u670d\u52a1\u8303\u56f4": [104, 107], "\u6cd5\u56fd\u7684\u9996\u90fd\u662f\u5df4\u9ece": 121, "\u6cd5\u56fd\u9996\u90fd\u662f\u54ea\u91cc": 121, "\u6df1\u5ea6\u6c42\u7d22": [104, 107], "\u751f\u6d3b": [104, 107], "\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u5f88\u57fa\u7840\u7684\u81ea\u6211\u4ecb\u7ecd\u95ee\u9898": [104, 107], "\u7531\u6df1\u5ea6\u6c42\u7d22\u516c\u53f8": [104, 107], "\u7ed3\u5c3e\u7528\u5f00\u653e\u6027\u95ee\u9898\u5f15\u5bfc\u5bf9\u8bdd\u5f88\u5173\u952e": [104, 107], "\u89e3\u7b54\u95ee\u9898": [104, 107], "\u8bed\u6c14\u7b80\u6d01\u4e2d\u6027": [104, 107], "\u8eab\u4efd\u5f52\u5c5e": [104, 107], "\u8fd9\u53ef\u80fd\u662f\u7b2c\u4e00\u6b21\u4e92\u52a8\u65f6\u7684\u5e38\u89c4\u5f00\u573a\u767d": [104, 107], "\u8fd9\u79cd\u573a\u666f\u4e0b\u65b0\u7528\u6237\u7684\u53ef\u80fd\u6027\u8f83\u9ad8": [104, 107], "\u907f\u514d\u663e\u5f97\u8f7b\u6d6e": [104, 107], "\u90a3\u4e2a\u7b11\u8138\u8868\u60c5": [104, 107], "\u91cd\u70b9\u8981\u8bf4\u660e\u4e09\u70b9": [104, 107], "\u968f\u53eb\u968f\u5230\u7684\u5c0f\u5e2e\u624b": [104, 107], "\u9700\u8981\u7ed9\u51fa\u6e05\u6670\u53cb\u597d\u7684\u81ea\u6211\u4ecb\u7ecd": [104, 107], "\u9999\u8549\u662f\u9ec4\u8272\u7684\u6c34\u679c": 121}, "titles": ["SGLang Documentation", "Attention Backend", "Checkpoint Engine Integration", "Cuda Graph for Multi-Modal Encoder in SGLang", "Deterministic Inference", "DP, DPA and SGLang DP Router", "DP for Multi-Modal Encoder in SGLang", "EPD Disaggregation", "Expert Parallelism", "Model Hooks", "Hierarchical KV Caching (HiCache)", "SGLang HiCache Best Practices", "HiCache System Design and Optimization", "Runtime Attach/Detach HiCache Storage Backend (No Restart)", "Hyperparameter Tuning", "LoRA Serving", "Observability", "PD Disaggregation", "Pipeline Parallelism for Long Context", "Quantization", "Quantized KV Cache", "R-Fork", "Reasoning Parser", "Server Arguments", "SGLang Model Gateway", "SGLang for RL Systems", "Speculative Decoding", "Structured Outputs", "Structured Outputs For Reasoning Models", "Tool Parser", "Query VLM with Offline Engine", "DeepSeek OCR (OCR-1 / OCR-2)", "DeepSeek V3/V3.1/R1 Usage", "DeepSeek V3.2 Usage", "Diffusion", "Diffusion Language Models (dLLMs)", "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang", "GLM-4.6V / GLM-4.5V Usage", "GPT OSS Usage", "Llama4 Usage", "MiniMax M2.1/M2 Usage", "SGLang Native APIs", "Offline Engine API", "Ollama-Compatible API", "OpenAI-Compatible APIs", "OpenAI APIs - Completions", "OpenAI APIs - Embedding", "OpenAI APIs - Vision", "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)", "Qwen3-Next Usage", "Qwen3-VL Usage", "Sampling Parameters", "Sending Requests", "Bench Serving Guide", "Benchmark and Profiling", "Contribution Guide", "Development Guide Using Docker", "Development Guide for JIT Kernels", "Evaluating New Models with SGLang", "PyPI Package Release Process", "Set Up Self-Hosted Runners for GitHub Actions", "SGLang diffusion CLI Inference", "SGLang Diffusion OpenAI API", "Perf Baseline Generation Script", "Compatibility Matrix", "Contributing to SGLang Diffusion", "Caching Acceleration", "SGLang Diffusion", "Install SGLang-Diffusion", "Attention Backends", "Cache-DiT Acceleration", "Caching Acceleration for Diffusion Models", "TeaCache Acceleration", "Performance Optimization", "Profiling Multimodal Generation", "How to Support New Diffusion Models", "Install SGLang", "SGLang Documentation", "SGLang Performance Dashboard", "AMD GPUs", "Contribution Guide", "SGLang installation with NPUs support", "Best Practice on Ascend NPU", "DeepSeek examples", "GLM-5", "&lt;no title&gt;", "Qwen3 examples", "Ascend NPUs", "Support Features on Ascend NPU", "Support Models on Ascend NPU", "CPU Servers", "MindSpore Models", "Moore Threads GPUs", "NVIDIA Jetson Orin", "TPU", "XPU", "Custom Chat Template", "Environment Variables", "Troubleshooting and Frequently Asked Questions", "Choices Methods in SGLang", "Frontend Language", "SGLang Frontend Language", "Learn More and Join the Community", "Deploy On Kubernetes", "LWS Based PD Deploy", "Multi-Node Deployment", "Multi-Node Deployment", "DeepSeekV32-Exp RBG Based PD Deploy", "Post-Training Integration", "Production Metrics", "Production Request Tracing", "Enabling cache for torch.compile", "Extending SGLang", "MindSpore Models", "Use Models From ModelScope", "How to Support New Models", "Transformers fallback in SGLang", "Supported Models", "Classification API", "Embedding Models", "Retrieval &amp; Ranking", "Rerank Models", "Specialized Models", "Reward Models", "Diffusion Language Models", "Large Language Models", "Text Generation", "Multimodal Language Models"], "titleterms": {"": [4, 5, 115], "0": [4, 98, 104, 107], "1": [13, 18, 30, 31, 32, 40, 43, 56, 57, 60, 68, 76, 78, 79, 81, 82, 83, 86, 90, 94, 104, 105, 107, 119], "100m": 82, "10m": 82, "11k": 82, "11m": 82, "128k": 18, "12m": 82, "13": 76, "16": [2, 82], "18k": 82, "18m": 82, "1_5k": 82, "1_6k": 82, "1k": 82, "2": [2, 13, 26, 29, 30, 31, 33, 43, 56, 57, 60, 68, 76, 78, 81, 82, 83, 90, 94, 97, 104, 107, 119], "2025": 33, "20m": 82, "235b": [18, 82, 86], "24": 82, "2507": 86, "2k": 82, "3": [13, 26, 29, 30, 43, 57, 60, 68, 76, 90, 94, 105], "30b": [4, 82, 86], "30m": 82, "32": 82, "32b": [82, 86], "3_5k": 82, "3_9k": 82, "3b": 90, "3k": 82, "4": [13, 29, 30, 36, 37, 39, 76, 82, 83, 94], "40": 24, "405b": 105, "429": 24, "480b": 82, "4k": 82, "5": [30, 36, 76, 84], "50m": 82, "5v": 37, "6": [36, 76], "64k": 82, "6k": 82, "6v": 37, "7": [36, 76], "7b": [61, 94], "8": [32, 82], "800i": [83, 86], "80b": 82, "8b": [4, 86, 94], "A": [41, 45, 46, 47, 52, 101], "For": [5, 23, 28, 30, 76, 81, 88, 97], "In": [33, 54, 107], "It": 72, "No": 13, "On": 103, "One": 107, "The": [4, 5, 98], "To": 25, "With": [68, 76], "a2": 82, "a22b": [18, 82, 86], "a3": [82, 83, 86], "a35b": 82, "a3b": [4, 82, 86], "about": 18, "abov": [37, 50], "acceler": [66, 67, 70, 71, 72], "access": 98, "accuraci": [20, 33, 39, 55, 58, 80, 84], "achiev": 14, "action": 60, "activ": 5, "adapt": 45, "adaptor": [15, 81], "add": [1, 24, 55, 57, 60, 80, 110, 115], "address": 3, "adjust": [14, 18], "admin": [13, 24], "adopt": 108, "advanc": [17, 19, 42, 56, 70, 77, 94, 97], "aim": 33, "aisbench": 84, "all": [8, 107], "amd": [68, 79], "an": 115, "api": [13, 15, 19, 22, 23, 24, 27, 28, 29, 30, 38, 41, 42, 43, 44, 45, 46, 47, 52, 54, 62, 88, 118], "approach": 30, "ar": [98, 109], "architectur": [2, 12, 13, 24, 75], "area": 94, "arg": [23, 88], "argument": [3, 4, 15, 23, 61], "ascend": [8, 17, 81, 82, 87, 88, 89], "ask": 98, "async": [18, 24], "asynchron": 42, "asyncio": 42, "atla": [83, 86], "attach": 13, "attent": [1, 3, 5, 23, 32, 64, 69, 73, 88, 94, 127], "authent": [24, 53], "auto": [19, 79], "automat": [1, 56], "avail": [19, 24, 75], "avoid": 14, "aw": 76, "awar": 24, "b": 14, "back": [12, 29], "backend": [1, 3, 4, 8, 11, 12, 13, 15, 17, 21, 23, 24, 29, 53, 61, 69, 70, 73, 88, 94, 97], "background": 13, "backward": 121, "balanc": [5, 8, 24, 25, 79, 81], "base": [5, 18, 64, 65, 104, 107], "baselin": 63, "basic": [4, 30, 45, 67, 70, 74, 77, 94, 101, 103], "batch": [8, 14, 23, 24, 42, 88, 101], "behavior": [4, 9, 13, 22], "being": 109, "bench": 53, "bench_offline_throughput": 54, "bench_serv": 54, "benchmark": [33, 39, 54, 55, 80, 82, 84, 90, 94, 95, 97, 115], "benefit": [2, 5, 19], "best": [5, 11, 18, 20, 24, 82], "bf16": [37, 50], "bia": 45, "bidirect": 127, "binari": 24, "bind": 24, "block": 32, "breaker": 24, "bucket": 24, "budget": [32, 36, 37], "buffer": 3, "bug": 54, "build": [0, 24, 33, 55], "built": 38, "c": 57, "cach": [10, 14, 20, 23, 24, 41, 49, 66, 67, 70, 71, 72, 73, 88, 97, 111], "call": [24, 29, 30, 32, 33, 97], "cann": 81, "capabl": 119, "capac": 14, "captur": 41, "card": 82, "case": [18, 103], "categori": 24, "caus": 4, "caveat": 13, "cfg": 72, "chang": 65, "characterist": 5, "chat": [29, 45, 96], "check": [24, 41, 57, 109], "checkpoint": [2, 19, 23, 33, 88], "choic": [29, 99], "choos": [15, 53], "chunk": [14, 18, 94], "ci": [0, 55, 65, 80, 97], "circuit": 24, "class": 118, "classif": [24, 118], "classifi": 41, "cli": [43, 61, 67, 69], "client": [29, 46, 47, 52, 119, 121, 124], "clone": [55, 80], "cloud": [61, 66, 76, 94], "co": 24, "code": [55, 57, 59, 80, 116, 124], "coder": 82, "collabor": 108, "collect": 109, "combin": 70, "command": [1, 3, 6, 23, 37, 50, 54, 90, 116, 121, 123, 124, 125, 127], "commit": [55, 65, 80], "common": [23, 76, 121], "commun": [5, 8, 11, 18, 24, 91, 102, 113], "comparison": [24, 26, 94], "compat": [15, 22, 27, 28, 29, 31, 43, 44, 64, 81, 118, 121], "compil": [0, 26, 94, 111], "complet": 45, "complex": [101, 110], "compon": [75, 81], "compos": 76, "comprehens": 94, "compressor": 19, "comput": [8, 70, 97], "concurr": 53, "config": [9, 60], "configur": [2, 4, 8, 9, 11, 17, 23, 24, 33, 39, 45, 49, 60, 61, 66, 69, 70, 72, 79, 82, 88, 94, 97, 109, 124], "connect": [24, 94], "connector": 24, "consider": [20, 54], "constrain": [51, 101], "constraint": 3, "contain": [56, 60, 93], "content": [24, 32], "context": [18, 33], "continu": 25, "contribut": [55, 65, 78, 80, 94], "control": [13, 14, 24, 101], "convent": 65, "convers": 24, "core": [11, 24, 51], "count": 70, "cp": 33, "cpu": [81, 90], "crash": 16, "creat": [19, 57, 81, 104], "cross": [41, 121], "cuda": [1, 3, 14, 76, 98], "curl": [46, 47, 52, 118], "current": [13, 29], "custom": [11, 23, 30, 51, 88, 94, 96], "dashboard": 78, "data": [5, 12, 13, 23, 24, 32, 78, 88], "dataset": 53, "dbcach": 70, "debug": [23, 24, 56, 88, 91, 97, 103, 113, 115], "debugg": 56, "decis": 72, "decod": [1, 8, 17, 23, 24, 26, 36, 38, 39, 41, 49, 51, 54, 84, 88, 94, 101, 104, 121], "decrypt": [23, 88], "deepep": [8, 81, 97], "deepgemm": 97, "deepseek": [5, 17, 18, 31, 32, 33, 45, 48, 79, 82, 83, 90, 97, 105], "deepseekv32": 107, "default": [4, 33, 51, 56], "defin": 29, "demo": 38, "denois": 74, "depend": [0, 91, 113], "deploi": [19, 24, 103, 104, 107], "deploy": [0, 11, 12, 24, 40, 78, 82, 84, 104, 105, 106], "deprec": 23, "design": [3, 12], "detach": 13, "detail": 118, "determin": 4, "determinist": [4, 25, 88, 98], "detoken": [24, 41], "dev": 56, "develop": [56, 57, 77], "devic": [91, 113], "dialog": 101, "diamond": 33, "differ": [1, 119], "diffus": [23, 34, 35, 61, 62, 65, 67, 68, 70, 71, 75, 77, 124], "dimens": 119, "disabl": [13, 70, 79, 81], "disaggreg": [7, 11, 12, 17, 18, 23, 24, 33, 54, 83, 84, 88], "discoveri": 24, "disk": [25, 41], "distanc": 72, "distribut": [5, 23, 25, 41, 54, 70, 88, 94, 97], "dit": [66, 67, 70, 71, 73], "dllm": 35, "doc": 0, "docker": [24, 33, 56, 60, 68, 76, 79, 81, 90, 94, 95], "document": [0, 55, 67, 77, 80, 94, 115, 121], "doe": 53, "doubl": 23, "download": 32, "dp": [5, 6, 13, 14], "dpa": 5, "draft": 26, "dsa": 33, "dump": [16, 23, 74, 88], "durat": 24, "dynam": [3, 11, 15, 18, 23, 88], "each": 5, "eagl": [23, 26, 36, 39, 49], "eagle3": [86, 94], "easi": 25, "ebnf": [27, 28, 45, 51], "edit": 75, "embed": [30, 41, 46, 89, 119, 121], "enabl": [11, 13, 18, 20, 29, 54, 67, 111], "encod": [3, 6, 23, 41, 88, 121], "encount": 98, "end": 53, "end_profil": 54, "endpoint": [24, 43, 51, 53, 54, 62, 118], "engin": [2, 22, 25, 27, 28, 29, 30, 42, 90, 94, 95, 115], "environ": [57, 70, 80, 81, 84, 91, 94, 97, 113], "ep": [5, 8], "epd": 7, "error": [14, 94, 98, 118], "evalu": [56, 58, 84], "even": 98, "exampl": [2, 3, 4, 6, 8, 19, 24, 29, 31, 32, 37, 41, 45, 50, 51, 53, 54, 61, 62, 64, 70, 75, 79, 83, 86, 90, 94, 103, 115, 116, 118, 119, 121, 123, 124, 125, 127], "execut": [0, 29], "exp": [82, 107], "experiment": [1, 33], "expert": [5, 8, 41, 45, 88], "explain": [53, 78], "explicitli": [91, 113], "export": [0, 19], "express": [27, 28], "extend": [110, 112], "extens": 8, "extern": [94, 115], "extra": 61, "factor": [18, 20], "factori": 9, "failur": 24, "fallback": 116, "faq": [32, 74, 104, 107], "featur": [19, 24, 67, 71, 77, 78, 88, 94, 116], "fetch": 78, "field": [9, 24, 118], "file": [23, 24, 54, 61, 88, 104, 107, 109, 124], "fine": 25, "fit": 3, "fix": 76, "flag": [25, 37, 50], "flap": 24, "flow": [24, 101], "flush": 41, "forc": 29, "fork": [21, 55, 80], "format": [20, 24, 29, 30, 53, 55, 80, 96, 118, 121], "forward": 23, "fp4": 20, "fp8": [18, 20, 32, 37, 50], "fraction": 14, "framework": [8, 81, 110], "frequenc": 26, "frequent": 98, "from": [12, 25, 33, 41, 55, 56, 68, 76, 79, 80, 81, 90, 92, 94, 95, 114, 115], "frontend": [100, 101], "full": [24, 37, 50, 74], "function": [24, 25, 29, 32, 33, 97], "futur": 15, "gatewai": [5, 24], "gemm": [23, 88], "gener": [4, 25, 34, 41, 42, 51, 52, 61, 62, 63, 64, 65, 67, 74, 97, 101, 126], "get": [41, 45, 67, 77], "github": [59, 60, 78], "glm": [36, 37, 48, 84], "go": 24, "gpqa": 33, "gpt": [38, 48], "gptqmodel": 19, "gpu": [15, 68, 70, 79, 92], "grain": 25, "grammar": [23, 88], "graph": [3, 14], "greedi": [4, 99], "group": 25, "growth": 24, "grpc": 24, "grub": 79, "gsm8k": [33, 83], "guid": [1, 53, 55, 56, 57, 77, 80, 109, 110], "guidanc": [8, 18, 26, 55, 80], "guidelin": [0, 11], "h20": 18, "h200": 32, "handl": [29, 118], "hang": 98, "har": 84, "hardwar": [37, 50, 77, 94], "head": 32, "health": [24, 41], "hf3f": 11, "hicach": [10, 11, 12, 13], "hierarch": [10, 23, 88], "high": [14, 24, 82, 94], "highlight": 26, "hiradixtre": 12, "histori": 24, "hook": [9, 23, 88], "hook_factori": 9, "host": [56, 60, 78], "hot": 24, "how": [5, 13, 29, 55, 65, 72, 75, 80, 94, 110, 115], "html": 0, "http": [13, 23, 24, 54, 67, 88], "hybrid": [1, 81], "hyperparamet": 14, "i": [7, 12, 17], "id": [24, 45, 46], "idl": 13, "illeg": 98, "imag": [30, 34, 37, 47, 50, 61, 62, 64, 75, 81, 104, 107, 121], "imbal": 24, "impact": 20, "implement": [8, 13, 18, 57, 75, 115, 118], "import": [37, 50, 54], "increas": 14, "infer": [4, 14, 24, 25, 42, 61, 70, 88, 91, 93, 105, 113], "info": 41, "initi": 29, "input": [3, 18, 30, 37, 46, 47, 50, 127], "instal": [0, 2, 19, 24, 33, 55, 67, 68, 74, 76, 79, 80, 81, 84, 90, 91, 92, 93, 94, 95, 113], "instruct": [82, 86, 121], "integ": 57, "integr": [2, 11, 12, 17, 24, 108], "interact": 115, "interest": 110, "interfac": [12, 57], "intern": 97, "introduct": [8, 84, 91, 113], "issu": [17, 24, 91, 94, 103, 113], "item": [23, 88], "itl": 18, "jetson": 93, "jinja": 96, "jit": 57, "join": 102, "json": [27, 28, 45, 51, 96], "jsonl": 53, "jump": 26, "k8": 104, "kei": [5, 11, 24, 53, 67, 71, 75, 103], "kernel": [23, 55, 57, 80, 81, 88], "known": [3, 6], "ktransform": 23, "kubernet": [24, 76, 103], "kv": [10, 14, 20], "l1": 72, "l3": 12, "languag": [24, 35, 81, 84, 89, 100, 101, 115, 124, 125, 127], "larg": [81, 89, 115, 125], "latenc": [82, 94], "latent": 32, "launch": [1, 22, 23, 24, 29, 31, 32, 33, 36, 37, 39, 41, 43, 45, 46, 47, 49, 50, 52, 57, 90, 94, 95, 101, 116, 119, 121, 123, 124, 125, 127], "layer": [23, 54], "layerwis": 54, "layout": 11, "lb": 104, "learn": 102, "length": [18, 99], "level": 9, "librari": [43, 81], "lifecycl": [9, 25], "likelihood": 99, "limit": [24, 55, 70, 80, 127], "line": 54, "list": [24, 90, 94, 95], "llama": [4, 17, 29, 30, 39, 48, 90, 105, 115], "llama3": 79, "llama4": 39, "llm": [19, 23, 58], "lm_eval": 39, "lmcach": [23, 88], "load": [5, 11, 15, 24, 25], "loader": [23, 88], "local": [12, 78], "locat": 74, "log": [16, 23, 24, 88], "logic": [1, 5], "logit": [45, 51], "long": [18, 33, 94], "lora": [15, 23, 45, 62, 64, 88], "low": [70, 82, 94], "lw": 104, "m2": 40, "make": [0, 59, 119], "mamba": [23, 49, 88], "manag": [3, 24, 62, 97], "manifest": [104, 107], "manual": [56, 78], "map": 81, "markdown": 0, "marker": 54, "mask": 70, "match": 12, "matrix": [1, 64, 69, 94], "matryoshka": 119, "matter": [4, 11], "max": 14, "maximum": 30, "mcp": 24, "mem": 14, "memfabr": 81, "memori": [11, 14, 20, 23, 24, 25, 81, 88, 94, 97, 98], "merg": [55, 80], "merger": 54, "messag": [29, 65], "metadata": 12, "method": [19, 26, 68, 76, 81, 94, 99], "metric": [16, 24, 53, 78, 109], "mha": 1, "middlewar": 24, "mindspor": [91, 113], "mini": 26, "minilb": 104, "minimax": [40, 48], "mix": [81, 82, 83, 121], "mla": [1, 5, 32], "modal": [3, 6, 23, 46, 88, 101], "mode": [5, 12, 17, 24, 29, 37, 50, 54, 82, 83, 91, 113], "model": [3, 4, 5, 6, 9, 19, 22, 23, 24, 26, 28, 29, 30, 32, 34, 35, 40, 41, 45, 46, 48, 53, 58, 64, 70, 71, 72, 75, 77, 81, 82, 84, 88, 89, 90, 91, 94, 95, 97, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 127], "modelopt": 19, "modelscop": 114, "modern": 5, "modul": 24, "moe": [4, 5, 8, 23, 41, 45, 86], "monitor": 24, "mooncak": [11, 17], "moor": [68, 92], "more": [48, 102], "mori": 97, "motiv": 3, "mp": 69, "mtl": 24, "multi": [2, 3, 6, 12, 17, 23, 24, 26, 32, 33, 46, 54, 84, 88, 94, 101, 105, 106, 118], "multimod": [51, 74, 81, 89, 115, 119, 121, 127], "multipl": [4, 15, 47], "multiplex": [23, 88], "musa": 68, "name": 9, "nativ": [5, 22, 27, 28, 29, 41, 52], "nccl": 21, "nest": 42, "never": 24, "new": [1, 8, 22, 29, 57, 58, 75, 115], "newcom": [55, 80], "next": [49, 82], "ngram": [23, 26, 88], "nixl": 17, "node": [2, 17, 23, 32, 54, 84, 88, 94, 105, 106], "non": [4, 22, 29, 37, 42, 50], "normal": [51, 99], "note": [24, 37, 38, 50, 51, 53, 54, 69, 74, 76, 127], "notebook": 0, "npu": [8, 80, 81, 82, 87, 88, 89], "nsa": 97, "nsight": [54, 74], "numa": [79, 81], "nvfp4": 33, "nvidia": [18, 19, 68, 93], "nvlink": 17, "nvtx": 54, "observ": [16, 24], "obtain": 81, "ocr": 31, "off": 67, "offlin": [14, 19, 22, 27, 28, 29, 30, 42, 91, 113, 115], "offload": [23, 88], "ollama": 43, "one": [32, 67], "onli": [41, 121], "onlin": 19, "oom": 94, "open": 25, "openai": [15, 22, 24, 27, 28, 29, 31, 44, 45, 46, 47, 52, 62], "opentelemetri": 24, "optim": [11, 12, 23, 32, 33, 37, 50, 64, 67, 73, 82, 88, 90, 94, 95, 97, 127], "option": [2, 9, 14, 23, 29, 51, 53, 56, 69, 78, 88, 97, 121], "oracl": 24, "organ": 12, "orin": 93, "oss": [38, 48], "other": [14, 51, 53, 54, 88], "our": 115, "out": [14, 81, 94, 98], "output": [27, 28, 29, 30, 45, 51, 53, 54, 74, 93, 119], "overal": 12, "overflow": 24, "overlap": [8, 15, 26], "overrid": [23, 88], "overview": [2, 8, 9, 13, 24, 69, 70, 71, 72, 73, 75, 118], "ovi": 61, "own": 19, "packag": [24, 59], "page": 78, "parallel": [2, 5, 8, 13, 18, 23, 32, 33, 88, 101], "param": 88, "paramet": [11, 12, 37, 45, 50, 51, 61, 69, 70, 72, 118, 121], "pars": 24, "parser": [22, 24, 29, 33, 38], "path": [13, 74], "pattern": 5, "paus": 25, "pd": [11, 12, 17, 18, 23, 24, 33, 54, 81, 83, 88, 104, 107], "penal": 51, "perf": [63, 74], "perform": [2, 5, 20, 24, 26, 30, 58, 65, 67, 70, 73, 78, 81, 84, 94, 97, 127], "pin": 15, "pip": [68, 76], "pipelin": [18, 33, 74, 75], "pitfal": 121, "plane": 24, "platform": [68, 69, 77], "polici": [5, 11, 24], "pool": 14, "popular": 48, "port": 115, "possibl": 54, "post": 108, "postgresql": 24, "postpon": 25, "power": 81, "pp": 33, "practic": [5, 11, 18, 20, 24, 82], "pre": [19, 55, 80], "precis": [37, 50], "precomput": 30, "predict": [26, 32, 33], "prefetch": [11, 12], "prefil": [1, 14, 17, 18, 23, 24, 54, 84, 88, 94, 104], "prepar": [80, 81, 84, 104, 107], "preprocess": 30, "prerequisit": [24, 43, 53, 61, 62, 81, 93, 103, 104, 107, 109], "prevent": 81, "prioriti": 69, "privaci": 24, "problem": [5, 76], "process": 59, "processor": [30, 51], "product": [16, 24, 109, 110], "profil": [17, 54, 56, 73, 74, 97], "prometheu": 24, "prompt": [31, 101], "promql": 24, "propag": 24, "protect": 65, "protobuf": [91, 113], "proxi": 24, "pypi": [59, 94], "python": [19, 24, 29, 38, 40, 43, 46, 47, 52, 57, 81, 118], "pytorch": [54, 74, 81], "quantis": [37, 50], "quantiz": [19, 20, 23, 88, 93, 97, 116], "quark_int4fp8_mo": 19, "queri": [13, 30, 121], "question": 98, "queu": 24, "queue": [14, 24], "quick": [5, 24, 26, 38, 43, 53, 67, 71, 76, 78, 119], "qwen": [7, 48, 75, 82, 94], "qwen2": 30, "qwen3": [4, 18, 45, 49, 50, 82, 86, 94, 121], "r": 21, "r1": [32, 82, 105], "radix": 49, "rang": 57, "rank": [12, 26, 120], "rate": [24, 53, 55, 80], "raw": 30, "rbg": 107, "rdma": 103, "re": 110, "readi": 24, "reason": [22, 24, 28, 32, 33, 38, 45], "recommend": [5, 24, 37, 50, 78, 79, 94], "redi": 24, "refactor": 18, "refer": [2, 5, 19, 24, 26, 67, 70, 71, 72, 73, 77, 93, 94], "refit": 25, "regex": [45, 51], "regist": [88, 115], "regular": [24, 27, 28], "relat": [12, 23, 88], "releas": [25, 59], "reliabl": 24, "remain": 103, "remot": [56, 116], "render": 0, "replai": 16, "report": [58, 65], "repositori": [55, 80], "reproduc": 4, "req": 14, "request": [14, 16, 22, 24, 29, 31, 37, 46, 47, 50, 52, 55, 80, 90, 94, 95, 110, 118, 119, 121], "requestmetricsexport": [23, 88], "requir": [9, 13, 17, 29, 40, 64, 91, 94, 113], "rerank": [41, 89, 121], "resourc": 94, "respons": [4, 24, 38, 118, 121], "restart": 13, "restrict": 3, "result": [29, 33, 39, 58, 98], "resum": 25, "retri": 24, "retriev": 120, "return": 45, "return_docu": 121, "review": [55, 80], "reward": [41, 89, 118, 123], "rich": 12, "rl": 25, "robin": 33, "roce": 103, "rocm": [68, 69], "root": 4, "rotari": 3, "round": [19, 33, 41], "rout": [24, 45], "router": [5, 17, 24, 25, 43], "run": [14, 32, 55, 60, 61, 76, 78, 79, 80, 81, 83, 86, 90, 91, 93, 113], "runner": [60, 121], "runtim": [13, 23, 24, 27, 28, 29, 57, 88], "rust": 24, "sagemak": 76, "sampl": [4, 23, 26, 51, 61, 88], "save": 20, "sbo": 8, "scale": 20, "scenario": [103, 110], "scene": 81, "schedul": [17, 23, 26, 88], "schema": [9, 22], "scheme": 81, "scm": 70, "score": [23, 41, 88, 118], "script": [63, 94], "search": 38, "section": 26, "secur": 24, "select": [1, 8, 17, 41, 69, 91, 99, 113], "self": [60, 78], "semant": 13, "send": [29, 37, 50, 52], "separ": [24, 81, 82], "sequenc": 33, "seri": 82, "serv": [15, 23, 53, 61, 62, 67, 88, 90, 94, 95, 115, 127], "server": [2, 4, 17, 22, 23, 24, 25, 29, 31, 37, 41, 43, 45, 46, 47, 50, 52, 54, 61, 62, 67, 78, 88, 90, 91, 98, 101, 113, 119], "servic": [24, 81, 104], "set": [24, 33, 60, 79, 81], "setup": [2, 5, 56, 57, 109, 110], "sgl": [55, 80], "sglang": [0, 2, 3, 4, 5, 6, 8, 11, 22, 24, 25, 27, 28, 29, 32, 33, 36, 37, 39, 41, 43, 49, 50, 54, 55, 56, 58, 61, 62, 65, 67, 68, 76, 77, 78, 79, 80, 81, 92, 93, 99, 101, 112, 115, 116], "sh": 60, "share": 54, "simplest": 30, "singl": [2, 8, 15, 17, 70, 84, 118], "size": [14, 18], "skypilot": [76, 94], "sleep": 25, "slice": 110, "slide": [64, 69], "slurm": 105, "small": 26, "smart": 43, "smg": 5, "smooth": 18, "snippet": 124, "softwar": 94, "solut": 4, "some": [91, 113], "sourc": [24, 33, 55, 68, 76, 79, 80, 81, 90, 92, 94, 95], "spars": 23, "sparsiti": 23, "spec": 9, "special": [64, 122], "specif": [22, 29, 37, 50, 68, 72, 94, 97], "spectul": 8, "specul": [1, 23, 26, 36, 38, 39, 49, 88, 94], "speed": [14, 55, 80], "split": 33, "srt": [27, 28, 29], "sta": 69, "stabl": 3, "stage": [74, 75], "standalon": 26, "standard": [5, 33, 68], "start": [5, 24, 43, 53, 56, 60, 61, 62, 67, 71, 77, 78, 91, 113, 119], "start_profil": 54, "state": 13, "static": [3, 14], "statu": 13, "step": [1, 57, 60, 70, 74, 79], "storag": [11, 12, 13, 24, 54, 61, 66, 97], "strategi": 73, "stream": [22, 29, 42, 51, 52, 53, 101], "strict": 13, "structur": [27, 28, 45, 51, 57, 78, 93], "studi": 18, "style": [0, 55, 80], "submiss": 14, "success": 103, "suit": 115, "summari": [9, 26, 43], "support": [1, 3, 4, 6, 8, 11, 20, 22, 23, 24, 28, 29, 40, 45, 53, 61, 69, 70, 71, 72, 75, 77, 81, 88, 89, 91, 94, 110, 113, 115, 116, 117, 118, 119, 121, 123, 124, 125, 127], "swap": 81, "switch": 62, "synchron": [12, 42], "system": [12, 25, 40, 54, 74, 79, 81, 94], "tabl": [24, 26], "tag": [27, 28], "target": [5, 74], "target_modul": 9, "taylors": 70, "tbo": 8, "teacach": [71, 72, 73], "temperatur": [4, 98], "templat": [29, 96], "tensor": [2, 5, 23, 25, 32, 57, 88], "terminu": 90, "test": [24, 33, 39, 40, 55, 80, 83, 94, 97, 115, 118], "text": [41, 121, 126], "think": [32, 36, 37, 45], "thread": [68, 92], "three": 30, "throughput": [14, 32, 82, 94], "tile": [64, 69], "time": [74, 94], "tip": [33, 39, 49, 54, 55, 70, 80], "tl": 24, "todo": 103, "token": [14, 18, 23, 24, 26, 32, 33, 41, 45, 53, 78, 88, 99], "tool": [24, 29, 38, 97], "top": 9, "top_n": 121, "torch": [26, 111], "torchao": [19, 93], "tp": [2, 14], "tpu": 94, "trace": [24, 54, 74, 110], "track": 72, "traffic": 5, "train": 108, "transfer": 12, "transferengin": 21, "transform": 116, "transport": [17, 24], "trigger": [55, 80], "trip": 41, "triton": 81, "troubleshoot": [2, 24, 53, 70, 78, 91, 94, 98, 109, 113], "try": 14, "tune": [14, 18, 24, 97], "turn": 101, "two": 8, "type": [23, 88], "ultra": 18, "uncondit": 99, "understand": 30, "unifi": [12, 17], "unit": [55, 80], "unsloth": 19, "up": [25, 56, 60], "updat": [0, 25, 41, 55, 59, 79, 80], "upload": 59, "us": [5, 13, 19, 25, 43, 45, 46, 47, 52, 54, 56, 57, 61, 68, 69, 76, 79, 81, 84, 90, 94, 95, 97, 114, 118], "usag": [2, 4, 7, 14, 15, 17, 19, 20, 21, 22, 24, 28, 32, 33, 37, 38, 39, 40, 42, 45, 48, 49, 50, 54, 63, 67, 69, 70, 77, 90, 101, 109, 118, 127], "user": 1, "util": 57, "uv": [68, 76], "v": 1, "v1": 41, "v2": 26, "v3": [18, 32, 33, 45, 79, 82, 83, 90, 97, 105], "variabl": [70, 97], "verif": [4, 94], "verifi": [5, 64], "version": [59, 81], "via": [26, 69, 115], "video": [34, 37, 50, 62, 64, 127], "view": [54, 74], "vision": [30, 47], "vl": [7, 30, 50, 86, 121], "vllm": [84, 115], "vlm": [30, 58], "vscode": 56, "wake": 25, "warmup": 79, "warn": 70, "wasm": 24, "web": [0, 38], "weight": [23, 25, 32, 41, 84, 88], "what": [7, 12, 17, 53], "when": 5, "why": [4, 7, 11, 12, 17, 18, 25], "wise": [32, 54], "without": 29, "work": [5, 15, 72], "worker": [24, 54], "workflow": [0, 12, 19, 54], "workload": 8, "wrapper": 115, "write": [9, 12, 55, 57, 80], "x": [32, 64, 83, 86], "xgrammar": 93, "xpu": 95, "ye": 121, "you": 110, "your": [19, 57]}})