Search.setIndex({"alltitles": {"/generate Endpoint": [[33, "generate-endpoint"]], "0. Prerequisites": [[57, "prerequisites"], [60, "prerequisites"]], "1. Image Preparation": [[57, "image-preparation"], [60, "image-preparation"]], "1. Launch a Matryoshka\u2011capable model": [[65, "launch-a-matryoshkacapable-model"]], "2. All In One manifest file": [[60, "all-in-one-manifest-file"]], "2. Deployment Manifest Files": [[57, "deployment-manifest-files"]], "2. Make requests with different output dimensions": [[65, "make-requests-with-different-output-dimensions"]], "AMD GPUs": [[43, null]], "API Endpoint": [[64, "api-endpoint"]], "API Surface": [[12, "api-surface"]], "API related": [[14, "api-related"]], "ASCEND": [[10, "ascend"]], "Accuracy Test with gpqa-diamond": [[21, "accuracy-test-with-gpqa-diamond"]], "Accuracy Test with gsm8k": [[21, "accuracy-test-with-gsm8k"]], "Accuracy Test with lm_eval": [[23, "accuracy-test-with-lm-eval"]], "Achieve a high token usage": [[7, "achieve-a-high-token-usage"]], "Achieving high throughput for offline batch inference": [[7, "achieving-high-throughput-for-offline-batch-inference"]], "Add a Runner": [[40, "add-a-runner"]], "Add the Model to the Test Suite": [[71, "add-the-model-to-the-test-suite"]], "Adjust the request submission speed to control #queue-req": [[7, "adjust-the-request-submission-speed-to-control-queue-req"]], "Advanced Configuration": [[10, "advanced-configuration"]], "Advanced Features": [[11, "advanced-features"], [42, null]], "Advanced Usage": [[25, "Advanced-Usage"]], "Architecture": [[2, "architecture"], [12, "architecture"]], "Args for multi-item scoring": [[14, "args-for-multi-item-scoring"]], "Arguments for LoRA Serving": [[8, "Arguments-for-LoRA-Serving"]], "Ascend NPUs": [[44, null]], "Attention Backend": [[1, null]], "Authentication": [[35, "authentication"]], "Available Quantization Methods": [[11, "available-quantization-methods"]], "Avoid out-of-memory errors by tuning --chunked-prefill-size, --mem-fraction-static, and --max-running-requests": [[7, "avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests"]], "Backend Compatibility": [[18, "Backend-Compatibility"]], "Basic Usage": [[3, "basic-usage"], [27, "Basic-Usage"], [42, null], [54, "Basic-Usage"]], "Basic example": [[56, "basic-example"]], "Batching": [[54, "Batching"]], "Bench Serving Guide": [[35, null]], "Benchmark": [[36, "benchmark"], [71, "benchmark"]], "Benchmark and Profiling": [[36, null]], "Benchmark the speed": [[37, "benchmark-the-speed"]], "Benchmarking Results": [[21, "benchmarking-results"], [23, "benchmarking-results"]], "Benchmarking with Requests": [[45, "benchmarking-with-requests"], [48, "benchmarking-with-requests"]], "Benefits of ModelOpt": [[11, "benefits-of-modelopt"]], "Block-wise FP8": [[20, "block-wise-fp8"]], "Build From Source": [[21, "build-from-source"]], "Build from source": [[37, "build-from-source"]], "Built-in Tools": [[22, "built-in-tools"]], "CPU Servers": [[45, null]], "CPU performance power scheme": [[44, "cpu-performance-power-scheme"]], "CUDA Error: Illegal Memory Access Encountered": [[51, "cuda-error-illegal-memory-access-encountered"]], "CUDA Out of Memory": [[51, "cuda-out-of-memory"]], "Cache-Aware Tuning": [[12, "cache-aware-tuning"]], "Capture expert selection distribution in MoE models": [[24, "Capture-expert-selection-distribution-in-MoE-models"]], "Chat Completions": [[27, "Chat-Completions"]], "Check if the metrics are being collected": [[61, "check-if-the-metrics-are-being-collected"]], "Checkpoint Engine Integration": [[2, null]], "Checkpoint Engine Options": [[2, "checkpoint-engine-options"]], "Choices Methods in SGLang": [[52, null]], "Choosing LoRA Backend": [[8, "Choosing-LoRA-Backend"]], "Choosing model and tokenizer": [[35, "choosing-model-and-tokenizer"]], "Circuit Breaker": [[12, "circuit-breaker"]], "Classification API": [[64, null]], "Classification Models (Multi-class)": [[64, "classification-models-multi-class"]], "Classify (reward model)": [[24, "Classify-(reward-model)"]], "Client Request": [[65, "client-request"]], "Co-launch Router + Workers": [[12, "co-launch-router-workers"]], "Command Line Usage": [[36, "command-line-usage"]], "Common Notes": [[41, "common-notes"]], "Common launch commands": [[14, "common-launch-commands"]], "Community and Support": [[5, "community-and-support"]], "Compatibility": [[64, "compatibility"]], "Completions": [[27, "Completions"]], "Complex Prompts": [[54, "Complex-Prompts"]], "Configuration Files": [[61, "configuration-files"]], "Configuration Guidelines": [[5, "configuration-guidelines"]], "Configuration Options": [[2, "configuration-options"]], "Configuration Reference": [[12, "configuration-reference"]], "Configuration Tips": [[21, "configuration-tips"], [23, "configuration-tips"], [31, "configuration-tips"]], "Configuration file support": [[14, "configuration-file-support"]], "Constrained Decoding": [[54, "Constrained-Decoding"]], "Constrained decoding": [[33, "constrained-decoding"]], "Context-parallel Tips": [[21, "context-parallel-tips"]], "Contribution Guide": [[37, null]], "Control Plane": [[12, "control-plane"]], "Control flow": [[54, "Control-flow"]], "Core HiCache Parameters": [[5, "core-hicache-parameters"]], "Core Settings": [[12, "core-settings"]], "Core parameters": [[33, "core-parameters"]], "Crash Dump and Replay": [[9, "crash-dump-and-replay"]], "Create decode k8s service": [[57, "create-decode-k8s-service"]], "Create prefill k8s service": [[57, "create-prefill-k8s-service"]], "Creating Service for Prefill and Decode": [[57, "creating-service-for-prefill-and-decode"]], "Currently supported parsers:": [[18, "Currently-supported-parsers:"]], "Custom Chat Template": [[49, null]], "Custom Storage Backend Integration": [[5, "custom-storage-backend-integration"]], "Custom logit processor": [[33, "custom-logit-processor"]], "Custom weight loader": [[14, "custom-weight-loader"]], "DSA long sequence context parallel optimization(experimental)": [[21, "dsa-long-sequence-context-parallel-optimization-experimental"]], "Data Parallelism Attention": [[20, "data-parallelism-attention"]], "Data Plane": [[12, "data-plane"]], "Data Transfer Optimization": [[6, "data-transfer-optimization"]], "Data Write-back": [[6, "data-write-back"]], "Data parallelism": [[14, "data-parallelism"]], "Datasets": [[35, "datasets"]], "Debug": [[56, "debug"]], "Debug SGLang with VSCode Debugger": [[38, "debug-sglang-with-vscode-debugger"]], "Debug tensor dumps": [[14, "debug-tensor-dumps"]], "Decode": [[57, "decode"]], "Decode Server Configuration": [[10, "decode-server-configuration"]], "DeepEP Configuration": [[50, "deepep-configuration"]], "DeepEP-compatible Library": [[44, "deepep-compatible-library"]], "DeepGEMM Configuration (Advanced Optimization)": [[50, "deepgemm-configuration-advanced-optimization"]], "DeepSeek Multi-Node": [[10, "deepseek-multi-node"], [10, "id4"], [10, "id7"]], "DeepSeek V3.2 Usage": [[21, null]], "DeepSeek V3/R1": [[58, "deepseek-v3-r1"]], "DeepSeek V3/V3.1/R1 Usage": [[20, null]], "DeepSeekV32-Exp RBG Based PD Deploy": [[60, null]], "Default Behavior": [[3, "default-behavior"]], "Define Messages": [[18, "Define-Messages"]], "Define Tools for Function Call": [[18, "Define-Tools-for-Function-Call"]], "Define a Tool Function": [[18, "Define-a-Tool-Function"]], "Deploy On Kubernetes": [[56, null]], "Deploy minilb and lb service": [[57, "deploy-minilb-and-lb-service"]], "Deploying Quantized Models": [[11, "deploying-quantized-models"]], "Deployment Modes": [[12, "deployment-modes"]], "Deployment with HF3FS": [[5, "deployment-with-hf3fs"]], "Deployment with Mooncake": [[5, "deployment-with-mooncake"]], "Deprecated arguments": [[14, "deprecated-arguments"]], "Deterministic Inference": [[3, null]], "Deterministic Inference with Non-Greedy Sampling (Temperature > 0)": [[3, "deterministic-inference-with-non-greedy-sampling-temperature-0"]], "Developer Guide": [[42, null]], "Development Guide Using Docker": [[38, null]], "Disable NUMA Auto-Balancing": [[43, "disable-numa-auto-balancing"]], "Disable NUMA balancing": [[44, "disable-numa-balancing"]], "Distributed Computing": [[50, "distributed-computing"]], "Docker": [[21, "docker"]], "Docs Workflow": [[0, "docs-workflow"]], "Documentation": [[71, "documentation"]], "Documentation Style Guidelines": [[0, "documentation-style-guidelines"]], "Double Sparsity": [[14, "double-sparsity"]], "Download Weights": [[20, "download-weights"]], "Dynamic Backend Loading": [[5, "dynamic-backend-loading"]], "Dynamic LoRA loading": [[8, "Dynamic-LoRA-loading"]], "EAGLE Decoding": [[15, "EAGLE-Decoding"]], "EAGLE Speculative Decoding": [[23, "eagle-speculative-decoding"], [31, "eagle-speculative-decoding"]], "EAGLE-2 Decoding via Frequency-Ranked Speculative Sampling": [[15, "EAGLE-2-Decoding-via-Frequency-Ranked-Speculative-Sampling"]], "EAGLE-2 Decoding with torch.compile": [[15, "EAGLE-2-Decoding-with-torch.compile"]], "EAGLE-2 decoding": [[15, "EAGLE-2-decoding"]], "EAGLE-3 Decoding": [[15, "EAGLE-3-Decoding"]], "EBNF": [[16, "EBNF"], [16, "id2"], [16, "id6"], [17, "EBNF"], [17, "id2"], [17, "id6"]], "Embedding Models": [[65, null]], "Enabling cache for torch.compile": [[63, null]], "Encode (embedding model)": [[24, "Encode-(embedding-model)"]], "End-to-end examples": [[35, "end-to-end-examples"]], "Environment Variables": [[50, null]], "Error Handling": [[64, "error-handling"]], "Evaluation": [[38, "evaluation"]], "Example Client Request": [[69, "example-client-request"]], "Example Configurations": [[3, "example-configurations"]], "Example Launch Command": [[69, "example-launch-command"]], "Example Usage": [[64, "example-usage"]], "Example launch Command": [[66, "example-launch-command"], [68, "example-launch-command"], [70, "example-launch-command"], [72, "example-launch-command"]], "Example usage with the above optimizations:": [[32, "example-usage-with-the-above-optimizations"]], "Example workflow": [[36, "example-workflow"]], "Example: DeepSeek-V3 Models": [[27, "Example:-DeepSeek-V3-Models"]], "Example: Implementing and Serving a Llama Wrapper Model": [[71, "example-implementing-and-serving-a-llama-wrapper-model"]], "Example: Qwen3 Models": [[27, "Example:-Qwen3-Models"]], "Example: Required Tool Choice": [[18, "Example:-Required-Tool-Choice"]], "Example: Running DeepSeek-V3.1-Terminus": [[45, "example-running-deepseek-v3-1-terminus"]], "Example: Specific Function Choice": [[18, "Example:-Specific-Function-Choice"]], "Examples": [[33, "examples"], [35, "examples"], [43, "examples"], [44, "examples"]], "Examples of Offline Model Quantization": [[11, "examples-of-offline-model-quantization"]], "Execute the Tool": [[18, "Execute-the-Tool"]], "Expert parallelism": [[14, "expert-parallelism"]], "FAQ": [[20, "faq"], [57, "faq"], [60, "faq"]], "FP8 (quantised) mode": [[32, "fp8-quantised-mode"]], "Fault Tolerance": [[12, "fault-tolerance"]], "Flush Cache": [[24, "Flush-Cache"]], "For PD-Multiplexing": [[14, "for-pd-multiplexing"]], "For deterministic inference": [[14, "for-deterministic-inference"]], "Forcing Pythonic Tool Call Output Without a Chat Template": [[18, "Forcing-Pythonic-Tool-Call-Output-Without-a-Chat-Template"]], "Fork and clone the repository": [[37, "fork-and-clone-the-repository"]], "Format code with pre-commit": [[37, "format-code-with-pre-commit"]], "Frequently Asked Questions": [[51, "frequently-asked-questions"]], "Frontend Language": [[53, null], [53, null]], "Function Calling / Tool Use": [[50, "function-calling-tool-use"]], "Function Calling and Reasoning Parser": [[21, "function-calling-and-reasoning-parser"]], "Function calling for DeepSeek Models": [[20, "function-calling-for-deepseek-models"]], "Future Works": [[8, "Future-Works"]], "GPT OSS Usage": [[22, null]], "General Configuration": [[50, "general-configuration"]], "General code style": [[37, "general-code-style"]], "Generate (text generation model)": [[24, "Generate-(text-generation-model)"]], "Generating Multiple Reproducible Responses": [[3, "generating-multiple-reproducible-responses"]], "Get Model Info": [[24, "Get-Model-Info"]], "Get Server Info": [[24, "Get-Server-Info"]], "Get Started": [[42, null]], "Getting Token IDs": [[27, "Getting-Token-IDs"]], "Greedy Token Selection": [[52, "greedy-token-selection"]], "HTTP API Usage": [[36, "http-api-usage"]], "HTTP server": [[14, "http-server"]], "Handle Tools": [[18, "Handle-Tools"], [18, "id1"]], "Hardware Platforms": [[42, null]], "Hardware-specific notes / recommendations": [[32, "hardware-specific-notes-recommendations"]], "Health Check": [[24, "Health-Check"]], "HiCache System Design and Optimization": [[6, null]], "HiRadixTree: Metadata Organization in HiCache": [[6, "hiradixtree-metadata-organization-in-hicache"]], "Hierarchical KV Caching (HiCache)": [[4, null]], "Hierarchical cache": [[14, "hierarchical-cache"]], "History & Data Connectors": [[12, "history-data-connectors"]], "How to Extend the Tracing Framework to Support Complex Tracing Scenarios": [[62, "how-to-extend-the-tracing-framework-to-support-complex-tracing-scenarios"]], "How to Support New Models": [[71, null]], "How to Support a New Language Model": [[71, "how-to-support-a-new-language-model"]], "How to Support a New Multimodal Large Language Model": [[71, "how-to-support-a-new-multimodal-large-language-model"]], "How to add Tracing for slices you\u2019re interested in?": [[62, "how-to-add-tracing-for-slices-you-re-interested-in"]], "How to enable": [[18, "How-to-enable"]], "How to support a new model?": [[18, "How-to-support-a-new-model?"]], "How to trigger CI": [[37, "how-to-trigger-ci"]], "How to update sgl-kernel": [[37, "how-to-update-sgl-kernel"]], "Hybrid attention (different backends for prefill vs decode) (Experimental)": [[1, "hybrid-attention-different-backends-for-prefill-vs-decode-experimental"]], "Hyperparameter Tuning": [[7, null]], "Image input:": [[32, "image-input"]], "Implementation Details": [[64, "implementation-details"]], "Implementing Our Model": [[71, "implementing-our-model"]], "Important Notes": [[36, "important-notes"]], "Important Server Parameters and Flags": [[32, "important-server-parameters-and-flags"]], "Initialize the Client": [[18, "Initialize-the-Client"]], "Install Dependency": [[0, "install-dependency"]], "Install From Source": [[45, "install-from-source"], [48, "install-from-source"]], "Install SGLang": [[41, null], [43, "install-sglang"]], "Install SGLang from Source": [[37, "install-sglang-from-source"]], "Install Using Docker": [[45, "install-using-docker"], [48, "install-using-docker"]], "Install Using Docker (Recommended)": [[43, "install-using-docker-recommended"]], "Install from Source": [[43, "install-from-source"]], "Installation": [[2, "installation"], [11, "installation"], [21, "installation"], [45, "installation"], [48, "installation"]], "Installing SGLang": [[44, "installing-sglang"]], "Installing SGLang from source": [[44, "installing-sglang-from-source"]], "Installing and running SGLang with Jetson Containers": [[46, "installing-and-running-sglang-with-jetson-containers"]], "Integration with PD Disaggregation": [[5, "integration-with-pd-disaggregation"]], "Integration with PD-Disaggregation Deployment Mode": [[6, "integration-with-pd-disaggregation-deployment-mode"]], "Interactive Debugging": [[71, "interactive-debugging"]], "Issues with Unified Scheduling": [[10, "issues-with-unified-scheduling"]], "JSON": [[16, "JSON"], [16, "id1"], [16, "id5"], [17, "JSON"], [17, "id1"], [17, "id5"]], "JSON Format": [[49, "json-format"]], "JSONL output format": [[35, "jsonl-output-format"]], "Jinja Format": [[49, "jinja-format"]], "Kernel backend": [[14, "kernel-backend"]], "Key Configurations with Storage Backends Enabled": [[5, "key-configurations-with-storage-backends-enabled"]], "Keys to success": [[56, "keys-to-success"]], "Kubernetes Discovery": [[12, "kubernetes-discovery"]], "LMCache": [[14, "lmcache"]], "LWS Based PD Deploy": [[57, null]], "Large Language Models": [[66, null]], "Launch A Server": [[24, "Launch-A-Server"], [27, "Launch-A-Server"], [28, "Launch-A-Server"], [29, "Launch-A-Server"], [34, "Launch-A-Server"], [54, "Launch-A-Server"]], "Launch Command for Different Attention Backends": [[1, "launch-command-for-different-attention-backends"]], "Launch DeepSeek V3.1/V3/R1 with SGLang": [[20, "launch-deepseek-v3-1-v3-r1-with-sglang"]], "Launch DeepSeek V3.2 with SGLang": [[21, "launch-deepseek-v3-2-with-sglang"]], "Launch Llama 4 with SGLang": [[23, "launch-llama-4-with-sglang"]], "Launch Qwen3-Next with SGLang": [[31, "launch-qwen3-next-with-sglang"]], "Launch Server": [[65, "launch-server"]], "Launch commands for SGLang": [[32, "launch-commands-for-sglang"]], "Launch of the Serving Engine": [[45, "launch-of-the-serving-engine"], [48, "launch-of-the-serving-engine"]], "Launch with one node of 8 x H200": [[20, "launch-with-one-node-of-8-x-h200"]], "Launching the Server": [[13, "Launching-the-Server"], [18, "Launching-the-Server"]], "Layer-wise NVTX Profiling with Nsight Systems": [[36, "layer-wise-nvtx-profiling-with-nsight-systems"]], "Learn More and Join the Community": [[55, null]], "Llama 3.1 405B": [[58, "llama-3-1-405b"]], "Llama Models": [[3, "llama-models"]], "Llama Single Node": [[10, "llama-single-node"], [10, "id3"], [10, "id6"]], "Llama4 Usage": [[23, null]], "LoRA": [[14, "lora"]], "LoRA GPU Pinning": [[8, "LoRA-GPU-Pinning"]], "LoRA Serving": [[8, null]], "Load Balancing Policies": [[12, "load-balancing-policies"]], "Local Match": [[6, "local-match"]], "Logging": [[9, "logging"], [14, "logging"]], "Logit Bias Support": [[27, "Logit-Bias-Support"], [27, "id1"]], "MCP & Advanced Tooling": [[12, "mcp-advanced-tooling"]], "MHA Backends": [[1, "mha-backends"]], "MLA Backends": [[1, "mla-backends"]], "Make a release in GitHub": [[39, "make-a-release-in-github"]], "Mamba Cache": [[14, "mamba-cache"]], "Matryoshka Embedding Example": [[65, "matryoshka-embedding-example"]], "MemFabric Adaptor": [[44, "memfabric-adaptor"]], "Memory Layout Optimization": [[5, "memory-layout-optimization"]], "Memory Management": [[50, "memory-management"]], "Memory and scheduling": [[14, "memory-and-scheduling"]], "Method 1: Installing from source with prerequisites": [[44, "method-1-installing-from-source-with-prerequisites"]], "Method 1: With pip or uv": [[41, "method-1-with-pip-or-uv"]], "Method 2: From source": [[41, "method-2-from-source"]], "Method 2: Using docker": [[44, "method-2-using-docker"]], "Method 3: Using docker": [[41, "method-3-using-docker"]], "Method 4: Using Kubernetes": [[41, "method-4-using-kubernetes"]], "Method 5: Using docker compose": [[41, "method-5-using-docker-compose"]], "Method 6: Run on Kubernetes or Clouds with SkyPilot": [[41, "method-6-run-on-kubernetes-or-clouds-with-skypilot"]], "Methods": [[52, "methods"]], "Metrics explained": [[35, "metrics-explained"]], "Model Thinking/Reasoning Support": [[27, "Model-Thinking/Reasoning-Support"]], "Model and tokenizer": [[14, "model-and-tokenizer"]], "Model override args": [[14, "model-override-args"]], "Model-Specific Behaviors": [[13, "Model-Specific-Behaviors"]], "Model-Specific Options": [[50, "model-specific-options"]], "Mooncake": [[10, "mooncake"]], "Multi Node Tensor Parallelism": [[20, "multi-node-tensor-parallelism"]], "Multi Token Prediction": [[15, "Multi-Token-Prediction"]], "Multi-Modal Embedding Model": [[28, "Multi-Modal-Embedding-Model"]], "Multi-Node Deployment": [[58, null], [59, null], [59, null]], "Multi-Node Inference on SLURM": [[58, "multi-node-inference-on-slurm"]], "Multi-Node Profiling and Shared Storage Considerations": [[36, "multi-node-profiling-and-shared-storage-considerations"]], "Multi-Node Setup (2 Nodes)": [[2, "multi-node-setup-2-nodes"]], "Multi-Node Setup with Tensor Parallelism (TP=16)": [[2, "multi-node-setup-with-tensor-parallelism-tp-16"]], "Multi-Rank Synchronization": [[6, "multi-rank-synchronization"]], "Multi-head Latent Attention (MLA) Throughput Optimizations": [[20, "multi-head-latent-attention-mla-throughput-optimizations"]], "Multi-modal Generation": [[54, "Multi-modal-Generation"]], "Multi-node distributed serving": [[14, "multi-node-distributed-serving"]], "Multi-token Prediction": [[20, "multi-token-prediction"], [21, "multi-token-prediction"]], "Multi-turn Dialog": [[54, "Multi-turn-Dialog"]], "Multimodal": [[33, "multimodal"]], "Multimodal Embedding Example": [[65, "multimodal-embedding-example"]], "Multimodal Language Models": [[68, null]], "Multiple-Image Inputs": [[29, "Multiple-Image-Inputs"]], "NIXL": [[10, "nixl"]], "NVIDIA Jetson Orin": [[46, null]], "NVLink Transport Configuration": [[10, "nvlink-transport-configuration"]], "Native API and SGLang Runtime (SRT)": [[16, "Native-API-and-SGLang-Runtime-(SRT)"], [17, "Native-API-and-SGLang-Runtime-(SRT)"], [18, "Native-API-and-SGLang-Runtime-(SRT)"]], "Nest Asyncio": [[25, "Nest-Asyncio"]], "Ngram speculative decoding": [[14, "ngram-speculative-decoding"]], "Non-FP8 (BF16 / full precision) mode": [[32, "non-fp8-bf16-full-precision-mode"]], "Non-Streaming Request": [[13, "Non-Streaming-Request"], [18, "Non-Streaming-Request"]], "Non-streaming Asynchronous Generation": [[25, "Non-streaming-Asynchronous-Generation"]], "Non-streaming Synchronous Generation": [[25, "Non-streaming-Synchronous-Generation"]], "Normal": [[33, "normal"]], "Note on defaults": [[33, "note-on-defaults"]], "Notes": [[22, "notes"], [35, "notes"]], "Observability": [[9, null], [12, "observability"]], "Offline Batch Inference": [[25, "Offline-Batch-Inference"]], "Offline Engine API": [[13, "Offline-Engine-API"], [16, "Offline-Engine-API"], [17, "Offline-Engine-API"], [18, "Offline-Engine-API"], [25, null]], "Offline Quantization": [[11, "offline-quantization"]], "Offloading": [[14, "offloading"]], "Online Quantization": [[11, "online-quantization"]], "OpenAI APIs - Completions": [[27, null]], "OpenAI APIs - Embedding": [[28, null]], "OpenAI APIs - Vision": [[29, null]], "OpenAI Backend Proxy": [[12, "openai-backend-proxy"]], "OpenAI Compatible API": [[13, "OpenAI-Compatible-API"], [16, "OpenAI-Compatible-API"], [17, "OpenAI-Compatible-API"], [18, "OpenAI-Compatible-API"]], "OpenAI-Compatible APIs": [[26, null]], "OpenAI-compatible API usage": [[8, "OpenAI-compatible-API-usage"]], "Optimization/debug options": [[14, "optimization-debug-options"]], "Optimizations": [[20, "optimizations"]], "Optimized Model List": [[45, "optimized-model-list"], [48, "optimized-model-list"]], "Option 1. Use the default dev container automatically from VSCode": [[38, "option-1-use-the-default-dev-container-automatically-from-vscode"]], "Option 2. Start up containers manually (advanced)": [[38, "option-2-start-up-containers-manually-advanced"]], "Other key options": [[35, "other-key-options"]], "Other options": [[33, "other-options"]], "Other tips": [[36, "other-tips"]], "Output Files": [[36, "output-files"]], "Overall Architecture": [[6, "overall-architecture"]], "Overall Workflow": [[6, "overall-workflow"]], "Overview": [[2, "overview"], [12, "overview"], [64, "overview"]], "PD Disaggregation": [[10, null], [21, "pd-disaggregation"]], "PD disaggregation": [[14, "pd-disaggregation"]], "Parallelism": [[54, "Parallelism"]], "Parameters": [[27, "Parameters"], [27, "id3"], [64, "parameters"]], "Penalizers": [[33, "penalizers"]], "Performance Benefits": [[2, "performance-benefits"]], "Performance Highlights": [[15, "Performance-Highlights"]], "Performance Optimization": [[68, "performance-optimization"]], "Performance Tuning": [[50, "performance-tuning"]], "Popular Model Usage (DeepSeeek, GPT-OSS, Llama, Qwen, and more)": [[30, null]], "Port a Model from vLLM to SGLang": [[71, "port-a-model-from-vllm-to-sglang"]], "Possible PyTorch bugs": [[36, "possible-pytorch-bugs"]], "Prefetch Policies": [[5, "prefetch-policies"]], "Prefetch from L3": [[6, "prefetch-from-l3"]], "Prefill": [[57, "prefill"]], "Prefill Server Configuration": [[10, "prefill-server-configuration"]], "Prefill/Decode": [[12, "prefill-decode"]], "Prefill/Decode Disaggregation": [[12, "prefill-decode-disaggregation"]], "Prerequisites": [[35, "prerequisites"], [46, "prerequisites"], [56, "prerequisites"], [61, "prerequisites"]], "Prevent swapping out system memory": [[44, "prevent-swapping-out-system-memory"]], "Production Metrics": [[9, "production-metrics"], [61, null]], "Production Request Tracing": [[62, null]], "Profile": [[38, "profile"]], "Profile Decode Workers": [[36, "profile-decode-workers"]], "Profile In PD Disaggregation Mode": [[36, "profile-in-pd-disaggregation-mode"]], "Profile Prefill Workers": [[36, "profile-prefill-workers"]], "Profile a server with HTTP API endpoints": [[36, "profile-a-server-with-http-api-endpoints"]], "Profile a server with sglang.bench_offline_throughput": [[36, "profile-a-server-with-sglang-bench-offline-throughput"]], "Profile a server with sglang.bench_serving": [[36, "profile-a-server-with-sglang-bench-serving"]], "Profile a server with sglang.profiler": [[36, "profile-a-server-with-sglang-profiler"]], "Profile with Nsight": [[36, "profile-with-nsight"]], "Profile with PyTorch Profiler": [[36, "profile-with-pytorch-profiler"]], "Profiler Trace Merger for Distributed Traces": [[36, "profiler-trace-merger-for-distributed-traces"]], "Profiling & Benchmarking": [[50, "profiling-benchmarking"]], "Profiling in PD Disaggregation Mode": [[10, "profiling-in-pd-disaggregation-mode"]], "PyPI Package Release Process": [[39, null]], "Python API Usage": [[11, "python-api-usage"]], "Python Tool": [[22, "python-tool"]], "Python Version": [[44, "python-version"]], "Pythonic Tool Call Format (Llama-3.2 / Llama-3.3 / Llama-4)": [[18, "Pythonic-Tool-Call-Format-(Llama-3.2-/-Llama-3.3-/-Llama-4)"]], "Pytorch and Pytorch Framework Adaptor on Ascend": [[44, "pytorch-and-pytorch-framework-adaptor-on-ascend"]], "Quantization": [[11, null], [72, "quantization"]], "Quantization and Export Workflow": [[11, "quantization-and-export-workflow"]], "Quantization and data type": [[14, "quantization-and-data-type"]], "Query Vision Language Model": [[19, null]], "Query via the offline Engine API": [[19, "Query-via-the-offline-Engine-API"], [19, "id1"]], "Query via the offline Engine API, but send precomputed embeddings": [[19, "Query-via-the-offline-Engine-API,-but-send-precomputed-embeddings"], [19, "id2"]], "Querying Llama 4 (Vision)": [[19, "Querying-Llama-4-(Vision)"]], "Querying Qwen-VL": [[19, "Querying-Qwen-VL"]], "Quick Demo": [[22, "quick-demo"]], "Quick Start": [[65, "quick-start"]], "Quick start": [[35, "quick-start"]], "Qwen3-30B-A3B (MoE Model)": [[3, "qwen3-30b-a3b-moe-model"]], "Qwen3-8B": [[3, "qwen3-8b"]], "Qwen3-Next Usage": [[31, null]], "Qwen3-VL Usage": [[32, null]], "RDMA RoCE case": [[56, "rdma-roce-case"]], "Rate Limiting & Queuing": [[12, "rate-limiting-queuing"]], "Rate, concurrency, and streaming": [[35, "rate-concurrency-and-streaming"]], "Reasoning Content for DeepSeek R1 & V3.1": [[20, "reasoning-content-for-deepseek-r1-v3-1"]], "Reasoning Parser": [[13, null]], "Reference": [[11, "reference"]], "References": [[2, "references"], [15, "References"], [42, null], [46, "references"]], "Registering an External Model Implementation": [[71, "registering-an-external-model-implementation"]], "Regular expression": [[16, "Regular-expression"], [16, "id3"], [16, "id7"], [17, "Regular-expression"], [17, "id3"], [17, "id7"]], "Related Parameters": [[6, "related-parameters"]], "Reliability & Flow Control": [[12, "reliability-flow-control"]], "Remaining issues": [[56, "remaining-issues"]], "Remote code": [[72, "remote-code"]], "Request Dump and Replay": [[9, "request-dump-and-replay"]], "Request Format": [[64, "request-format"]], "Requesting a review for merge": [[37, "requesting-a-review-for-merge"]], "Requirements": [[10, "requirements"], [10, "id1"]], "Rerank Models": [[69, null]], "Response Fields": [[64, "response-fields"]], "Response Format": [[64, "response-format"]], "Responses API": [[22, "responses-api"]], "Responses API & Built-in Tools": [[22, "responses-api-built-in-tools"]], "Retries": [[12, "retries"]], "Reward Models": [[70, null]], "Reward Models (Single score)": [[64, "reward-models-single-score"]], "RoCE scenario": [[56, "roce-scenario"]], "Router Integration": [[10, "router-integration"]], "Run and add unit tests": [[37, "run-and-add-unit-tests"]], "Running DeepSeek-V3": [[43, "running-deepseek-v3"], [44, "running-deepseek-v3"]], "Running Inference": [[46, "running-inference"]], "Running Llama3.1": [[43, "running-llama3-1"]], "Running examples on Multi-node": [[20, "running-examples-on-multi-node"]], "Running quantization with TorchAO": [[46, "running-quantization-with-torchao"]], "Runtime options": [[14, "runtime-options"]], "SGLang Documentation": [[0, null], [42, null]], "SGLang Frontend Language": [[54, null]], "SGLang HiCache Best Practices": [[5, null]], "SGLang Model Gateway (formerly SGLang Router)": [[12, null]], "SGLang Native API": [[13, "SGLang-Native-API"]], "SGLang Native APIs": [[24, null]], "SGLang Server Options": [[2, "sglang-server-options"]], "SGLang\u2019s Solution": [[3, "sglang-s-solution"]], "Sampling Parameters": [[33, null]], "Sampling parameters": [[33, "id1"]], "Security & Authentication": [[12, "security-authentication"]], "Send Results Back to Model": [[18, "Send-Results-Back-to-Model"]], "Sending Image/Video Requests": [[32, "sending-image-video-requests"]], "Sending Requests": [[34, null]], "Separate Launch (HTTP)": [[12, "separate-launch-http"]], "Server Arguments": [[3, "server-arguments"], [14, null]], "Service Discovery (Kubernetes)": [[12, "service-discovery-kubernetes"]], "Serving Multiple Adaptors": [[8, "Serving-Multiple-Adaptors"]], "Serving Our Model Via SGLang\u2019s Offline Engine": [[71, "serving-our-model-via-sglang-s-offline-engine"]], "Serving Single Adaptor": [[8, "Serving-Single-Adaptor"]], "Set Up Self-Hosted Runners for GitHub Action": [[40, null]], "Setup Docker Container": [[38, "setup-docker-container"]], "Setup Guide": [[61, "setup-guide"], [62, "setup-guide"]], "Setup VSCode on a Remote Host": [[38, "setup-vscode-on-a-remote-host"]], "Single Node Setup": [[2, "single-node-setup"]], "Speculative Decoding": [[15, null]], "Speculative decoding": [[14, "speculative-decoding"]], "Speculative decoding with hybrid attention": [[1, "speculative-decoding-with-hybrid-attention"]], "Step 1: Start a docker container.": [[40, "step-1-start-a-docker-container"]], "Step 2: Configure the runner by config.sh": [[40, "step-2-configure-the-runner-by-config-sh"]], "Step 3: Run the runner by run.sh": [[40, "step-3-run-the-runner-by-run-sh"]], "Steps to add a new attention backend": [[1, "steps-to-add-a-new-attention-backend"]], "Storage & Caching": [[50, "storage-caching"]], "Storage & Privacy": [[12, "storage-privacy"]], "Streaming": [[33, "streaming"], [34, "Streaming"], [34, "id1"], [54, "Streaming"]], "Streaming Asynchronous Generation": [[25, "Streaming-Asynchronous-Generation"]], "Streaming Request": [[13, "Streaming-Request"], [18, "Streaming-Request"]], "Streaming Synchronous Generation": [[25, "Streaming-Synchronous-Generation"]], "Structural Tag": [[16, "Structural-Tag"], [16, "id4"], [16, "id8"], [17, "Structural-Tag"], [17, "id4"]], "Structured Outputs": [[16, null]], "Structured Outputs (JSON, Regex, EBNF)": [[27, "Structured-Outputs-(JSON,-Regex,-EBNF)"], [33, "structured-outputs-json-regex-ebnf"]], "Structured Outputs For Reasoning Models": [[17, null]], "Structured output with XGrammar": [[46, "structured-output-with-xgrammar"]], "Support Matrix": [[1, "support-matrix"]], "Supported Backends": [[3, "supported-backends"]], "Supported Models": [[17, "Supported-Models"], [42, null], [64, "supported-models"], [65, "supported-models"]], "Supported Models & Parsers": [[13, "Supported-Models-&-Parsers"]], "Supported Models and Configuration": [[27, "Supported-Models-and-Configuration"]], "Supported Tool Choice Options": [[18, "Supported-Tool-Choice-Options"]], "Supported backends and endpoints": [[35, "supported-backends-and-endpoints"]], "Supported features": [[72, "supported-features"]], "Supported models": [[66, "supported-models"], [68, "supported-models"], [70, "supported-models"]], "Supported rerank models": [[69, "supported-rerank-models"]], "Supporting New Reasoning Model Schemas": [[13, "Supporting-New-Reasoning-Model-Schemas"]], "System Configuration": [[43, "system-configuration"]], "System Design": [[6, "system-design"]], "System Settings": [[44, "system-settings"]], "TODO": [[56, "todo"]], "TPU": [[47, null]], "Table of Contents": [[12, "table-of-contents"]], "Test the accuracy": [[37, "test-the-accuracy"]], "Testing": [[64, "testing"]], "Testing & Debugging (Internal/CI)": [[50, "testing-debugging-internal-ci"]], "Testing and Debugging": [[71, "testing-and-debugging"]], "The Root Cause of Non-Determinism": [[3, "the-root-cause-of-non-determinism"]], "The results are not deterministic, even with a temperature of 0": [[51, "the-results-are-not-deterministic-even-with-a-temperature-of-0"]], "The server hangs": [[51, "the-server-hangs"]], "Thinking Budget for DeepSeek R1": [[20, "thinking-budget-for-deepseek-r1"]], "Tips for newcomers": [[37, "tips-for-newcomers"]], "Token Length Normalized": [[52, "token-length-normalized"]], "Tokenize/Detokenize Example (Round Trip)": [[24, "Tokenize/Detokenize-Example-(Round-Trip)"]], "Tool & Reasoning Parser": [[22, "tool-reasoning-parser"]], "Tool Choice Mode": [[18, "Tool-Choice-Mode"]], "Tool Parser": [[18, null]], "Transformers fallback in SGLang": [[72, null]], "Triton on Ascend": [[44, "triton-on-ascend"]], "Troubleshooting": [[2, "troubleshooting"], [12, "troubleshooting"], [35, "troubleshooting"], [51, "troubleshooting"], [61, "troubleshooting"]], "Troubleshooting and Frequently Asked Questions": [[51, null]], "Try other options": [[7, "try-other-options"]], "Tune --cuda-graph-max-bs": [[7, "tune-cuda-graph-max-bs"]], "Tune --dp-size and --tp-size": [[7, "tune-dp-size-and-tp-size"]], "Tune --mem-fraction-static to increase KV cache pool capacity": [[7, "tune-mem-fraction-static-to-increase-kv-cache-pool-capacity"]], "Unconditional Likelihood Normalized": [[52, "unconditional-likelihood-normalized"]], "Unified Interfaces and Rich L3 Storage Backends": [[6, "unified-interfaces-and-rich-l3-storage-backends"]], "Update Documentation": [[0, "update-documentation"]], "Update GRUB Settings": [[43, "update-grub-settings"]], "Update Weights From Disk": [[24, "Update-Weights-From-Disk"]], "Update the version in code": [[39, "update-the-version-in-code"]], "Upload the PyPI package": [[39, "upload-the-pypi-package"]], "Usage": [[3, "usage"], [8, "Usage"], [10, "usage"], [10, "id2"], [10, "id5"], [13, "Usage"], [17, "Usage"], [27, "Usage"], [27, "id2"], [61, "usage"]], "Usage Examples": [[2, "usage-examples"]], "Usage Notes": [[68, "usage-notes"]], "Use Models From ModelScope": [[67, null]], "User Guide": [[1, "user-guide"]], "Using --enable-layerwise-nvtx-marker with Nsight Systems and /start_profile": [[36, "using-enable-layerwise-nvtx-marker-with-nsight-systems-and-start-profile"]], "Using /end_profile endpoint": [[36, "using-end-profile-endpoint"]], "Using /start_profile endpoint": [[36, "using-start-profile-endpoint"]], "Using GPTQModel": [[11, "using-gptqmodel"]], "Using Input IDs": [[28, "Using-Input-IDs"]], "Using LLM Compressor": [[11, "using-llm-compressor"]], "Using LoRA Adapters": [[27, "Using-LoRA-Adapters"]], "Using NVIDIA ModelOpt": [[11, "using-nvidia-modelopt"]], "Using Native Generation APIs": [[34, "Using-Native-Generation-APIs"]], "Using OpenAI Python Client": [[28, "Using-OpenAI-Python-Client"], [29, "Using-OpenAI-Python-Client"], [34, "Using-OpenAI-Python-Client"]], "Using Python": [[64, "using-python"]], "Using Python Requests": [[28, "Using-Python-Requests"], [29, "Using-Python-Requests"], [34, "Using-Python-Requests"]], "Using auto-round": [[11, "using-auto-round"]], "Using cURL": [[28, "Using-cURL"], [29, "Using-cURL"], [34, "Using-cURL"]], "Using curl": [[64, "using-curl"]], "Verification": [[3, "verification"]], "Video Input Support": [[68, "video-input-support"]], "Video Input:": [[32, "video-input"]], "View traces": [[36, "view-traces"]], "Warmup Step": [[43, "warmup-step"]], "Web Search Tool": [[22, "web-search-tool"]], "What it does": [[35, "what-it-does"]], "Why Deterministic Inference Matters": [[3, "why-deterministic-inference-matters"]], "Why HiCache Matters": [[5, "why-hicache-matters"]], "Why and What is HiCache?": [[6, "why-and-what-is-hicache"]], "Why and What is PD Disaggregation?": [[10, "why-and-what-is-pd-disaggregation"]], "Worker Lifecycle & Dynamic Scaling": [[12, "worker-lifecycle-dynamic-scaling"]], "Write documentations": [[37, "write-documentations"]], "XPU": [[48, null]], "gRPC Launch": [[12, "grpc-launch"]], "v1/rerank (cross encoder rerank model)": [[24, "v1/rerank-(cross-encoder-rerank-model)"]], "vLLM": [[44, "vllm"]]}, "docnames": ["README", "advanced_features/attention_backend", "advanced_features/checkpoint_engine", "advanced_features/deterministic_inference", "advanced_features/hicache", "advanced_features/hicache_best_practices", "advanced_features/hicache_design", "advanced_features/hyperparameter_tuning", "advanced_features/lora", "advanced_features/observability", "advanced_features/pd_disaggregation", "advanced_features/quantization", "advanced_features/router", "advanced_features/separate_reasoning", "advanced_features/server_arguments", "advanced_features/speculative_decoding", "advanced_features/structured_outputs", "advanced_features/structured_outputs_for_reasoning_models", "advanced_features/tool_parser", "advanced_features/vlm_query", "basic_usage/deepseek_v3", "basic_usage/deepseek_v32", "basic_usage/gpt_oss", "basic_usage/llama4", "basic_usage/native_api", "basic_usage/offline_engine_api", "basic_usage/openai_api", "basic_usage/openai_api_completions", "basic_usage/openai_api_embeddings", "basic_usage/openai_api_vision", "basic_usage/popular_model_usage", "basic_usage/qwen3", "basic_usage/qwen3_vl", "basic_usage/sampling_params", "basic_usage/send_request", "developer_guide/bench_serving", "developer_guide/benchmark_and_profiling", "developer_guide/contribution_guide", "developer_guide/development_guide_using_docker", "developer_guide/release_process", "developer_guide/setup_github_runner", "get_started/install", "index", "platforms/amd_gpu", "platforms/ascend_npu", "platforms/cpu_server", "platforms/nvidia_jetson", "platforms/tpu", "platforms/xpu", "references/custom_chat_template", "references/environment_variables", "references/faq", "references/frontend/choices_methods", "references/frontend/frontend_index", "references/frontend/frontend_tutorial", "references/learn_more", "references/multi_node_deployment/deploy_on_k8s", "references/multi_node_deployment/lws_pd/lws_pd_deploy", "references/multi_node_deployment/multi_node", "references/multi_node_deployment/multi_node_index", "references/multi_node_deployment/rbg_pd/deepseekv32_pd", "references/production_metrics", "references/production_request_trace", "references/torch_compile_cache", "supported_models/classify_models", "supported_models/embedding_models", "supported_models/generative_models", "supported_models/modelscope", "supported_models/multimodal_language_models", "supported_models/rerank_models", "supported_models/reward_models", "supported_models/support_new_models", "supported_models/transformers_fallback"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["README.md", "advanced_features/attention_backend.md", "advanced_features/checkpoint_engine.md", "advanced_features/deterministic_inference.md", "advanced_features/hicache.rst", "advanced_features/hicache_best_practices.md", "advanced_features/hicache_design.md", "advanced_features/hyperparameter_tuning.md", "advanced_features/lora.ipynb", "advanced_features/observability.md", "advanced_features/pd_disaggregation.md", "advanced_features/quantization.md", "advanced_features/router.md", "advanced_features/separate_reasoning.ipynb", "advanced_features/server_arguments.md", "advanced_features/speculative_decoding.ipynb", "advanced_features/structured_outputs.ipynb", "advanced_features/structured_outputs_for_reasoning_models.ipynb", "advanced_features/tool_parser.ipynb", "advanced_features/vlm_query.ipynb", "basic_usage/deepseek_v3.md", "basic_usage/deepseek_v32.md", "basic_usage/gpt_oss.md", "basic_usage/llama4.md", "basic_usage/native_api.ipynb", "basic_usage/offline_engine_api.ipynb", "basic_usage/openai_api.rst", "basic_usage/openai_api_completions.ipynb", "basic_usage/openai_api_embeddings.ipynb", "basic_usage/openai_api_vision.ipynb", "basic_usage/popular_model_usage.rst", "basic_usage/qwen3.md", "basic_usage/qwen3_vl.md", "basic_usage/sampling_params.md", "basic_usage/send_request.ipynb", "developer_guide/bench_serving.md", "developer_guide/benchmark_and_profiling.md", "developer_guide/contribution_guide.md", "developer_guide/development_guide_using_docker.md", "developer_guide/release_process.md", "developer_guide/setup_github_runner.md", "get_started/install.md", "index.rst", "platforms/amd_gpu.md", "platforms/ascend_npu.md", "platforms/cpu_server.md", "platforms/nvidia_jetson.md", "platforms/tpu.md", "platforms/xpu.md", "references/custom_chat_template.md", "references/environment_variables.md", "references/faq.md", "references/frontend/choices_methods.md", "references/frontend/frontend_index.rst", "references/frontend/frontend_tutorial.ipynb", "references/learn_more.md", "references/multi_node_deployment/deploy_on_k8s.md", "references/multi_node_deployment/lws_pd/lws_pd_deploy.md", "references/multi_node_deployment/multi_node.md", "references/multi_node_deployment/multi_node_index.rst", "references/multi_node_deployment/rbg_pd/deepseekv32_pd.md", "references/production_metrics.md", "references/production_request_trace.md", "references/torch_compile_cache.md", "supported_models/classify_models.md", "supported_models/embedding_models.md", "supported_models/generative_models.md", "supported_models/modelscope.md", "supported_models/multimodal_language_models.md", "supported_models/rerank_models.md", "supported_models/reward_models.md", "supported_models/support_new_models.md", "supported_models/transformers_fallback.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 37, 38, 41, 43, 44, 46, 52, 54, 56, 61, 62, 64, 65, 66, 68, 69, 72], "0": [0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 46, 48, 50, 54, 56, 58, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72], "00": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54, 56, 58], "000": [17, 21, 37, 42], "0000": [7, 56], "00001": 11, "00002962350845336914": 28, "00004738569259643555": 28, "00005257129669189453": 28, "00006532669067382812": 28, "00008237361907958984": 28, "0000928044319152832": 28, "0000998377799987793": 28, "0001": 56, "00010514259338378906": 28, "0001322031021118164": 28, "00013875961303710938": 28, "00014603137969970703": 28, "0001493692398071289": 28, "0001697540283203125": 28, "00017774105072021484": 28, "00018644332885742188": 28, "0001951456069946289": 28, "0002028942108154297": 28, "0002053976058959961": 28, "00021159648895263672": 28, "00021409988403320312": 28, "00023102760314941406": [24, 28], "0002351999282836914": 28, "00025582313537597656": 28, "0002701282501220703": 28, "00027441978454589844": 28, "00029540061950683594": 28, "0003": 15, "00031065940856933594": 28, "00032067298889160156": 28, "0003418922424316406": 28, "0003495216369628906": 28, "00035071372985839844": 28, "0003693103790283203": 28, "0003848075866699219": 28, "00039005279541015625": 28, "0003972053527832031": 28, "0004031658172607422": 28, "00040984153747558594": 28, "0004382133483886719": 28, "0004413127899169922": 28, "00044417381286621094": 28, "0004513263702392578": 28, "0004620552062988281": 28, "0005130767822265625": 28, "0005335807800292969": 28, "0005621910095214844": 28, "0005698204040527344": 28, "0005784034729003906": 28, "0006489753723144531": 28, "0006608963012695312": 28, "0006771087646484375": 28, "0006952285766601562": 28, "0007076263427734375": 28, "0007262229919433594": 28, "000728607177734375": 28, "0007519721984863281": 28, "0007572174072265625": 28, "0007658004760742188": 28, "0007991790771484375": 28, "0008139610290527344": 28, "0008296966552734375": 28, "0008397102355957031": 28, "0008406639099121094": 28, "0008764266967773438": 28, "0009050369262695312": 28, "0009250640869140625": 28, "0009288787841796875": 28, "0009407997131347656": 28, "0009546279907226562": 28, "0009584426879882812": 28, "0009703636169433594": 28, "000988006591796875": 28, "0009918212890625": 28, "001": [57, 60, 61], "0010013580322265625": 28, "0010061264038085938": 28, "0010251998901367188": 28, "0010318756103515625": 28, "0010385513305664062": 28, "0010423660278320312": 28, "001056671142578125": 28, "0010623931884765625": 28, "0010852813720703125": 28, "0010995864868164062": 28, "0011196136474609375": 28, "0011234283447265625": 28, "0011415481567382812": 28, "0011529922485351562": 28, "0011587142944335938": 28, "001186370849609375": 28, "0011911392211914062": 28, "0011949539184570312": 28, "00119781494140625": 28, "0012035369873046875": 28, "00121307373046875": 28, "0012311935424804688": 28, "0012607574462890625": 28, "0012693405151367188": 28, "0012760162353515625": 28, "0012845993041992188": 28, "0012979507446289062": 28, "0013246536254882812": 28, "001338958740234375": 28, "0013513565063476562": 28, "001354217529296875": 28, "0013570785522460938": 28, "0013742446899414062": 28, "001377105712890625": 28, "0013799667358398438": 28, "0013914108276367188": 28, "0014181137084960938": 28, "001422882080078125": 28, "0014295578002929688": 28, "0014467239379882812": 28, "0014743804931640625": 28, "0014867782592773438": 28, "0014982223510742188": 28, "0015039443969726562": 28, "0015106201171875": 28, "001552581787109375": 28, "0015573501586914062": 28, "0015630722045898438": 28, "0015840530395507812": 28, "00159454345703125": 28, "0016031265258789062": 28, "0016222000122070312": 28, "0016231536865234375": 28, "0016326904296875": 28, "0016994476318359375": 28, "0017156600952148438": 28, "0017194747924804688": 28, "001720428466796875": 28, "0017271041870117188": 28, "0017423629760742188": 28, "0017652511596679688": 28, "0017824172973632812": 28, "00179290771484375": 28, "001811981201171875": 28, "0018157958984375": 28, "0018186569213867188": 28, "0018243789672851562": 28, "0018367767333984375": 28, "0018520355224609375": 28, "0018749237060546875": 28, "0018901824951171875": 28, "0019025802612304688": 28, "0019130706787109375": 28, "0019359588623046875": 28, "0019464492797851562": 28, "001983642578125": 28, "0019989013671875": 28, "002": [13, 14, 16, 17, 18, 19, 24, 25], "00201416015625": 28, "002033233642578125": 28, "0020389556884765625": 28, "0020427703857421875": 28, "002044677734375": 28, "0020751953125": 28, "0020847320556640625": 28, "0021038055419921875": 28, "0021190643310546875": 28, "002124786376953125": 28, "00214385986328125": 28, "0021457672119140625": 28, "00217437744140625": 28, "002193450927734375": 28, "0021953582763671875": 28, "0022068023681640625": 28, "0022106170654296875": 28, "0022411346435546875": 28, "0022487640380859375": 28, "0022735595703125": 28, "002288818359375": 28, "0023021697998046875": 28, "0023040771484375": 28, "002338409423828125": 28, "002349853515625": 28, "0023708343505859375": 28, "0023746490478515625": 28, "00238800048828125": 28, "0024089813232421875": 28, "002460479736328125": 28, "0024623870849609375": 28, "0024738311767578125": 28, "002513885498046875": 28, "0025234222412109375": 28, "0025348663330078125": 28, "0025424957275390625": 28, "0025730133056640625": 28, "0025844573974609375": 28, "0025882720947265625": 28, "00261688232421875": 28, "0026378631591796875": 28, "0026416778564453125": 28, "00264739990234375": 28, "0026607513427734375": 28, "00270843505859375": 28, "002750396728515625": 28, "002765655517578125": 28, "00276947021484375": 28, "0027828216552734375": 28, "0027980804443359375": 28, "002826690673828125": 28, "002838134765625": 28, "0028438568115234375": 28, "002849578857421875": 28, "0028591156005859375": 28, "002864837646484375": 28, "00286865234375": 28, "002918243408203125": 28, "0029296875": 28, "0029582977294921875": 28, "0029697418212890625": 28, "00298309326171875": 28, "0029964447021484375": 28, "0030002593994140625": 28, "00301361083984375": 28, "0030498504638671875": 28, "0030574798583984375": 28, "0030612945556640625": 28, "003070831298828125": 28, "00307464599609375": 28, "0030803680419921875": 28, "003086090087890625": 28, "00308990478515625": 28, "0030918121337890625": 28, "003139495849609375": 28, "0031452178955078125": 28, "0031528472900390625": 28, "003154754638671875": 28, "0031948089599609375": 28, "003215789794921875": 28, "00322723388671875": 28, "0032444000244140625": 28, "0032711029052734375": [24, 28], "00328826904296875": 28, "003307342529296875": 28, "0033359527587890625": 28, "0033473968505859375": 28, "003353118896484375": 28, "00336456298828125": 28, "0033740997314453125": 28, "0033931732177734375": 28, "0034122467041015625": 28, "00342559814453125": 28, "0034503936767578125": 28, "0034637451171875": 28, "00347137451171875": 28, "003475189208984375": 28, "00350189208984375": 28, "0035037994384765625": 28, "003520965576171875": 28, "003574371337890625": 28, "003582000732421875": 28, "0036029815673828125": 28, "0036106109619140625": 28, "003631591796875": 28, "0036411285400390625": 28, "0036945343017578125": 28, "003711700439453125": 28, "0037212371826171875": 28, "0037288665771484375": 28, "0037326812744140625": 28, "003742218017578125": 28, "003753662109375": 28, "0037593841552734375": 28, "0037841796875": 28, "0037975311279296875": 28, "0038051605224609375": 28, "0038089752197265625": 28, "00382232666015625": 28, "003833770751953125": 28, "003917694091796875": 28, "00394439697265625": 28, "003948211669921875": 28, "003963470458984375": 28, "003971099853515625": 28, "003978729248046875": 28, "0039825439453125": 28, "003986358642578125": 28, "003993988037109375": 28, "00400543212890625": 28, "004016876220703125": 28, "004024505615234375": 28, "0040435791015625": 28, "00405120849609375": 28, "0040740966796875": 28, "004100799560546875": 28, "004123687744140625": 28, "004150390625": 28, "00415802001953125": 28, "004161834716796875": 28, "00417327880859375": 28, "004184722900390625": 28, "0041961669921875": 28, "004207611083984375": 28, "00424957275390625": 28, "004276275634765625": 28, "004283905029296875": 28, "0042877197265625": 28, "004390716552734375": 28, "00440216064453125": 28, "004413604736328125": 28, "004497528076171875": 28, "004512786865234375": 28, "0045318603515625": 28, "0045623779296875": 28, "00457000732421875": 28, "0045928955078125": 28, "00463104248046875": 28, "004642486572265625": 28, "00466156005859375": 28, "004665374755859375": 28, "004680633544921875": 28, "004688262939453125": 28, "00469207763671875": 28, "004695892333984375": 28, "00469970703125": 28, "0047149658203125": 28, "004726409912109375": 28, "0047607421875": 28, "004810333251953125": 28, "0048370361328125": 28, "00484466552734375": 28, "00487518310546875": 28, "004878997802734375": 28, "00493621826171875": 28, "0049591064453125": 28, "00496673583984375": 28, "004970550537109375": 28, "004974365234375": 28, "004985809326171875": 28, "005": 61, "0050048828125": 28, "005008697509765625": 28, "005023956298828125": 28, "005035400390625": 28, "005039215087890625": 28, "0050811767578125": 28, "005096435546875": 28, "005107879638671875": 28, "00513458251953125": 28, "005161285400390625": 28, "00521087646484375": 28, "005222320556640625": 28, "005237579345703125": 28, "00524139404296875": 28, "00525665283203125": 28, "005260467529296875": 28, "00527191162109375": 28, "00531005859375": 28, "005397796630859375": 28, "005405426025390625": 28, "00540924072265625": 28, "0054168701171875": 28, "00543975830078125": 28, "0054473876953125": 28, "00545501708984375": 28, "0054779052734375": 28, "00551605224609375": 28, "005519866943359375": 28, "005527496337890625": 28, "0055389404296875": 28, "005588531494140625": 28, "0055999755859375": 28, "00560760498046875": 28, "005626678466796875": 28, "005634307861328125": 28, "005657196044921875": 28, "00566864013671875": 28, "00569915771484375": 28, "0057220458984375": 28, "005725860595703125": 28, "005767822265625": 28, "0057830810546875": 28, "005794525146484375": 28, "00579833984375": 28, "00580596923828125": 28, "00583648681640625": 28, "005840301513671875": 28, "005847930908203125": 28, "005855560302734375": 28, "005859375": 28, "005878448486328125": 28, "005886077880859375": 28, "005893707275390625": 28, "0059051513671875": [24, 28], "00594329833984375": 28, "005962371826171875": 28, "005970001220703125": 28, "005992889404296875": 28, "00600433349609375": 28, "0060272216796875": 28, "00604248046875": 28, "00605010986328125": 28, "0060577392578125": 28, "006076812744140625": 28, "00611114501953125": 28, "006134033203125": 28, "006137847900390625": 28, "006145477294921875": 28, "0061492919921875": 28, "006160736083984375": 28, "00616455078125": 28, "006168365478515625": 28, "006175994873046875": 28, "00620269775390625": 28, "0062255859375": 28, "006229400634765625": 28, "0062408447265625": 28, "006256103515625": 28, "006259918212890625": 28, "006275177001953125": 28, "0063323974609375": 28, "00637054443359375": 28, "006374359130859375": 28, "00640106201171875": 28, "006420135498046875": 28, "006435394287109375": 28, "006450653076171875": 28, "0064544677734375": 28, "006465911865234375": 28, "006504058837890625": 28, "0065155029296875": 28, "006534576416015625": 28, "006542205810546875": 28, "0065765380859375": 28, "006580352783203125": 28, "00658416748046875": 28, "006587982177734375": 28, "006595611572265625": 28, "006618499755859375": 28, "006626129150390625": 28, "006633758544921875": 28, "006664276123046875": 28, "006687164306640625": 28, "00669097900390625": 28, "0066986083984375": 28, "006710052490234375": 28, "006717681884765625": 28, "00673675537109375": 28, "006755828857421875": 28, "00676727294921875": 28, "00679779052734375": 28, "006816864013671875": 28, "006908416748046875": 28, "006916046142578125": 28, "006923675537109375": 28, "006969451904296875": 28, "00698089599609375": 28, "006999969482421875": 28, "007007598876953125": 28, "007022857666015625": 28, "0070343017578125": 28, "00704193115234375": 28, "007106781005859375": 28, "007110595703125": 28, "007137298583984375": 28, "00717926025390625": 28, "007228851318359375": 28, "0072479248046875": 28, "00725555419921875": 28, "007289886474609375": 28, "007305145263671875": 28, "0073089599609375": 28, "00731658935546875": 28, "00733184814453125": 28, "00734710693359375": 28, "007373809814453125": 28, "00739288330078125": 28, "0074005126953125": 28, "00740814208984375": 28, "0074310302734375": 28, "007457733154296875": 28, "007465362548828125": 28, "00748443603515625": 28, "0074920654296875": 28, "00749969482421875": 28, "007507552643049313": 61, "007518768310546875": 28, "007534027099609375": 28, "0075531005859375": 28, "00759124755859375": 28, "00763702392578125": 28, "007678985595703125": 28, "007709503173828125": 28, "007720947265625": 28, "0077362060546875": 28, "00775146484375": 28, "007755279541015625": 28, "007778167724609375": 28, "007793426513671875": 28, "0077972412109375": 28, "00782012939453125": 28, "0078277587890625": 28, "00783538818359375": 28, "007843017578125": 28, "0078582763671875": 28, "007904052734375": 28, "0079193115234375": 28, "00794219970703125": 28, "007965087890625": 28, "00799560546875": 28, "00803375244140625": 28, "00807952880859375": 28, "00809478759765625": 28, "00811767578125": 28, "0081329345703125": 28, "0081634521484375": 28, "0081787109375": 28, "00820159912109375": 28, "00821685791015625": 28, "00824737548828125": 28, "0082550048828125": 28, "00826263427734375": 28, "0082855224609375": 28, "00829315185546875": 28, "00833892822265625": 28, "0083465576171875": 28, "00835418701171875": 28, "00836944580078125": 28, "0083770751953125": 28, "00838470458984375": 28, "0084228515625": 28, "00843048095703125": 28, "0084381103515625": 28, "00844573974609375": 28, "008453369140625": 28, "00847625732421875": 28, "008514404296875": 28, "0085296630859375": 28, "008544921875": 28, "00855255126953125": 28, "0085601806640625": 28, "00856781005859375": 28, "008575439453125": 28, "00860595703125": 28, "0086212158203125": 28, "0086669921875": 28, "0086822509765625": 28, "00868988037109375": 28, "008697509765625": 28, "00872039794921875": 28, "00872802734375": 28, "00873565673828125": 28, "0087432861328125": 28, "00878143310546875": 28, "00879669189453125": 28, "00881195068359375": 28, "008819580078125": 28, "00882720947265625": 28, "00884246826171875": 28, "00885772705078125": 28, "0088958740234375": 28, "0089111328125": 28, "0089263916015625": 28, "00893402099609375": 28, "00896453857421875": 28, "00897979736328125": 28, "009002685546875": 28, "0090179443359375": 28, "00902557373046875": 28, "00905609130859375": 28, "009063720703125": 28, "00907135009765625": 28, "0091094970703125": 28, "00911712646484375": 28, "00913238525390625": 28, "00914764404296875": 28, "00916290283203125": 28, "0091705322265625": 28, "00919342041015625": 28, "0092010498046875": 28, "00923919677734375": 28, "009246826171875": 28, "00925445556640625": 28, "00930023193359375": 28, "0093536376953125": 28, "00936126708984375": 28, "00939178466796875": 28, "0093994140625": 28, "00945281982421875": 28, "00946044921875": 28, "00948333740234375": 28, "009490966796875": 28, "00952911376953125": 28, "0095367431640625": 28, "00954437255859375": 28, "0095672607421875": 28, "00958251953125": 28, "00960540771484375": 28, "009613037109375": 28, "009674072265625": 28, "00968170166015625": 28, "0096893310546875": 28, "00970458984375": 28, "00975799560546875": 28, "00978851318359375": 28, "00980377197265625": 28, "00981903076171875": 28, "00982666015625": 28, "00983428955078125": 28, "009857177734375": 28, "00986480712890625": 28, "00988006591796875": 28, "00994110107421875": 28, "00995635986328125": 28, "01": [7, 8, 13, 15, 16, 17, 18, 19, 24, 28, 29, 54, 56, 61], "0100250244140625": 28, "010040283203125": 28, "010101318359375": 28, "01010894775390625": 28, "0101165771484375": 28, "0101318359375": 28, "01013946533203125": 28, "01015472412109375": 28, "010162353515625": 28, "01018524169921875": 28, "01019287109375": 28, "0102081298828125": 28, "010223388671875": 28, "0102386474609375": 28, "01024": 11, "01025390625": 28, "01026153564453125": 28, "0102691650390625": 28, "01031494140625": 28, "0103302001953125": 28, "010345458984375": 28, "01035308837890625": 28, "01038360595703125": 28, "0104522705078125": 28, "010467529296875": 28, "01052093505859375": 28, "01053619384765625": 28, "0105438232421875": 28, "0105743408203125": 28, "01058197021484375": 28, "01064300537109375": 28, "01065826416015625": 28, "0106658935546875": 28, "01068115234375": 28, "01068878173828125": 28, "010711669921875": 28, "0107269287109375": 28, "0107421875": 28, "01074981689453125": 28, "010772705078125": 28, "01078033447265625": 28, "01079559326171875": 28, "01080322265625": 28, "0108184814453125": 28, "01084136962890625": 28, "0108489990234375": 28, "0108795166015625": 28, "010894775390625": 28, "01097869873046875": 28, "01099395751953125": 28, "01100921630859375": 28, "011016845703125": 28, "0110321044921875": 28, "0110626220703125": 28, "011077880859375": [24, 28], "01110076904296875": 28, "0111083984375": 28, "01113128662109375": 28, "01114654541015625": 28, "0111846923828125": 28, "01119232177734375": 28, "01123046875": 28, "01123809814453125": 28, "0112457275390625": 28, "0112762451171875": 28, "01129913330078125": 28, "01131439208984375": 28, "01132965087890625": 28, "0113372802734375": 28, "0113525390625": 28, "01136016845703125": 28, "0113677978515625": 28, "01137542724609375": 28, "011383056640625": 28, "0113983154296875": 28, "01141357421875": 28, "01143646240234375": 28, "011444091796875": 28, "01145172119140625": 28, "011474609375": 28, "0114898681640625": 28, "011505126953125": 28, "01151275634765625": 28, "0115203857421875": 28, "01152801513671875": 28, "01153564453125": 28, "0115814208984375": 28, "01158905029296875": 28, "0115966796875": 28, "0116119384765625": 28, "011627197265625": 28, "01171875": 28, "01175689697265625": 28, "01177978515625": 28, "01178741455078125": 28, "01180267333984375": 28, "01184844970703125": 28, "0118560791015625": 28, "01189422607421875": 28, "01190948486328125": 28, "0119476318359375": 28, "01195526123046875": 28, "011962890625": 28, "01198577880859375": 28, "01200103759765625": 28, "0120391845703125": 28, "01207733154296875": 28, "0120849609375": 28, "01210784912109375": 28, "01212310791015625": 28, "01213836669921875": 28, "01214599609375": 28, "0121612548828125": 28, "01218414306640625": 28, "0121917724609375": 28, "01219940185546875": 28, "01220703125": 28, "01224517822265625": 28, "01226806640625": 28, "012298583984375": 28, "0123291015625": 28, "012359619140625": 28, "0123748779296875": 28, "01241302490234375": 28, "012420654296875": 28, "012451171875": 28, "01247406005859375": 28, "01248931884765625": 28, "0125274658203125": 28, "01253509521484375": 28, "012542724609375": 28, "0125579833984375": 28, "01256561279296875": 28, "01259613037109375": 28, "012603759765625": 28, "01262664794921875": 28, "01263427734375": 28, "01264190673828125": 28, "01276397705078125": 28, "012786865234375": 28, "01280975341796875": 28, "0128326416015625": 28, "01285552978515625": 28, "01287078857421875": 28, "01287841796875": 28, "0128936767578125": 28, "012908935546875": 28, "01300811767578125": 28, "0130157470703125": 28, "01302337646484375": 28, "01303863525390625": 28, "0130462646484375": 28, "01305389404296875": 28, "01308441162109375": 28, "01312255859375": 28, "01317596435546875": 28, "01320648193359375": 28, "01325225830078125": 28, "01326751708984375": 28, "01328277587890625": 28, "0132904052734375": 28, "0133056640625": 28, "01332855224609375": 28, "0133514404296875": 28, "01335906982421875": 28, "01336669921875": 28, "01340484619140625": 28, "01346588134765625": 28, "01348114013671875": 28, "01349639892578125": 28, "0135040283203125": 28, "01355743408203125": 28, "01360321044921875": 28, "01361083984375": 28, "0136260986328125": 28, "01364898681640625": 28, "01367950439453125": 28, "01371002197265625": 28, "0137176513671875": 28, "01372528076171875": 28, "01373291015625": 28, "01374053955078125": 28, "013763427734375": 28, "0137786865234375": 28, "0138092041015625": 28, "01381683349609375": 28, "01384735107421875": 28, "01386260986328125": 28, "01389312744140625": 28, "01392364501953125": 28, "0139312744140625": 28, "013946533203125": 28, "01397705078125": 28, "0140228271484375": 28, "0140533447265625": [24, 28], "0140838623046875": 28, "01409912109375": 28, "01412200927734375": 28, "014129638671875": 28, "0141448974609375": 28, "01415252685546875": 28, "01418304443359375": 28, "0142059326171875": 28, "0142364501953125": 28, "01427459716796875": 28, "014312744140625": 28, "0143280029296875": 28, "0143585205078125": 28, "014373779296875": 28, "01441192626953125": [24, 28], "01442718505859375": 28, "01445770263671875": 28, "0144805908203125": 28, "014495849609375": 28, "0145111083984375": 28, "0145263671875": 28, "01454925537109375": 28, "01456451416015625": 28, "01457977294921875": 28, "014617919921875": 28, "0146484375": 28, "0146636962890625": 28, "014678955078125": 28, "0146942138671875": 28, "01470184326171875": 28, "01471710205078125": 28, "01473236083984375": 28, "0147857666015625": 28, "0148162841796875": 28, "01483154296875": 28, "0148468017578125": 28, "01488494873046875": 28, "01490020751953125": 28, "01491546630859375": 28, "01495361328125": 28, "0149993896484375": 28, "015": 61, "0150146484375": 28, "01505279541015625": 28, "01506805419921875": 28, "01509857177734375": 28, "01513671875": 28, "0151519775390625": 28, "01519012451171875": 28, "01520538330078125": 28, "01522064208984375": 28, "01523590087890625": 28, "01525115966796875": 28, "0152740478515625": 28, "01531982421875": 28, "01535797119140625": 28, "01540374755859375": 28, "01541900634765625": 28, "0154266357421875": 28, "01544189453125": 28, "015472412109375": 28, "0154876708984375": 28, "01551055908203125": 28, "01557159423828125": 28, "01558685302734375": 28, "0156097412109375": 28, "0156707763671875": 28, "01568603515625": 28, "015716552734375": 28, "0157318115234375": 28, "0157470703125": 28, "015777587890625": 28, "0157928466796875": 28, "015838623046875": 28, "0158538818359375": 28, "015869140625": 28, "0158843994140625": 28, "015899658203125": 28, "0159149169921875": 28, "015960693359375": 28, "0159759521484375": 28, "0159912109375": [24, 28], "0160064697265625": 28, "016021728515625": 28, "0160675048828125": 28, "0160980224609375": 28, "016143798828125": 28, "01617431640625": 28, "0161895751953125": 28, "016265869140625": 28, "016326904296875": 28, "016357421875": 28, "016448974609375": 28, "016510009765625": 28, "0165252685546875": 28, "0166015625": 28, "0166168212890625": 28, "016632080078125": 28, "0166778564453125": 28, "016693115234375": 28, "0167236328125": 28, "0167388916015625": 28, "0167694091796875": 28, "01678466796875": 28, "016815185546875": 28, "0168304443359375": 28, "016845703125": 28, "0168609619140625": 28, "016876220703125": 28, "016937255859375": 28, "0169677734375": 28, "016998291015625": 28, "0170745849609375": 28, "01708984375": 28, "0171966552734375": 28, "0172119140625": 28, "0172271728515625": 28, "017242431640625": 28, "0172882080078125": 28, "017333984375": 28, "017364501953125": 28, "0173797607421875": 28, "0174102783203125": 28, "0174560546875": 28, "017486572265625": 28, "0175018310546875": 28, "01751708984375": 28, "0175323486328125": 28, "0175628662109375": 28, "017578125": 28, "0176239013671875": 28, "01763916015625": 28, "0176849365234375": 28, "0177001953125": 28, "017730712890625": 28, "0177764892578125": 28, "0178070068359375": 28, "0178375244140625": 28, "017852783203125": 28, "01788330078125": 28, "0178985595703125": 28, "017913818359375": 28, "0179290771484375": 28, "0180816650390625": 28, "01812744140625": 28, "018157958984375": 28, "0181732177734375": 28, "018218994140625": 28, "0182342529296875": 28, "01824951171875": 28, "018280029296875": 28, "0183258056640625": 28, "01837158203125": 28, "018402099609375": 28, "0184173583984375": 28, "0184326171875": 28, "018463134765625": 28, "0185394287109375": 28, "0185546875": 28, "018585205078125": 28, "0186004638671875": 28, "018707275390625": 28, "01873779296875": 28, "0187530517578125": 28, "018768310546875": 28, "0188446044921875": 28, "018890380859375": 28, "0189208984375": 28, "0189361572265625": 28, "018951416015625": 28, "0189666748046875": 28, "01898193359375": 28, "019012451171875": 28, "01904296875": 28, "019073486328125": 28, "01910400390625": 28, "019134521484375": 28, "0192413330078125": 28, "01934814453125": 28, "0193634033203125": 28, "0193939208984375": 28, "0194854736328125": 28, "01953125": 28, "0196075439453125": 28, "019622802734375": 28, "0196533203125": 28, "019683837890625": 28, "0196990966796875": 28, "01971435546875": 28, "019775390625": 28, "0198211669921875": 28, "0198516845703125": 28, "019927978515625": 28, "019989013671875": 28, "01it": 15, "02": [8, 13, 15, 16, 17, 18, 24, 25, 28, 29, 34, 54, 56, 61], "0200": 56, "0200042724609375": 28, "020050048828125": 28, "0200653076171875": 28, "020111083984375": 28, "020172119140625": 28, "0202178955078125": 28, "020233154296875": 28, "02032470703125": 28, "0203399658203125": 28, "0204315185546875": 28, "02044677734375": 28, "020477294921875": 28, "0205535888671875": 28, "02056884765625": 28, "0206298828125": 28, "0207061767578125": 28, "020721435546875": 28, "0207977294921875": 28, "02081298828125": 28, "0208282470703125": 28, "020843505859375": 28, "0208587646484375": 28, "0208740234375": 28, "0208892822265625": 28, "0209503173828125": 28, "0210418701171875": 28, "02117919921875": 28, "0211944580078125": 28, "021209716796875": 28, "0212249755859375": 28, "0212860107421875": 28, "0213470458984375": 28, "021392822265625": 28, "02142333984375": 28, "0214385986328125": 28, "021453857421875": 28, "021484375": 28, "021514892578125": 28, "0215301513671875": 28, "0215451717376709": 16, "0215911865234375": 28, "0216": 15, "0216522216796875": 28, "02166748046875": 28, "0216827392578125": 28, "0217132568359375": 28, "0217742919921875": 28, "0218": 15, "0218353271484375": 28, "0218658447265625": 28, "021881103515625": 28, "0219573974609375": 28, "0219879150390625": 28, "02203369140625": 28, "0222015380859375": 28, "022216796875": 28, "0222625732421875": 28, "0222930908203125": 28, "0223236083984375": 28, "0224456787109375": 28, "0224761962890625": 28, "022491455078125": 28, "0225": 56, "0226": 15, "02264404296875": 28, "022735595703125": 28, "0228424072265625": [24, 28], "022857666015625": 28, "0229": 15, "022918701171875": 28, "0229949951171875": 28, "023": 65, "023040771484375": 28, "0230712890625": 28, "0231170654296875": 28, "02313232421875": 28, "0231475830078125": 28, "023162841796875": 28, "0232391357421875": 28, "0232696533203125": 28, "0233": 15, "0233306884765625": 28, "0233612060546875": 28, "0235137939453125": 28, "0235748291015625": 28, "02362060546875": 28, "0238494873046875": 28, "02386474609375": 28, "0238800048828125": 28, "023956298828125": 28, "02398681640625": 28, "024017333984375": 28, "02410888671875": 28, "0241546630859375": 28, "02423095703125": 28, "0242462158203125": 28, "024322509765625": 28, "0243988037109375": 28, "024505615234375": 28, "02471923828125": 28, "024749755859375": 28, "0247650146484375": 28, "0247802734375": 28, "0247955322265625": 28, "0248565673828125": 28, "0248870849609375": 28, "0249176025390625": 28, "025": 61, "0251617431640625": 28, "02520751953125": 28, "025238037109375": 28, "0252838134765625": 28, "025299072265625": 28, "0254058837890625": 28, "0255279541015625": 28, "025543212890625": 28, "0255584716796875": 28, "0255889892578125": 28, "0256500244140625": 28, "0256805419921875": 28, "025848388671875": 28, "025970458984375": 28, "0260009765625": 28, "026031494140625": 28, "026092529296875": 28, "0261688232421875": 28, "02618408203125": 28, "026214599609375": 28, "0262451171875": 28, "0262603759765625": 28, "0262908935546875": 28, "02642822265625": 28, "0264739990234375": 28, "0266265869140625": 28, "0266876220703125": 28, "0267": 15, "0267181396484375": 28, "0268": 15, "0268402099609375": 28, "0269775390625": 28, "0269927978515625": 28, "02716064453125": 28, "0272064208984375": 28, "0272369384765625": 28, "02728271484375": 28, "0272979736328125": [24, 28], "0273284912109375": 28, "0274200439453125": 28, "0275421142578125": 28, "027618408203125": 28, "027923583984375": 28, "0279693603515625": 28, "028045654296875": 28, "028076171875": 28, "0280914306640625": 28, "0281524658203125": 28, "0282135009765625": 28, "028228759765625": 28, "0282745361328125": 28, "028289794921875": 28, "0283050537109375": 28, "0284271240234375": 28, "0284423828125": 28, "028472900390625": 28, "0285491943359375": 28, "028656005859375": 28, "0286865234375": 28, "02874755859375": 28, "0288848876953125": 28, "0289154052734375": 28, "0289306640625": 28, "029052734375": 28, "0291595458984375": 28, "0291900634765625": 28, "029296875": 28, "02935791015625": 28, "0294036865234375": 28, "0294342041015625": 28, "0294952392578125": 28, "0295562744140625": 28, "029571533203125": 28, "029632568359375": 28, "0298004150390625": 28, "0298309326171875": 28, "0299": 15, "029937744140625": 28, "02it": 54, "03": [7, 8, 13, 15, 16, 17, 24, 61], "030029296875": 28, "0300445556640625": 28, "0301055908203125": 28, "0301361083984375": 28, "0301666259765625": 28, "030242919921875": 28, "0303": 15, "030364990234375": 28, "0305023193359375": 28, "030670166015625": 28, "0307769775390625": 28, "030975341796875": 28, "0310211181640625": 28, "0311431884765625": 28, "0311737060546875": 28, "0312674": 16, "03143310546875": 28, "03155517578125": 28, "031646728515625": 28, "0319": 15, "032012939453125": 28, "032135009765625": 28, "032318115234375": 28, "0324": [10, 18, 20], "032440185546875": 28, "032470703125": 28, "032501220703125": 28, "03271484375": 28, "032806396484375": 28, "03289794921875": 28, "03314208984375": 28, "03326416015625": 28, "0333251953125": 28, "033447265625": 28, "03375244140625": 28, "0338134765625": 28, "033935546875": 28, "0340576171875": 28, "03411865234375": 28, "03424072265625": 28, "0343017578125": 28, "034454345703125": 28, "03448486328125": 28, "0345458984375": 28, "034637451171875": 28, "03466796875": 28, "034759521484375": 28, "03509521484375": 28, "035247802734375": 28, "035308837890625": 28, "03570556640625": 28, "035888671875": 28, "03607177734375": 28, "03619384765625": 28, "0362548828125": 28, "036346435546875": 28, "036376953125": 28, "036468505859375": 28, "036529541015625": 28, "03668212890625": 28, "03692626953125": 28, "0369873046875": 28, "037078857421875": 28, "0372314453125": 28, "037506103515625": 28, "037841796875": 28, "0380859375": 28, "038116455078125": 28, "03826904296875": 28, "038604736328125": 28, "038787841796875": 28, "038818359375": 28, "038848876953125": 28, "03924560546875": 28, "039276123046875": 28, "0393": 15, "0394": 15, "039435e": 61, "039459228515625": 28, "039703369140625": 28, "04": [8, 15, 18, 24, 28, 40, 56, 61], "0402": 15, "040252685546875": 28, "0403": 15, "0404052734375": 28, "0406": 15, "040618896484375": 28, "0406494140625": 28, "040802001953125": 28, "0409": 15, "041412353515625": 28, "041717529296875": 28, "041961669921875": 28, "0424": 15, "04248046875": 28, "0426": 15, "0427": 15, "042938232421875": 28, "0432": 15, "044219970703125": 28, "045166015625": 28, "045257568359375": 28, "04534912109375": 28, "0458984375": 28, "0467529296875": 28, "0469": 15, "0474": 15, "047698974609375": 28, "0478": 15, "0482": 15, "048248291015625": 28, "048370361328125": 28, "0484": 15, "04840087890625": 28, "048492431640625": 28, "0485": 15, "0488": 15, "0491": 15, "0494": 15, "049652099609375": 28, "04986572265625": [24, 28], "049957275390625": 28, "05": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54, 56, 61], "0506": 15, "05078125": 28, "05117154121398926": 16, "0512": 15, "05199599266052246": 34, "0528": [13, 15, 27, 57], "052978515625": 28, "053497314453125": 28, "0540": 15, "05401611328125": 28, "0550": 15, "055081129074097": 17, "0552": 15, "0553": 15, "0563": 15, "0564": 15, "056488037109375": 28, "0565": 15, "0568": 15, "057037353515625": 28, "057373046875": 28, "05792236328125": 28, "0583": 15, "059112548828125": 28, "05987548828125": 28, "05it": [16, 29], "06": [8, 15, 16, 24, 61], "06072998046875": 28, "0608": 15, "0611572265625": 28, "0625": 28, "062744140625": 28, "0631103515625": 28, "0633544921875": 28, "0638": 15, "0643310546875": 28, "0645": 15, "06707763671875": 28, "0671": 15, "0673": 15, "0677": 15, "068603515625": 28, "06927490234375": 28, "06f507603ed64b3596eb933fe169dab0": 34, "06it": 54, "07": [16, 17, 19, 24, 27, 56], "0703125": 24, "0707": 15, "0713": 15, "07232666015625": 28, "073486328125": 28, "0743": 15, "0748": 15, "0749": 15, "075": 61, "07500000000000001": 61, "0753": 15, "0761": 15, "0764": 15, "0775146484375": 28, "0777": 15, "07958984375": 28, "0796": 15, "07977294921875": 28, "07it": 16, "08": [7, 15, 19, 24, 56, 61], "0800": 15, "08087158203125": 28, "0834": 15, "0835": 15, "0876": 15, "0891": 15, "089599609375": 28, "08it": 8, "09": [15, 17, 51, 54], "0905": 15, "0908": 15, "0909": 15, "0910": 15, "0918": 15, "09197998046875": 28, "0923": 15, "0924": 66, "0931": 15, "0943603515625": 28, "0944": 15, "0945": 15, "0946044921875": 28, "09521484375": 28, "0953": 15, "09625244140625": 28, "0980": 15, "0986": 15, "0987": 15, "0997": 15, "09it": [8, 18, 24, 27], "0dd7": 56, "0rc1": 40, "0x0": 56, "1": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 46, 48, 50, 54, 56, 61, 62, 63, 64, 66, 68, 69, 70, 71], "10": [0, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 36, 44, 54, 56, 60, 61, 64, 66], "100": [5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 34, 35, 36, 54, 61], "1000": [13, 14, 16, 17, 18, 19, 24, 25, 35, 36], "10000": 5, "1000000": 23, "10000000": [13, 14, 16, 17, 18, 19, 24, 25], "100000000": 60, "1000000000": 60, "10001": 12, "10007": 17, "1002": 14, "1004": 14, "10040": 17, "1005": 15, "1008": 14, "100b": 66, "100mb": 36, "1012": 17, "1013": 15, "10146": 17, "1016": [14, 15], "10161": 17, "1019": 15, "10200": 24, "102349": 24, "1024": [6, 11, 13, 16, 17, 18, 19, 20, 24, 25, 35, 36, 45, 48, 57, 60, 61, 65], "10277": 17, "1028": 15, "10282": 17, "10295": 17, "1034": 15, "10346": 17, "1035": [17, 61], "1036": 15, "104": [8, 13, 16, 17, 18, 19, 25], "1042": 17, "10449": 17, "10449576377868652": 16, "1045": [15, 17], "10462164878845215": 16, "105": 17, "1051": 15, "10542": 17, "10696": 17, "106b": 68, "10702": 17, "1075": 17, "1077": 17, "10771": 24, "1079": 17, "1080p": 35, "1080x1920": 35, "1083": 17, "1084": [15, 17, 24, 34], "109": 21, "1091": 24, "10912": 60, "10926": 17, "10948": 17, "1096": 17, "10997": 17, "109b": 23, "10it": [8, 24, 27], "10m": 23, "11": [7, 8, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 34, 36, 44, 54, 56, 61], "110": 15, "11008": [15, 61], "11008x4096": 15, "1101": 17, "1105": 17, "11050": 24, "11059": 17, "1110": 15, "11111": 27, "11136": 17, "11141": 17, "1119": 17, "112": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "11228": 61, "1124": [17, 66], "11245": 17, "1125": 61, "1128": 17, "1129598617553711": 16, "1142": 17, "11426": 17, "115": 8, "1152": [13, 16, 17, 18, 19, 24, 25], "1153": 17, "11566": 17, "1157": 15, "11584": 16, "116": [20, 22], "116093850019932e": 61, "1163": 15, "11649": 17, "11652": 24, "11685": 61, "11689": 17, "118": 8, "1181": 17, "1182": 17, "1184": 17, "1187": [17, 24], "1189": 17, "119": 8, "1194": 15, "1196": 17, "11b": 68, "11it": 19, "12": [8, 10, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 28, 36, 40, 41, 45, 48, 54, 58], "120": [12, 13, 16, 17, 18, 19, 25, 50], "1200": [24, 60], "120000": 21, "12065": 21, "12068": 17, "12095": [17, 24, 34], "120b": [18, 22, 66], "121": 8, "12148": 24, "12159": 17, "1229": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "123": [13, 16, 17, 18, 19, 25, 27, 62], "12345": 27, "123456": 22, "123859": 61, "1241": 17, "12440": 17, "1246": 17, "1248": 17, "125": [24, 45], "1251": 17, "1255": 15, "1260": 15, "1265": 17, "1267": 17, "127": [5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 33, 34, 35, 36, 44, 56, 64, 65, 69], "12713": 17, "1273": 17, "12752": 17, "128": [1, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 27, 33, 35, 38, 43, 45, 46, 48, 50, 59, 61, 65], "1280": [13, 16, 17, 18, 19, 24, 25], "128009": [15, 16], "1281": 17, "12815": 17, "128902e": 61, "128e": 23, "128g": 40, "128k": [66, 68], "128x11008": 15, "128x128": 20, "128x4096": 15, "1290": 17, "12914": 17, "12943": 17, "12b": 68, "12it": 16, "12t": 66, "13": [7, 8, 15, 16, 17, 18, 22, 24, 28, 34, 54], "13035": 17, "13038": 17, "1304": 24, "130859375": 28, "130b": 66, "131072": [15, 24, 60], "1314": 15, "1319": 21, "1325": 15, "13289": 17, "132b": 66, "1330": 61, "1335": 17, "13352": 17, "13382": 17, "1340": 17, "1345": 17, "1349": 17, "13530": 17, "135m": 66, "136": [13, 16, 17, 18, 19, 25, 57, 60], "13604": 17, "13656": 17, "1366": 17, "1369": 15, "13702": 24, "1372": 17, "1376": 17, "1378": 17, "138": [20, 22], "13837": 17, "139": 18, "139271293": 18, "13959": 34, "13b": [66, 68], "13it": 8, "14": [8, 15, 16, 17, 18, 22, 24, 54, 57, 60, 61], "140": 61, "14005ec78cb04ec0b18b8f55f887a5dc": 16, "14006": 61, "14007": 61, "1401": 17, "1402": 17, "1408": [13, 16, 17, 18, 19, 24, 25], "1410": 17, "1414": 17, "14164": 17, "14190": 17, "1420137882232666": 16, "14202141761779785": 16, "14202547073364258": 16, "14205": [17, 24], "14260": 17, "1429": [17, 24], "1431": 17, "14311": 24, "1438": 17, "144": [13, 16, 17, 18, 19, 24, 25], "1445": 15, "1447": 17, "1447237": 16, "147": 17, "1477": 17, "148": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "1482": 17, "1490": 17, "1495": 17, "14b": [1, 66], "14it": [8, 16], "15": [8, 15, 16, 17, 18, 22, 24, 54, 56, 61], "150": [27, 54], "15029": 24, "151": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "1513": 61, "1513671875": 28, "151643": [17, 24], "151645": [15, 27, 29, 34], "151649": 17, "152": [13, 16, 17, 18, 19, 25], "1522": 12, "15344": 24, "1536": [13, 16, 17, 18, 19, 24, 25, 65], "15423": 17, "15544": 17, "15662": 17, "1575": 15, "158": 15, "15817": 17, "1583": 15, "1588": 17, "1590": 17, "1592": 17, "15934": 17, "15b": [66, 68], "15b3": 56, "15it": [8, 24], "16": [1, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 34, 35, 44, 45, 54, 56, 57, 58, 60, 66], "160": [7, 13, 16, 17, 18, 19, 24, 25], "16045": 17, "1616": 17, "162": 61, "16328": 17, "1633": 17, "16384": [7, 13, 14, 16, 17, 18, 19, 24, 25, 56], "163840": 56, "164": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "16448": 24, "1650390625": 28, "1651": 17, "1664": [13, 16, 17, 18, 19, 24, 25], "1667": 17, "16686": 62, "167": 45, "1677": 17, "168": [13, 14, 16, 17, 18, 19, 25], "1681": 17, "16875": 61, "169": [57, 60], "16926": 17, "16e": [18, 19, 23, 66], "16g": [43, 44], "16it": [15, 24], "16k": 66, "17": [7, 8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54, 56], "171": 45, "171662e": 61, "17194": 17, "172": [57, 58, 60], "17275261878967285": 24, "1737": 17, "1741": 17, "1741943359375": 28, "17432": 17, "1744": 17, "1745383213": 64, "1745993638": 20, "174c174aef504374bad0043097720253": 27, "175": 22, "1750252498": [57, 60], "1752": 17, "176": [13, 16, 17, 18, 19, 24, 25], "1763357663": 15, "1763357728": 16, "1763357757": 15, "1763357809": 18, "1763357810": 17, "1763357811": 15, "1763357813": 18, "1763357815": 17, "1763357816": 17, "1763357829": 17, "1763357835": 17, "1763357863": 15, "1763357899": 18, "1763357902": 15, "1763357940": 24, "1763357963": 27, "1763357964": 27, "1763358012": 29, "1763358013": 29, "1763358014": [29, 34], "1763358015": 34, "1763358074": 24, "1772": 15, "17724609375": 28, "17767": 17, "178": 17, "1792": [13, 16, 17, 18, 19, 24, 25], "17b": [18, 19, 23, 66], "18": [8, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 54, 56, 58], "1815": 61, "1817": 17, "18172": 17, "18304": 17, "18386": 17, "184": [13, 16, 17, 18, 19, 25], "1850": 17, "1855": 17, "1868896484375": 28, "187": 22, "1879": [17, 34], "19": [8, 15, 16, 17, 18, 24, 28], "19083": 17, "19091": 17, "192": [13, 14, 16, 17, 18, 19, 24, 25], "1920": [13, 16, 17, 18, 19, 24, 25], "1947": 17, "1948": 17, "19482": 17, "1970": 61, "19730": 2, "198": [17, 21, 24], "1986": 17, "1988": 17, "1990": 17, "1995": 17, "19it": 8, "1b": [11, 18, 38, 66, 68, 72], "1m": [1, 23, 66], "1p1d": 57, "1t": 66, "1v": 68, "1x": 15, "2": [0, 1, 5, 6, 8, 10, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 45, 48, 49, 50, 54, 56, 58, 61, 64, 66, 68, 70, 71, 72], "20": [2, 7, 8, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 50, 54, 56, 60, 61], "200": [8, 13, 16, 17, 18, 19, 22, 24, 25, 35, 37, 44, 56], "2000": [7, 35, 38], "20000": [12, 56, 58], "2005": 15, "2009": 17, "20094": 17, "200k": 66, "20102": [57, 60], "2015": 17, "2016": 25, "2022": [17, 24], "2023": 17, "2023todai": 16, "2024userpari": 16, "2025": [7, 8, 13, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 34, 44, 51, 54, 55, 56], "2036": 17, "20474": 24, "2048": [7, 13, 15, 16, 17, 18, 19, 21, 23, 24, 25, 35, 51, 57, 60], "20480": [13, 16, 17, 18, 24, 25], "2055": 17, "2058": 24, "206": 22, "20643": 17, "208": [13, 16, 17, 18, 19, 24, 25, 54], "2086": 34, "20b": [18, 66], "20it": 8, "21": [16, 18, 24, 44, 61], "210": [22, 45], "2101326": 17, "210267874": 19, "2111": 17, "214": 45, "2141000": 16, "2147000": [16, 17], "2147483648": 60, "21500000": 16, "2155": 17, "216": [13, 16, 17, 18, 19, 25], "21615": 17, "2163": 17, "2176": [13, 16, 17, 18, 19, 24, 25], "21815": 17, "2182": 17, "21938": [17, 24], "21b": 66, "21it": [8, 15], "22": [8, 13, 15, 16, 17, 18, 20, 24, 25, 51, 60], "220": [16, 17], "2208": 17, "221": [57, 60], "222": 54, "22314": 17, "2236": 17, "224": [13, 16, 17, 18, 19, 24, 25], "22464": 17, "2248": 17, "224gb": 58, "22517": 17, "2266": 17, "2270": 24, "22707": 17, "2278": 17, "2293": 17, "2297": 17, "2299": 17, "22it": [8, 16], "22m": [57, 60], "23": [13, 15, 17, 18, 24, 56], "2304": [13, 16, 17, 18, 19, 24, 25], "2308": 17, "232": [13, 16, 17, 18, 19, 25], "2326": 61, "233": 7, "234": 17, "235": [21, 57, 60], "235b": [5, 13, 32, 45, 68], "2379": 17, "23974": 17, "23it": 15, "24": [13, 15, 16, 17, 18, 19, 24, 25, 44, 45, 56, 57], "240": [13, 16, 17, 18, 19, 24, 25], "2400": 17, "2407": 18, "240gb": 6, "2417": 61, "242": [57, 60], "2427": 17, "24297": 17, "2430822": 24, "2432": [13, 16, 17, 18, 19, 24, 25], "244": 15, "2441": 17, "2461": 17, "247": 61, "2474": 17, "24758": 17, "248": [13, 16, 17, 18, 19, 25], "2486572265625": 28, "24872": 17, "2494": 17, "24b": 68, "24it": 24, "25": [6, 8, 15, 16, 17, 18, 21, 24, 27, 54, 56, 61], "25000": 14, "2503": 68, "2506": 17, "25069": 17, "2507": [5, 13], "2513": 61, "2521": 17, "2527": 17, "253": 45, "2530": [15, 17], "253125": 61, "253b": 66, "254": 17, "25470": 17, "2548": 17, "255b": 66, "256": [6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 24, 25, 35, 36, 38, 54, 65, 68], "2560": [13, 16, 17, 18, 19, 24, 25], "25648": 17, "256mb": 12, "2578": 17, "25it": 24, "26": [15, 16, 24, 57, 60], "262": 17, "262144": [57, 60], "26306266784668": 61, "264": 17, "264404296875": 28, "26553": 17, "2660": 17, "266055e": 61, "2688": [13, 16, 17, 18, 19, 24, 25], "2697": 17, "2699": 17, "26it": 24, "27": [8, 13, 15, 22, 24, 56, 61], "2704": 17, "271": 17, "27190": 17, "273": 17, "2750": 17, "277": 22, "27748": 17, "2776": 17, "279": [16, 17, 24, 34], "2797": 17, "27b": [66, 68, 70], "27it": [15, 16, 24], "28": [8, 13, 16, 17, 18, 19, 24, 25, 61, 66], "2806": [17, 24], "281": 18, "2814453125": 61, "2816": [13, 16, 17, 18, 19, 24, 25], "282095952": 24, "2826": 61, "2830": 15, "2849": 15, "28668": 17, "287": [17, 24], "28715": 24, "2872": 17, "288": [13, 16, 17, 18, 19, 24, 25], "28it": [8, 24], "29": [15, 18, 22, 60], "29000": 12, "290b": 66, "29138749187": 22, "2924": [17, 24], "2938": 17, "294": 17, "2944": [13, 16, 17, 18, 19, 24, 25], "29500": 2, "295344": 16, "2953484": 16, "2953508": 16, "29553": 24, "296": 17, "296752e": 61, "29it": 16, "2_6": 68, "2a": 0, "2ab7e2cff7d54b25a54249598156808d": 15, "2b": [11, 65, 66, 68], "2c5c02a899444e6db4c32d4e2021667d": 15, "2f": [24, 69], "2t": 66, "2x": [5, 56], "3": [0, 1, 3, 7, 8, 10, 11, 12, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 43, 44, 45, 46, 48, 49, 54, 56, 57, 60, 61, 63, 66, 68, 70, 71, 72], "30": [6, 8, 12, 15, 17, 18, 19, 24, 37, 54, 57, 60, 61], "300": [10, 13, 14, 16, 17, 18, 19, 24, 25, 29, 32, 60, 68], "3000": [35, 60, 61], "30000": [3, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 32, 33, 35, 36, 38, 41, 43, 44, 45, 49, 57, 58, 60, 61, 65, 66, 67, 68, 69, 70, 72], "30001": [10, 12, 36, 57], "30002": 36, "30003": 36, "30011": 12, "3002": 17, "3003": 17, "30080": 60, "301": [17, 24], "3023557662963867": 24, "30282": 24, "3033": 24, "30339": 17, "304": [17, 24, 34], "3042": 17, "307": 29, "3070": 17, "3072": [13, 16, 17, 18, 19, 24, 25], "3076": 17, "307c71a63fcf46e8aea696edc5d8bf7c": 16, "308": 17, "30800": [57, 60], "3082": 24, "309": 17, "3090": 61, "3092": [17, 24], "30b": [18, 32, 66, 68], "30gb": 6, "31": [15, 16, 18, 24, 41, 50], "3100": 24, "31000": 12, "31094": 24, "311": 17, "3118": 17, "312226e": 61, "31273": 17, "31299": 17, "314": 61, "3146": 17, "314b": 66, "315": [16, 17, 24, 34], "3156": 17, "317": 7, "3170": 17, "32": [1, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 33, 34, 36, 48, 56, 57, 60, 61], "320": [13, 16, 17, 18, 19, 24, 25], "3200": [13, 16, 17, 18, 19, 24, 25], "3207": 17, "3211": 17, "3213": 17, "323": [17, 24, 34], "3231": 17, "32313": 17, "3239": 17, "3239384": 16, "32406": 24, "3248779296875": 61, "3259": 17, "326": 17, "32768": [24, 57, 60], "3278": 17, "3283": [17, 24, 34], "32930": 17, "32b": 45, "32exp": 60, "32g": [38, 41], "32it": [16, 17], "33": [8, 13, 15, 24, 29, 54], "330": [16, 17, 24], "3316703": 34, "3328": [13, 16, 17, 18, 19, 24, 25], "3330": 17, "334": 17, "336": 65, "33896": 17, "339675e": 61, "33it": [8, 15], "34": [8, 13, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 34, 54], "341": 17, "3410": 17, "34106": 17, "3427": 15, "3456": [13, 16, 17, 18, 19, 24, 25], "3460": [15, 17], "34833": 17, "3489": 17, "34it": 34, "35": [8, 15, 16, 17, 24, 25, 54], "3500000": 17, "3501": 17, "35127": 17, "3518979474117756e": 61, "352": [13, 16, 17, 18, 19, 24, 25], "35212": 17, "3522": 17, "3523695": 17, "3526": 17, "3535": 17, "353f238509504ae8b4813cb008788ce": 34, "3545": 17, "3546": 17, "35544": 17, "356": 17, "3561": 17, "3565": 17, "3567": 15, "357747e": 61, "358": 17, "3584": [13, 16, 17, 18, 19, 24, 25], "3598": 17, "35it": [8, 15, 34], "36": [8, 15, 17, 18, 19, 22, 24, 34], "3600": 20, "3600000": 17, "36038": 27, "360p": 35, "36342": 24, "3643": 17, "36458": 24, "36575": 54, "367": 17, "3688": 15, "369": [17, 24], "36972": 17, "369873046875": 28, "36b": 66, "36f5a319ae834ed8a92d276c47114d5c": 17, "36it": 24, "37": [15, 16, 17, 18, 19, 24, 27, 34], "370959": 7, "3712": [13, 16, 17, 18, 19, 24, 25], "3728": 17, "373": [15, 17, 29], "37318": 54, "37362": 17, "37390": 24, "374": [16, 17, 22, 24, 34], "37406": 24, "37685": 24, "3776": 17, "37838": 17, "3786": 17, "3793": 17, "37962": 24, "3796875": 61, "37976": 24, "37978": 24, "38": [8, 13, 15, 17, 18, 19, 24, 25, 27], "380": 19, "3819": 24, "382": [17, 24, 61], "3825": 24, "384": [13, 16, 17, 18, 19, 24, 25], "3840": [13, 16, 17, 18, 19, 24, 25], "3847": 17, "385": 17, "387": 17, "3872": 17, "3873": 15, "3880": 17, "3881": 17, "3884": 17, "3886": 24, "3889": 15, "389": [17, 24, 34], "389414e": 61, "3897": 17, "38it": 24, "39": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 45, 54], "3950": 24, "3953": 17, "39651": 17, "3968": [13, 16, 17, 18, 19, 24, 25], "39814": 17, "398335218429565": 17, "39it": [15, 19, 24], "3_1": 66, "3_3": 66, "3b": [18, 19, 35, 45, 48, 66], "3dfad7d74eae427dbc153e193caba35": 15, "3e": 2, "3f": 6, "3fe8e98963dd451481f344dbcb026d39": 17, "3moe": 66, "3next": 66, "3rd": 27, "3x": 6, "4": [0, 1, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 24, 25, 27, 28, 29, 31, 34, 36, 45, 50, 54, 56, 57, 58, 60, 61, 66, 68, 70], "40": [13, 14, 15, 16, 17, 18, 19, 24, 25, 29, 45, 54, 61, 66], "400": [42, 64], "4000": 43, "40000": 56, "400757e": 61, "400b": [23, 66], "401": 35, "403": 35, "405": 17, "40526": 17, "40698": 24, "407": 18, "408": 12, "409": [17, 24], "4096": [7, 13, 14, 15, 16, 17, 18, 19, 24, 25, 50, 51, 60], "4096x12288": 15, "4096x22016": 15, "4096x32000": 15, "4096x4096": 15, "40it": [8, 24], "41": [15, 16, 17, 24, 54], "4106": 15, "4120": 17, "4135": 17, "414": 17, "416": [13, 16, 17, 18, 19, 24, 25], "4185": 17, "419": [17, 24], "42": [3, 15, 24, 25, 27, 29, 45], "420": 18, "421": 17, "422": 24, "4231324": 17, "42471e2138954446a86fbe7535ab3e36": 16, "424b": 66, "425": 24, "4257": 17, "427": 18, "4285": 15, "429": [12, 17, 24], "4297": 17, "42it": [15, 25], "43": [3, 13, 15, 17, 45], "4311": 17, "4317": [13, 14, 16, 17, 18, 19, 24, 25, 62], "4318": 62, "432": [17, 24], "4325": 17, "4329": 15, "433413": 61, "4340292513370514": 64, "43441": 17, "43464": [17, 24], "43602": 17, "4362": 17, "4378": 17, "438": 17, "4383": 17, "4396": 17, "43it": 16, "44": [3, 8, 15, 24, 34], "4411": 17, "442518254": 16, "4428": 17, "44292": 17, "444": 24, "44441": 17, "4460": 17, "448": [13, 16, 17, 18, 19, 24, 25], "44868": 17, "4494": 17, "44it": 16, "45": [3, 15, 16, 17, 24, 34], "450": 24, "4505": [24, 34], "4512": 24, "45541": 16, "456": 17, "458": 17, "4586": 17, "4588": 17, "4594": 7, "45it": 29, "46": [3, 13, 15, 16, 24], "46321": 17, "4658": 17, "466": 18, "468": [17, 24], "4684": 17, "46it": [15, 54], "47": [17, 24], "4704": 15, "4707": 17, "4710": 17, "4714": 17, "4715": 17, "4718": 17, "4734": 17, "4755": 17, "4756": 17, "476": 17, "47990": 17, "47b": 66, "47it": 34, "48": [13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 45], "480": [13, 16, 17, 18, 19, 24, 25], "481": 17, "482": 17, "4849": 17, "48506": [17, 24], "486": 61, "487316894531251": 61, "48908": 56, "48924": 56, "4893": 15, "49": [8, 13, 15, 16, 24, 29, 61], "497": 17, "4977": 17, "498": [16, 22], "4998": 15, "49b": 66, "49it": [8, 19], "4a": 35, "4b": [27, 35, 65, 66, 68], "4bit": 11, "4k": 35, "4th": [27, 45], "4therefor": 54, "4v": [66, 68], "4xh100": 31, "5": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24, 25, 27, 28, 29, 33, 34, 35, 36, 37, 40, 43, 44, 45, 48, 54, 56, 57, 60, 61, 64, 65, 66, 67, 68, 70, 71], "50": [3, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 24, 27, 28, 34, 54, 56, 61], "500": [14, 17, 35, 37, 50, 62, 64], "5000": [10, 44], "50000": 14, "50051": 5, "5008": 17, "50100": 16, "5011": 17, "5018": 16, "5055": 17, "50577": 17, "50814177726902": 61, "5089": 17, "50d301f929bd43218d3f5334615ac212": 18, "51": [13, 15, 24], "510": 17, "5109": 17, "512": [6, 7, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 35, 36, 54, 65], "512x768": 35, "514771912145079": 61, "515": 17, "5157": 17, "518": 17, "5189": 17, "519091844558716": 17, "51it": [8, 19, 29, 54], "52": [15, 27, 58, 66], "5226": 21, "523": 17, "524": 24, "5240": 17, "524288": 57, "525": 17, "5257": 24, "5263": 17, "5267": 24, "527617": 16, "52956": 17, "52b": 66, "52cb49cb5eee4c028029cbebbd954ac1": 17, "52it": 8, "53": [15, 17, 24, 27, 34], "532": 17, "532660245895386": 17, "533": 15, "5338": 17, "5358": 17, "537": 17, "54": 15, "540": 17, "5421": 17, "54231": 17, "544": 24, "5486": 17, "55": [8, 15, 16, 18], "5501": 17, "5512": 17, "5530": 17, "5535": 17, "554": 17, "5542": 17, "55557": 17, "557572e": 61, "558": 18, "559": 15, "55it": 13, "56": [13, 16, 17, 18, 19, 25, 29], "5646": 17, "5648": 17, "565970778465271": 64, "567": 17, "5671": 17, "56729": 17, "56953125": 61, "56dc209d72a0469eb7053c05a9d66b2b": 34, "56it": [15, 18], "57": [15, 18], "570": 19, "5707": 24, "5711": 17, "572": 17, "57406": 24, "57466": 24, "576": [17, 24], "5777": 17, "57868": 17, "5791549598": 61, "58": [8, 15, 16, 19, 22, 24, 27, 34], "582": 24, "5847": 17, "5889": 17, "58it": 18, "59": [8, 15, 24, 34], "590": 17, "59108": 17, "593": 61, "594": 17, "5944": 17, "595": 17, "59604": [17, 24], "596463012695313": 61, "5975": 17, "5978": 17, "59924": [17, 24], "59it": [8, 18], "5b": [0, 8, 24, 25, 27, 28, 34, 48, 64, 66, 70, 71], "5bac47b2d3ef47a7a8d85532f1987d22": 16, "5m": 23, "5moe": 66, "5t": 66, "5v": 68, "5x": 20, "6": [8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 35, 36, 44, 45, 46, 54, 56, 61, 68], "60": [12, 24, 25, 28, 29, 36, 54, 56, 60, 61], "600": [10, 12, 17], "6000": 12, "6005": 24, "6017": 57, "6049": 17, "60506": 17, "606": 17, "60704": 16, "609": 16, "6099": 17, "60it": [24, 29], "61": 22, "6169": 17, "6171": 17, "61it": 54, "62": [8, 17, 24, 27, 54], "62166": 17, "624": [17, 24], "624b5873a6004410a74f2ce11f63e708": 27, "62it": [15, 18], "63172": 24, "633": 17, "63593": 17, "63594": 17, "6364": 17, "63861": 17, "63it": [18, 29], "64": [1, 5, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 48, 50, 54, 57, 60, 62], "640": [13, 16, 17, 18, 19, 24, 25], "646": [17, 24], "6481": 24, "64it": [18, 24, 54], "64x11008": 15, "64x4096": 15, "65": [13, 15, 32], "6501ef8e2d874006bf555bc80cddc7c5": 20, "65063": 17, "6513": 17, "6528": 15, "6540": 17, "65536": [7, 19, 23], "6573": 17, "65it": 18, "66": 29, "6648": 17, "6648002": 17, "6655": 24, "665690": 7, "6657": 44, "666": 18, "6688": 44, "6696": 17, "66it": 18, "67": 54, "6707": 17, "67108864": 12, "67115251": 17, "671b": 66, "672": 24, "6722": [17, 24], "6753473281860352": 17, "675360918045044": 17, "675368070602417": 17, "6755": 17, "6771": 17, "678": 17, "67890": 27, "67it": [27, 54], "68": [15, 24], "6801": 17, "6810": 17, "6864": 16, "6894": 17, "6896": 17, "68it": 24, "69": [13, 15, 17, 24], "6915": 17, "695": 17, "6955": 17, "698": 17, "6980p": [20, 45], "69it": 18, "6b": [65, 66], "6lcbd": 57, "6th": 45, "7": [7, 8, 13, 14, 15, 16, 17, 18, 19, 23, 24, 27, 34, 36, 44, 51, 54, 56, 57, 61, 64, 66], "70": [17, 36], "700": 17, "7007": 16, "702": 17, "7025": 17, "7039": 17, "7042": 17, "705": 17, "7071": 17, "70b": [18, 45], "70it": [8, 18, 54], "71": [15, 17], "712400": 56, "71248052b72b47e9bf7ccce52413afda": 15, "714": [17, 24], "7148": 24, "71486": 17, "715": 17, "71854": 17, "7196": 17, "71it": 18, "72": [13, 15, 16, 17, 18, 19, 25, 27, 54], "720p": 35, "72216": 24, "7276": 17, "728": 17, "7281": 17, "72b": [68, 70], "72it": [24, 54], "73": [15, 61], "73089": 17, "730975341796876": 61, "73594": 17, "736846": 24, "7378": 17, "7388": 17, "739364367": 13, "73950": 17, "73it": 24, "74": [15, 23, 24], "7407": [17, 24, 34], "74572": 17, "7460": 17, "747085c900ea420387dcd9114a05bd1": 27, "7482": 17, "749": 22, "74972bd2fbd640ffb9bd77b4fa3a648": 15, "74m": [57, 60], "75": [8, 10, 15, 16, 18, 23, 24, 27, 54, 61], "752": 17, "7546": 17, "756": 17, "7565": 17, "758": 17, "75b": 66, "75it": [18, 54], "76": [15, 25, 27, 34], "763": 17, "76602": 17, "768": [7, 13, 16, 17, 18, 19, 24, 25], "7683": 17, "77": 15, "770": 17, "773": 17, "7772": [17, 24, 34], "77it": [8, 18], "78": 15, "7826": 17, "783": 21, "784590359": 25, "785": 17, "78718": 17, "788": [17, 21], "78it": 13, "79": [15, 19, 21], "793": 21, "794": 16, "797": 21, "798": 21, "79it": 15, "7ae557604adf67be50417f59c2c2f167def9a775": 24, "7b": [11, 13, 15, 17, 18, 24, 29, 33, 37, 49, 54, 65, 66, 67, 68, 70], "7db452c86bcc480cab267a350bee118a": 29, "7f": 56, "7fa2af80": 36, "7x": 20, "8": [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 27, 32, 33, 34, 35, 36, 38, 43, 44, 45, 46, 51, 54, 56, 57, 58, 60, 61], "80": [8, 12, 13, 15, 16, 17, 18, 19, 23, 24, 25, 29, 54], "800": 20, "8000": [10, 12, 21, 35, 36, 44, 57, 58, 60, 64], "8001": [12, 44], "800i": [20, 44], "803": 21, "80486": 17, "807": 17, "808": 21, "8080": [0, 5, 12, 60], "809": 24, "8097": 17, "80b": [18, 31, 66], "80it": 18, "81": 15, "8125": 17, "816043786240": 5, "8173": 17, "8192": [7, 13, 15, 16, 17, 18, 19, 24, 25, 32, 46, 50, 56], "81it": 8, "82": [7, 15, 17, 45], "821": 17, "8241": 17, "825": 17, "829": 17, "82it": 29, "83": [8, 15, 54], "830": 24, "833478": 17, "835": [13, 16, 17, 18, 25], "83it": 54, "84": [15, 56], "841": 24, "8416": 24, "841992937": 24, "84204177856446": 61, "8444": 24, "845": [17, 61], "847": 17, "849": [57, 60], "84it": 54, "85": [5, 8, 15, 18], "8542968750000001": 61, "855": 61, "8566": 17, "8585": 24, "85it": 8, "86": [15, 24, 45, 61], "862": 17, "8651": 17, "8661": 17, "866964": 61, "86it": 16, "8704": 17, "8791692": 24, "88": [13, 15, 16, 17, 18, 19, 24, 25], "8816264033084": 24, "88190": 17, "8832519531250003": 61, "8833": 22, "885": [24, 28], "8856": 1, "8884": 37, "889": 15, "88it": 15, "89": [15, 56], "892": 17, "8926": [17, 24], "894": 17, "89469451904297": 61, "8950973": 17, "895103": 17, "8951063": 17, "896": [13, 16, 17, 18, 19, 24, 25], "8965": 62, "899": 24, "8998": [13, 14, 16, 17, 18, 19, 21, 24, 25], "8a7053ee33d24d179cfd8f31c0abedac": 34, "8b": [1, 2, 8, 10, 11, 12, 14, 15, 16, 18, 24, 33, 35, 36, 41, 43, 44, 45, 46, 48, 61, 63, 66, 68, 70, 71], "8t": 66, "8th": 27, "8x": 20, "8xh100": 23, "8xh200": 21, "9": [7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 35, 36, 40, 45, 48, 54, 56, 61], "90": [15, 18], "9001": 12, "9069": 17, "9080": 17, "9090": 61, "91": 15, "911": 17, "9120": 2, "91426": 17, "9155": 24, "916": 17, "91it": [8, 15], "92": [8, 15, 16, 17, 18], "9220": 37, "9221679687500002": 61, "9246": 17, "9286": 17, "92b5e07c7d11415d836c7cef8346cc14": 17, "92it": 54, "93": [15, 56], "930": 17, "9301066": 16, "9355": 17, "938": 17, "939": 17, "93945": 17, "93it": [15, 17], "94": [8, 15], "941": 61, "9420": 17, "944": 17, "94451": 24, "947": 17, "949": [17, 24], "94it": [24, 25], "95": [8, 11, 13, 15, 16, 17, 18, 25, 27, 51], "950195e": 61, "95518": 17, "956": 21, "9567": 17, "95it": 15, "96": [13, 15, 16, 17, 18, 19, 24, 25, 27, 59], "9625": [17, 24, 34], "9658": 17, "97": 15, "9729": [17, 24], "9733": 17, "9760": 17, "979": 17, "97904": 17, "97m": [57, 60], "98": [8, 15, 29], "9806": 34, "9822": 16, "983": 36, "98314275991e4c949f44233fdfdecf66": 16, "984": 14, "9840b35b0578466fb3acef951fd7b2b1": 18, "9856": 24, "99": 15, "990": 17, "992": 14, "9940": 17, "994023": 16, "996": 14, "9966": 17, "998": 14, "9998": 7, "999999": 23, "9b": [66, 68], "9bf17f2847b046c7b2d5495f4b4f9682": 64, "9c5dbfc57": [57, 60], "9dff": 56, "9th": 27, "9x": 20, "A": [6, 7, 8, 10, 12, 13, 14, 15, 17, 20, 21, 25, 33, 36, 37, 41, 45, 46, 48, 56, 62, 65, 66, 69, 70, 72], "And": [15, 22], "As": [6, 7, 17, 25, 29, 36], "At": [6, 56, 57, 60], "But": [15, 17, 27], "By": [3, 5, 6, 7, 8, 9, 14, 15, 20, 22, 33, 49, 54, 61, 71, 72], "For": [0, 1, 5, 6, 8, 10, 11, 13, 15, 16, 18, 20, 21, 22, 23, 27, 28, 31, 32, 33, 34, 35, 36, 37, 41, 42, 45, 52, 56, 60, 61, 62, 65, 66, 68, 71], "If": [0, 1, 6, 7, 8, 10, 11, 14, 16, 17, 18, 20, 21, 25, 32, 33, 35, 36, 37, 38, 41, 43, 44, 45, 49, 51, 56, 61, 62, 63, 64, 65, 66, 68, 71], "In": [6, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 24, 25, 27, 28, 29, 34, 38, 43, 50, 51, 54, 56, 57, 62, 71], "It": [1, 6, 7, 12, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 27, 31, 32, 33, 34, 35, 36, 41, 42, 45, 49, 52, 65, 66, 68, 71], "Its": [20, 42], "NOT": [18, 49], "No": [3, 8, 12, 13, 15, 17, 22, 24, 27, 50, 61], "Not": [1, 14, 35, 50], "OFED": 56, "On": [6, 7, 21, 32, 45, 59, 62], "One": [17, 19, 27, 33], "Or": [10, 11, 15, 17, 18, 35, 46, 67], "THE": 27, "That": [15, 17, 71, 72], "The": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 44, 45, 46, 48, 50, 52, 54, 55, 56, 57, 60, 61, 62, 63, 64, 66, 68, 69, 71, 72], "Their": 62, "Then": [11, 13, 17, 37, 40, 45, 56, 58, 61, 71], "There": [15, 38, 49, 54], "These": [11, 14, 15, 22, 27, 37, 50, 62, 66, 68, 70, 71], "To": [1, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 43, 45, 51, 54, 57, 61, 62, 67, 71], "Will": 1, "With": [0, 20, 21, 35, 36, 43, 68], "_": 54, "____": [24, 25], "_______": 25, "__call__": [33, 71], "__init__": [39, 71], "__main__": 71, "__name__": 71, "_attn_implement": 72, "_dynamo": 15, "_supports_attention_backend": 72, "_work": 24, "a10": 41, "a100": [1, 20, 32, 41, 42], "a2": [21, 24, 44, 56], "a223b273fa1340488c3d972f022bf75c": 24, "a22b": [5, 13, 32, 45, 68], "a2a": [10, 14, 57, 60], "a2dc": 56, "a3": [20, 21, 44], "a36b": 66, "a3b": [18, 31, 32, 66, 68], "a40": 1, "a800": 20, "a800m": 66, "aarch64": 44, "ab": 12, "abbrevi": [16, 17, 18], "abc": 6, "abigail": 25, "abil": [25, 66], "abl": [61, 71], "abnorm": 11, "abort_on_priority_when_dis": [13, 16, 17, 18, 19, 24, 25], "about": [6, 7, 14, 15, 16, 17, 22, 25, 27, 38, 48, 49, 51, 54, 55, 68, 71, 72], "abov": [5, 14, 15, 18, 20, 27, 33, 35, 36, 37, 41, 45, 48, 51, 52, 54, 56, 62, 71], "absolut": [0, 12], "absorpt": 20, "acc": 14, "acc_typ": 15, "acceler": [2, 7, 14, 15, 20, 41], "accept": [10, 12, 14, 15, 27, 33, 35, 58, 66, 68, 71], "accept_length": 35, "access": [6, 12, 14, 16, 17, 20, 27, 36, 37, 41, 45, 50, 56, 57, 60, 61, 62, 71], "accommod": 62, "accomplish": 25, "accord": [1, 10, 11, 18, 22, 25, 31, 36, 56, 57, 60], "accordingli": [0, 12, 13, 18, 24], "account": [25, 37, 51], "accumul": 51, "accur": [17, 25, 31, 65], "accuraci": [11, 14, 15, 25, 66, 68, 69, 71], "achiev": [3, 6, 8, 15, 20, 21, 27, 51, 56, 66, 68], "across": [2, 3, 5, 6, 8, 12, 14, 20, 36, 42, 50, 51, 52, 58, 62], "act": [18, 22], "action": 11, "activ": [7, 11, 14, 20, 36, 42, 44, 45, 48, 54, 56, 58, 66], "actual": [6, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54, 57, 60, 61, 62, 64], "ad": [0, 3, 8, 9, 12, 13, 14, 17, 18, 22, 27, 41, 61, 62], "adapt": [8, 14, 21, 25, 56, 71], "adapter_a": [8, 27], "adapter_b": 27, "adb": 12, "add": [0, 2, 5, 11, 12, 13, 14, 16, 17, 18, 20, 23, 25, 28, 31, 33, 35, 36, 38, 43, 45, 51, 57, 60, 61, 68], "add_generation_prompt": [13, 16, 17, 18], "add_link": 62, "add_special_token": 24, "add_work": 12, "addit": [2, 3, 8, 13, 18, 25, 27, 37, 52, 62, 64, 71], "addition": [15, 20, 21, 25, 36, 45, 48, 56], "addr": [2, 10, 14, 21, 44, 56, 57, 58, 60], "address": [2, 5, 6, 10, 12, 14, 25, 45, 48, 50, 51, 54, 56, 58], "adept": 66, "adjust": [15, 17, 20, 23, 24, 31, 35, 51, 57, 60, 61], "admin": [12, 61], "administr": [17, 25], "adopt": [8, 12, 14, 42], "adv": 36, "advanc": [8, 21, 22, 33, 36, 62, 66, 68], "advis": 16, "aerob": 54, "affect": [6, 8, 10, 11, 14, 44], "affin": 50, "aflah02": 58, "afm": 66, "aforement": 21, "african": 17, "after": [0, 6, 8, 10, 11, 13, 14, 15, 20, 25, 32, 34, 35, 36, 46, 51, 57, 62, 68, 71], "afterward": [15, 43, 44], "ag": 56, "again": [6, 8, 11, 15, 18, 27, 43, 71], "against": [0, 6, 11, 14, 35, 52], "agent": [12, 35, 66], "aggreg": [6, 35, 62], "aggress": 12, "agx": 46, "ahrenheit": 18, "ai": [0, 1, 10, 12, 13, 16, 17, 18, 20, 21, 22, 25, 27, 38, 43, 44, 45, 46, 55, 56, 57, 60, 66, 68, 71], "aibrix": [6, 14], "aig": 57, "ailuropoda": [24, 69], "aim": [15, 20, 50, 54, 56], "aiohttp": 35, "airsch": 19, "aiter": [1, 14, 50], "aiter_attn": 14, "ai\u52a9\u624b": [57, 60], "alexandr": 17, "algo": 31, "algoprog": 8, "algorithm": [6, 11, 14, 15, 20, 21, 23, 31, 57, 60], "alia": [12, 43, 44], "alibaba": [24, 28, 32, 65, 66, 68], "align": [11, 12, 66, 68, 70], "aliv": 54, "all": [0, 1, 2, 3, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 20, 21, 27, 29, 33, 35, 36, 37, 38, 40, 41, 50, 52, 57, 62, 64, 67, 71], "all_attention_funct": 72, "all_hip": 43, "all_other_model": 71, "all_reduc": 6, "allen": 66, "allenai": [11, 66], "allevi": 6, "allgath": 14, "alloc": [6, 7, 14, 24, 36, 61], "allocator_ascend": 37, "allow": [2, 5, 6, 9, 14, 15, 17, 20, 25, 27, 32, 36, 38, 41, 50, 57, 62, 64, 65, 68, 71], "allow_auto_trunc": [13, 16, 17, 18, 19, 24, 25], "allow_tf32": 15, "allreduc": 14, "almost": 71, "along": [8, 17, 54, 66], "alongsid": [12, 36, 68], "alpha": 66, "alreadi": [6, 8, 10, 11, 20, 22, 61, 62, 65], "alright": 17, "alsac": 15, "also": [1, 6, 7, 8, 11, 14, 15, 17, 18, 20, 21, 22, 24, 25, 27, 28, 29, 33, 34, 35, 36, 37, 41, 43, 44, 46, 49, 51, 54, 56, 57, 58, 62, 68, 71, 72], "alter": 21, "altern": [0, 5, 6, 11, 14, 29, 52, 70], "alwai": [0, 1, 3, 7, 13, 14, 16, 17, 18, 25, 27, 33, 37, 64], "am": [17, 25, 27], "amazon": 6, "amd": [21, 40, 41, 42, 50], "amd64": 44, "amen": 17, "america": [16, 17], "among": [5, 6, 15, 20, 62], "amount": [8, 27, 45], "amphitheat": 27, "amx": 45, "amxint4": 24, "an": [1, 2, 5, 6, 8, 11, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 51, 52, 54, 56, 61, 62, 66, 67, 68, 70], "analysi": [13, 14, 18, 25, 38], "analyst": 22, "analyz": [17, 24, 25, 27, 36, 68], "ancient": 27, "anesthet": 25, "angl": 15, "ani": [1, 6, 9, 11, 12, 14, 15, 17, 18, 20, 25, 27, 33, 36, 37, 41, 44, 54, 56, 64, 65, 71, 72], "annot": [12, 14, 15, 18, 27, 34, 36], "anonym": 62, "anoth": [1, 7, 8, 10, 14, 15, 17, 29, 36, 43, 45, 48, 51, 54, 62], "answer": [13, 15, 16, 17, 18, 25, 27, 52, 54, 68], "anthrop": 25, "antidisestablishmentarian": 52, "antiquit\u00e9": 17, "anyth": [17, 25], "apach": 66, "apart": [17, 24], "apeach": [64, 70], "api": [6, 33, 41, 42, 45, 48, 49, 52, 54, 56, 57, 62, 68], "api_kei": [12, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 33, 34], "apivers": [56, 57, 60], "app": [12, 57, 60], "appear": [14, 19, 27, 29, 33, 36, 37, 54], "append": [3, 12, 18, 20, 35, 43], "append_messag": 19, "appli": [0, 8, 11, 12, 14, 19, 20, 25, 27, 35, 37, 38, 41, 44, 45, 56, 57], "applic": [8, 12, 17, 20, 24, 25, 28, 29, 34, 36, 42, 45, 56, 57, 60, 64], "apply_chat_templ": [13, 16, 17, 18, 23, 24], "appreci": 37, "approach": [3, 6, 7, 17, 20, 36, 41, 57], "appropri": [0, 6, 11, 15, 17, 27, 35, 64], "approv": 37, "approxim": 17, "apt": [0, 36, 40], "ar": [0, 1, 2, 3, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 48, 49, 50, 52, 54, 55, 56, 57, 60, 65, 66, 68, 69, 70, 71, 72], "arc": [17, 48], "arce": 66, "arch": 40, "architectur": [1, 11, 20, 22, 24, 36, 65, 66, 68, 71], "area": [17, 19, 24, 25, 54], "arg": [10, 21, 24, 36, 38, 52, 65], "argument": [11, 12, 16, 17, 18, 20, 21, 23, 24, 27, 31, 32, 33, 35, 36, 37, 41, 42, 46, 62, 71], "arguments_non_stream": 18, "aris": 51, "around": [17, 18, 20, 25, 71], "arrai": [17, 35, 64], "arriv": [13, 14, 35], "art": [17, 37, 66], "articl": [22, 25], "artifici": [25, 71], "artist": 25, "ascend": [1, 14, 41, 42], "ascend_attn": 14, "ascend_instal": 44, "ascend_mf_store_url": [10, 44], "ask": [13, 15, 17, 18, 27, 37, 42, 54], "aspect": [2, 14], "assembli": 15, "assert": [24, 33, 36], "asset": 29, "assign": [8, 33], "assist": [6, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 33, 34, 49, 52, 54, 57, 60], "assistant_begin": 54, "assistant_end": 54, "associ": [3, 12, 17, 20, 54], "assum": [13, 17, 18], "async": [5, 14, 25, 71], "async_gener": [25, 71], "async_stream_and_merg": 25, "asynchron": [32, 71], "asyncio": 71, "as\u8fbe\u82ac\u5947": 17, "at_least_on": 16, "atla": [20, 44], "atp": 12, "atp_dsn": 12, "atp_password": 12, "atp_pool_max": 12, "atp_pool_min": 12, "atp_tns_alia": 12, "atp_us": 12, "atp_wallet_path": 12, "attach": 68, "attachment_ep_statist": 57, "attact": 18, "attain": 7, "attempt": [6, 35], "atten_tp_s": 21, "attent": [3, 6, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 32, 34, 41, 42, 44, 46, 48, 50, 54, 56, 57, 60, 65, 66, 69, 71, 72], "attention_backend": [13, 16, 17, 18, 19, 24, 25], "attention_interfac": 72, "attn": 14, "attn_output": 72, "attn_weight": 72, "attract": [18, 25, 52], "attribut": 62, "audio": [15, 18, 24, 27, 33, 34, 68], "audio_data": 33, "audiodataitem": 33, "aug": 22, "augment": [66, 68], "august": [22, 44], "augustu": 27, "auror": 54, "australia": [8, 15, 27, 34], "auth": [12, 35], "author": [12, 35, 57, 60], "auto": [0, 13, 14, 15, 16, 17, 18, 19, 24, 25, 35, 50, 61, 63], "auto_awq": 11, "auto_gptq": 11, "auto_map": 72, "auto_next_anon": 62, "auto_round": 11, "autograd": 36, "autom": [25, 43], "automat": [0, 1, 5, 6, 8, 11, 12, 14, 18, 21, 24, 27, 32, 33, 35, 36, 37, 45, 61, 62, 64], "autonom": [12, 25], "autoprocessor": 19, "autoregress": 15, "autoround": 11, "autoroundmllm": 11, "autosc": 41, "autotag": 46, "autotoken": [11, 13, 16, 17, 18, 24, 28], "autotun": [15, 63], "aux": 15, "auxiliari": 10, "avail": [6, 8, 12, 14, 16, 17, 20, 22, 24, 27, 28, 29, 34, 35, 41, 43, 45, 50, 51, 56, 61, 64, 66, 72], "avail_mem": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 29, 34, 54], "available_gpu_mem": [7, 24], "available_tool": 18, "averag": [14, 17, 52], "averagetemperatur": 17, "avoid": [5, 6, 8, 11, 14, 17, 21, 23, 27, 32, 36, 37, 38, 45, 48, 51, 54, 56, 67], "await": [25, 71], "awar": [10, 25], "awq": [11, 14, 20, 42], "awq_marlin": [11, 14], "b": [3, 8, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 34, 41, 43, 44, 45, 48, 51, 54, 56, 57, 60, 62], "b200": [1, 20, 21, 32], "b300": 42, "b351773f3ffc4834bfc9968f0ee2ce97": 17, "b580": 48, "baai": [24, 65, 66, 69], "back": [12, 14, 17, 21, 25, 29, 54, 64, 72], "backbon": 68, "backend": [10, 13, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 34, 36, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 57, 58, 60, 61, 65, 69, 71, 72], "backend_nam": [5, 6, 14], "backendfactori": 5, "background": [12, 19, 25, 29, 61, 72], "backoff": 12, "backtrac": 36, "backu": 18, "backup": 14, "backward": [8, 14, 27], "bad": [52, 64], "baichuan": 66, "baichuan2": 66, "baichuanai": 66, "baidu": 66, "balanc": [5, 6, 10, 14, 20, 22, 27, 29, 54, 57, 60], "balanced": 14, "bandwidth": [2, 6, 10], "bank": 34, "bar": [38, 66, 68], "bare": 45, "base": [1, 5, 6, 8, 10, 11, 14, 15, 17, 20, 21, 22, 27, 32, 33, 35, 36, 44, 50, 52, 56, 58, 59, 62, 63, 65, 66, 69, 70], "base64": 33, "base_config": 71, "base_gpu_id": [13, 16, 17, 18, 19, 24, 25], "base_url": [13, 15, 16, 17, 18, 20, 22, 23, 24, 27, 28, 29, 33, 34, 36], "baseformatdetector": 18, "baselin": [6, 71], "basemodel": [16, 17], "basemultimodalprocessor": 71, "basereasoningformatdetector": 13, "bash": [0, 36, 39, 40, 45, 46, 58], "bashrc": [36, 45], "basi": 21, "basic": [8, 17, 35, 36, 66], "basic_qa": 54, "batch": [3, 6, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 29, 33, 34, 35, 36, 37, 38, 42, 45, 50, 51, 56, 57, 68], "batch_siz": [11, 23], "batchspanprocessor": 50, "bc": 27, "be670a5f193e49529c30da01bd432c6d": 29, "bear": [24, 69], "bearer": [12, 35, 57, 60], "becaus": [6, 15, 17, 18, 35, 44, 54, 71], "becom": [2, 25], "bedroom": 17, "been": [6, 11, 15, 17, 25, 27, 36, 45, 48, 56], "befor": [0, 1, 2, 6, 7, 8, 9, 10, 12, 14, 17, 18, 20, 35, 36, 37, 46, 62, 68, 71], "beforehand": 20, "begin": [16, 17, 24, 36, 54, 62], "behavior": [10, 14, 18, 32, 33, 35, 50, 68, 70], "beij": [16, 17, 20], "being": [7, 10, 14, 17, 19, 25, 27, 54, 62], "believ": 17, "belong": [6, 54], "below": [1, 8, 14, 15, 18, 24, 32, 33, 38, 40, 41, 43, 44, 45, 54, 62, 65, 66, 68, 71], "bench": [15, 36, 42, 65], "bench_one_batch": [36, 38, 71], "bench_one_batch_serv": 36, "bench_serv": [35, 43, 45, 48, 61], "bench_sglang": [21, 38], "bench_specul": [15, 20, 21], "benchmark": [6, 8, 9, 10, 11, 15, 24, 35, 38, 42, 43, 61, 68], "benchmark_and_profil": 71, "benefici": 7, "benefit": [6, 36], "berlin": [15, 16, 17, 27, 52], "berlin3": 54, "bertforsequenceclassif": 64, "besid": 54, "bespok": 52, "best": [4, 6, 15, 17, 20, 21, 27, 32], "best_effort": [5, 6, 13, 14, 16, 17, 18, 19, 24, 25], "better": [6, 7, 8, 11, 14, 16, 20, 21, 24, 25, 27, 33, 41, 65, 68], "between": [1, 2, 5, 6, 7, 10, 14, 17, 24, 33, 35, 36, 54, 57, 65, 66], "bewar": 45, "beyond": [6, 12, 20, 21], "bf": [13, 14, 16, 17, 18, 19, 24, 25], "bf16": [14, 18, 20, 21, 44, 45, 48], "bfloat16": [14, 15, 24, 31, 46, 50], "bge": [24, 65, 69], "bgererankmodel": 69, "bia": [25, 71], "bias": 71, "bicam": 17, "big": 17, "bigcod": 66, "bilingu": 66, "billion": 66, "bin": [14, 38, 40, 45, 58], "bingyuan": 17, "birth": 17, "bit": [11, 17], "bitsandbyt": [11, 14], "black": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "blackwel": [1, 11, 18, 20, 21, 50], "blank": 35, "blob": [19, 29, 32, 33, 54], "block": [6, 17, 37, 50, 54], "block_k": 15, "block_m": 15, "block_n": 15, "blockwis": 50, "blog": [6, 20, 51, 55, 58], "blogpost": 52, "blood": 54, "blue": [8, 13, 15, 16, 17, 18, 19, 24, 27, 28, 29, 34, 54], "bluefield": 56, "bmm": [20, 50], "bnf": [16, 33], "board": 29, "boast": 17, "bodi": [8, 35], "bogart": 54, "bogor": 8, "bond0": 60, "book": 29, "bool": [8, 14, 33, 50, 71], "boolean": 37, "boost": 54, "bootstrap": [10, 12, 14, 21, 44, 62], "bootstrap_room": 62, "bootstrap_room_list": 62, "bootstrap_room_span": 62, "border": 24, "born": 54, "borough": 17, "boston": 18, "bot": [16, 17, 37], "both": [1, 2, 6, 7, 8, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 27, 33, 35, 36, 38, 50, 51, 54, 61, 65, 68, 71], "bottleneck": [5, 36], "bottom": [22, 38], "bound": [14, 24], "boundari": [6, 12, 18], "box": [13, 32], "bracket": 17, "branch": [0, 1, 14, 15, 37, 41, 43, 44], "brandenburg": 17, "bras\u00edlia": [8, 15, 54], "brave_search": [16, 17], "brazil": [8, 15, 54], "breadth": 14, "break": [17, 27, 33, 34, 44], "breakdown": [27, 35], "breakpoint": 38, "bridg": 17, "brief": [17, 25], "bright": 54, "bring": 25, "broad": 66, "broadcast": 2, "broader": 25, "brows": 61, "browser": [0, 22, 36, 61, 62], "browser_serv": 22, "bucket": [12, 14], "bucket_e2e_request_lat": [13, 16, 17, 18, 19, 24, 25], "bucket_inter_token_lat": [13, 16, 17, 18, 19, 24, 25], "bucket_time_to_first_token": [13, 16, 17, 18, 19, 24, 25], "budget": 6, "buffer": [1, 7, 13, 14], "bug": [5, 11, 37, 51], "build": [0, 3, 6, 10, 11, 15, 17, 19, 24, 25, 29, 38, 39, 43, 44, 45, 46, 48, 50, 62, 68], "built": [6, 8, 14, 27, 36, 37, 41, 43, 68], "buliltin": 14, "bullet": 17, "bump": 37, "burst": 35, "busi": [17, 25, 29, 66], "bustl": 54, "bytesio": 19, "b\u00e2timent": 24, "c": [3, 8, 17, 18, 24, 25, 27, 34, 41, 43, 56, 60, 62], "c3ec": 56, "c4": 11, "c45a1056868f40d697692cb3b1e47460": 17, "c4ai": 66, "c7": 56, "c79a": 56, "ca": [16, 17, 18], "cab": 19, "cach": [1, 3, 5, 6, 8, 10, 15, 20, 21, 23, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 51, 56, 57, 60, 61, 67, 69], "cache_awar": 12, "cache_hit_r": 61, "cached_token": [16, 17, 24, 34], "cadenc": 12, "caf\u00e9": 64, "calcul": [10, 11, 13, 14, 22, 54], "calibr": 11, "calibration_dataset": 11, "california": [16, 17, 18], "call": [1, 12, 14, 15, 16, 17, 22, 24, 25, 27, 32, 35, 36, 42, 52, 54, 57, 62, 68, 69, 71], "call_0a5a0a618d7044d1b9df3fef": 18, "call_0ed439c74fa24a1aaa4b733": 18, "call_130b860886ca4692b3e460a4": 18, "call_470a7947b8ea4fd0937733d2": 18, "call_4aacc74fe8c649bbb3a28ef3": 18, "call_74e2dae734554332b59e1613": 18, "call_7e3e7048c89343cc805b7e06": 18, "call_7fc5fe0ca5dd4632b3d5fae2": 18, "call_a0d02a1458544b58be13451": 18, "call_c24fd91462ae4558b83e9439": 18, "call_dbb6116cef4441d99346ba3f": 18, "caller": 37, "can": [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 62, 63, 65, 66, 68, 71, 72], "canada": [27, 34], "canberra": [8, 15, 27, 34], "candid": 15, "cannot": [1, 36, 45, 56], "cano": 46, "cap": [35, 43], "capabl": [12, 23, 24, 25, 27, 31, 32, 43, 57, 60, 68], "capac": [5, 6, 12, 14, 15, 20, 21], "capit": [8, 11, 15, 16, 17, 18, 20, 24, 25, 27, 33, 34, 52, 54, 65, 71], "capital_info": 16, "capital_inform": 17, "capitalinfo": [16, 17], "caption": 68, "captur": [1, 2, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 25, 27, 29, 34, 36, 50, 54, 56], "car": 25, "carbohydr": 54, "care": 22, "career": 25, "carefulli": 29, "carri": 19, "cascad": 15, "case": [0, 1, 6, 7, 8, 11, 17, 20, 21, 25, 35, 36, 51, 54, 66], "cast": [14, 15, 20], "cat": [14, 44], "categori": 17, "cathedr": [17, 25], "caus": [9, 10, 14, 17, 18, 36, 51], "causallm": 14, "caveat": 36, "cb": 12, "cbm": [57, 60], "cc48b5a76294465db80e323c00426509": 16, "ccccdd": [57, 60], "cd": [10, 21, 39, 41, 43, 44, 45, 48, 61], "celsiu": [16, 17, 18], "censu": 17, "center": [15, 17, 25, 27], "centimet": 25, "central": 12, "centuri": 27, "certain": [15, 17, 43, 62], "certainli": 54, "certif": 17, "cf": 57, "chain": 42, "challeng": [10, 25, 37, 51], "chambr": 24, "champ": 15, "chanc": [15, 17, 18], "chang": [0, 15, 17, 20, 21, 22, 24, 25, 33, 36, 37, 38, 40, 43, 44, 51, 56, 60, 61, 65, 71], "channel": [5, 11, 13, 14, 18, 20, 37, 45, 48], "chapter": 25, "charact": [25, 54, 68, 71], "character": 25, "character_gen": 54, "character_regex": 54, "characterist": 6, "chart": 57, "chat": [8, 11, 12, 13, 14, 15, 16, 17, 20, 23, 24, 29, 32, 33, 34, 35, 42, 46, 57, 60, 65, 66, 68, 69, 71], "chat_exampl": 54, "chat_templ": [13, 16, 17, 18, 19, 20, 24, 25, 49], "chat_template_kwarg": 27, "chatcomplet": [15, 18, 27, 34], "chatcompletionmessag": [15, 18, 27, 34], "chatcompletionmessagefunctiontoolcal": 18, "chatglm": 66, "chatglm2": 66, "chatml": [49, 68], "cheaper": 68, "check": [0, 2, 5, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 27, 28, 29, 33, 34, 35, 37, 41, 44, 45, 50, 54, 56, 72], "check_output": [28, 29, 34], "checker": 12, "checkout": [15, 45, 48], "checkpoint": [8, 11, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 32, 34, 36, 42, 54, 71], "checkpoint_engin": 2, "checkpoint_engine_wait_weights_before_readi": [13, 16, 17, 18, 19, 24, 25], "chene": 15, "child": 6, "children": 50, "china": [16, 17, 24, 69], "chines": [17, 27, 66], "choic": [13, 14, 15, 16, 17, 20, 21, 27, 29, 34, 53, 54, 57, 60], "choicedeltatoolcal": 18, "choicedeltatoolcallfunct": 18, "choices_method": 52, "choos": [1, 3, 5, 6, 12, 14, 15, 16, 17, 38], "chosen": [1, 14], "chrome": 36, "chunk": [1, 3, 8, 13, 14, 18, 20, 21, 24, 27, 32, 33, 34, 42, 50, 51, 57, 60, 69], "chunked_prefill_s": [7, 13, 16, 17, 18, 19, 24, 25, 56], "chunkedsgmv": [8, 14], "ch\u00e2teau": 17, "ci": [0, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "circular": 14, "cite": 17, "citi": [15, 16, 17, 18, 20, 24, 25, 29, 34, 54, 71], "cit\u00e9": 17, "civil": 27, "ckpt": 14, "clariti": [8, 13, 15, 16, 17, 18, 20, 24, 27, 28, 29, 34, 54], "class": [1, 5, 6, 14, 16, 17, 18, 33, 71, 72], "class_0": 64, "class_1": 64, "class_nam": [5, 6, 14], "classic": [1, 6], "classif": 70, "classifi": [34, 64, 70], "clean": [0, 10, 19], "cleaned_chunk": 25, "clear": 17, "clearli": 17, "cli": [12, 14, 24, 36], "click": 37, "client": [7, 8, 12, 13, 15, 16, 17, 20, 22, 27, 33, 36, 50, 56], "client_tool_choic": 18, "climat": 17, "climb": 22, "clip": [50, 65, 68], "clone": [10, 21, 41, 43, 44, 45, 46, 48], "close": [11, 12, 22], "cloth": [19, 29, 54], "cloudi": 18, "cloudli": 18, "cluster": [6, 14, 41, 42, 44, 45, 56, 57, 58], "clusterfirstwithhostnet": [56, 57, 60], "clusterip": [57, 60], "cm1": 56, "cn": 44, "cnam": 17, "cnbc": 22, "co": [24, 65], "coast": 17, "code": [0, 1, 5, 7, 8, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 36, 38, 43, 44, 45, 48, 51, 54, 56, 57, 60, 62, 64, 65, 66, 68, 69, 70, 71], "code_interpret": 22, "codebas": [0, 37], "codeown": 37, "coder": 18, "cofeai": 66, "coffe": 64, "coher": [15, 66], "cohereforai": 66, "collabor": 66, "collect": [11, 14, 25, 50], "collect_tokens_histogram": [13, 16, 17, 18, 19, 24, 25], "collector": [14, 62], "colleg": 17, "coloni": 25, "color": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 36, 54], "colosseum": 27, "column": 1, "com": [10, 12, 19, 21, 24, 29, 32, 33, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 54, 55, 56, 57, 60, 62, 68], "combin": [1, 2, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 24, 27, 28, 29, 34, 36, 54, 68], "come": [14, 15, 72], "comma": [14, 17], "command": [9, 10, 11, 18, 20, 21, 23, 28, 34, 38, 40, 41, 43, 44, 45, 46, 48, 56, 57, 60, 61, 71], "comment": 17, "commerci": 66, "commit": [0, 14], "common": [0, 1, 6, 17, 25, 35, 37, 51, 56], "commonli": [17, 18], "commun": [2, 14, 36, 42, 56, 57], "compact": [14, 66, 68], "compani": [25, 55, 57], "compar": [6, 20, 66, 71], "comparison": [52, 71], "compat": [3, 5, 6, 11, 12, 14, 20, 22, 24, 27, 28, 29, 33, 35, 42, 49, 56, 57, 60, 62, 68], "compet": 66, "compil": [0, 7, 14, 17, 20, 43, 45, 50, 56], "compile_deep_gemm": 20, "complet": [5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 36, 45, 46, 48, 54, 56, 57, 60, 64, 66, 68], "completion_templ": [13, 16, 17, 18, 19, 24, 25], "completion_token": [15, 16, 17, 18, 20, 24, 27, 28, 29, 34, 57, 60, 64], "completion_tokens_detail": [15, 18, 27, 34], "completionchoic": 27, "completionusag": [15, 18, 27, 34], "complex": [0, 17, 25, 37, 66, 68], "complianc": 12, "compon": [2, 6, 7, 11, 37, 57, 71], "compos": [61, 62], "comprehens": [6, 12, 17, 18, 50, 69], "compressedtensorsconfig": 11, "compris": 10, "comput": [6, 10, 11, 14, 15, 19, 20, 21, 24, 25, 29, 36, 46, 51, 54], "con": 1, "concaten": 20, "concis": [17, 25, 27, 37, 71], "conclud": [13, 24], "concord": 24, "concurr": [1, 6, 7, 8, 12, 14, 32, 51, 62], "conda": [41, 44, 45, 48], "conda_ex": 45, "conda_prefix": 45, "conda_root": 45, "condabin": 45, "condit": [6, 10], "confid": [15, 17, 52], "config": [5, 6, 8, 10, 11, 12, 14, 15, 24, 36, 38, 45, 46, 50, 57, 61, 64, 65, 71, 72], "configur": [0, 6, 8, 11, 20, 24, 35, 37, 38, 56, 57, 60, 62, 71], "configure_log": 9, "confirm": [17, 43, 61], "conflict": [48, 61], "confus": [15, 17], "connect": [2, 8, 10, 12, 13, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 34, 35, 38, 54, 58, 61], "connect_data": 12, "connectx": 56, "consecut": [6, 10, 14, 50], "consensu": 6, "conserv": [7, 14], "consid": [0, 6, 11, 12, 15, 17, 33], "consider": 25, "consist": [2, 3, 6, 12, 20, 37, 62, 66], "consol": [35, 38], "consolid": 50, "constant": 33, "constantli": 25, "constrain": [14, 16], "constrained_json_disable_any_whitespac": [13, 16, 17, 18, 19, 24, 25], "constrained_json_whitespace_pattern": [13, 16, 17, 18, 19, 24, 25], "constraint": [1, 16, 17, 33, 50, 54, 62], "construct": [27, 35, 45], "constructor": 71, "consult": 14, "consum": [6, 7, 68], "consumpt": 15, "contact": 57, "contain": [2, 6, 14, 20, 24, 27, 36, 41, 44, 45, 52, 56, 57, 60, 61, 62], "container": 56, "container_id": 61, "container_nam": 61, "containerd": 56, "containerport": [56, 57, 60], "content": [9, 13, 14, 15, 16, 17, 18, 19, 24, 27, 28, 29, 32, 33, 34, 35, 36, 57, 60, 64, 68, 70], "context": [5, 6, 12, 14, 15, 17, 23, 25, 32, 35, 46, 48, 50, 57, 60, 62, 66, 68], "context_len": [7, 24, 56], "context_length": [13, 14, 15, 16, 17, 18, 19, 24, 25], "contigu": 6, "continu": [5, 6, 12, 14, 15, 21, 24, 25, 36, 42, 50], "contract": 13, "contrast": 6, "contribut": [5, 12, 15, 42, 49, 57], "contributor": [0, 37, 66], "control": [5, 6, 8, 9, 10, 14, 15, 18, 27, 32, 33, 35, 36, 42, 50, 56], "conv": [19, 24], "conveni": [11, 36, 43, 54], "convent": [5, 10], "convers": [5, 12, 19, 23, 25, 35, 49, 66, 68, 71], "convert": [6, 11, 16, 17, 25, 27, 62, 68, 71], "convert_dict_to_tool": 18, "cooldown": 12, "coordin": 17, "copi": [5, 6, 14, 17, 19, 32, 41, 63, 68], "core": [6, 8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 42, 45, 54, 62], "corpu": 66, "correct": [0, 8, 14, 17, 18, 25, 27, 36, 71], "correctli": [17, 21, 27, 36, 56, 71, 72], "correspond": [1, 6, 8, 11, 14, 17, 18, 28, 33, 37, 62, 71], "cost": [14, 17, 36, 65, 66, 68], "cot": 13, "could": [14, 15, 17, 22, 25, 43, 44, 56], "count": [6, 12, 24, 27, 35, 45, 50], "counter": [12, 61], "countri": [8, 15, 16, 17, 27, 33, 34, 54], "cover": [6, 12, 17, 27, 28, 29, 56, 71], "coverag": 37, "cp": [21, 45, 48], "cp311": [10, 44], "cp_size": 21, "cpp": 36, "cpu": [2, 5, 6, 8, 11, 13, 14, 16, 17, 18, 19, 20, 24, 25, 36, 37, 41, 42, 50, 57, 58, 60, 68], "cpu0": 44, "cpu_count": 10, "cpu_offload_gb": [13, 16, 17, 18, 19, 24, 25], "cpufreq": 44, "crash": [14, 60], "crash_dump": 9, "crash_dump_fold": [13, 16, 17, 18, 19, 24, 25], "creat": [0, 1, 6, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 33, 34, 37, 38, 41, 43, 44, 45, 48, 60, 62, 64, 71], "creativ": 27, "credenti": 12, "credibl": 17, "critic": [1, 3, 6, 36, 37], "cross": [5, 6, 17, 21, 65, 68, 69], "crucial": [1, 17, 56], "csgmv": [8, 13, 14, 16, 17, 18, 19, 24, 25], "csrc": 36, "csv": [14, 24], "ctrl": [24, 56], "cubla": 51, "cuda": [1, 2, 3, 6, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 32, 36, 38, 40, 41, 45, 46, 48, 56, 57, 60], "cuda_graph_b": [13, 16, 17, 18, 19, 24, 25], "cuda_graph_max_b": [13, 16, 17, 18, 19, 24, 25], "cuda_hom": 41, "cuda_launch_block": [57, 60], "cuda_profil": 36, "cuda_visible_devic": 40, "cudagraph": [14, 63], "cudamemcpyasync": 6, "cudaprofilerapi": 36, "cudaprofilerstart": 36, "cudaprofilerstop": 36, "cudnn": 46, "cultur": [15, 17, 25], "cumul": 33, "curiou": 17, "curl": [9, 12, 20, 24, 33, 36, 40, 45, 48, 57, 60, 61], "curl_command": [29, 34], "curl_id": 28, "curl_text": 28, "current": [1, 8, 10, 11, 12, 14, 16, 17, 20, 21, 22, 25, 33, 35, 37, 44, 45, 48, 50, 51, 57, 60, 62, 69], "current_estim": 17, "custom": [0, 6, 12, 13, 16, 17, 18, 19, 20, 21, 24, 25, 27, 35, 42, 50, 61], "custom_backend_nam": 5, "custom_logit_processor": [20, 33], "custom_param": [20, 33], "custom_param_list": 33, "custom_serv": 25, "custom_weight_load": [13, 16, 17, 18, 19, 24, 25], "customlogitprocessor": [20, 33], "cut": [11, 20], "cutedsl": 14, "cutlass": [1, 8, 11, 14, 50], "cutlass_mla": [1, 14], "cutlassmla": 20, "cycl": 12, "d": [8, 12, 14, 17, 20, 21, 24, 25, 27, 28, 29, 34, 36, 41, 45, 54, 57, 58, 60, 61, 62, 64], "d2h": [14, 32], "d4e0cd3cc914488cb6db96dca1338ff2": 17, "d6aeb48f1ce44911b4ef980556e5327b": 18, "dai": [18, 20, 22, 27, 54], "dame": [17, 24, 25], "damm": 17, "dao": 20, "dashboard": 61, "data": [5, 7, 10, 13, 15, 17, 18, 22, 24, 25, 27, 28, 29, 32, 33, 34, 36, 42, 43, 60, 61, 62, 64, 65, 68, 71], "data1": [56, 57, 60], "data_fil": 11, "databas": [12, 25], "databrick": 66, "dataload": 14, "dataset": [11, 21, 23, 36, 43, 45, 48, 61, 65], "datasourc": 61, "date": [16, 17, 22], "davinci": 44, "davinci0": 44, "davinci1": 44, "davinci10": 44, "davinci11": 44, "davinci12": 44, "davinci13": 44, "davinci14": 44, "davinci15": 44, "davinci2": 44, "davinci3": 44, "davinci4": 44, "davinci5": 44, "davinci6": 44, "davinci7": 44, "davinci8": 44, "davinci9": 44, "davinci_manag": 44, "dbazur": 38, "dbrx": 66, "de": [17, 24], "deactiv": 41, "deadlock": 14, "death": [17, 54], "deb": 36, "debri": 19, "debug": [2, 3, 9, 12, 15, 36], "debug_tensor_dump_inject": [13, 16, 17, 18, 19, 24, 25], "debug_tensor_dump_input_fil": [13, 16, 17, 18, 19, 24, 25], "debug_tensor_dump_lay": [13, 16, 17, 18, 19, 24, 25], "debug_tensor_dump_output_fold": [13, 16, 17, 18, 19, 24, 25], "debugg": 3, "debugpi": 38, "deceas": 54, "decemb": 16, "decid": [14, 17], "decis": 25, "declar": 71, "decod": [5, 6, 7, 20, 21, 29, 34, 35, 42, 44, 45, 50, 51, 60, 62, 66, 68, 72], "decode1": 12, "decode_addr": 21, "decode_attention_backend": [13, 16, 17, 18, 19, 24, 25], "decode_host_ip": 44, "decode_log_interv": [13, 16, 17, 18, 19, 24, 25], "decode_master_ip": 10, "decode_unicod": [33, 34], "decord": 68, "decoupl": 68, "decreas": [7, 27, 31, 51], "decrypted_config_fil": [13, 16, 17, 18, 19, 24, 25], "decrypted_draft_config_fil": [13, 16, 17, 18, 19, 24, 25], "dedic": [6, 10, 27, 33, 36, 41, 45, 48, 68, 71], "dee": [57, 60], "deep": 22, "deep_gemm": [14, 50], "deepep": [10, 14, 21, 57, 60], "deepep_config": [13, 16, 17, 18, 19, 24, 25], "deepep_mod": [13, 16, 17, 18, 19, 24, 25], "deeper": [15, 37], "deepgemm": 20, "deepli": [12, 24], "deepseeek": 42, "deepseek": [1, 2, 5, 6, 7, 11, 12, 13, 14, 15, 17, 18, 30, 38, 41, 42, 46, 56, 57, 59, 60, 66, 68], "deepseek_r1_0528": 57, "deepseek_v3": 38, "deepseek_v3_mo": 56, "deepseekr10528": 57, "deepseekr1thinkingbudgetlogitprocessor": 20, "deepseekv3": [14, 18, 20], "deepseekv31": [14, 18], "deepseekv32": [18, 59], "deepseekv32_pd": 21, "def": [16, 17, 18, 25, 33, 52, 54, 71, 72], "default": [1, 2, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 31, 34, 35, 36, 41, 43, 44, 49, 50, 52, 54, 56, 60, 61, 62, 64, 68, 71, 72], "defin": [1, 13, 14, 16, 17, 24, 32, 33, 49, 54, 58, 61, 71], "definit": [15, 17, 61], "degrad": [8, 15, 56], "degre": [18, 25], "delai": [2, 10, 11, 22, 36], "delet": [12, 14, 41], "delete_ckpt_after_load": [13, 16, 17, 18, 19, 24, 25], "delimit": [13, 14, 18], "deliv": [42, 66], "delta": [13, 14, 18, 20, 27, 34], "demand": 8, "dementor": 54, "demo": 14, "demograph": 17, "demonstr": [6, 8, 11, 18, 24, 25, 27, 66, 71], "denot": [14, 17], "dens": [14, 57, 60, 66], "dep": [35, 41, 48], "depend": [1, 6, 11, 17, 35, 45, 48, 60, 62], "depict": 19, "deploi": [5, 10, 20, 41, 59, 63], "deploy": [2, 10, 11, 14, 21, 32, 41, 42, 45, 56, 60, 65, 66, 68, 69], "deprec": [12, 18, 24, 50], "depth": [15, 17, 44, 66], "deriv": [15, 70], "describ": [25, 27, 29, 33, 37, 41, 43, 52, 61, 62, 64], "descript": [3, 10, 12, 14, 16, 17, 18, 20, 23, 31, 33, 36, 50, 65, 66, 68, 69, 70, 71], "descriptor": [12, 35], "design": [1, 4, 5, 10, 13, 20, 21, 27, 29, 42, 62, 64, 66, 68, 69], "desir": [16, 45, 48], "desktop": 61, "destin": [10, 25], "detach": 19, "detail": [1, 5, 6, 8, 9, 10, 12, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 31, 33, 35, 36, 37, 45, 46, 48, 51, 56, 68, 71], "detailed_tip": 54, "detect": [8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 50, 54], "detector": 18, "determin": [6, 7, 14, 18, 45, 52, 62], "determinist": [37, 42], "deterministiclogitprocessor": 33, "detoken": [33, 50], "detokenization_result": 24, "detokenize_payload": 24, "detokenize_respons": 24, "detokenize_url": 24, "dev": [14, 36, 40, 41, 43, 44, 45, 56, 57, 60], "devcontain": 38, "devel": 40, "develop": [3, 6, 8, 14, 18, 20, 21, 25, 27, 36, 37, 41, 44, 48, 55, 62, 66], "developer_guid": 71, "devic": [5, 6, 10, 11, 13, 14, 16, 17, 18, 19, 20, 24, 25, 32, 37, 40, 41, 43, 44, 45, 46, 48, 50, 56, 57, 60, 66, 68], "device_config": 11, "device_list": 5, "device_map": 11, "device_nam": [10, 24], "deviceconfig": 11, "devkit": 46, "devtool": 36, "df": 14, "dgx": 41, "diagnos": 56, "diagnosi": 25, "diagram": 38, "dialogu": [5, 66], "dict": [14, 16, 17, 18, 19, 33], "dictionari": [14, 17, 18, 27], "did": 24, "didn": [17, 18], "diet": 54, "differ": [3, 6, 8, 11, 14, 15, 17, 20, 21, 24, 25, 29, 32, 35, 38, 43, 45, 50, 51, 56, 57, 60, 61, 62, 63, 67, 71], "diffus": [42, 65], "dimens": [14, 36], "dir": [11, 12, 14, 36, 56], "direct": [2, 5, 6, 14, 25], "directli": [0, 2, 6, 11, 12, 13, 14, 15, 16, 17, 25, 27, 36, 37, 57, 71], "directori": [2, 12, 14, 36, 38, 50, 61, 62, 67, 71], "directoryorcr": [57, 60], "dirt": 19, "disabl": [3, 11, 12, 13, 14, 15, 17, 20, 24, 35, 36, 38, 45, 48, 50, 51, 57, 60, 69], "disable_chunked_prefix_cach": [13, 16, 17, 18, 19, 24, 25], "disable_cuda_graph": [13, 16, 17, 18, 19, 24, 25], "disable_cuda_graph_pad": [13, 16, 17, 18, 19, 24, 25], "disable_custom_all_reduc": [13, 16, 17, 18, 19, 24, 25], "disable_fast_image_processor": [13, 16, 17, 18, 19, 24, 25], "disable_flashinfer_cutlass_moe_fp4_allgath": [13, 16, 17, 18, 19, 24, 25], "disable_hybrid_swa_memori": [13, 16, 17, 18, 19, 24, 25], "disable_outlines_disk_cach": [13, 16, 17, 18, 19, 24, 25], "disable_overlap_schedul": [13, 16, 17, 18, 19, 24, 25], "disable_radix_cach": [13, 16, 17, 18, 19, 24, 25], "disable_shared_experts_fus": [13, 16, 17, 18, 19, 24, 25], "disable_tokenizer_batch_decod": [13, 16, 17, 18, 19, 24, 25], "disaggreg": [42, 44, 57, 59, 60, 62], "disaggregation_bootstrap_port": [13, 16, 17, 18, 19, 24, 25], "disaggregation_decode_dp": [13, 16, 17, 18, 19, 24, 25], "disaggregation_decode_enable_offload_kvcach": [13, 16, 17, 18, 19, 24, 25], "disaggregation_decode_polling_interv": [13, 16, 17, 18, 19, 24, 25], "disaggregation_decode_tp": [13, 16, 17, 18, 19, 24, 25], "disaggregation_ib_devic": [13, 16, 17, 18, 19, 24, 25], "disaggregation_mod": [13, 16, 17, 18, 19, 24, 25], "disaggregation_prefill_pp": [13, 16, 17, 18, 19, 24, 25], "disaggregation_transfer_backend": [13, 16, 17, 18, 19, 24, 25], "discourag": [27, 33], "discov": 12, "discoveri": 60, "discuss": [5, 20, 37], "disjoint": 14, "disk": [2, 14, 50, 67, 71], "dispatch": [1, 14, 50, 51, 57, 60], "displai": [0, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 38, 43, 54], "dissect": 17, "dist": [2, 10, 14, 15, 20, 21, 44, 56, 57, 58, 60], "dist_init_addr": [13, 16, 17, 18, 19, 24, 25], "dist_port": 21, "dist_timeout": [13, 16, 17, 18, 19, 24, 25], "distil": [13, 17, 27, 45, 46], "distinct": 10, "distinguish": 62, "distrib_releas": 36, "distribut": [0, 2, 6, 10, 12, 33, 41, 42, 56], "district": 17, "distro": 43, "divers": [3, 6, 15, 17, 27, 33], "divid": [17, 35], "divis": 21, "dlami": 38, "dn": 54, "dnspolici": [56, 57, 60], "do": [0, 1, 11, 14, 17, 18, 20, 27, 36, 37, 40, 45, 51, 58, 71], "doc": [6, 15, 16, 33, 36, 37, 38, 41, 43, 46, 52, 71], "doc_patch": [8, 13, 15, 16, 17, 18, 24, 25, 27, 28, 29, 34, 54], "docker": [14, 20, 22, 36, 42, 46, 50, 56, 61, 62, 67], "dockerfil": [41, 43, 44, 45], "dockerx": 43, "document": [1, 5, 6, 8, 10, 12, 14, 15, 18, 20, 21, 22, 24, 25, 27, 38, 41, 43, 45, 46, 48, 49, 50, 56, 58, 64, 68, 69], "doe": [6, 9, 14, 15, 17, 36, 37, 38, 71], "doesn": 56, "domain": 2, "domin": 25, "don": [15, 17, 18, 19, 23, 27, 33, 36, 37, 38, 43, 44, 68, 71], "donald": 52, "done": [15, 20, 29, 33, 34, 36, 40, 58], "dot": 68, "dotsvlm": 68, "doubl": [17, 27], "down": [7, 17, 19, 22, 27, 51, 52], "down_proj": [8, 14], "downcast": [24, 28], "download": [10, 11, 14, 15, 24, 33, 35, 36, 38, 44, 45, 48, 71], "download_dir": [13, 16, 17, 18, 19, 24, 25], "downstream": 12, "downward": 56, "dp": [10, 12, 14, 20, 21, 36, 44, 57, 60], "dp_attent": 14, "dp_rank": 62, "dp_size": [7, 13, 16, 17, 18, 19, 21, 24, 25], "dpkg": 36, "dr": 27, "draft": [1, 14, 15, 20, 21, 23, 31], "dramat": 5, "drape": 29, "drastic": 37, "dri": [40, 43], "drive": 25, "driven": [19, 25, 35], "driver": [44, 56], "drop": [44, 50], "drug": 25, "drun": [43, 44], "ds_channel_config_path": [13, 16, 17, 18, 19, 24, 25], "ds_heavy_channel_num": [13, 16, 17, 18, 19, 24, 25], "ds_heavy_channel_typ": [13, 16, 17, 18, 19, 24, 25], "ds_heavy_token_num": [13, 16, 17, 18, 19, 24, 25], "ds_sparse_decode_threshold": [13, 16, 17, 18, 19, 24, 25], "dsa": 1, "dshm": [56, 57, 60], "dsn": 12, "dsv32": [21, 60], "dtype": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 31, 46], "dual": 1, "dual_chunk_flash_attn": [1, 14], "dublin": [16, 17], "duck": 52, "ducx_path": 10, "due": [3, 7, 10, 11, 17, 36, 37, 38, 44, 46, 50, 52, 62], "dummi": [2, 14, 33, 36], "dump": [16, 17, 28, 33, 60, 64], "dump_expert_distribution_record": 24, "duplic": [20, 37], "durat": [12, 20, 32, 35, 36], "dure": [1, 6, 7, 8, 10, 11, 14, 21, 24, 27, 32, 33, 36, 45, 50, 51, 62, 69], "dusti": 46, "dustin": 46, "dv": 38, "dynam": [3, 6, 10, 11, 14, 15, 25, 36, 51, 57, 60, 68], "dynamic_batch_tokenizer_batch_s": [13, 16, 17, 18, 19, 24, 25], "dynamic_batch_tokenizer_batch_timeout": [13, 16, 17, 18, 19, 24, 25], "dynamo": [10, 14, 15], "d\u00e9fens": 17, "e": [0, 1, 3, 5, 6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 27, 32, 35, 36, 37, 38, 40, 41, 43, 44, 45, 48, 54, 58, 61, 62, 66, 68, 71], "e2": [14, 32], "e2d1e9af027c4e2db23ac7eed408cd7": 16, "e2e_lat": [16, 17, 24, 34], "e2e_request_latency_second": 61, "e2e_request_latency_seconds_bucket": 61, "e2e_request_latency_seconds_count": 61, "e2e_request_latency_seconds_sum": 61, "e4m3": 20, "e5": [42, 65], "each": [0, 1, 2, 3, 6, 8, 10, 14, 17, 20, 24, 25, 27, 32, 33, 35, 36, 45, 50, 54, 56, 58, 62, 64, 68, 71], "eager": [13, 16, 17, 18, 19, 24, 25], "eagl": [1, 14, 20, 21], "eagle2": 14, "eagle3": [14, 15, 23], "earli": [7, 66], "earlier": 52, "earn": 22, "earth": 17, "easi": [11, 13, 17, 25, 37, 42, 54], "easier": [17, 38, 71], "easili": [17, 25, 71], "east": 44, "eater": 54, "ebnf": 18, "ebnf_grammar": [16, 17], "ec": [57, 60], "ec94295ea028423889a4da96eba609d6": 24, "echo": [36, 40, 43, 44, 58], "econom": [15, 17, 25], "ecosystem": 48, "edg": [11, 66, 68], "edit": [38, 40], "educ": [17, 25], "effect": [2, 6, 15, 17, 25, 27, 56], "effici": [2, 5, 6, 8, 10, 14, 15, 20, 21, 24, 25, 32, 33, 37, 42, 45, 46, 65, 66, 68, 69], "effort": 5, "eg": [14, 32], "eic": 14, "eiffel": [15, 17, 24, 25], "eight": [56, 68], "eighth": 27, "either": [11, 14, 17, 21, 22, 33, 41], "elabor": 11, "elaps": [24, 56], "elast": 14, "elastic_ep_backend": [13, 16, 17, 18, 19, 24, 25], "element": [14, 27], "eleutherai": 52, "elev": 17, "elif": 54, "els": [8, 16, 17, 24, 37], "elsiu": 18, "embed": [8, 12, 14, 26, 27, 33, 34, 42, 69, 70, 71], "embedding_process": [24, 28], "emerg": 25, "emit": 36, "emot": 25, "empathet": 25, "emperor": 27, "emploi": [6, 15, 33, 68], "empti": [18, 24, 27, 36, 44], "emptydir": [56, 57, 60], "emul": 1, "en": [11, 65], "enabl": [1, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 23, 27, 28, 29, 31, 32, 33, 35, 38, 43, 44, 45, 46, 48, 50, 51, 57, 60, 61, 62, 65, 66, 68, 69], "enable_ascend_transfer_with_mooncak": 10, "enable_attn_tp_input_scatt": [13, 16, 17, 18, 19, 24, 25], "enable_broadcast_mm_inputs_process": [13, 16, 17, 18, 19, 24, 25], "enable_cache_report": [13, 16, 17, 18, 19, 24, 25], "enable_cudagraph_gc": [13, 16, 17, 18, 19, 24, 25], "enable_custom_logit_processor": [13, 16, 17, 18, 19, 24, 25], "enable_deterministic_infer": [13, 16, 17, 18, 19, 24, 25], "enable_double_spars": [13, 16, 17, 18, 19, 24, 25], "enable_dp_attent": [13, 16, 17, 18, 19, 24, 25], "enable_dp_lm_head": [13, 16, 17, 18, 19, 24, 25], "enable_draft_weights_cpu_backup": [13, 16, 17, 18, 19, 24, 25], "enable_dynamic_batch_token": [13, 16, 17, 18, 19, 24, 25], "enable_eplb": [13, 16, 17, 18, 19, 24, 25], "enable_expert_distribution_metr": [13, 16, 17, 18, 19, 24, 25], "enable_flashinfer_allreduce_fus": [13, 16, 17, 18, 19, 24, 25], "enable_fp32_lm_head": [13, 16, 17, 18, 19, 24, 25], "enable_hierarchical_cach": [13, 16, 17, 18, 19, 24, 25], "enable_layerwise_nvtx_mark": [13, 16, 17, 18, 19, 24, 25], "enable_lmcach": [13, 16, 17, 18, 19, 24, 25], "enable_lora": [8, 13, 16, 17, 18, 19, 24, 25], "enable_memory_sav": [13, 16, 17, 18, 19, 24, 25], "enable_metr": [13, 16, 17, 18, 19, 24, 25, 60], "enable_metrics_for_all_schedul": [13, 16, 17, 18, 19, 24, 25], "enable_mixed_chunk": [13, 16, 17, 18, 19, 24, 25], "enable_mscclpp": [13, 16, 17, 18, 19, 24, 25], "enable_multimod": [13, 16, 17, 18, 19, 24, 25], "enable_nan_detect": [13, 16, 17, 18, 19, 24, 25], "enable_nccl_nvl": [13, 16, 17, 18, 19, 24, 25], "enable_nsa_prefill_context_parallel": [13, 16, 17, 18, 19, 24, 25], "enable_p2p_check": [13, 16, 17, 18, 19, 24, 25], "enable_pdmux": [13, 16, 17, 18, 19, 24, 25], "enable_piecewise_cuda_graph": [13, 16, 17, 18, 19, 24, 25], "enable_priority_schedul": [13, 16, 17, 18, 19, 24, 25], "enable_profile_cuda_graph": [13, 16, 17, 18, 19, 24, 25], "enable_request_time_stats_log": [13, 16, 17, 18, 19, 24, 25], "enable_return_hidden_st": [13, 16, 17, 18, 19, 24, 25], "enable_single_batch_overlap": [13, 16, 17, 18, 19, 24, 25], "enable_symm_mem": [13, 16, 17, 18, 19, 24, 25], "enable_think": [13, 27], "enable_tokenizer_batch_encod": [13, 16, 17, 18, 19, 24, 25], "enable_torch_compil": [13, 16, 17, 18, 19, 24, 25], "enable_torch_symm_mem": [13, 16, 17, 18, 19, 24, 25], "enable_trac": [13, 16, 17, 18, 19, 24, 25], "enable_two_batch_overlap": [13, 16, 17, 18, 19, 24, 25], "enable_weights_cpu_backup": [13, 16, 17, 18, 19, 24, 25], "encapsul": 6, "encod": [14, 27, 28, 33, 34, 68, 69], "encoding_for_model": 27, "encoding_format": 65, "encount": [7, 11, 20, 36, 41, 43, 44, 56, 61], "encourag": [7, 27, 33, 37], "end": [13, 14, 16, 17, 24, 25, 27, 33, 34, 36, 44, 54, 56, 61, 62, 68, 71], "end_tag": [16, 17], "endem": [24, 69], "endorphin": 54, "endpoint": [2, 12, 14, 16, 17, 24, 34, 41, 54, 61, 62, 71], "enforc": [8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 50, 54], "engag": [27, 54], "engin": [6, 10, 11, 14, 15, 20, 29, 36, 37, 42, 43, 44, 46, 51, 54, 57], "england": [16, 17, 33], "english": [17, 27, 66], "enhanc": [15, 25, 54, 66, 68], "enjoi": 25, "enough": [7, 14], "ensembl": 35, "ensur": [0, 2, 3, 5, 6, 8, 10, 12, 15, 17, 18, 20, 21, 22, 35, 36, 37, 38, 43, 44, 46, 58, 60, 61, 69, 71], "enter": [38, 62], "enterpris": [6, 11, 12, 41, 66], "entir": [10, 15, 16, 17, 36, 43], "entri": [7, 12], "entryclass": 71, "entrypoint": [2, 64, 71], "enum": [16, 17, 18], "enumer": [11, 33, 54], "env": [41, 43, 44, 45, 56, 57, 60, 62, 67], "env_fold": 58, "envelop": 14, "environ": [5, 6, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 34, 35, 36, 37, 40, 41, 42, 45, 48, 54, 56, 57, 58, 60, 61, 62, 67], "eo": [7, 33, 35], "eof": 14, "eom": 18, "eot": 19, "ep": [14, 21, 32, 36, 44, 57, 60], "ep_dispatch_algorithm": [13, 16, 17, 18, 19, 24, 25], "ep_num_redundant_expert": [13, 16, 17, 18, 19, 24, 25], "ep_siz": [13, 16, 17, 18, 19, 24, 25], "eplb": [14, 57, 60], "eplb_algorithm": [13, 16, 17, 18, 19, 24, 25], "eplb_min_rebalancing_utilization_threshold": [13, 16, 17, 18, 19, 24, 25], "eplb_rebalance_layers_per_chunk": [13, 16, 17, 18, 19, 24, 25], "eplb_rebalance_num_iter": [13, 16, 17, 18, 19, 24, 25], "equal": [8, 13, 14, 21, 35], "equip": [21, 45], "equival": [34, 43, 51], "erni": 66, "err": 58, "error": [0, 2, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 35, 36, 37, 45, 56, 58, 61], "error_messag": 8, "error_typ": 64, "especi": [2, 6, 7, 8, 14, 18, 25, 37, 38], "essai": 27, "essenti": [5, 17, 25, 56, 61, 71], "establish": [13, 17, 27], "estim": [17, 50], "et": 22, "etc": [5, 11, 12, 14, 18, 35, 36, 42, 43, 44, 64, 66, 71], "eth": 56, "ethernet": 56, "ethic": 25, "ethnic": 17, "europ": [15, 17, 24, 25, 34], "european": 15, "eval": [19, 21, 37, 71], "evalu": [3, 15, 24, 35, 37, 70], "even": [3, 25, 38, 50, 52, 66, 68], "even_k": 15, "event": [14, 18, 36], "eventu": [12, 71], "everi": [0, 6, 9, 14, 36, 37, 38, 45, 62], "everyth": 17, "evict": [6, 8, 12, 14], "evolv": [12, 25], "exa": 22, "exa_api_kei": 22, "exact": [6, 17, 22], "exactli": [12, 17, 36, 71], "exampl": [0, 1, 5, 6, 8, 12, 14, 15, 16, 17, 21, 22, 23, 25, 28, 31, 37, 38, 40, 41, 48, 52, 58, 61, 62, 67], "example_function_nam": [16, 17], "example_imag": [19, 29, 32, 33, 54], "example_nam": [16, 17], "example_valu": [16, 17], "exampleoutput": 27, "exaon": 66, "exce": [6, 14, 32, 33, 37, 45, 50, 71], "excel": [1, 37, 66], "except": [15, 18, 24, 72], "excit": 25, "exclus": 36, "exec": [0, 36, 38], "execut": [0, 6, 11, 12, 16, 17, 22, 36, 41, 45, 56, 57, 62, 65, 69, 70], "exercis": 54, "exhibit": 66, "exist": [0, 1, 5, 6, 11, 14, 37, 38, 57, 60, 62, 71], "exit": 58, "exp": [18, 21, 59], "expand": [1, 6, 54, 71], "expandable_seg": 44, "expans": 15, "expect": [3, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 34, 36, 54], "expens": 37, "experi": [3, 11, 25, 57], "experienc": 20, "experiment": [14, 50], "expert": [7, 20, 42, 50, 57, 59, 60, 66], "expert_distribution_recorder_buffer_s": [13, 16, 17, 18, 19, 24, 25], "expert_distribution_recorder_mod": [13, 16, 17, 18, 19, 24, 25], "expert_record_server_process": 24, "expir": 12, "explain": [17, 22, 25, 62, 65, 71], "explan": [1, 18, 45, 46, 48], "explicit": [12, 18], "explicitli": [8, 12, 13, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 34, 45, 54, 61, 62], "exploit": 6, "explor": [1, 25, 27, 68], "exponenti": 14, "export": [5, 10, 12, 22, 35, 36, 38, 40, 41, 43, 44, 45, 62, 67, 71], "export_metrics_to_fil": [13, 16, 17, 18, 19, 24, 25], "export_metrics_to_file_dir": [13, 16, 17, 18, 19, 24, 25], "exported_model": 11, "expos": [6, 9, 12, 22, 27, 35, 36, 57, 61], "express": [33, 54, 66, 68], "extend": [5, 6, 12, 14, 15, 18, 20, 21, 27, 35, 52, 66, 71], "extens": [38, 42, 68], "extern": [5, 12, 22, 24, 42], "extra": [5, 6, 14, 21, 35, 45], "extra_bodi": [13, 16, 17, 20, 27, 33], "extract": [25, 37, 68, 71], "extrem": [6, 8, 18, 37], "f": [8, 11, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 32, 33, 34, 41, 43, 44, 45, 54, 56, 57, 62, 69, 71], "f1": 38, "f5": 38, "f7ff": 56, "f9d05de5dd4945c5bacb5d130dc37fa1": 16, "f_": 15, "f_1": 15, "f_k": 15, "fa3": [1, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 32, 34, 54], "fa4": [1, 14], "fabdb6a30b49f79a7aba0f2ad9df9b399473380f": 38, "face": [11, 14, 25, 27, 42, 49, 66, 71], "facilit": [20, 45, 65], "fact": [8, 17, 25], "factor": [11, 12, 14, 15, 17, 35, 51], "factori": 12, "factual": [25, 71], "fahrenheit": [16, 17, 18], "fail": [0, 8, 11, 18, 24, 35, 36, 37, 52, 58], "failur": [10, 11, 12, 41], "failurethreshold": 60, "fake": [11, 14], "fall": [12, 14, 21, 64, 72], "fallback": [14, 16, 17, 33, 42], "fals": [12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 33, 34, 36, 38, 50, 57, 60, 71], "famili": [1, 12, 13, 27, 32, 65, 66, 68, 69, 70], "familiar": 15, "famou": [15, 17], "famous_landmark": 17, "far": [15, 33], "fascin": 27, "fast": [1, 6, 14, 22, 37, 42, 66], "faster": [6, 8, 15, 37, 41, 65, 66, 68], "fastest": [15, 17], "fat": 54, "fault": 10, "favor": [7, 27], "fcf": [10, 13, 14, 16, 17, 18, 19, 24, 25], "fe36": 56, "fe64": 56, "fe6e": 56, "fe73": 56, "fe80": 56, "feather": 54, "featur": [0, 1, 2, 3, 5, 8, 12, 14, 15, 17, 18, 20, 21, 23, 29, 31, 32, 36, 37, 55, 56, 62, 68, 71], "feder": 17, "feed": [12, 71], "feedback": 5, "feel": [17, 37, 44], "feet": 25, "festiv": 25, "fetch": [6, 16, 17, 18, 35, 36], "few": [37, 43], "few_shot_gsm8k": 37, "ff54dc10200441ab9c801600adf62643": 29, "ffn": 14, "fi": 58, "fiber": 54, "fiction": [25, 71], "field": [8, 14, 16, 17, 24, 25, 35, 71], "fieldpath": [57, 60], "fieldref": [57, 60], "fifo": [8, 12, 14], "figur": [17, 38], "file": [0, 2, 6, 9, 12, 24, 32, 33, 35, 37, 45, 48, 49, 51, 56, 64, 68, 71], "file_storage_path": [13, 16, 17, 18, 19, 24, 25], "filenam": 14, "fill": 54, "fillmor": 52, "filt": 17, "filter": 18, "final": [13, 15, 17, 18, 51, 71], "final_respons": 18, "find": [0, 13, 14, 15, 16, 17, 18, 21, 27, 33, 37, 41, 51, 56, 61, 62, 71], "fine": [6, 10, 17, 18, 21, 32, 36, 66, 68], "finer": 62, "finetun": 18, "finish": [20, 36], "finish_reason": [15, 16, 17, 18, 20, 24, 27, 29, 34, 57, 60], "fire": [24, 43, 45, 56], "firm": 22, "firmwar": 44, "first": [0, 2, 5, 6, 7, 8, 11, 12, 13, 14, 17, 19, 20, 24, 25, 27, 28, 29, 35, 36, 37, 38, 41, 45, 50, 58, 61, 62, 71], "first_answ": 54, "firstli": 36, "fit": [6, 17, 21, 41], "five": 37, "fix": [0, 1, 37, 41], "flag": [2, 3, 5, 12, 14, 17, 20, 21, 33, 35, 36, 38, 45, 50, 62, 65, 68], "flap": 12, "flash": [14, 32, 50], "flash_attn": 21, "flash_attn_with_kvcach": 21, "flash_mla": 21, "flash_mla_sparse_fwd": 21, "flash_mla_with_kvcach": 21, "flashattent": [1, 3, 21], "flashattention3": 20, "flashattention_backend": 1, "flashinf": [1, 3, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 29, 41, 46, 50, 54], "flashinfer_cutedsl": 14, "flashinfer_cutlass": 14, "flashinfer_mla": 1, "flashinfer_mla_disable_rag": [13, 16, 17, 18, 19, 24, 25], "flashinfer_mxfp4": 14, "flashinfer_mxfp4_moe_precis": [13, 16, 17, 18, 19, 24, 25], "flashinfer_trtllm": [1, 14], "flashmla": [1, 14, 20], "flashmla_auto": 21, "flashmla_decod": 14, "flashmla_kv": [14, 21], "flashmla_prefil": 14, "flashmla_spars": [13, 14, 16, 17, 18, 19, 21, 24, 25], "fleet": 12, "flex_attent": [1, 14], "flexattent": 1, "flexibl": [8, 34, 42, 65, 69], "flexibli": 20, "flight": [12, 35], "flm": 66, "float": [3, 12, 14, 27, 33, 65], "float16": [14, 15, 24, 28], "float32": [13, 14, 15, 16, 17, 18, 19, 24, 25, 28, 31], "flourish": 27, "flow": [42, 62], "fluctuat": 17, "fluenci": 27, "flush": [12, 25, 33, 34, 35, 54], "flush_cach": [12, 24, 35], "fly": 11, "focal": 22, "focus": [17, 25, 27], "fold": 19, "folder": [0, 9, 14, 36, 38, 40, 60, 61, 63], "follow": [0, 1, 3, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 20, 21, 24, 25, 27, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 45, 46, 51, 54, 56, 57, 58, 61, 62, 64, 66, 68, 71, 72], "foo": [16, 17], "food": 54, "fool": 22, "foot": 25, "footprint": 1, "forbidden": 17, "forc": [10, 33, 41, 45, 50], "forev": 40, "fork": [36, 54], "form": [17, 18, 33, 36, 45, 48], "format": [2, 8, 11, 14, 16, 17, 20, 24, 27, 33, 36, 57, 61, 62, 68], "formerli": [42, 55], "formul": 25, "forward": [1, 12, 14, 37, 50, 71, 72], "forward_batch": 71, "forward_batch_info": 71, "forward_decod": [1, 71], "forward_extend": [1, 71], "forwardbatch": 71, "found": [3, 6, 8, 10, 14, 17, 24, 25, 44, 46, 56], "foundat": 66, "four": [20, 25, 62], "fp16": [14, 58], "fp32": 14, "fp4": [1, 11, 14, 42], "fp8": [1, 7, 11, 14, 21, 42, 45, 50, 58], "fp8_dynam": 11, "fp8_e4m3": [1, 14, 21], "fp8_e5m2": [14, 20], "fp8_kernel": 11, "fp8dq": [11, 14], "fp8wo": [11, 14], "fr": 15, "frac": 36, "fraction": [5, 10, 14, 15, 20, 21, 23, 32, 44, 45, 46, 51, 56, 57, 60], "fragment": [18, 20], "frame": 68, "framework": [6, 37, 42, 60, 69], "franc": [8, 11, 15, 16, 17, 18, 20, 24, 25, 27, 33, 34, 52, 54, 65, 71], "francisco": [16, 17, 18], "franklin": 46, "free": [17, 37, 44], "freeli": 62, "french": [15, 24, 25], "freq_32768": 15, "frequenc": [6, 32, 33], "frequency_penalti": [27, 33], "frequent": [6, 7, 8, 10, 14, 42], "fridai": 22, "from": [0, 1, 2, 3, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 25, 27, 28, 29, 33, 34, 35, 36, 42, 46, 49, 50, 51, 54, 60, 61, 62, 64, 66, 68, 69, 70, 72], "from_pretrain": [11, 13, 16, 17, 18, 19, 24, 28], "front": 25, "frontend": [42, 49], "frozen": 14, "fruit": 54, "full": [5, 7, 8, 12, 14, 20, 24, 36, 56, 65, 66, 68], "full_argu": 18, "full_siz": 14, "fulli": [0, 3, 6, 11, 12, 18, 20, 27, 37, 43, 57, 60, 66], "func_latency_second": 61, "func_latency_seconds_bucket": 61, "func_latency_seconds_count": 61, "func_latency_seconds_sum": 61, "func_name1": 18, "func_name2": 18, "function": [0, 1, 6, 14, 15, 16, 17, 27, 37, 52, 54, 61, 71], "function_cal": [15, 18, 27, 34], "function_call_input": 18, "function_call_pars": 18, "function_call_respons": 18, "function_call_response_json": 18, "function_dict": 18, "function_nam": [16, 17], "functioncallpars": 18, "functool": [15, 71], "fundament": 5, "further": [6, 15, 17, 25, 41, 62], "furthermor": 15, "fuse": [11, 50], "fused_moe_triton": [24, 57], "fusion": [11, 14, 50], "futur": [6, 11, 13, 14, 24, 25, 50, 57, 71], "g": [0, 1, 3, 5, 6, 7, 8, 11, 13, 14, 16, 17, 18, 20, 22, 32, 35, 36, 37, 38, 40, 41, 45, 48, 61, 66, 68, 71], "gaa": 17, "gain": [6, 66], "game": 25, "garbag": 14, "gate": [11, 17], "gate_proj": [8, 14], "gate_up_proj": 14, "gatewai": 42, "gather": [14, 17, 68], "gaudi": 11, "gaug": [12, 61], "gaull": 17, "gb": [5, 7, 8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 29, 34, 54, 56], "gb200": 42, "gc": 14, "gc_warning_threshold_sec": [13, 16, 17, 18, 19, 24, 25], "gd": 6, "gemm": [8, 14, 50], "gemma": [42, 66, 68, 70], "gemma2forsequenceclassif": [64, 70], "gemma3": 29, "gen": [7, 45, 52, 54, 66], "gen_data": [13, 18], "gen_respons": [13, 18], "gen_throughput": 61, "gen_url": [13, 18], "gener": [6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 27, 35, 36, 42, 44, 45, 56, 61, 62, 63, 64, 66, 68, 71], "generate_request": 61, "generate_stream": 35, "generated_text": [13, 18, 35], "generatereqinput": 33, "generation_config": [14, 33], "generation_tokens_bucket": [13, 16, 17, 18, 19, 24, 25], "generation_tokens_tot": 61, "generative_model": 71, "geograph": 17, "geographi": [16, 17], "germani": [15, 16, 17, 24, 27, 54], "get": [0, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 28, 31, 35, 36, 37, 41, 45, 48, 56, 57, 60, 65, 71], "get_current_d": [16, 17], "get_current_weath": [16, 17, 18], "get_embed": 71, "get_image_featur": 71, "get_load": 12, "get_max_total_num_token": 24, "get_memory_pool_s": 24, "get_messag": [16, 17, 18], "get_model_info": [12, 14, 24, 56], "get_model_load": 11, "get_prompt": 19, "get_server_arg": 24, "get_server_info": [12, 24, 35], "get_start": 0, "get_tourist_attract": 18, "get_weath": 18, "gf_auth_anonymous_en": 61, "gf_server_http_port": 61, "ggml": [16, 33], "gguf": [11, 14, 72], "giant": [24, 69], "gibberish": 35, "gid": 56, "gigabyt": [6, 14], "git": [10, 21, 37, 40, 41, 43, 44, 45, 46, 48], "gite": 44, "github": [5, 10, 19, 21, 24, 29, 32, 33, 37, 41, 43, 44, 45, 46, 47, 48, 51, 54, 60, 62, 66, 68], "githubusercont": 29, "give": [8, 13, 16, 17, 18, 40, 54, 71], "given": [6, 15, 16, 17, 18, 20, 21, 24, 33, 54], "glm": [14, 18, 42, 66, 68], "glm4": 12, "glm45": 14, "global": [6, 16, 17, 45, 62], "gloo": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "gloo_socket_ifnam": [56, 60], "glynn": 17, "gme": 65, "gnupg": 36, "go": [17, 22, 25, 27, 43, 44, 47, 61], "goal": [25, 71], "god": 27, "good": [7, 17, 20, 37, 43], "googl": [42, 54, 66, 68], "govern": [15, 17, 24, 27], "gperftool": 45, "gpt": [12, 13, 14, 18, 27, 42, 66], "gptq": [11, 14, 42], "gptq_marlin": [11, 14], "gpu": [3, 5, 6, 7, 10, 11, 14, 15, 20, 21, 23, 24, 31, 32, 36, 37, 38, 40, 41, 42, 48, 50, 56, 57, 58, 59, 60, 67, 68], "gpu_id_step": [13, 16, 17, 18, 19, 24, 25], "grade": [11, 41], "grafana": 61, "grain": [6, 10, 21, 36, 54, 62, 68], "grammar": [14, 16, 17, 18, 33, 58], "grammar_backend": [13, 16, 17, 18, 19, 24, 25], "grand": 17, "granit": 66, "grant": 12, "granular": [6, 36], "graph": [1, 2, 3, 8, 11, 14, 15, 20, 24, 36, 38, 51, 56, 57, 60], "graphic": 48, "gre": 58, "great": [17, 64], "greater": [2, 8, 10, 14, 15], "greatli": 25, "greedi": 33, "greedy_token_select": 52, "greenctx": 14, "greet": 33, "grep": [45, 56, 57, 60], "grok": 66, "group": [3, 6, 14, 17, 20, 35, 40, 43, 46], "group_m": 15, "group_siz": [11, 14], "grow": [17, 33], "growth": [12, 17], "growth_rat": 17, "growthproject": 17, "grpc": 62, "grpc_mode": [13, 16, 17, 18, 19, 24, 25], "grpo": 3, "grub_cmdline_linux": 43, "gryffindor": 54, "gserver": 35, "gsm8k": [37, 38, 71], "gsp": 35, "gt": [17, 19, 54], "gte": [24, 28, 42, 65], "guarante": [6, 16, 33], "guard": 11, "gui": 36, "guiana": 15, "guid": [5, 10, 14, 16, 18, 20, 33, 34, 36, 41, 43, 44, 56, 70], "guidanc": [15, 51, 71], "guidelin": [37, 71], "gz": [11, 36, 38], "h": [12, 20, 28, 29, 34, 36, 45, 48, 57, 60, 64], "h100": [1, 15, 20, 23, 32, 41, 42, 59], "h20": [1, 2, 20, 56], "h200": [1, 21, 23, 31, 32, 59], "ha": [1, 6, 7, 8, 11, 14, 15, 17, 18, 20, 22, 23, 24, 25, 31, 36, 45, 56, 60, 62, 66, 72], "habit": 54, "had": 27, "hadn": 36, "hadrian": 27, "hakota": 54, "half": [14, 46, 54], "hall": 17, "halt": 8, "hand": 7, "handl": [5, 10, 13, 14, 20, 24, 25, 27, 33, 34, 36, 54, 56, 57, 65, 68, 71], "hang": [14, 54], "happen": [7, 11, 14, 32, 68, 72], "happi": 37, "hard": [5, 56], "hardwar": [1, 8, 11, 21, 25, 37, 43, 44], "harm": 38, "harri": 54, "has_audio_understand": 24, "has_image_understand": 24, "hash": 71, "hasn": 56, "hat": 66, "have": [8, 10, 11, 14, 15, 16, 17, 20, 22, 25, 27, 29, 36, 37, 43, 44, 45, 48, 50, 52, 56, 57, 62, 66, 68, 71], "haven": 15, "hccl_buffsiz": 44, "he": 54, "head": [1, 6, 14, 21, 32, 36, 57, 58, 60, 68, 71], "head_nod": 58, "header": [12, 14, 62, 64], "header_end": 19, "header_start": 19, "headlin": 22, "health": [10, 12, 50, 60], "health_gener": 24, "healthi": [7, 12, 54], "heartbeat": 10, "heaven": 17, "heavi": 14, "heavili": 18, "hei": 33, "height": 25, "heightxwidth": 35, "helfpul": 22, "hello": [11, 18, 25, 33, 71], "helm": 57, "help": [0, 6, 7, 14, 16, 17, 18, 19, 22, 25, 27, 33, 35, 36, 37, 43, 51, 54, 57, 60, 61], "henc": 17, "her": 27, "here": [5, 6, 7, 8, 11, 15, 16, 17, 18, 19, 20, 24, 25, 27, 33, 34, 41, 43, 44, 54, 56, 57, 61, 72], "heterogen": 12, "heurist": [7, 21], "hf": [11, 12, 15, 24, 35, 49, 66, 68, 70, 71], "hf3f": [6, 14], "hf_home": [24, 40], "hf_token": [40, 41, 43, 44, 45, 71], "hf_xxx": 40, "hfd": 44, "hi": [24, 25, 33, 58, 69], "hicach": [14, 42], "hicache_io_backend": [13, 16, 17, 18, 19, 24, 25], "hicache_mem_layout": [13, 16, 17, 18, 19, 24, 25], "hicache_ratio": [6, 13, 14, 16, 17, 18, 19, 24, 25], "hicache_s": [6, 13, 16, 17, 18, 19, 24, 25], "hicache_storage_backend": [13, 16, 17, 18, 19, 24, 25], "hicache_storage_backend_extra_config": [6, 13, 16, 17, 18, 19, 24, 25], "hicache_storage_prefetch_polici": [13, 16, 17, 18, 19, 24, 25], "hicache_write_polici": [13, 16, 17, 18, 19, 24, 25], "hicachefil": 6, "hicachestorag": 6, "hidden": [14, 15, 25, 33], "hidden_st": [71, 72], "hide": 6, "hierarch": [5, 6, 42], "hierarchi": [6, 36, 62], "high": [6, 8, 11, 12, 14, 15, 18, 20, 22, 32, 33, 42, 46, 52, 54, 65, 66, 69], "higher": [1, 5, 6, 7, 14, 15, 22, 27, 33], "highest": [12, 33, 52], "highest_token_prob": 33, "highli": 33, "highlight": [8, 13, 16, 17, 18, 24, 25, 27, 28, 29, 34, 54], "hilab": 68, "hisi_hdc": 44, "histogram": [12, 14, 61], "histor": [17, 50], "histori": [17, 18, 25], "historian": 27, "historical_popul": 17, "hit": [5, 6, 7, 12, 33, 56, 61], "hmm": [17, 27], "hobbi": 25, "hold": 6, "holist": 68, "home": [17, 25, 38, 43, 57], "hood": 51, "hope": 17, "hopper": [1, 11, 20, 21, 50], "host": [2, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 41, 43, 44, 45, 46, 48, 50, 54, 56, 57, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72], "hostipc": [56, 57, 60], "hostnam": [14, 58], "hostnetwork": [56, 57, 60], "hostpath": [56, 57, 60], "hot": [6, 12], "hottest": 6, "hour": 20, "hous": 54, "how": [0, 6, 7, 11, 14, 15, 17, 20, 24, 25, 27, 35, 36, 42, 43, 45, 48, 52, 58, 61, 68], "howev": [6, 7, 8, 18, 20, 44, 51, 56, 62, 71, 72], "hpu": [14, 21], "html": [0, 16, 36, 63, 71], "http": [0, 2, 3, 5, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 68, 69, 71], "http_server": [24, 64, 71], "http_worker_ipc": 8, "httpget": 60, "hub": [14, 17, 24, 25, 41, 43, 72], "hufflepuff": 54, "hug": [11, 14, 27, 42, 49, 66, 71], "huge": 15, "huggingfac": [11, 12, 14, 19, 24, 38, 40, 41, 43, 45, 65, 66, 67, 68, 69, 70, 71], "huggingface_hub": 71, "huggingfacetb": 66, "hui": 17, "human": [25, 70], "humor": 19, "hybrid": [13, 14, 23, 27, 66], "hybrid_attn_backend": 1, "hybrid_kvcache_ratio": [13, 16, 17, 18, 19, 24, 25], "hyperparamet": [14, 42], "i": [0, 1, 2, 3, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72], "ib": [5, 10, 14, 56, 57, 60], "ibdev2netdev": 56, "ibm": 66, "ibstatu": 56, "ibv_devic": 56, "ibv_devinfo": 56, "icon": [15, 17, 25, 29], "id": [10, 12, 13, 14, 15, 16, 17, 18, 20, 24, 29, 33, 34, 35, 36, 57, 60, 64], "id2label": 64, "idea": [6, 37], "ideal": [5, 12, 69], "ident": [3, 6, 43], "identif": 36, "identifi": [2, 5, 13, 14, 17, 25, 36, 45, 48, 64, 66, 68, 69, 70], "idl": [6, 14, 20], "ignor": [11, 14, 15, 35], "ignore_eo": 33, "igw": 12, "iii": 17, "illustr": 45, "im_end": [19, 33, 49, 54], "im_start": [19, 33, 49, 54], "imag": [14, 19, 24, 27, 33, 35, 38, 41, 42, 43, 44, 45, 46, 54, 56, 61, 65, 66, 68, 71], "image_byt": 54, "image_data": [19, 33], "image_featur": 19, "image_fil": 54, "image_grid_thw": 19, "image_id": 41, "image_nam": [44, 46], "image_output": 19, "image_pad": 19, "image_path": 65, "image_qa": 54, "image_token": 19, "image_url": [29, 32, 54], "imagedataitem": 33, "imbal": [10, 12, 50], "imit": 71, "immedi": [6, 17, 35, 36, 37], "immun": 54, "impact": [6, 17, 25, 36], "impl": [14, 72], "implement": [1, 5, 6, 12, 13, 14, 15, 18, 20, 21, 27, 35, 50, 51, 52, 57, 62, 66, 68, 72], "impli": 22, "import": [0, 3, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 33, 34, 54, 64, 65, 68, 69, 71, 72], "import_model_class": 71, "import_new_model_class": 71, "impos": 62, "improv": [3, 5, 6, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 25, 27, 28, 29, 32, 34, 54, 66, 68, 69], "inaccur": 36, "inc": 66, "inch": 25, "includ": [6, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 24, 25, 27, 35, 36, 42, 45, 51, 54, 61, 64, 65, 66, 71], "inclus": 36, "inclusionai": 66, "incom": [6, 10, 14], "inconsist": [6, 18, 35], "incorpor": [8, 15, 29, 54, 60, 66, 69], "incorrect": [15, 52], "increas": [2, 6, 10, 12, 14, 15, 17, 18, 20, 21, 25, 27, 31, 66, 68], "increasingli": 25, "incredibli": 25, "increment": [6, 7], "incur": 52, "indent": 64, "independ": [12, 20], "indetermin": 51, "index": [0, 15, 18, 20, 21, 24, 27, 28, 29, 34, 36, 44, 45, 48, 57, 60, 64], "indic": [1, 7, 10, 17, 50, 54, 56], "individu": [17, 25, 36, 71], "indoor": 29, "inductor_root_cach": 63, "industri": [12, 23, 25, 42], "ineffici": [10, 36], "inf": [33, 35, 45, 48, 61], "infer": [2, 6, 8, 10, 11, 12, 20, 32, 35, 37, 42, 43, 45, 47, 48, 51, 56, 60, 66, 68, 71], "inference_mod": 50, "infiniband": [14, 56, 57, 60], "infinit": [14, 35], "influenc": [17, 25], "info": [5, 8, 13, 14, 15, 16, 17, 18, 19, 25, 27, 28, 29, 32, 34, 44, 54, 56, 58], "inform": [10, 16, 17, 18, 21, 22, 24, 25, 27, 33, 36, 45, 54, 64, 72], "infra": 41, "infrastructur": 37, "ing": 20, "inher": 6, "inherit": [1, 12, 18, 71], "init": [2, 10, 12, 14, 21, 24, 44, 56, 57, 58, 60], "init_cuda_graph_st": 1, "init_expert_loc": [13, 16, 17, 18, 19, 24, 25], "init_forward_metadata": 1, "init_forward_metadata_capture_cuda_graph": 1, "init_forward_metadata_replay_cuda_graph": 1, "initi": [1, 2, 6, 8, 10, 12, 13, 14, 15, 24, 27, 28, 29, 33, 45, 51, 52, 54, 58, 62], "initialdelaysecond": [56, 60], "inject": 14, "innov": 20, "input": [3, 6, 8, 10, 13, 14, 15, 18, 21, 22, 24, 27, 33, 35, 36, 38, 42, 43, 45, 48, 51, 61, 64, 65, 66, 71], "input_emb": [14, 33, 71], "input_id": [14, 18, 19, 28, 33, 71], "input_ids_embed": 28, "input_len": 35, "input_text": 24, "insert": [25, 62], "insid": [12, 36, 38, 40], "inspect": [7, 12, 36], "inspir": 6, "inst": 68, "instal": [10, 12, 14, 22, 34, 35, 36, 38, 39, 40, 42, 56, 57, 60, 61, 62], "installationguid": 36, "instanc": [5, 6, 10, 11, 12, 14, 15, 27, 33, 36, 52, 61], "instant": 12, "instanti": 12, "instantli": 36, "instead": [6, 8, 14, 15, 17, 18, 22, 33, 35, 50, 51, 61, 64, 71], "instinct": 43, "instruct": [0, 1, 3, 5, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 48, 54, 56, 58, 61, 63, 65, 66, 67, 68, 71, 72], "instruct_lora_4_alpha_16": 8, "instrument": 62, "int": [10, 12, 14, 16, 17, 33], "int4": [11, 42, 46, 50], "int4_awq": 14, "int4wo": [11, 14, 46], "int8": [11, 14, 20, 45], "int8_kernel": 11, "int8dq": [11, 14], "int8wo": [11, 14], "intak": 54, "integ": [14, 16, 17, 33, 35, 64], "integr": [11, 12, 22, 25, 37, 42, 50, 56, 65, 66, 68, 71], "integratedtermin": 38, "intel": [1, 11, 41, 42, 45, 48], "intel_amx": 14, "intel_xpu": [1, 48], "intellig": [5, 25, 71], "intens": 10, "intention": 8, "inter": [14, 35], "interact": [0, 14, 25, 36, 42], "interchang": 17, "interest": [37, 57], "interfac": [42, 61, 64, 65, 69, 71], "interleav": 29, "intermedi": 14, "intern": [27, 36, 38, 56, 61, 64, 71], "internal_st": 24, "internlm": [66, 70], "internlm2": [66, 70], "internlm2forrewardmod": 70, "internlm2forrewardmodel": 64, "interpret": [13, 18, 22], "interrupt": 10, "interv": [10, 12, 14, 50], "intervitensinc": 45, "intfloat": 65, "introduc": [6, 7, 8, 10, 14, 20, 24, 37, 48, 51, 56], "introduct": [25, 37, 71], "introductori": 71, "intuit": 42, "invalid": [21, 64], "invari": [3, 14], "invest": 25, "investig": 51, "invoc": 21, "invok": [11, 18], "involv": [6, 13, 20, 62, 71], "io": [5, 6, 14, 19, 56, 57, 60], "io_struct": [18, 33], "iommu": 43, "ip": [2, 14, 22, 50, 54, 58, 61], "ipc": [32, 38, 41, 43, 44, 45, 67], "ipc_lock": [57, 60], "ipynb": [0, 8], "ipython": 25, "ireland": [16, 17], "iron": 29, "irrelev": 25, "is_embed": [13, 16, 17, 18, 19, 24, 25], "is_gener": 24, "is_in_ci": 19, "is_matryoshka": 65, "is_multimodal_model": 71, "isn": 56, "isol": [11, 56], "issu": [1, 3, 5, 6, 8, 11, 14, 17, 20, 21, 23, 37, 41, 43, 44, 45, 48, 51, 54, 61, 62], "is\u00e8r": 17, "itali": [15, 16, 17, 24, 27, 54], "itd": 38, "item": [12, 24, 37, 69], "item1": 14, "item2": 14, "item_id": 12, "iter": [2, 14, 24, 36], "iter_lin": [33, 34], "itl": 35, "its": [6, 14, 15, 16, 17, 22, 24, 25, 33, 36, 44, 50, 52, 62, 65, 66, 71], "j": 58, "j_master": 58, "j_node": 58, "jaeger": 62, "jamesliu1": 15, "janu": 68, "japan": [8, 15, 27, 54], "japanes": 66, "jason9693": [64, 70], "java": 25, "javascript": [17, 25], "javel": 17, "jax": [14, 47], "jet": 66, "jetpack": 46, "jetson": [41, 42], "jinja": [18, 20], "jit": 50, "jitter": 12, "job": [12, 25, 37, 58], "jobs_presenting_ipod": [32, 68], "johnni": 46, "join": [5, 18, 42], "jointli": 66, "joke": 3, "jpeg": 35, "jpg": 65, "json": [3, 5, 6, 8, 11, 12, 13, 14, 15, 18, 20, 24, 28, 29, 32, 34, 35, 36, 38, 54, 57, 60, 61, 62, 64, 65, 68, 69, 71], "json_data": 8, "json_model_override_arg": [13, 16, 17, 18, 19, 24, 25], "json_output": 54, "json_schema": [16, 17, 33], "judgment": 6, "jul": 16, "jump": [13, 22], "jupyt": 0, "just": [7, 8, 14, 17, 40, 49, 50, 71, 72], "justmycod": 38, "k": [15, 17, 24, 33], "k2": [12, 18, 59], "k8": [41, 56, 60], "k_cach": 21, "k_proj": [8, 14], "keep": [0, 12, 14, 17, 22, 27, 32, 37, 38, 44, 58, 68, 71], "keep_mm_feature_on_devic": [13, 16, 17, 18, 19, 24, 25], "kei": [1, 6, 10, 12, 14, 16, 17, 20, 22, 24, 25, 27, 33, 36, 43, 54, 57, 60, 68, 71], "kept": 22, "kernel": [1, 3, 5, 6, 8, 11, 13, 16, 17, 18, 19, 20, 21, 24, 25, 36, 41, 43, 44, 45, 50, 51], "kernel_ascend": 14, "key_featur": 17, "key_stat": 72, "keysight": 17, "keyword": 71, "kfd": [40, 43], "kill": 36, "kilomet": 17, "kimi": [12, 13, 14, 18, 27, 42, 59, 68], "kimi_k2": [14, 18], "kind": [56, 57, 60], "kingdom": [27, 54], "kit": 46, "km\u00b2": 17, "know": [15, 17, 25, 27, 44, 71], "knowledg": [16, 17, 27], "known": [11, 15, 17, 25, 66], "korean": 66, "kt_cpuinfer": [13, 16, 17, 18, 19, 24, 25], "kt_max_deferred_experts_per_token": [13, 16, 17, 18, 19, 24, 25], "kt_method": [13, 16, 17, 18, 19, 24, 25], "kt_num_gpu_expert": [13, 16, 17, 18, 19, 24, 25], "kt_threadpool_count": [13, 16, 17, 18, 19, 24, 25], "kt_weight_path": [13, 16, 17, 18, 19, 24, 25], "kubectl": [41, 56, 57, 60], "kubernet": [6, 14, 59], "kv": [1, 5, 6, 10, 14, 20, 21, 23, 24, 31, 36, 42, 44, 50, 51], "kv_cache_dtyp": [13, 16, 17, 18, 19, 21, 24, 25], "kv_events_config": [13, 16, 17, 18, 19, 24, 25], "kvcach": [5, 6, 10, 14, 23, 24, 35], "kwarg": 72, "l": [17, 33, 58], "l1": 6, "l12": 22, "l15": 22, "l1a": 24, "l2": 6, "l27": 22, "l31": 22, "l34": 22, "l38": 22, "l4": 41, "l40": [20, 41], "l53": 22, "l57": 22, "la": [17, 24], "lab": [3, 33, 68], "label": [12, 13, 14, 16, 17, 18, 19, 24, 25, 36, 37, 40, 56, 57, 60, 61, 62, 64], "label1": 14, "label2": 14, "label_0": 64, "label_1": 64, "lack": [11, 35], "land": 17, "landmark": [15, 17, 24, 25], "landscap": 25, "lang": [19, 29, 32, 33, 54], "languag": [6, 10, 14, 27, 29, 32, 34, 41, 42, 49, 72], "larg": [1, 2, 6, 7, 10, 12, 14, 17, 20, 32, 35, 36, 41, 42, 59, 65, 68, 69], "larger": [6, 7, 8, 10, 14, 20, 21, 33, 45, 48, 66, 68], "largest": [17, 24, 27, 34, 66], "last": [13, 14, 15, 40, 41, 43, 44, 62, 64], "last_gen_throughput": 24, "last_hidden_st": 19, "lastli": 71, "late": 22, "latenc": [6, 8, 10, 12, 14, 20, 21, 32, 35, 36, 37, 42, 61, 65, 68, 69], "latent": [1, 14], "later": [7, 9, 17, 18, 40, 46, 52], "latest": [16, 17, 21, 22, 23, 25, 32, 41, 44, 45, 55, 56, 60, 61, 65, 66, 67], "latitud": 17, "latter": 6, "launch": [0, 2, 5, 9, 11, 16, 17, 22, 25, 33, 36, 37, 38, 41, 43, 46, 49, 58, 61, 62, 63, 67, 71], "launch_lb": 44, "launch_rout": [10, 12, 21, 36, 57, 60, 62], "launch_serv": [1, 2, 3, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 48, 49, 54, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72], "launch_server_cmd": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "laundri": 54, "law": [20, 27], "layer": [1, 5, 6, 8, 11, 12, 14, 15, 20, 24, 37, 50, 51, 57, 60, 71], "layer_first": [5, 6, 13, 14, 16, 17, 18, 19, 24, 25], "layer_id": 71, "layerwis": 14, "layerwise_profil": 36, "layout": [6, 14], "lb": 62, "ld_library_path": 12, "ld_preload": 45, "le": [17, 61], "lead": [3, 6, 8, 10, 11, 15, 23, 25, 33, 35, 51], "leader": [56, 57, 60], "leadercr": 57, "leadertempl": [56, 57], "leaderworkerset": [56, 57, 60], "leaderworkertempl": [56, 57], "leaf": 6, "leak": 12, "lean": 54, "learn": [0, 1, 3, 14, 17, 25, 27, 42, 43, 65, 66, 68, 70, 71], "least": [8, 14, 18, 33, 54, 56], "leav": [17, 33, 44], "lee": 27, "left": 38, "legaci": 12, "legal": 17, "legislatur": 17, "len": [33, 34, 35, 36, 45, 48], "length": [3, 6, 8, 13, 14, 15, 16, 17, 18, 21, 23, 24, 27, 28, 29, 32, 33, 34, 35, 36, 46, 50, 54, 57, 60], "less": [7, 10, 35, 36], "let": [13, 14, 15, 17, 18, 19, 25, 27, 44, 54, 71], "letter": [16, 17, 18, 27, 29], "level": [5, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 22, 24, 27, 28, 29, 32, 33, 34, 36, 43, 50, 54, 62, 66], "leverag": [6, 24, 43, 66, 72], "lfu": 14, "lg": 66, "lgai": 66, "li": 62, "lib": [15, 45, 48], "libiomp5": 45, "libnuma": 45, "librari": [14, 17, 20, 21, 71], "libsqlit": 45, "libtbbmalloc": 45, "libtcmalloc": 45, "licens": 66, "lid": 56, "life": 1, "lift": 22, "light": 24, "lighter": 12, "lightn": 21, "like": [1, 2, 3, 7, 11, 13, 15, 17, 18, 20, 24, 25, 36, 37, 45, 50, 54, 56, 61, 65], "likelihood": 27, "lill": 15, "limit": [5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 32, 34, 35, 36, 44, 46, 51, 52, 54, 56, 57, 60], "line": [8, 10, 11, 14, 16, 17, 19, 22, 24, 25, 32, 37, 45, 48, 61], "linear": [6, 11], "linearli": 33, "ling": 66, "linguist": 68, "link": [0, 10, 56, 71], "link_lay": 56, "link_up": 56, "linkedin": 55, "linkup": 56, "lint": [0, 37], "linux": [38, 40], "linux64cli": 38, "linux_aarch64": [10, 44], "list": [3, 8, 12, 13, 14, 15, 17, 18, 20, 22, 24, 27, 28, 33, 34, 36, 50, 51, 54, 62, 64, 71], "list_work": 12, "listen": 14, "lite": [66, 68], "liter": 18, "liuhaotian": [65, 68], "live": [12, 25, 36], "livenessprob": 60, "ll": [13, 17, 18, 27, 36, 56], "llama": [1, 8, 11, 12, 14, 15, 16, 24, 29, 33, 35, 36, 38, 41, 42, 43, 44, 45, 46, 48, 49, 61, 63, 65, 66, 68, 70, 72], "llama2": [15, 68], "llama3": [14, 15, 18, 68], "llama4": [18, 30], "llama4forconditionalgener": 19, "llama_ckpt": 71, "llama_dir": 71, "llama_wrapp": 71, "llamaattent": 71, "llamaconfig": 71, "llamaforcausallm": 71, "llamaforsequenceclassif": [64, 70], "llamaforsequenceclassificationwithnormal_weight": 64, "llamamlp": 71, "llamawrapp": 71, "llava": [29, 33, 65, 68], "llavavid": 68, "llguidanc": [14, 16], "llm": [3, 6, 10, 12, 13, 15, 16, 17, 18, 19, 21, 23, 25, 35, 41, 42, 43, 45, 48, 52, 66, 68, 71], "llmcompressor": 11, "lm": [14, 57, 60], "lm_head": [11, 15, 71], "lmcach": 6, "lmdeploi": 35, "lmhead": 15, "lmm": [33, 68], "lmsy": [15, 18, 51, 55, 58], "lmsysorg": [21, 38, 40, 41, 43, 55, 57, 60, 67], "load": [2, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 33, 34, 35, 36, 49, 54, 57, 61, 72], "load_balance_method": [13, 16, 17, 18, 19, 24, 25], "load_config": 11, "load_dataset": 11, "load_format": [13, 14, 16, 17, 18, 19, 24, 25], "load_imag": [33, 54], "load_lora_adapt": 8, "load_model": 11, "load_watch_interv": [13, 16, 17, 18, 19, 24, 25], "loadconfig": 11, "loaded_adapt": 8, "loader": [11, 71], "local": [0, 12, 14, 15, 22, 23, 24, 27, 28, 29, 35, 37, 38, 41, 44, 54, 66, 68, 70, 71], "local_attention_s": 14, "local_dir": 71, "local_ip": [10, 21], "localhost": [2, 3, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 54, 61, 68], "locat": [0, 6, 14, 15, 16, 17, 18, 24, 33, 34, 36, 38, 57, 60], "lof": 14, "log": [2, 5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 27, 28, 29, 32, 33, 34, 45, 50, 54, 56, 60, 61], "log_level": [13, 16, 17, 18, 19, 24, 25], "log_level_http": [13, 16, 17, 18, 19, 24, 25], "log_request": [13, 16, 17, 18, 19, 24, 25], "log_requests_level": [13, 16, 17, 18, 19, 24, 25], "logger": 14, "logic": [18, 64], "login": 61, "logit": [14, 20, 71], "logit_bia": 27, "logits_processor": 71, "logitsprocessor": 71, "logitsprocessoroutput": 71, "logo": 29, "logprob": [3, 14, 15, 18, 20, 27, 29, 33, 34, 51, 52, 57, 60], "logprob_start_len": [33, 51], "loir": 17, "londen": 24, "london": [16, 17, 24, 27, 52, 54], "londron": 17, "long": [0, 5, 6, 7, 14, 15, 20, 35, 36, 51, 66], "longer": [6, 10, 14, 27, 37, 38, 50, 52], "longest": 7, "longitud": 17, "look": [7, 16, 17, 21, 35, 37, 45, 48, 49, 71], "loop": [12, 25, 54], "lora": [33, 35, 42, 68], "lora0": 8, "lora0_new": 8, "lora1": 8, "lora2": 8, "lora3": 8, "lora_backend": [8, 13, 16, 17, 18, 19, 24, 25], "lora_eviction_polici": [8, 13, 16, 17, 18, 19, 24, 25], "lora_nam": [8, 14], "lora_path": [8, 13, 14, 16, 17, 18, 19, 24, 25, 27, 33, 35], "lora_target_modul": [8, 13, 16, 17, 18, 19, 24, 25], "lose": 10, "loss": 11, "loui": 17, "louvr": [15, 17, 24, 25], "love": [25, 64], "low": [6, 7, 14, 15, 20, 22, 27, 33, 35, 36, 42, 51, 69], "low_lat": [14, 44, 60], "lower": [1, 6, 7, 11, 12, 14, 20, 27, 37, 51, 71], "lpm": [7, 14], "lru": [8, 13, 14, 16, 17, 18, 19, 24, 25], "lru_cach": [15, 71], "lsb": 36, "lsof": 61, "lspci": 56, "lt": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "lustr": 36, "lw": [21, 56, 59, 60], "lws_group_siz": [56, 57, 60], "lws_leader_address": [56, 57, 60], "lws_worker_index": [56, 57, 60], "lyon": [15, 25], "m": [1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 48, 49, 54, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72], "m2": 66, "m3": [24, 69], "ma": 18, "maas_hosted_model": 57, "machin": [1, 3, 14, 21, 25, 38, 41, 43, 44, 61, 63, 71], "made": [17, 25], "madrid": [27, 54], "magic": 54, "mai": [6, 7, 8, 9, 10, 11, 14, 15, 18, 21, 22, 27, 35, 36, 38, 43, 45, 51, 54, 56, 57, 60, 62, 65, 67, 69, 70], "main": [2, 3, 19, 24, 25, 29, 32, 33, 35, 37, 45, 48, 54, 57, 60, 62, 65, 68, 71], "main_doc": [57, 60], "mainli": [6, 14, 24], "maintain": [3, 6, 17, 37, 54, 62, 71], "major": [6, 15, 16, 17, 25, 27, 37, 44, 56, 71], "make": [0, 3, 7, 8, 14, 15, 16, 17, 18, 20, 25, 27, 36, 37, 44, 56, 64, 69, 71], "mamba": [31, 66], "mamba_full_memory_ratio": [13, 16, 17, 18, 19, 24, 25], "mamba_ssm_dtyp": [13, 16, 17, 18, 19, 24, 25], "man": [29, 54], "manag": [2, 5, 9, 10, 11, 12, 14, 18, 25, 41, 54], "mandarin": 17, "manhattan": 54, "mani": [1, 6, 7, 8, 14, 15, 20, 25, 27, 35, 36, 45, 51, 52, 63, 71], "manifest": 14, "manner": [15, 17, 33], "manual": [0, 8, 20, 36, 37, 46, 62, 67], "manylinux_2_28_aarch64": 44, "map": [12, 14, 15, 38, 44, 61, 64], "marai": 17, "margin": 6, "mark": [10, 14, 17, 62], "markdown": 0, "marker": 14, "market": [17, 22], "marlin": [11, 14, 50], "marseil": 15, "mask": 33, "massachusett": 18, "master": 2, "match": [1, 7, 12, 14, 16, 17, 18, 21, 23, 24, 33, 61, 71], "matched_stop": [15, 18, 20, 27, 29, 34, 57, 60], "matchlabel": 57, "materi": 55, "math": [35, 54, 66, 70], "mathemat": 51, "matrix": [20, 50], "matryoshka_dimens": 65, "maverick": 23, "max": [8, 10, 12, 14, 15, 20, 21, 24, 31, 32, 35, 44, 45, 50, 51, 56, 57, 60, 63], "max_concurr": 35, "max_export_batch_s": 50, "max_gen_tok": 23, "max_loaded_lora": [8, 13, 16, 17, 18, 19, 24, 25], "max_lora_chunk_s": [13, 16, 17, 18, 19, 24, 25], "max_lora_rank": [8, 13, 16, 17, 18, 19, 24, 25], "max_loras_per_batch": [8, 13, 16, 17, 18, 19, 24, 25], "max_mamba_cache_s": [13, 16, 17, 18, 19, 24, 25], "max_model_len": 24, "max_new_token": [3, 7, 8, 11, 13, 16, 17, 18, 33, 34], "max_position_embed": 15, "max_prefill_token": [7, 13, 16, 17, 18, 19, 24, 25, 56], "max_queued_request": [13, 16, 17, 18, 19, 24, 25], "max_req_input_len": 24, "max_running_request": [7, 13, 16, 17, 18, 19, 24, 25, 56], "max_token": [15, 16, 17, 18, 20, 27, 29, 32, 33, 34, 54, 57, 60, 68], "max_total_num_token": [7, 24, 56], "max_total_token": [13, 16, 17, 18, 19, 24, 25], "maxim": [1, 6, 7, 8, 15], "maximum": [7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 32, 33, 34, 45, 50, 51, 54], "maxsurg": 57, "maxunavail": 57, "mayb": [15, 17], "mc_force_mnnvl": 10, "mc_te_metr": [57, 60], "mcdse": 42, "mcp": 22, "md": [0, 21, 37, 71], "me": [3, 13, 15, 16, 17, 25, 27, 54], "mean": [6, 7, 10, 14, 16, 17, 18, 21, 35, 43, 45, 50, 72], "meaning": 64, "measur": [33, 35], "mechan": [6, 11, 20, 21, 65, 70], "medatada": 1, "median": 35, "medic": 25, "mediterranean": 24, "medium": [22, 56, 57, 60], "meet": [6, 14, 17, 25, 71], "megatron": 66, "meituan": 45, "melanoleuca": [24, 69], "mellanox": 56, "mem": [5, 6, 10, 14, 15, 20, 21, 23, 24, 32, 36, 44, 45, 46, 51, 56, 57, 58, 60], "mem_fraction_stat": [7, 13, 16, 17, 18, 19, 24, 25], "member": [57, 71], "memfabric_url": 44, "memori": [1, 6, 8, 10, 12, 15, 17, 20, 23, 24, 32, 36, 45, 46, 56, 57, 60, 68], "memory_usag": 24, "mental": 54, "mention": [15, 17], "merg": [20, 24, 35, 36, 68], "merge_profil": 36, "merged_output": 25, "messag": [13, 14, 15, 16, 17, 20, 24, 27, 29, 32, 33, 34, 35, 57, 60, 64, 68], "messages_requir": 18, "messages_specif": 18, "met": [17, 24], "meta": [1, 2, 3, 8, 10, 11, 12, 14, 15, 16, 18, 19, 23, 33, 35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 58, 61, 63, 66, 68, 71, 72], "meta_info": [16, 17, 24, 34], "metadata": [1, 2, 5, 12, 14, 15, 18, 27, 29, 34, 36, 56, 57, 60, 68], "metal": [19, 45, 54], "meter": 17, "method": [2, 5, 12, 14, 15, 20, 21, 27, 33, 36, 43, 53, 71], "methodologi": 66, "metric": [5, 12, 14, 32, 42, 50], "metropolitan": 24, "mf_adapt": [10, 44], "mf_whl_name": 44, "mha": [6, 21], "mha_one_shot": 21, "mi300": 42, "mi300x": [20, 43], "mi350": 21, "mi355": [21, 42], "michelangelo": 17, "micro": 14, "microsoft": [38, 66, 68], "mid": [15, 22], "midtown": 54, "might": [8, 9, 11, 17, 24, 33, 38, 48, 50, 51, 61], "migrat": [17, 64], "mild": 27, "millard": 52, "million": [17, 25], "mimo": [15, 66, 68], "min": [0, 6, 14, 22, 33, 37], "min_new_token": 33, "min_p": 33, "mind": [0, 15, 37], "miner": 54, "mini": [62, 66, 68], "mini_lb": 44, "minicpm": [66, 68], "minicpm3": 66, "minim": [6, 15, 37, 68], "minimax": 66, "minimum": [6, 11, 12, 14, 20, 21], "minimum_token": 14, "ministri": 54, "minor": [8, 14, 37], "minut": [7, 9, 10, 20, 24, 54], "mislead": 52, "mismatch": 24, "miss": [12, 35, 49, 64], "misses_tot": 12, "mission": 27, "mistak": 17, "mistral": [12, 14, 18, 42, 65, 66, 68], "mistralai": [18, 66, 68], "mitig": [6, 23], "mix": [1, 11, 14, 17, 54], "mixtral": 66, "mixtur": [20, 66], "ml": 56, "mla": [6, 14], "mlc": 16, "mllm": 71, "mlp": [11, 14, 68], "mlx5_0": [5, 14, 57, 60], "mlx5_1": [14, 60], "mlx5_2": 60, "mlx5_3": 60, "mlx5_4": 60, "mlx5_5": [57, 60], "mlx5_6": [57, 60], "mlx5_7": 60, "mlx5_bond_0": [56, 57], "mlx5_bond_1": [56, 57], "mlx5_bond_2": [56, 57], "mlx5_bond_3": [56, 57], "mlx5_roce0": 10, "mm": [1, 14, 15, 17, 32, 68], "mm_attention_backend": [13, 16, 17, 18, 19, 24, 25], "mm_fp4": 50, "mm_item": 19, "mm_max_concurrent_cal": [13, 16, 17, 18, 19, 24, 25], "mm_per_request_timeout": [13, 16, 17, 18, 19, 24, 25], "mmap": 14, "mmlu": [23, 71], "mmlu_pro": 23, "mmmu": [35, 71], "mobil": [66, 68], "modal": [19, 23, 32, 35, 42, 65, 68], "mode": [1, 2, 3, 5, 13, 14, 21, 23, 24, 25, 27, 35, 38, 44, 46, 51, 56, 57, 60, 63], "model": [0, 1, 2, 5, 6, 7, 8, 10, 15, 16, 21, 22, 23, 25, 29, 31, 32, 33, 34, 36, 37, 38, 40, 41, 43, 44, 46, 49, 52, 54, 56, 57, 58, 60, 61, 63, 72], "model_arch_name_to_cl": 71, "model_arg": 23, "model_class": 71, "model_config": [11, 15, 24, 28, 71], "model_dump_json": 16, "model_executor": 71, "model_id": 11, "model_id_or_path": [45, 48], "model_impl": [13, 16, 17, 18, 19, 24, 25], "model_json_schema": [16, 17], "model_load": [11, 71], "model_loader_extra_config": [13, 16, 17, 18, 19, 24, 25], "model_nam": [11, 13, 18, 24, 61, 64, 71], "model_name_tool_choic": 18, "model_path": [5, 11, 13, 16, 17, 18, 19, 24, 25, 58, 71], "model_valid": 16, "model_validate_json": 16, "modelcloud": 11, "modelconfig": 11, "modelopt": 14, "modelopt_checkpoint_restore_path": [11, 13, 16, 17, 18, 19, 24, 25], "modelopt_checkpoint_save_path": [11, 13, 16, 17, 18, 19, 24, 25], "modelopt_export_path": [11, 13, 16, 17, 18, 19, 24, 25], "modelopt_fp4": [1, 11, 14], "modelopt_fp8": 11, "modelopt_qu": [13, 16, 17, 18, 19, 24, 25], "modelopt_quantize_and_export": 11, "modelregistri": 71, "modelrunn": 71, "modelscop": [35, 42, 50], "moder": [27, 54, 70], "modern": [6, 24], "modif": [37, 56], "modifi": [11, 27, 36, 37, 38, 41, 56, 57, 61, 71], "modul": [5, 6, 8, 14, 36, 38, 71, 72], "module_path": [5, 6, 14], "moe": [1, 10, 11, 14, 20, 44, 50, 57, 60, 66, 68], "moe_a2a_backend": [13, 16, 17, 18, 19, 21, 24, 25], "moe_dense_tp_s": [13, 16, 17, 18, 19, 21, 24, 25], "moe_runner_backend": [13, 16, 17, 18, 19, 24, 25], "moe_wna16": 14, "mongolian": 17, "monitor": [2, 12, 60, 61, 62], "mont": 38, "mood": 54, "moon": 27, "mooncak": [6, 13, 14, 16, 17, 18, 19, 24, 25, 35, 44], "mooncake_devic": 5, "mooncake_global_segment_s": 5, "mooncake_ib_devic": [13, 16, 17, 18, 19, 24, 25], "mooncake_mast": 5, "mooncake_protocol": 5, "mooncake_te_meta_data_serv": 5, "moonshotai": [18, 68], "mop": 19, "more": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 41, 42, 44, 45, 48, 51, 54, 56, 62, 65, 68, 71, 72], "morgan": 22, "moscow": 15, "most": [0, 6, 7, 8, 15, 17, 18, 22, 24, 25, 36, 37, 42, 45, 49, 54, 56, 71, 72], "mostli": 51, "motlei": 22, "mount": [38, 40], "mountpath": [56, 57, 60], "move": [5, 6, 15, 17, 68], "movement": 6, "mp4": [32, 68], "mrl": 65, "mscclpp": 14, "msg": 15, "mt": 15, "mt43244": 56, "mtp": [15, 20, 21], "much": [0, 6, 7, 37, 71], "muggl": 54, "multi": [1, 5, 8, 12, 23, 32, 41, 42, 48, 50, 56, 68, 71], "multi_item_scoring_delimit": [13, 16, 17, 18, 19, 24, 25], "multi_modal_projector": 19, "multi_node_deploy": 21, "multi_turn_qa": 54, "multiformatpars": 18, "multilingu": [65, 66, 70], "multimod": [1, 14, 23, 32, 42, 66], "multimodal_language_model": 71, "multimodal_processor": 71, "multipl": [1, 2, 6, 10, 12, 14, 15, 18, 20, 22, 27, 33, 35, 36, 37, 50, 54, 58, 62, 66, 68, 71], "multipli": [12, 25], "multitud": 17, "museum": [15, 17, 25], "musician": 25, "must": [6, 8, 10, 11, 12, 14, 16, 17, 18, 21, 33, 36, 37, 56, 62, 71], "mutual": 36, "mv": 43, "mxfp4": [11, 14], "my": [2, 15, 17, 25, 27, 37, 71], "my_checkpoint": 11, "my_model": 49, "my_model_templ": 49, "my_packag": 14, "myattent": 72, "myhuaweicloud": 44, "mymodel": 72, "mysteri": 27, "n": [1, 3, 6, 8, 13, 14, 15, 16, 17, 18, 24, 25, 27, 33, 34, 35, 45, 48, 54, 57, 58, 60, 65, 69], "n1": [15, 27, 34], "n10": 27, "n2": [15, 27, 34], "n3": [15, 27, 34], "n4": 27, "n5": 27, "n6": 27, "n7": 27, "n8": 27, "n9": 27, "na": 24, "nalright": 17, "name": [0, 2, 5, 6, 8, 11, 14, 16, 17, 18, 20, 21, 24, 25, 27, 33, 35, 36, 38, 40, 43, 44, 45, 48, 49, 52, 54, 56, 57, 60, 61, 62, 64, 71], "name1": 35, "name2": 35, "name_non_stream": 18, "namespac": [12, 60], "nan": [14, 24], "nano": 66, "nanoth": 15, "nation": [15, 17], "nativ": [1, 6, 8, 12, 22, 33, 35, 42, 56, 68], "natur": [6, 27, 37], "naur": 18, "navig": 61, "navit": 68, "nb": 24, "nbase": 24, "nbstripout": 0, "nc": [24, 58], "ncapit": 15, "nccl": [14, 20, 51, 56, 57, 58, 60], "nccl_debug": 56, "nccl_ib_gid_index": [38, 43, 56, 60], "nccl_ib_hca": [57, 60], "nccl_ib_qps_per_connect": [57, 60], "nccl_ib_sl": [57, 60], "nccl_ib_split_data_on_qp": [57, 60], "nccl_ib_tc": [57, 60], "nccl_ib_timeout": 60, "nccl_init_addr": 58, "nccl_min_nchannel": [57, 60], "nccl_net_plugin": [57, 60], "nccl_port": [13, 16, 17, 18, 19, 24, 25], "nccl_socket_ifnam": [56, 60], "ncontent": 17, "nd": 24, "ndescrib": 33, "ndetoken": 24, "ndoubl": 17, "ndr": 56, "ndv5": 43, "nearli": 43, "neatli": 17, "necessari": [6, 41, 51, 56, 71], "need": [1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 17, 18, 20, 21, 23, 24, 25, 27, 35, 36, 37, 38, 40, 43, 44, 45, 49, 51, 54, 56, 57, 60, 61, 62, 65, 67, 71, 72], "neg": [27, 33], "nemo": [18, 66], "nemotron": 66, "nest": 62, "nest_asyncio": [19, 25], "netdev": 56, "network": [2, 24, 38, 43, 44, 45, 46, 51, 56, 57, 60, 61], "networkconfig": 57, "neural": 24, "neuralmag": 11, "neutral": [25, 71], "never": 12, "new": [0, 5, 6, 7, 8, 12, 14, 15, 16, 17, 22, 24, 25, 27, 33, 37, 39, 40, 42, 45, 50, 54, 56, 57, 62, 64, 66], "new_token_ratio": 7, "new_york": [16, 17], "newer": [41, 45], "newli": [6, 21, 71], "newmodeldetector": 18, "next": [6, 13, 15, 17, 18, 30, 33, 62, 66, 68, 71], "next_token_logit": 71, "nextn": [14, 31], "nf": 36, "nfirst": 17, "nfor": 17, "ngener": [16, 17, 25], "nhttp": 24, "ni": [15, 17], "nic": [6, 56], "nice": 25, "nicknam": 17, "nightli": 41, "ninth": 27, "nixl": [6, 14], "nlastli": 17, "nlet": 15, "nlook": 17, "nlp": [24, 28, 65, 66], "nn": [56, 72], "nnext": 17, "nnode": [2, 10, 13, 14, 16, 17, 18, 19, 24, 25, 44, 56, 57, 58, 60], "nnow": 17, "no_grad": 71, "no_stop_trim": [18, 33], "node": [5, 6, 12, 15, 24, 41, 42, 44, 50, 56, 57, 60, 62], "node1": 56, "node_rank": [13, 16, 17, 18, 19, 24, 25], "nodeport": [57, 60], "nodeselector": [57, 60], "nois": 3, "nokai": 15, "non": [1, 12, 27, 35, 37, 50, 54, 64, 71], "nondeterminist": 51, "none": [8, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 33, 34, 50, 57, 60, 71], "normal": [1, 13, 14, 18, 60, 62], "normal_text": 18, "north": [15, 17], "northern": 17, "northwestern": 24, "notabl": [17, 24, 25, 45], "notat": 17, "note": [1, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 27, 28, 29, 34, 37, 38, 40, 43, 45, 48, 49, 50, 54, 56, 57, 58, 60, 62, 64, 67, 71], "notebook": [0, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "noth": [12, 14], "notic": [17, 44, 51, 56, 57], "notr": [17, 24, 25], "nousresearch": 43, "novel": 27, "now": [1, 15, 17, 22, 24, 27, 36, 38, 43, 44, 54, 64, 71], "nowadai": 37, "npari": 24, "npcach": 14, "npleas": 17, "nproc": 2, "nprompt": [25, 71], "npu": [1, 14, 21, 41, 42], "npugraph": 44, "nput": 17, "nround": 24, "nsa": [1, 14, 21], "nsa_decode_backend": [13, 16, 17, 18, 19, 24, 25], "nsa_prefill_backend": [13, 16, 17, 18, 19, 24, 25], "nsight": 14, "nsure": 17, "nsy": [36, 38], "ntask": 58, "nthe": [15, 17], "nthi": 17, "nthink": 17, "ntoken": 24, "null": [13, 14, 16, 17, 18, 19, 20, 24, 25, 28, 29, 41, 57, 60, 64], "num": [14, 15, 20, 21, 23, 31, 35, 36, 37, 38, 43, 45, 48, 57, 60, 61], "num_class": 64, "num_concurr": 23, "num_continuous_decode_step": [13, 16, 17, 18, 19, 24, 25], "num_fewshot": 23, "num_fram": 68, "num_hidden_lay": 36, "num_key_value_head": 36, "num_paused_request": 24, "num_queue_req": 61, "num_reserved_decode_token": [13, 16, 17, 18, 19, 24, 25], "num_running_req": 61, "num_stag": 15, "num_step": 36, "num_token_to_fetch": 6, "num_used_token": 61, "num_warp": 15, "numa": [14, 45], "numa_balanc": [43, 44], "numa_nod": [13, 16, 17, 18, 19, 24, 25], "numactl": 45, "number": [1, 2, 6, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 45, 50, 54, 61, 62, 64], "numer": [20, 24, 25, 51], "numexpr": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "numexpr_max_thread": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "numpi": [14, 35], "nurgaliyev": 46, "nutanix": 8, "nutrient": 54, "nv": 46, "nvda": 22, "nvfp4": [11, 14, 50], "nvfp4_awq": 14, "nvidia": [1, 14, 20, 22, 23, 36, 37, 40, 41, 42, 56, 57, 60, 66], "nvidia_h100_80gb_hbm3": 24, "nvidia_h100_80gb_hbm3_down": 24, "nvila": 68, "nvl": 14, "nvl72": 10, "nvme": 38, "nvpmodel": 46, "nvrtc": 50, "nvshmem_bootstrap_uid_sock_ifnam": 60, "nvshmem_disable_p2p": 60, "nvshmem_enable_nic_pe_map": 57, "nvshmem_hca_list": 57, "nvshmem_hca_pe_map": 57, "nvshmem_ib_gid_index": [57, 60], "nvshmem_ib_sl": 60, "nvshmem_ib_traffic_class": [57, 60], "nvtx": 14, "nwait": [15, 17], "ny": [16, 17, 18], "nyou": 33, "n\u00fa\u00f1ez": 46, "n\u4f60\u597d\u5440": [57, 60], "n\u55ef": [57, 60], "n\u6211\u7684\u4efb\u52a1\u5c31\u662f\u966a\u4f60\u804a\u5929": [57, 60], "n\u7528\u6237\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u80cc\u666f\u4fe1\u606f": [57, 60], "n\u7528\u6ce2\u6d6a\u7ebf\u7ed3\u5c3e\u53ef\u4ee5\u8f6f\u5316\u8bed\u6c14": [57, 60], "n\u7b54\u6848": 24, "n\u8003\u8651\u5230\u4e2d\u6587\u7528\u6237": [57, 60], "o": [5, 6, 10, 15, 16, 17, 28, 33, 36, 38, 40, 44, 58, 68], "o_proj": [8, 14], "oai": 35, "ob": 44, "object": [6, 14, 15, 16, 17, 18, 20, 27, 28, 29, 33, 34, 35, 57, 60, 64], "observ": [15, 42, 62], "obtain": [6, 15, 18, 24, 52, 56, 62], "occasion": 7, "occup": [36, 54], "occur": [7, 24, 33, 51], "ocr": 68, "odd": 35, "odel": 13, "ofassistantgener": 16, "ofed_info": 56, "off": [20, 31, 43, 50, 65], "offer": [17, 33, 42, 66, 68, 69, 70], "offici": [14, 17, 20, 21, 23, 25, 37, 38, 43, 49, 57], "official_nam": 17, "officiallanguag": 17, "offlin": [10, 29, 36, 42], "offload": [5, 6], "offload_group_s": [13, 16, 17, 18, 19, 24, 25], "offload_mod": [13, 16, 17, 18, 19, 24, 25], "offload_num_in_group": [13, 16, 17, 18, 19, 24, 25], "offload_prefetch_step": [13, 16, 17, 18, 19, 24, 25], "often": [6, 17, 20, 24, 50, 70], "oh": 17, "ok": [24, 56], "okai": [7, 17, 27], "old": 27, "older": 56, "olmo": 66, "oltp": 14, "om": 41, "omit": [27, 52, 65], "omni": 68, "onboard": 12, "onc": [1, 6, 15, 17, 18, 24, 27, 28, 29, 37, 38, 52, 56, 63], "oncal": 37, "ondemand": 44, "one": [1, 6, 8, 10, 12, 13, 14, 16, 17, 18, 22, 24, 27, 29, 33, 35, 36, 37, 41, 43, 44, 50, 51, 52, 61, 65, 72], "oneshot": 11, "onevis": [29, 33, 68], "ongo": [10, 23, 36], "onli": [1, 2, 3, 5, 6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 33, 35, 36, 38, 41, 43, 44, 46, 48, 51, 52, 54, 56, 66, 69, 71], "onlin": [20, 35, 36, 58], "only_run": 71, "oom": [7, 23, 51], "op": [6, 14], "open": [0, 12, 15, 19, 23, 36, 37, 38, 41, 42, 43, 44, 45, 61, 66, 68], "openai": [14, 15, 20, 22, 24, 33, 35, 42, 45, 48, 49, 52, 54, 64, 65, 66, 68], "openai_api_complet": 8, "openai_api_kei": [35, 40], "openbmb": [66, 68], "opentelemetri": [14, 62], "oper": [1, 3, 5, 6, 10, 12, 13, 14, 15, 20, 24, 36, 37, 41, 45, 50, 57, 60, 65], "opt": [11, 38, 43], "optic": 68, "optim": [1, 2, 3, 4, 7, 8, 10, 11, 12, 15, 23, 24, 37, 43, 57, 66, 69], "option": [5, 8, 10, 11, 12, 13, 15, 17, 22, 27, 36, 41, 52, 61, 62, 64, 71], "oracl": 12, "oraclecloud": 12, "orchestr": 12, "order": [3, 12, 45, 54, 69], "org": [18, 44, 45, 48, 51, 58, 63, 66, 68], "organ": [5, 17], "orient": 6, "orig_logit": 71, "origin": [1, 8, 11, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54, 64], "orin": 42, "orion": 66, "orionstarai": 66, "oserror": 41, "oss": [12, 13, 14, 18, 27, 42, 66], "otel_exporter_otlp_traces_protocol": 62, "otel_trac": 62, "other": [0, 2, 8, 9, 14, 15, 17, 18, 19, 20, 21, 25, 27, 29, 37, 41, 43, 45, 50, 51, 52, 54, 58, 61, 62, 63, 66, 68, 71], "otherwis": [14, 17, 21, 35, 36, 62, 65, 72], "otlp": 62, "otlp_traces_endpoint": [13, 16, 17, 18, 19, 24, 25, 62], "ottawa": [27, 34], "our": [0, 8, 11, 15, 21, 22, 25, 33, 37, 51, 57, 64], "out": [8, 13, 14, 15, 17, 18, 19, 23, 24, 27, 29, 32, 36, 37, 41, 45, 54, 58, 67], "outcom": 25, "outdat": 17, "outlin": [14, 16, 18, 20, 33, 50], "output": [0, 3, 6, 8, 11, 13, 14, 15, 20, 21, 22, 24, 25, 28, 29, 34, 37, 38, 42, 43, 45, 48, 50, 51, 54, 56, 57, 58, 61, 66, 68, 70, 71], "output_dir": [11, 36], "output_hidden_st": 19, "output_id": [16, 17, 24, 34], "output_len": 35, "output_text": 22, "outsid": 17, "ov": [33, 68], "over": [0, 6, 8, 10, 11, 12, 14, 17, 21, 25, 29, 36, 42, 50], "overal": [17, 20, 25], "overflow": 12, "overhead": [6, 7, 8, 14, 15, 21, 25, 36, 37, 42, 68], "overlap": [2, 6, 14, 15, 25, 36, 45, 48, 50, 52, 57], "overrid": [5, 6, 12, 15, 33, 35, 36, 49, 65], "oversight": 25, "overview": [6, 16, 17, 20, 28, 37], "overweight": 22, "overwrit": 50, "own": [12, 14, 15, 37, 41, 45, 48, 58], "p": [14, 15, 21, 22, 33, 41, 43, 45, 57, 61, 67], "p2p": [2, 14, 50], "p95": 35, "p99": 35, "p_": 15, "packag": [2, 15, 22, 37, 41, 43, 44, 45, 48, 57, 62], "pad": [14, 50, 71], "pad_input_id": 71, "page": [1, 5, 6, 8, 14, 22, 28, 37, 41, 42, 48, 51, 57, 60, 72], "page_first": [5, 6, 14], "page_first_direct": [5, 6, 14], "page_first_kv_split": 14, "page_s": [1, 6, 13, 16, 17, 18, 19, 24, 25], "pah": 15, "pai": 56, "pair": [5, 17, 29, 35], "pairwis": 24, "palac": 17, "panda": [24, 69], "pandoc": 0, "pant": 29, "pantheon": 27, "paper": [1, 8, 15], "paragraph": [24, 54], "parallel": [0, 6, 7, 8, 10, 15, 18, 32, 36, 38, 42, 45, 50, 56, 57, 59, 60, 70], "param": [8, 14, 18, 24, 35, 66], "param1": 18, "param2": 18, "param_dict": 33, "paramet": [2, 7, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 34, 36, 38, 42, 45, 48, 50, 51, 57, 58, 60, 66, 71], "parc": 17, "pari": [8, 15, 16, 17, 18, 20, 24, 25, 27, 33, 34, 52, 54], "paris2": 54, "parisian": 17, "pariti": 12, "park": [17, 19, 29], "parliament": 15, "parliamentari": 17, "pars": [11, 13, 17, 18, 22, 27, 50, 64], "parse_function_cal": 18, "parse_non_stream": [13, 18], "parse_url": [13, 18], "parser": [12, 14, 17, 19, 20, 27, 42, 66], "part": [1, 6, 17, 24, 51, 57], "partial": [14, 18], "particip": 2, "particular": [17, 18], "particularli": [3, 17, 36], "partit": [14, 20, 50, 58], "partli": 18, "pass": [0, 6, 8, 14, 15, 27, 35, 37, 50, 68, 71], "passer": 54, "passion": 25, "password": 61, "patch": 62, "patch14": 65, "patchleadertempl": 60, "patchworkertempl": 60, "path": [1, 2, 3, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 49, 50, 52, 54, 56, 57, 58, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72], "patrick": 17, "patronu": 54, "pattern": [6, 10, 14, 15, 16, 17, 33, 36, 37, 56], "paus": 38, "payload": [12, 16, 17, 35, 60, 65, 69], "pci": 43, "pd": [12, 42, 44, 59, 62], "pd_role": 60, "pdmux": 14, "pdmux_config_path": [13, 16, 17, 18, 19, 24, 25], "peak": [7, 14, 20, 51], "pedestrian": 19, "peer": [2, 8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 50, 54], "penalti": 27, "peopl": [17, 19, 37], "per": [1, 2, 6, 7, 8, 10, 11, 12, 14, 15, 20, 32, 33, 35, 36, 50, 58, 60, 61, 68], "per_row": [11, 14], "per_tensor": [11, 14], "perfectli": 3, "perfetto": [36, 62], "perform": [1, 5, 6, 8, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 32, 34, 36, 42, 43, 45, 46, 48, 52, 54, 56, 62, 65, 66, 69, 71], "perhap": 17, "period": [12, 50], "periodsecond": [56, 57, 60], "perman": [8, 61], "permiss": 37, "persimmon": 66, "persist": 12, "person": [19, 25], "petit_nvfp4": 14, "phase": [1, 6, 8, 10, 14, 15, 20, 62], "phi": [66, 68], "philschmid": 8, "phoenix": [17, 54], "phrase": 27, "phy": 56, "physic": [50, 54], "physical_st": 56, "pick": [12, 35, 37], "pickl": 9, "piec": 17, "piecewis": 14, "piecewise_cuda_graph_compil": [13, 16, 17, 18, 19, 24, 25], "piecewise_cuda_graph_max_token": [13, 16, 17, 18, 19, 24, 25], "piecewise_cuda_graph_token": [13, 16, 17, 18, 19, 24, 25], "pil": 19, "pillow": 35, "pin": 14, "pip": [0, 2, 10, 11, 14, 21, 36, 39, 40, 43, 44, 45, 48, 62], "pip3": [21, 37, 41, 48], "pipelin": [0, 12, 14, 15, 42, 50, 70], "pixel_valu": 19, "place": [6, 17, 18, 19, 24, 37], "plan": [1, 8, 17, 18, 24, 25, 38, 41, 50], "planet": 27, "platform": [1, 41, 45], "playground": [9, 71], "pleas": [1, 8, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 28, 29, 33, 36, 37, 38, 41, 43, 44, 45, 46, 47, 48, 51, 54, 56, 58, 60, 62, 71], "plenti": 54, "plu": [12, 13, 32, 66], "plugin": [6, 18, 56], "png": [19, 29, 32, 33, 35, 54], "po": [57, 60], "pod": 12, "point": [3, 12, 15, 17, 22, 25, 57, 60, 61, 62, 71], "poisson": 35, "polici": [3, 6, 7, 8, 10, 14, 15, 60], "polit": 15, "poll": [12, 14], "pont": 17, "pool": [6, 8, 12, 14, 24, 32, 50, 51], "poorli": 52, "popul": [16, 17, 24, 33, 71], "popular": [11, 25, 27, 42, 45], "population_2022": 17, "port": [0, 2, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 38, 41, 43, 44, 49, 50, 54, 56, 57, 58, 60, 61, 62, 65, 66, 67, 68, 69, 70, 72], "port_tool_choic": 18, "portion": [2, 18, 51], "posit": [25, 27, 33, 68, 71], "possibl": [0, 6, 7, 14, 15, 17, 25, 37, 71], "possibli": [19, 62], "post": [3, 8, 11, 12, 13, 15, 16, 17, 18, 24, 28, 29, 32, 33, 34, 35, 36, 51, 56, 57, 58, 60, 62, 64, 65, 68, 69], "post1": 44, "post3": [24, 41, 43, 44], "potenti": [14, 15, 25, 45, 48, 62], "potter": 54, "power": [12, 15, 21, 25, 36, 42, 43, 68], "power_of_two": 12, "pp": [14, 36], "pp_max_micro_batch_s": [13, 16, 17, 18, 19, 24, 25], "pp_proxy_tensor": 71, "pp_size": [13, 16, 17, 18, 19, 24, 25], "ppproxytensor": 71, "pprint": 20, "pr": [0, 21, 23, 31, 37, 60, 71], "practic": [4, 36], "pre": [0, 1, 11, 14, 43, 44, 61], "prebuilt": 44, "preced": 27, "precipit": 17, "precis": [6, 11, 14, 17, 20, 25], "precompil": [15, 20, 50], "precomputed_embed": 19, "predefin": [14, 71], "predict": [25, 35, 52, 64, 66], "preempt": 14, "preemption": 14, "prefer": [0, 14, 17, 18, 24, 25, 35, 37, 38, 45, 70], "preferred_sampling_param": [13, 16, 17, 18, 19, 24, 25], "prefetch": 14, "prefetch_threshold": 6, "prefetch_timeout_bas": 6, "prefetch_timeout_per_ki_token": 6, "prefil": [3, 5, 6, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 32, 42, 44, 50, 51, 56, 60, 61, 62, 69, 71], "prefill1": 12, "prefill_addr": 21, "prefill_attention_backend": [13, 16, 17, 18, 19, 24, 25], "prefill_host_ip": 44, "prefill_in1024": 57, "prefill_master_ip": 10, "prefill_round_robin_bal": [13, 16, 17, 18, 19, 24, 25], "prefix": [1, 3, 6, 7, 12, 14, 20, 21, 35, 36, 42, 50, 51, 71], "preliminari": 2, "prepar": [3, 56], "prereleas": 41, "prerequisit": 36, "prescript": 25, "presenc": 17, "presence_penalti": [27, 33], "present": [6, 17, 21, 68], "preserv": 18, "preset": [35, 57], "presid": [15, 25, 52], "press": [24, 29, 38, 56], "pressur": 6, "pretrain": 66, "pretrainedmodel": 72, "pretti": [17, 20], "prev": [33, 34], "prevent": [6, 7, 8, 10, 14, 17, 27, 37, 38, 45, 48, 51, 56], "preview": [0, 8], "previou": [20, 22, 61, 62, 66], "previous": [14, 33], "price": 22, "primari": [45, 48], "primarili": [25, 37, 41, 50, 66], "primit": [12, 52], "principl": 62, "print": [3, 8, 11, 17, 18, 19, 22, 24, 25, 27, 28, 32, 33, 34, 35, 36, 54, 64, 65, 68, 69, 71], "print_highlight": [13, 15, 16, 17, 18, 24, 27, 28, 29, 33, 34, 54], "prior": 45, "priorit": 37, "prioriti": [14, 64], "priority_scheduling_preemption_threshold": [13, 16, 17, 18, 19, 24, 25], "prison": 17, "privaci": [25, 27], "privat": 6, "privileg": [38, 43, 44, 45, 56, 57, 60], "pro": [1, 23, 48, 68, 71], "proactiv": 6, "prob": [14, 64], "probabl": [14, 15, 17, 33, 64], "probe": 12, "problem": [10, 11, 13, 25, 41, 44, 54, 56], "proc": [43, 44], "proceed": 6, "process": [2, 6, 10, 12, 14, 15, 17, 20, 21, 24, 25, 27, 32, 35, 36, 37, 50, 54, 56, 61, 62, 64, 66, 68, 69], "process_tracing_init": 62, "processed_prompt": 19, "processor": [14, 19, 20, 27, 45, 68, 71], "produc": [3, 18, 35, 61, 66], "product": [3, 6, 11, 12, 21, 22, 42, 72], "profil": [14, 35, 37, 42], "profile_id": 36, "profile_log": 36, "profiler_python": 36, "program": [25, 27, 38, 42, 65, 68, 69], "programmat": [11, 17, 36], "progress": 12, "progress_bar": 54, "project": [17, 19, 21, 22, 24, 25, 29, 32, 33, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 54, 55, 60, 62, 66, 68], "projector": 68, "prometheu": [9, 12, 14, 61], "promis": [14, 25], "prompt": [3, 7, 11, 13, 14, 16, 17, 18, 19, 20, 22, 24, 25, 27, 33, 35, 36, 42, 43, 45, 48, 51, 61, 68, 71], "prompt_token": [15, 16, 17, 18, 20, 24, 27, 28, 29, 34, 57, 60, 64], "prompt_tokens_bucket": [13, 16, 17, 18, 19, 24, 25], "prompt_tokens_detail": [14, 15, 18, 20, 27, 28, 29, 34, 57, 60, 64], "prompt_tokens_tot": 61, "pronounc": 15, "pronunci": 15, "propag": [12, 62], "proper": [17, 35, 37, 45, 56], "properli": [17, 43, 45, 56, 62], "properti": [16, 17, 18, 20, 33], "propos": [6, 18], "protein": 54, "proto": 62, "protobuf": 62, "protocol": [12, 56, 57, 60, 64], "prototyp": 12, "provid": [2, 3, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, 24, 25, 27, 28, 29, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 50, 58, 61, 62, 64, 65, 66, 68, 70, 71], "prss": 38, "prune": 12, "psychotrop": 25, "pt": [14, 15, 19, 43, 66], "pta_nam": 44, "pta_url": 44, "pta_vers": 44, "pta_whl_nam": 44, "pth": 11, "ptq": 11, "pub": 36, "public_sglang_ci": 24, "publish": 14, "pull": [0, 21, 22, 37, 38, 40], "punica": 8, "pure": [14, 21, 37, 54], "purpos": [6, 9, 14], "push": [0, 37], "put": [16, 17], "pwd": 11, "py": [1, 2, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 33, 34, 36, 37, 38, 39, 43, 49, 54, 64, 71], "pybase64": 35, "pydant": [16, 17], "pypi": [37, 44, 45], "pyproject": [37, 39, 43, 45, 48], "pyproject_cpu": 45, "pyproject_oth": 43, "pyproject_xpu": 48, "python": [1, 2, 5, 6, 10, 12, 13, 14, 16, 17, 21, 23, 24, 25, 27, 32, 33, 35, 36, 37, 38, 39, 41, 43, 45, 46, 48, 49, 54, 57, 58, 61, 62, 66, 67, 68, 71, 72], "python3": [1, 3, 5, 8, 9, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72], "python_execution_backend": 22, "python_serv": 22, "python_tag": 18, "pytorch": [1, 11, 14, 41, 45, 48, 50, 51, 63], "pytorch2": 44, "pytorch_npu_alloc_conf": 44, "pytorch_vers": 44, "q": [20, 21], "q2": 22, "q4": 55, "q4_k_m": 11, "q_proj": [8, 14], "qa": 6, "qdrep": 36, "qingdao": 20, "qk": [13, 14, 16, 17, 18, 19, 24, 25], "qkv": [11, 14], "qkv_proj": [14, 36], "qoq": 14, "qperf": 56, "quad": 13, "qualiti": [11, 15, 16, 24, 25, 65, 66], "quant": [11, 14], "quant_config": [11, 71], "quant_path": 11, "quantiz": [1, 7, 13, 16, 17, 18, 19, 20, 24, 25, 42, 44, 45, 50, 71], "quantization_param_path": [13, 16, 17, 18, 19, 24, 25], "quantizationconfig": 71, "quantizationmodifi": 11, "quantize_and_sav": 11, "quantize_and_serv": [13, 16, 17, 18, 19, 24, 25], "quantizeconfig": 11, "quantized_model": 11, "quantized_tinyllama_fp4": 11, "quantized_tinyllama_fp8": 11, "quarter": 17, "queri": [0, 6, 9, 14, 16, 17, 24, 35, 42, 68, 69], "query_st": 72, "query_weath": 20, "question": [13, 15, 17, 20, 21, 25, 27, 35, 37, 38, 42, 43, 54, 68], "queu": 14, "queue": [10, 12, 24, 56, 61], "queue_schedul": 44, "quick": [12, 17, 34, 36, 37, 41], "quickli": [0, 36, 37], "quit": [17, 24, 56], "quot": [17, 22], "quotat": 17, "qwen": [0, 1, 2, 3, 8, 11, 13, 14, 17, 18, 24, 25, 27, 29, 31, 32, 34, 35, 36, 37, 42, 45, 48, 54, 65, 66, 67, 68, 70, 71], "qwen1": 24, "qwen2": [0, 1, 8, 11, 18, 19, 24, 25, 27, 28, 29, 33, 34, 35, 37, 48, 54, 57, 60, 64, 65, 67, 68, 70, 71], "qwen25": [14, 18], "qwen2_5_vlforconditionalgener": [19, 68], "qwen2forcausallm": 24, "qwen2forrewardmodel": [64, 70], "qwen2forsequenceclassif": [64, 70], "qwen2vl": 71, "qwen3": [2, 5, 12, 13, 14, 18, 30, 45, 65, 66, 68], "qwen3_cod": [14, 18], "qwen3forcausallm": 66, "qwen3forsequenceclassif": 64, "qwq": [17, 45], "r": [0, 15, 16, 17, 27, 54, 64, 66], "r1": [1, 2, 5, 11, 12, 13, 14, 17, 27, 30, 41, 43, 44, 45, 46, 56, 57, 66], "race": 10, "rack": 54, "radix": [3, 14, 24, 35, 36, 51, 57, 60, 69], "radix_cach": 3, "radix_eviction_polici": [13, 16, 17, 18, 19, 24, 25], "radixattent": [5, 6, 14, 42, 71], "radixtre": 6, "rag": [14, 21], "rais": [14, 22, 24, 35, 62], "raise_for_statu": 24, "ralli": 22, "ram": 14, "ran": 71, "random": [12, 14, 15, 35, 36, 43, 45, 48, 60, 61], "random_se": [13, 16, 17, 18, 19, 24, 25], "randomli": [33, 35], "rang": [6, 7, 11, 14, 15, 24, 25, 27, 33, 35, 36, 42, 45, 48, 61], "rank": [2, 8, 10, 12, 13, 14, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 34, 36, 44, 45, 50, 54, 56, 57, 58, 60, 70], "rapid": [6, 25, 44], "rapidli": 25, "rate": [5, 6, 15, 22, 45, 48, 56, 61], "rather": [7, 11], "ratio": [5, 6, 12, 14, 23, 35, 45, 48, 61], "ravenclaw": 54, "raw": [19, 29, 32, 33, 54, 68, 71], "raw_tool": 18, "rbac": 12, "rbg": [21, 59], "rbg_pd": 21, "rc": 36, "rc_rdma_write_bw": 56, "rdma": [5, 6, 38, 43, 44, 57, 60], "re": [0, 14, 17, 20, 37, 38, 56, 71], "reach": [6, 22], "reachabl": 35, "read": [6, 14, 17, 33, 38, 43, 68], "readabl": 24, "readi": [2, 6, 7, 11, 12, 21, 24, 27, 36, 43, 45, 56, 58, 66, 71], "readinessprob": [56, 57, 60], "readm": [37, 71], "real": [6, 11, 14, 16, 17, 18, 36, 66], "realiti": 25, "realloc": 43, "reasoing_cont": 17, "reason": [9, 12, 14, 15, 18, 32, 42, 50, 66, 68], "reasoning_cont": [13, 15, 17, 18, 20, 27, 29, 34, 57, 60], "reasoning_effort": 22, "reasoning_pars": [12, 13, 16, 17, 18, 19, 24, 25], "reasoning_text": 13, "reasoning_token": [15, 18, 27, 28, 29, 34], "reasoningpars": 13, "rebal": [14, 60], "rebalanc": 14, "reboot": 43, "rebuild": 0, "recal": [15, 17], "receiv": [6, 10, 20, 27, 62, 71], "recent": [8, 14, 15, 17, 22, 51], "recip": [11, 63], "recogn": [13, 23, 66, 71], "recognit": 68, "recommend": [0, 1, 2, 5, 6, 8, 10, 11, 14, 18, 20, 22, 23, 27, 36, 37, 41, 44, 45], "reconstruct": [20, 24], "reconstructed_text": 24, "record": [6, 14, 24, 25, 50, 62], "record_shap": 50, "recoveri": 41, "recreategrouponpodrestart": [56, 57], "recv": 14, "red": 66, "redhatai": 45, "rednot": 68, "reduc": [0, 1, 2, 3, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 20, 24, 25, 27, 28, 29, 33, 34, 36, 37, 51, 54, 62, 65, 68], "reduct": [3, 20], "redund": [6, 11, 14, 57, 60], "redundantli": 6, "ree": 15, "ref": [32, 68], "refer": [5, 6, 7, 10, 14, 17, 18, 20, 21, 22, 27, 28, 29, 33, 34, 36, 37, 41, 43, 48, 51, 56, 58, 60, 71], "referenc": 17, "reference_hf": 71, "refin": [54, 69, 70], "refus": [15, 18, 27, 34], "regard": 62, "regardless": [14, 35], "regex": [14, 16, 17, 54], "region": [12, 15, 17, 36], "regist": [5, 12, 36], "registr": 12, "registri": [12, 71], "regress": [11, 37], "regul": [12, 25], "regular": [8, 12, 15, 33, 54], "regular_expression_gen": 54, "reichstag": 17, "reign": 27, "reinforc": [3, 66, 68, 70], "reiniti": 8, "reinstal": [10, 41, 45], "reject": 15, "rel": [0, 3, 12], "relat": [8, 29, 37, 41, 45, 49, 56, 57, 60], "relationship": [6, 62], "relax": 10, "releas": [8, 13, 22, 36, 37, 41, 43, 44, 54, 57], "release_memory_occup": 14, "release_weights_occup": 14, "relev": [0, 8, 15, 16, 17, 69], "reli": [37, 71], "reliabl": [3, 17, 18, 25, 66], "reload": 8, "remain": [8, 12, 51, 62, 68], "rememb": [0, 15, 17, 28], "remind": [16, 17], "remot": [1, 10, 12, 14, 15, 20, 21, 23, 24, 32, 43, 44, 45, 48, 56, 57, 60, 65, 68, 69, 70], "remote_inst": 14, "remote_instance_weight_loader_seed_instance_ip": [13, 16, 17, 18, 19, 24, 25], "remote_instance_weight_loader_seed_instance_service_port": [13, 16, 17, 18, 19, 24, 25], "remote_instance_weight_loader_send_weights_group_port": [13, 16, 17, 18, 19, 24, 25], "remov": [0, 12, 15, 19, 25, 33, 38, 43, 71], "remove_work": 12, "renaiss": 17, "renderd176": 40, "renderd184": 40, "reorder": [7, 20], "rep": 36, "repeat": [8, 21, 25, 32, 33, 38], "repetit": [27, 33], "repetition_penalti": [24, 33], "replac": [8, 25, 41, 43, 44, 45, 58, 61, 62, 71], "replai": [1, 36], "replay_request_dump": 9, "repli": [16, 17], "replica": [56, 57, 60], "repo": [12, 14, 15, 36, 37, 38, 66, 68], "repo_id": 71, "report": [5, 14, 21, 32, 35, 36, 51, 71], "repositori": [2, 5, 24, 38, 44, 45, 46], "repres": [6, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54, 62, 65], "represent": [14, 65], "reproduc": 27, "republ": [15, 17], "req": [24, 35, 56, 62], "req_id": 62, "req_root_span": 62, "request": [0, 3, 5, 6, 8, 10, 12, 14, 15, 16, 17, 19, 20, 21, 24, 27, 31, 33, 35, 36, 38, 42, 43, 44, 50, 51, 56, 57, 58, 60, 61, 68, 71], "request_r": 35, "requestexcept": 24, "requir": [0, 1, 6, 11, 12, 14, 15, 16, 17, 20, 21, 22, 25, 33, 35, 38, 41, 43, 44, 45, 51, 56, 62, 64, 65, 69, 70, 71, 72], "rerank": [12, 15, 42], "reranker_process": 24, "research": [17, 66], "reserv": [7, 8, 14], "resid": [6, 8, 12, 15, 17], "residu": 14, "resolut": [35, 68], "resolv": [0, 10, 11, 20, 37, 51, 56, 65], "resort": 64, "resourc": [6, 10, 41, 46, 56, 57, 60, 65, 71], "respect": [20, 27, 34, 62], "respond": [12, 17, 18, 25, 27], "respons": [6, 8, 12, 13, 14, 15, 16, 17, 18, 20, 24, 25, 27, 28, 29, 32, 33, 34, 52, 65, 68, 69, 70], "response1": 24, "response2": 24, "response_cont": 16, "response_data": 16, "response_format": [16, 17], "response_json": [24, 69], "response_non_stream": [13, 18], "response_requir": 18, "response_sent_to_client_t": [16, 17, 24, 34], "response_specif": 18, "response_stream": [13, 18], "rest": [12, 17], "restart": [20, 24, 38, 40, 56], "restartpolici": [56, 57, 60], "restor": [11, 14], "restrict": [17, 35], "result": [3, 6, 8, 10, 13, 14, 16, 17, 20, 22, 24, 27, 28, 31, 35, 36, 37, 45, 52, 64, 66, 68, 69, 70, 71], "resume_memory_occup": 14, "resume_weights_occup": 14, "retain": [25, 32], "reth0": 56, "reth2": 56, "reth4": 56, "reth6": 56, "retoken": 35, "retract": [7, 14, 50], "retracted_req": 7, "retri": 0, "retriev": [5, 6, 12, 65, 66, 69], "return": [6, 12, 14, 16, 17, 18, 24, 33, 54, 64, 65, 71], "return_hidden_st": 33, "return_logprob": [16, 17, 33], "return_tensor": 19, "return_text_in_logprob": 33, "reus": [0, 5, 6, 11, 12, 14, 21, 37, 71], "reusabl": 6, "reuter": 22, "rev": 56, "revis": [13, 14, 16, 17, 18, 19, 24, 25], "revolut": 25, "reward": [34, 42], "reward_process": 24, "rf": [41, 43], "rich": [17, 20, 25, 54], "rid": [8, 33, 57, 60, 62, 64], "right": [17, 27, 37, 51], "rigor": 37, "risen": 22, "risk": [7, 15], "river": 17, "rl": [3, 15, 66, 68], "rl_on_policy_target": [13, 16, 17, 18, 19, 24, 25], "rlhf": 70, "rlimit_nofil": 35, "rm": [40, 41, 43, 44, 46, 70], "rmsnorm": [14, 71], "roadmap": [3, 8, 12, 20, 21, 23, 55], "roar": 44, "robin": [14, 60], "robust": [35, 65], "roce": [38, 43], "rocm": [1, 21, 43], "rocm630": 40, "role": [12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 29, 32, 33, 34, 56, 57, 60, 68], "rolebasedgroup": 60, "roll": [24, 43, 45, 56], "rollingupd": 57, "rollingupdateconfigur": 57, "rolloutstrategi": 57, "roman": 27, "rome": [15, 16, 17, 27], "rome2": 54, "room": 62, "root": [6, 16, 17, 33, 36, 38, 41, 43, 44, 45, 56, 57, 60, 62, 63, 67, 71], "rope": 50, "rotari": 68, "roughli": [22, 51], "round": [14, 18, 35, 60], "round_robin": [12, 13, 14, 16, 17, 18, 19, 24, 25], "rout": [10, 12, 35, 64, 66, 68], "router": [7, 14, 21, 36, 42, 60, 62, 64], "router_log": 12, "rst": 0, "rule": [7, 14], "run": [0, 1, 2, 3, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 42, 48, 50, 51, 54, 56, 57, 58, 60, 61, 63, 67, 68, 71], "run_batch": 54, "run_ev": 21, "run_llm": 71, "runnabl": 0, "runner": [1, 14, 24, 50], "runner_allow_runasroot": 40, "runtim": [8, 11, 12, 24, 33, 36, 37, 42, 45, 46, 48, 50, 68, 71], "runtimeendpoint": [52, 54], "runtimeerror": 36, "russia": 15, "rust": [12, 57, 64], "s3": 6, "safe": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "safetensor": [8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "sai": [25, 27, 54], "saint": [17, 24], "same": [3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 21, 24, 27, 33, 36, 37, 51, 54, 62, 64, 71], "sampl": [1, 12, 14, 20, 24, 34, 35, 41, 42, 51, 68, 71], "sampler": 68, "sampling_backend": [13, 16, 17, 18, 19, 24, 25], "sampling_default": [13, 16, 17, 18, 19, 24, 25], "sampling_param": [3, 8, 11, 13, 16, 17, 18, 25, 33, 34, 71], "sampling_se": 3, "samplingparam": 33, "san": [16, 17, 18], "sandbox": 22, "saniti": 37, "sarah": 27, "satisfi": 17, "save": [2, 7, 11, 14, 24, 31, 36, 38, 51, 68], "save_dir": 11, "save_pretrain": 11, "saver": 14, "sbatch": 58, "sbin": 44, "scalabl": [45, 68], "scalar": 70, "scale": [6, 10, 11, 14, 20, 33, 35, 41, 59, 66, 69], "scaling_governor": 44, "scarc": 8, "scatter": [14, 62], "scenario": [1, 3, 5, 6, 8, 14, 20, 21, 57, 60], "scene": [19, 68], "schedul": [5, 6, 7, 15, 25, 35, 37, 42, 45, 48, 50, 60, 62], "schedule_conserv": [13, 16, 17, 18, 19, 24, 25], "schedule_delay_milli": 50, "schedule_low_priority_values_first": [13, 16, 17, 18, 19, 24, 25], "schedule_polici": [13, 16, 17, 18, 19, 24, 25], "scheduler_output_processor_mixin": 37, "scheduler_recv_interv": [13, 16, 17, 18, 19, 24, 25], "schema": [8, 12, 14, 16, 17, 33, 54], "schema_get_current_d": [16, 17], "schema_get_current_weath": [16, 17], "scheme": [6, 11], "scienc": [25, 66], "scontrol": 58, "scope": 12, "score": [21, 24, 69, 70, 71], "scout": [18, 19, 23, 66], "scrape": 61, "scratch": 68, "screenshot": 62, "script": [9, 11, 20, 21, 22, 25, 35, 36, 37, 38, 43, 45, 46, 48, 50, 58, 64, 71], "sdk": 62, "sdpa": [1, 14], "sea": [17, 24], "seamless": [11, 64], "seamlessli": 5, "search": [6, 14, 16, 17, 20, 21, 54, 65, 66, 68, 69], "seat": 15, "seatbelt": 54, "sec": [12, 14, 56, 60], "seccomp": 43, "second": [2, 8, 10, 12, 13, 14, 15, 17, 29, 32, 34, 35, 37, 50, 61, 66], "second_answ": 54, "secret": [12, 41, 43, 44, 45], "section": [8, 10, 17, 27, 33, 44, 51, 56, 57, 60, 61, 62, 68, 71], "secur": [14, 25, 36, 43, 56], "securitycontext": [56, 57, 60], "see": [1, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 20, 25, 27, 28, 33, 34, 36, 41, 45, 48, 51, 54, 56, 61, 68, 71, 72], "seed": [3, 14, 27], "seem": [17, 18, 19, 27, 35], "seen": [17, 23, 31], "segment": [14, 62], "sein": 17, "select": [1, 6, 11, 12, 14, 15, 21, 27, 33, 35, 41, 50, 57, 60], "selector": [12, 56, 57, 60], "self": [25, 27, 28, 29, 33, 71, 72], "self_attn": 36, "semant": [65, 69], "send": [0, 7, 9, 12, 14, 16, 17, 29, 33, 35, 36, 42, 43, 51, 58, 62, 68], "send_on": 36, "sender": 62, "sens": [17, 25], "sensetim": 66, "sensit": [6, 8, 12], "sent": [17, 35, 45, 48], "sentenc": [17, 22, 24, 27, 29, 33], "seo": 54, "sep": [44, 49], "sep_styl": 49, "separ": [2, 8, 10, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 34, 36, 37, 54, 57, 62, 68], "separate_reason": [13, 27], "separate_reasoning_data": 13, "separate_reasoning_response_json": 13, "septemb": 44, "seq": [21, 24, 56], "sequenc": [6, 8, 10, 14, 15, 20, 27, 33, 36, 70], "sequenti": 57, "seri": [13, 17, 18, 20, 45, 48, 66, 70], "serial": [12, 33], "serv": [0, 6, 12, 15, 20, 21, 23, 27, 31, 36, 41, 42, 56, 58, 65, 69], "served_model_nam": [13, 16, 17, 18, 19, 24, 25], "server": [0, 5, 6, 7, 8, 9, 11, 15, 16, 17, 20, 21, 22, 25, 33, 35, 37, 38, 42, 43, 46, 49, 50, 56, 58, 61, 62, 63, 64, 67, 71], "server_arg": [8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54, 71], "server_ip": 56, "server_nam": 62, "server_process": [8, 13, 15, 16, 17, 18, 24, 27, 34, 54], "server_process_tool_choic": 18, "serverarg": [13, 16, 17, 18, 19, 24, 25], "servic": [14, 22, 27, 28, 29, 36, 41, 45, 56, 60, 61, 64], "service_nam": 12, "service_ti": [15, 18, 27, 34], "servicenow": 66, "serving_classifi": 64, "session": [12, 18, 36, 62], "set": [1, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 45, 46, 48, 49, 50, 51, 54, 56, 58, 61, 62, 63, 65, 67, 70, 71, 72], "set_default_backend": 54, "setup": [10, 14, 27, 36, 41, 42, 56, 69], "setup_rocm": 43, "setuptool": [45, 48], "sever": [6, 11, 17, 24, 25, 33, 36, 71], "sgl": [5, 11, 13, 14, 16, 17, 18, 19, 21, 22, 24, 25, 29, 32, 33, 38, 39, 40, 41, 43, 44, 45, 47, 48, 52, 54, 55, 57, 58, 60, 62, 64, 66, 68, 71], "sgl_": 50, "sgl_cach": 57, "sgl_cache1": 57, "sgl_cache4": 60, "sgl_chunked_prefix_cache_threshold": [50, 57], "sgl_dg_use_nvrtc": 50, "sgl_disable_tp_memory_inbalance_check": 50, "sgl_enable_jit_deepgemm": 60, "sgl_in_deepgemm_precompile_stag": 50, "sgl_is_first_rank_on_nod": 50, "sgl_router_active_work": 12, "sgl_router_cache_hits_tot": 12, "sgl_router_generate_duration_second": 12, "sgl_router_processed_requests_tot": 12, "sgl_router_requests_tot": 12, "sgl_router_running_request": 12, "sgl_use_deepgemm_bmm": 50, "sglang": [1, 4, 6, 7, 8, 9, 10, 11, 14, 15, 19, 22, 25, 27, 28, 29, 33, 34, 35, 39, 40, 45, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "sglang_": 50, "sglang_allow_overwrite_longer_context_len": 50, "sglang_block_nonzero_rank_children": 50, "sglang_ci_small_kv_s": 50, "sglang_clip_max_new_tokens_estim": 50, "sglang_cpu_omp_threads_bind": 45, "sglang_cutedsl_moe_nvfp4_dispatch": 50, "sglang_cutlass_mo": 50, "sglang_debug_memory_pool": 50, "sglang_deepep_bf16_dispatch": 50, "sglang_deepep_num_max_dispatch_tokens_per_rank": 44, "sglang_detokenizer_max_st": 50, "sglang_dev": 38, "sglang_dg_cache_dir": 50, "sglang_disable_consecutive_prefill_overlap": 50, "sglang_disable_fa4_warmup": 50, "sglang_disable_outlines_disk_cach": 50, "sglang_disable_request_log": 50, "sglang_disaggregation_bootstrap_timeout": [10, 60], "sglang_disaggregation_heartbeat_interv": 10, "sglang_disaggregation_heartbeat_max_failur": 10, "sglang_disaggregation_queue_s": 10, "sglang_disaggregation_thread_pool_s": 10, "sglang_disaggregation_waiting_timeout": [10, 60], "sglang_enable_flashinfer_fp8_gemm": 50, "sglang_enable_jit_deepgemm": [20, 50, 57], "sglang_enable_torch_compil": 50, "sglang_enable_torch_inference_mod": 50, "sglang_eplb_heatmap_collection_interv": 50, "sglang_flashinfer_fp4_gemm_backend": 50, "sglang_force_fp8_marlin": 50, "sglang_forward_unknown_tool": 50, "sglang_fused_mla_enable_rope_fus": 50, "sglang_hack_deepep_new_mod": 57, "sglang_hack_deepep_num_sm": 57, "sglang_health_check_timeout": 50, "sglang_host_ip": 50, "sglang_imag": 43, "sglang_int4_weight": 50, "sglang_is_flashinfer_avail": 50, "sglang_is_in_ci": [40, 50], "sglang_is_in_ci_amd": 50, "sglang_jit_deepgemm_compile_work": 50, "sglang_jit_deepgemm_precompil": 50, "sglang_logging_config_path": 50, "sglang_moe_pad": 50, "sglang_mooncake_custom_mem_pool": 10, "sglang_mooncake_trans_thread": 57, "sglang_npu": 44, "sglang_npu_use_mlapo": 44, "sglang_one_visible_device_per_process": 50, "sglang_otlp_exporter_max_export_batch_s": [50, 62], "sglang_otlp_exporter_schedule_delay_milli": [50, 62], "sglang_port": 50, "sglang_pp_layer_partit": 50, "sglang_profile_record_shap": 50, "sglang_profile_with_stack": [36, 50], "sglang_random": 35, "sglang_record_step_tim": 50, "sglang_request_dump": 9, "sglang_rout": [10, 12, 14, 21, 36, 57, 60, 62], "sglang_server_host": 61, "sglang_set_cpu_affin": [50, 57, 60], "sglang_skip_p2p_check": 50, "sglang_skip_sgl_kernel_version_check": 60, "sglang_storag": [13, 14, 16, 17, 18, 19, 24, 25], "sglang_support_cutlass_block_fp8": 50, "sglang_test_request_time_stat": 50, "sglang_test_retract": 50, "sglang_test_retract_no_prefill_b": 50, "sglang_tool_strict_level": 50, "sglang_torch_profiler_dir": [35, 36, 50], "sglang_use_ait": 50, "sglang_use_cpu_engin": 45, "sglang_use_cuda_ipc_transport": 32, "sglang_use_modelscop": [35, 50, 67], "sglang_vlm_cache_size_mb": 32, "sglang_wait_weights_ready_timeout": 50, "sglang_zhync": 38, "sglangtracepropagatecontext": 62, "sglangtracereqcontext": 62, "sglangtracethreadcontext": 62, "sglroutertestatp_high": 12, "sgmv": 8, "sh": [0, 39, 43, 46, 60], "shakhizat": 46, "shape": [8, 11, 19, 25, 33, 36, 50], "shard": [8, 10, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "sharded_st": 14, "share": [1, 5, 6, 7, 8, 10, 12, 14, 16, 17, 22, 32, 35, 37, 40, 55, 56, 57, 62], "sharegpt": [35, 36], "sharpli": 22, "she": 27, "shell": [28, 29, 34, 36, 38], "ship": [12, 63], "shirt": 54, "shm": [14, 38, 40, 41, 43, 44, 45, 56, 57, 60], "short": [14, 21, 22, 25, 27, 33, 35, 71], "shorter": 52, "shortest": 12, "shortest_queu": 14, "shorthand": 14, "shot": [18, 21, 37, 38], "should": [3, 6, 7, 8, 14, 15, 17, 18, 20, 21, 22, 25, 27, 36, 38, 45, 49, 56, 57, 61, 62, 71], "show": [2, 3, 8, 14, 17, 18, 19, 21, 22, 27, 29, 43, 44, 54, 56, 58, 68], "show_time_cost": [13, 16, 17, 18, 19, 24, 25], "showcas": 58, "shown": [8, 18, 19, 36, 43], "shutdown": [13, 16, 17, 18, 25, 71], "side": [8, 14, 36, 37, 64, 68], "sig": [56, 57, 60], "sigmoid": 24, "signal": 22, "signatur": 71, "signific": [2, 10, 17, 20, 25, 37, 51, 66], "significantli": [2, 6, 21, 32, 54], "silent": 15, "siluandmul": 71, "similar": [1, 17, 24, 27, 33, 71], "similarli": [6, 45, 51, 66, 71], "simpl": [6, 7, 11, 17, 21, 25, 45, 54, 56, 71], "simpler": 36, "simpli": [11, 16, 24, 52, 65, 69], "simplifi": [20, 36], "simultan": 10, "sinc": [6, 8, 17, 18, 22, 23, 25, 31, 37], "singl": [3, 6, 12, 14, 17, 18, 20, 21, 27, 33, 36, 37, 41, 42, 43, 58, 71], "singleprocess": 15, "situat": 25, "size": [1, 2, 3, 5, 6, 8, 10, 11, 12, 14, 19, 20, 21, 24, 31, 32, 35, 36, 38, 40, 41, 43, 44, 45, 46, 48, 50, 51, 56, 57, 58, 60, 65, 66, 69, 70], "sk": [22, 35, 40], "skew": 33, "skip": [0, 11, 14, 24, 35, 36, 38, 43, 50, 63], "skip_server_warmup": [13, 16, 17, 18, 19, 24, 25], "skip_special_token": [13, 18, 24, 33], "skip_tokenizer_init": [13, 16, 17, 18, 19, 24, 25], "sky": 41, "skyserv": 41, "skywork": [24, 42, 70], "slack": [5, 37, 55], "sleep": [2, 14, 40, 58], "sleep_on_idl": [13, 16, 17, 18, 19, 24, 25], "slice_span": 62, "slide": [1, 20, 55], "slight": 51, "slightli": [27, 51], "slo": 6, "slot": 8, "slow": [7, 14, 51, 63], "slowdown": 35, "slower": 6, "slowli": 7, "slurm_log": 58, "slurm_nodeid": 58, "slurm_nodelist": 58, "slurm_procid": 58, "slytherin": 54, "sm": [14, 56], "sm10": 14, "sm100": 21, "sm75": 41, "sm90": [14, 21], "sm_group_num": [13, 16, 17, 18, 19, 24, 25], "small": [0, 6, 7, 14, 15, 20, 21, 36, 37, 50, 51, 66, 68], "small3": 66, "smaller": [6, 7, 8, 14, 24, 37, 51, 70], "smallest": 33, "smollm": 66, "smooth": [27, 28, 29, 37], "smoother": 14, "smoothli": 36, "snapshot": [12, 24, 32, 71], "snapshot_download": 71, "snc": 45, "snippet": [18, 22, 36, 37], "so": [0, 1, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 33, 34, 36, 45, 54, 71], "societi": [25, 27], "socket": [2, 45, 56], "soft": 35, "softshel": 54, "softwar": 25, "solar": 66, "solut": [6, 13, 14, 25, 41], "solv": [13, 25, 44, 54], "some": [0, 1, 7, 11, 15, 17, 18, 20, 21, 25, 27, 35, 36, 37, 38, 40, 45, 56, 57, 61, 62, 65, 66, 69, 70, 71], "someon": [17, 25], "someth": [15, 17], "sometim": [9, 15, 17, 24, 51, 56, 69], "soon": [11, 72], "sophist": 25, "sort": 33, "sota": 66, "sound": 15, "sourc": [3, 10, 15, 16, 17, 22, 23, 33, 36, 42, 58, 61, 66, 68, 71], "south": 34, "space": [6, 27, 31, 33, 35, 65, 67], "spaces_between_special_token": 33, "spain": [27, 54], "span": [6, 36, 62, 66], "spark": [41, 42], "spars": [14, 21, 66], "sparseautomodelforcausallm": 11, "speak": 51, "spec": [1, 15, 56, 57, 60, 64], "speci": [24, 69], "special": [13, 17, 18, 25, 33, 64, 66, 68, 70], "specif": [1, 5, 6, 11, 14, 17, 20, 27, 33, 36, 37, 41, 48, 66, 68], "specifi": [1, 3, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 32, 33, 34, 36, 40, 43, 45, 49, 52, 54, 61, 62, 65], "specific_funct": 18, "specul": [20, 21, 35, 42], "speculative_accept_threshold_acc": [13, 16, 17, 18, 19, 24, 25], "speculative_accept_threshold_singl": [13, 16, 17, 18, 19, 24, 25], "speculative_algorithm": [13, 16, 17, 18, 19, 24, 25], "speculative_attention_mod": [13, 16, 17, 18, 19, 24, 25], "speculative_draft_load_format": [13, 16, 17, 18, 19, 24, 25], "speculative_draft_model_path": [13, 15, 16, 17, 18, 19, 24, 25], "speculative_draft_model_revis": [13, 16, 17, 18, 19, 24, 25], "speculative_eagle_topk": [13, 15, 16, 17, 18, 19, 24, 25], "speculative_moe_runner_backend": [13, 15, 16, 17, 18, 19, 24, 25], "speculative_ngram_branch_length": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_capac": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_match_typ": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_max_bfs_breadth": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_max_match_window_s": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_min_bfs_breadth": [13, 16, 17, 18, 19, 24, 25], "speculative_ngram_min_match_window_s": [13, 16, 17, 18, 19, 24, 25], "speculative_num_draft_token": [13, 15, 16, 17, 18, 19, 24, 25], "speculative_num_step": [13, 15, 16, 17, 18, 19, 24, 25], "speculative_token_map": [13, 16, 17, 18, 19, 24, 25], "speech": 66, "speed": [6, 14, 15, 20, 21, 35, 51, 56], "speedup": [20, 21], "spell": [15, 27], "split": [1, 3, 6, 11, 12, 14, 17, 35, 37], "split_kv": 1, "sql": [8, 27], "sqrt": 71, "squar": [17, 71], "src": [12, 38, 60, 64], "srt": [1, 2, 9, 11, 12, 13, 19, 20, 24, 33, 44, 54, 57, 64, 66, 68, 71, 72], "srt_npu": 44, "srun": 58, "sse": [12, 17, 22], "ssh": 38, "ssm": [14, 31], "st": [17, 41], "stabil": [20, 21], "stabilityai": 66, "stabl": [3, 27, 38, 43], "stablelm": 66, "stack": [12, 15, 36, 50, 60, 61, 68], "stag": 54, "stage": [10, 12, 14], "stai": [0, 12, 48, 50, 54], "stand": [7, 14, 17, 19, 29], "standalon": [14, 15], "standard": [1, 3, 6, 13, 21, 27, 56, 64, 71], "stanlei": 22, "starcod": 66, "starcoder2": 66, "start": [0, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 22, 24, 27, 33, 34, 36, 37, 43, 45, 46, 48, 54, 56, 61, 62, 67, 71], "start_expert_distribution_record": 24, "start_profil": 35, "start_step": 36, "start_tag": [16, 17], "startswith": [33, 34], "startup": [8, 12, 14, 15, 21, 24, 38, 43, 56, 57, 60], "startuppolici": 57, "starvat": 8, "stat": [12, 14, 24], "state": [6, 7, 8, 12, 14, 15, 16, 17, 18, 20, 25, 27, 33, 34, 37, 50, 54, 56, 66], "state_cloud": 44, "statefulset": 41, "statement": [25, 71], "static": [5, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 32, 36, 44, 45, 46, 51, 56, 57, 60], "static_config": 61, "statist": [11, 12, 35, 50], "statu": [12, 16, 17, 24, 38, 41, 54, 56, 61, 64], "status_cod": 8, "std": 35, "stdio": 12, "steadi": 7, "step": [0, 6, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 25, 31, 36, 37, 38, 45, 50, 56, 63, 71], "step3": [14, 18], "stephen": 17, "stick": 17, "still": [7, 8, 10, 14, 17, 18, 20, 21, 22, 24, 27, 44, 57, 62], "stochast": 3, "stock": 22, "stop": [6, 7, 14, 15, 16, 17, 24, 27, 29, 33, 34, 36, 54, 61], "stop_after_first": 16, "stop_expert_distribution_record": 24, "stop_profil": 35, "stop_regex": 33, "stop_str": 49, "stop_token_id": 33, "storag": [14, 25], "store": [5, 6, 12, 14, 36, 62], "stori": 27, "str": [8, 12, 14, 16, 17, 18, 33, 71], "straightforward": [7, 15, 17, 25], "strap": 54, "strasbourg": 15, "strategi": [6, 7, 8, 10, 14], "strawberri": 27, "stream": [12, 14, 16, 17, 20, 27, 71], "stream_and_merg": 25, "stream_interv": [13, 16, 17, 18, 19, 24, 25], "stream_output": [13, 16, 17, 18, 19, 24, 25], "stream_reason": 13, "streamabl": 12, "streamlin": [11, 65], "street": [19, 29, 54], "streetlight": 19, "strength": 54, "stress": 54, "strict": [35, 50], "strictli": [8, 17], "stride": 15, "string": [3, 6, 7, 8, 14, 16, 17, 18, 20, 24, 27, 33, 64], "strip": [33, 34], "strive": 25, "strong": [6, 22, 25, 32, 52, 54, 66], "strongest": 6, "strongli": [27, 43], "structal": 33, "structur": [6, 12, 18, 25, 42, 50, 54, 62, 68], "structural_tag": [16, 17, 33], "stuck": 56, "student": [17, 54], "studio": 38, "style": [14, 15, 35, 54, 72], "styliz": 29, "sub": [20, 24, 45], "subclass": 13, "subdirectori": 0, "subdomainpolici": 57, "submit": [7, 35, 37, 58], "subprocess": [14, 28, 29, 34], "subsequ": 6, "subset": 52, "substanti": [6, 10], "succe": 57, "succeed": 24, "success": [8, 12, 24, 38, 43], "successfulli": [6, 8, 44, 56, 61], "successor": 66, "successthreshold": 60, "succinctli": 25, "sudo": [43, 44, 46], "suffici": [6, 7, 68], "sugar": 54, "suggest": [5, 7, 11, 16, 32, 46, 54], "suitabl": [6, 14, 69], "sum": [13, 22], "summar": [54, 66, 68], "summari": [35, 54], "sunni": 27, "super": [66, 71], "supercharg": 43, "superior": [27, 66], "supervisor": 25, "suppli": [12, 14, 20, 52], "support": [2, 6, 7, 8, 9, 10, 11, 12, 15, 16, 20, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 36, 37, 41, 44, 46, 47, 48, 50, 52, 54, 56], "suppos": 17, "sure": [0, 13, 15, 17, 18, 27, 34, 36, 37, 44, 54, 56, 71], "surg": 22, "surpass": 66, "surprisingli": 66, "survei": 25, "surveyor": 25, "suv": 54, "svc": [57, 60], "svnl": 54, "swa": 14, "swa_full_tokens_ratio": [13, 16, 17, 18, 19, 24, 25], "swa_siz": 14, "swappi": 44, "sweatshirt": 19, "switch": [5, 14, 35, 41, 56, 72], "sy": [43, 44, 60], "symbol": [15, 17], "symm": 14, "symmetr": 14, "sync": 38, "synchron": [5, 20, 37], "synonym": 12, "syntact": 14, "syntax": [8, 17, 27], "synthet": 35, "sys_ptrac": 43, "sysctl": 44, "system": [2, 4, 5, 8, 10, 11, 14, 16, 17, 18, 19, 22, 25, 27, 33, 35, 45, 49, 50, 54, 56, 57, 60, 61, 66, 69, 71], "system_fingerprint": [15, 18, 27, 34], "systemcut": 16, "systemprompt": 5, "t": [14, 15, 17, 18, 19, 22, 23, 27, 33, 36, 37, 38, 43, 44, 45, 54, 56, 68, 71], "t4": 41, "t_": 15, "t_2": 15, "tabl": [1, 3, 14, 45, 48, 66, 68, 71], "tag": [13, 14, 18, 33, 37, 50], "tailor": [10, 32], "taint": [57, 60], "take": [0, 7, 10, 11, 14, 15, 20, 24, 27, 36, 38, 43, 56, 67, 71], "tall": 25, "tar": 38, "target": [1, 8, 11, 14, 15, 22, 35, 36, 61], "targetport": [56, 57, 60], "task": [2, 23, 25, 27, 29, 37, 58, 64, 65, 66, 68, 69, 70], "taxi": [19, 29, 54], "tbb": 45, "tbo": 14, "tbo_token_distribution_threshold": [13, 16, 17, 18, 19, 24, 25], "tcp": [10, 12, 44, 56, 57, 60], "tcpsocket": [56, 57], "teacher": 54, "team": [11, 20, 25, 38], "tech": [21, 25], "technic": [8, 16], "techniqu": [6, 8, 11, 14, 65], "technologi": [25, 56], "tee": [36, 44], "tele": 66, "teleai": 66, "tell": [3, 22, 25, 27, 36, 61], "temp": 3, "temper": 17, "temperatur": [8, 11, 13, 14, 15, 16, 17, 18, 20, 24, 25, 27, 29, 33, 34, 35, 54, 71], "templ": 27, "templat": [12, 13, 14, 20, 23, 24, 27, 33, 35, 42, 57, 60, 65, 68, 69, 71], "tempor": 68, "temporari": 10, "temporarili": 12, "tenant": 12, "tend": 56, "tensor": [6, 7, 8, 32, 36, 37, 42, 45, 50, 56, 57, 60, 68, 70, 71], "tensorrt": 35, "term": [6, 14, 17], "termin": [2, 5, 6, 8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 32, 34, 36, 38, 41, 43, 45, 48, 54], "terminate_process": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "terminu": 21, "territori": 15, "tesla": 25, "test": [1, 2, 3, 8, 13, 15, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 32, 33, 34, 36, 40, 45, 46, 54, 56, 58, 68], "test_classify_api": 64, "test_determinist": 3, "test_eagle_infer_a": 37, "test_eagle_infer_b": 37, "test_eval_accuracy_larg": 37, "test_generation_model": 71, "test_gpt_oss_1gpu": 37, "test_oth": 71, "test_util": 19, "test_vision_openai_server_": 71, "test_vision_openai_server_a": 71, "test_vision_openai_server_b": 71, "testgenerationmodel": 71, "text": [3, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 27, 28, 29, 32, 33, 34, 35, 64, 65, 66, 68, 71], "text_complet": 27, "text_embed": 28, "text_input": 65, "text_it": 54, "text_qa": 54, "textual": 71, "th": 14, "than": [7, 8, 10, 11, 14, 15, 24, 33, 37, 41, 45, 54, 67, 71], "thank": [15, 37, 46, 56, 58], "theater": 25, "thei": [0, 8, 10, 15, 17, 25, 29, 33, 45, 50, 56, 61, 66, 68, 69, 70, 71], "theloirev": 17, "them": [1, 9, 11, 17, 20, 22, 24, 25, 35, 37, 38, 43, 50, 51, 57, 61, 62, 68, 71], "therebi": 6, "therefor": [6, 7, 8, 13, 24, 27], "thi": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 46, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72], "thing": [7, 25, 71, 72], "think": [3, 13, 14, 15, 17, 18, 21, 31, 57, 60, 68], "think_end_token": 17, "thinking_budget": 20, "third": [17, 22, 27], "thoroughli": 71, "those": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "thought": 17, "thousand": 6, "thread": [8, 10, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54, 62], "thread_finish_flag": 62, "thread_label": 62, "thread_span": 62, "three": [1, 3, 5, 6, 15, 16, 27, 34, 54], "threshold": [6, 9, 12, 14, 21, 50], "threshold_acc": 14, "through": [6, 8, 12, 18, 20, 21, 27, 35, 36, 37, 43, 44, 55, 68], "throughout": 25, "throughput": [8, 12, 13, 14, 15, 16, 17, 18, 21, 24, 27, 28, 29, 32, 34, 35, 37, 42, 51, 54, 61, 66, 69, 71], "thu": [25, 27, 38, 71, 72], "thudm": 66, "thumb": 7, "thunlp": 15, "tiananmen": 17, "tibetan": 17, "tier": [5, 6, 12], "tiktoken": 27, "til": 44, "tile": 14, "tilelang": [14, 21], "time": [0, 1, 2, 6, 7, 8, 10, 11, 14, 15, 16, 17, 20, 24, 25, 27, 28, 32, 33, 35, 36, 37, 38, 45, 50, 51, 56, 58, 61, 71], "time_per_output_token_second": 61, "time_per_output_token_seconds_bucket": 61, "time_per_output_token_seconds_count": 61, "time_per_output_token_seconds_sum": 61, "time_to_first_token_second": 61, "time_to_first_token_seconds_bucket": 61, "time_to_first_token_seconds_count": 61, "time_to_first_token_seconds_sum": 61, "timelin": 36, "timeout": [5, 6, 10, 12, 14, 20, 23, 32, 50, 60], "timeoutsecond": 60, "timestamp": [17, 35, 64], "timestep": 15, "timezon": [16, 17], "tinyllama": 11, "tip": [0, 51, 54], "tip_suggest": 54, "titl": [25, 71], "tl": 15, "tmp": [9, 14, 36, 40, 50, 62], "tmp_autoround": 11, "tn": 12, "to_str": [20, 33], "toast": 15, "todai": [18, 20, 27], "todo": 44, "togeth": [6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54, 68], "tok": 35, "token": [1, 6, 10, 11, 12, 13, 16, 17, 18, 23, 28, 31, 33, 41, 43, 45, 49, 50, 56, 57, 60, 61, 62, 64, 66, 68, 71], "token_capac": 24, "token_id": [24, 27, 33], "token_ids_logprob": 33, "token_length_norm": 52, "token_usag": 61, "tokenization_result": 24, "tokenize_payload": 24, "tokenize_respons": 24, "tokenize_url": 24, "tokenizer_free_server_process": 24, "tokenizer_manag": 18, "tokenizer_metrics_allowed_custom_label": [13, 16, 17, 18, 19, 24, 25], "tokenizer_metrics_custom_labels_head": [13, 16, 17, 18, 19, 24, 25], "tokenizer_mod": [13, 16, 17, 18, 19, 24, 25], "tokenizer_path": [13, 16, 17, 18, 19, 24, 25], "tokenizer_worker_num": [13, 16, 17, 18, 19, 24, 25], "tokenizers_parallel": [16, 17, 28], "tokyo": [8, 15, 18, 27, 54], "tokyo3": 54, "toler": [10, 57, 60], "tolist": 19, "toml": [37, 39, 43, 45, 48], "tone": 17, "too": [7, 8, 17, 20, 35, 37], "tool": [14, 16, 17, 20, 21, 36, 42, 54, 62, 66, 68], "tool_cal": [15, 18, 20, 27, 29, 34, 57, 60], "tool_call_id": 18, "tool_call_pars": [13, 16, 17, 18, 19, 24, 25], "tool_chat_template_deepseekv3": [18, 20], "tool_chat_template_deepseekv31": 18, "tool_chat_template_llama4_python": 18, "tool_choic": 18, "tool_dict": 18, "tool_get_current_d": [16, 17], "tool_get_current_weath": [16, 17], "tool_nam": 18, "tool_serv": [13, 16, 17, 18, 19, 24, 25], "tool_to_cal": 18, "tool_us": 54, "toolcallitem": 18, "toolkit": 46, "tools_tag_list": 18, "top": [6, 15, 18, 19, 25, 33, 66], "top_k": [24, 33, 71], "top_logprobs_num": 33, "top_p": [11, 13, 14, 16, 17, 18, 24, 25, 27, 33, 35], "topk": [1, 14, 15, 20, 21, 23, 31], "topo": 60, "topologi": [12, 60], "torch": [1, 7, 10, 14, 20, 24, 28, 36, 44, 45, 48, 50, 56, 71, 72], "torch_compile_caching_tutori": 63, "torch_compile_max_b": [13, 16, 17, 18, 19, 24, 25], "torch_dtyp": [11, 19], "torch_log": 15, "torch_n": [1, 14, 24, 65, 69], "torch_npu": 44, "torchao": [11, 14, 48], "torchao_config": [13, 16, 17, 18, 19, 24, 25], "torchaudio": 48, "torchinductor_cache_dir": [14, 63], "torchinductor_root": 14, "torchrun": 2, "torchvis": [44, 45, 48], "torchvision_vers": 44, "toront": 24, "total": [6, 7, 10, 12, 14, 17, 21, 25, 27, 35, 36, 45, 64, 66], "total_input_token": 35, "total_kv_token": 21, "total_output_token": 35, "total_q_token": 21, "total_retract": [16, 17, 24, 34], "total_token": [15, 18, 20, 27, 28, 29, 34, 57, 60, 64], "toulous": 25, "tourism": 17, "tourist": [18, 25], "toward": [22, 33, 68, 70], "towel": 19, "tower": [15, 17, 24, 25], "tp": [1, 5, 6, 10, 12, 14, 18, 20, 21, 22, 23, 27, 31, 32, 36, 38, 43, 44, 45, 48, 56, 57, 58, 60, 70], "tp0": 56, "tp1": 56, "tp16": 58, "tp2": 56, "tp3": 56, "tp4": 56, "tp5": 56, "tp6": [45, 56], "tp7": 56, "tp8": 20, "tp_rank": 62, "tp_size": [6, 8, 13, 16, 17, 18, 19, 21, 24, 25, 58], "tpot": 35, "tpu": [41, 42], "tqdm": 35, "tr": 36, "trace": [9, 12, 14, 15, 35, 42, 50, 56], "trace_context": 62, "trace_get_proc_propagate_context": 62, "trace_get_remote_propagate_context": 62, "trace_req_finish": 62, "trace_req_start": 62, "trace_set_proc_propagate_context": 62, "trace_set_remote_propagate_context": 62, "trace_set_thread_info": 62, "trace_slice_end": 62, "trace_slice_start": 62, "tracing_compos": 62, "track": [6, 12, 21, 23, 24, 36, 62, 64], "trade": [22, 31, 65], "tradit": 5, "tradition": 10, "traffic": [12, 61], "trail": 17, "train": [3, 11, 15, 18, 21, 24, 25, 36, 54, 65, 66, 68], "trajectori": 22, "tran": 54, "transfer": [2, 5, 8, 10, 14, 38, 44, 62], "transferengin": 6, "transform": [11, 13, 14, 16, 17, 18, 19, 22, 24, 25, 28, 35, 42, 49, 66, 71], "transformersmodel": 72, "transit": [27, 28, 29], "transpar": 25, "transport": [12, 32], "travel": [18, 27], "travers": 6, "treat": [24, 50], "tree": [12, 14, 15, 24], "trend": [25, 71], "triag": 37, "trial": 3, "trigger": [6, 14, 16, 17, 24, 36, 45], "triggered_tag": 16, "trillion": 66, "trim": [18, 33], "triniti": 17, "triomph": 17, "trip": 18, "triton": [1, 3, 8, 14, 20, 24, 41, 45, 48, 50, 65, 69], "triton_3_4_0": 24, "triton_attention_num_kv_split": [13, 16, 17, 18, 19, 24, 25], "triton_attention_reduce_in_fp32": [13, 16, 17, 18, 19, 24, 25], "triton_attention_split_tile_s": [13, 16, 17, 18, 19, 24, 25], "triton_attn": 14, "triton_backend": 1, "triton_kernel": 14, "triton_mm_10": 15, "triton_mm_102": 15, "triton_mm_103": 15, "triton_mm_106": 15, "triton_mm_107": 15, "triton_mm_11": 15, "triton_mm_111": 15, "triton_mm_113": 15, "triton_mm_114": 15, "triton_mm_115": 15, "triton_mm_116": 15, "triton_mm_119": 15, "triton_mm_12": 15, "triton_mm_120": 15, "triton_mm_123": 15, "triton_mm_124": 15, "triton_mm_128": 15, "triton_mm_130": 15, "triton_mm_133": 15, "triton_mm_136": 15, "triton_mm_137": 15, "triton_mm_139": 15, "triton_mm_14": 15, "triton_mm_140": 15, "triton_mm_141": 15, "triton_mm_143": 15, "triton_mm_145": 15, "triton_mm_147": 15, "triton_mm_148": 15, "triton_mm_149": 15, "triton_mm_150": 15, "triton_mm_153": 15, "triton_mm_154": 15, "triton_mm_157": 15, "triton_mm_158": 15, "triton_mm_162": 15, "triton_mm_164": 15, "triton_mm_167": 15, "triton_mm_17": 15, "triton_mm_170": 15, "triton_mm_171": 15, "triton_mm_172": 15, "triton_mm_174": 15, "triton_mm_175": 15, "triton_mm_176": 15, "triton_mm_179": 15, "triton_mm_18": 15, "triton_mm_20": 15, "triton_mm_22": 15, "triton_mm_23": 15, "triton_mm_26": 15, "triton_mm_27": 15, "triton_mm_30": 15, "triton_mm_31": 15, "triton_mm_36": 15, "triton_mm_37": 15, "triton_mm_4": 15, "triton_mm_45": 15, "triton_mm_46": 15, "triton_mm_47": 15, "triton_mm_48": 15, "triton_mm_49": 15, "triton_mm_50": 15, "triton_mm_54": 15, "triton_mm_55": 15, "triton_mm_56": 15, "triton_mm_58": 15, "triton_mm_60": 15, "triton_mm_61": 15, "triton_mm_64": 15, "triton_mm_65": 15, "triton_mm_68": 15, "triton_mm_69": 15, "triton_mm_7": 15, "triton_mm_74": 15, "triton_mm_75": 15, "triton_mm_8": 15, "triton_mm_83": 15, "triton_mm_84": 15, "triton_mm_85": 15, "triton_mm_87": 15, "triton_mm_88": 15, "triton_mm_89": 15, "triton_mm_92": 15, "triton_mm_93": 15, "triton_mm_94": 15, "triton_mm_96": 15, "triton_mm_97": 15, "triton_mm_98": 15, "triton_mm_99": 15, "trivial": [13, 14, 16, 17, 18, 19, 24, 25], "troubleshoot": [42, 56], "trt": [21, 35], "trtllm": [1, 14, 20], "trtllm_mha": [1, 14], "trtllm_mla": [1, 14, 20], "true": [1, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 40, 44, 50, 54, 56, 57, 60, 61, 62, 65, 67, 71, 72], "truncat": [14, 15, 36, 65], "trunk": 19, "truss": 35, "trust": [1, 10, 14, 15, 20, 21, 23, 32, 38, 43, 44, 45, 48, 56, 57, 60, 65, 68, 69, 70], "trust_remote_cod": [11, 13, 16, 17, 18, 19, 24, 25, 72], "try": [6, 11, 14, 17, 20, 24, 37, 41, 44, 51, 56], "tse": 14, "ttft": [10, 35, 71], "tune": [6, 8, 14, 15, 18, 21, 32, 42, 43, 48, 57, 63, 66, 70], "tuned_8sm": 57, "tunnel": 38, "turbo": 27, "turn": [5, 12, 20], "tutori": [16, 27, 28, 29, 63], "twice": [6, 51], "twine": 39, "twitter": 55, "two": [1, 2, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 29, 33, 38, 41, 49, 50, 51, 54, 56, 57, 58, 62, 71, 72], "txt": 0, "type": [3, 12, 16, 17, 18, 20, 22, 24, 27, 28, 29, 32, 33, 34, 35, 36, 38, 57, 60, 61, 64, 68, 71], "typic": [7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 24, 27, 28, 29, 34, 35, 37, 41, 44, 54, 56], "typo": 17, "u": [18, 22, 25, 44, 52, 57, 71], "ubiquit": 54, "ubuntu": [36, 56], "ubuntu1804": 36, "ubuntu22": 40, "ucx": 10, "ud": 2, "ui": [36, 61, 62], "ultra": [6, 66], "unabl": 71, "uncach": 3, "unchang": 33, "unconditional_likelihood_norm": 52, "unconfin": 43, "under": [0, 6, 8, 14, 18, 20, 21, 36, 37, 48, 51, 61, 66, 71], "understand": [0, 6, 17, 24, 25, 27, 37, 62, 66, 68], "unexpect": 8, "unicamer": 17, "unifi": [8, 12, 20, 27], "uniform": [12, 14], "unintend": 33, "union": [8, 14, 33], "uniqu": [3, 64], "unit": [8, 16, 17, 18, 25, 27, 34, 54], "unittest": [37, 71], "univers": 17, "unix": [2, 64], "unknown": 50, "unless": [12, 35], "unlik": 15, "unload": 8, "unload_lora_adapt": 8, "unlock": 12, "unnecessari": 25, "unpin": 8, "unpredict": 25, "unrel": 6, "unrestrict": 33, "unset": 14, "unspecifi": [1, 14, 35], "unsur": [66, 68], "until": [7, 8, 20, 33, 36, 58], "unus": 60, "unusu": [19, 29], "up": [6, 7, 10, 12, 14, 17, 20, 22, 23, 24, 25, 29, 36, 37, 41, 43, 44, 45, 46, 48, 56, 61, 62, 66], "up_proj": [8, 14], "upcom": [21, 22], "updat": [2, 5, 8, 11, 12, 14, 17, 18, 25, 36, 40, 50, 51, 55, 61, 71], "update_weight": 24, "update_weights_from_disk": 24, "upgrad": [21, 40, 41, 43, 44, 45, 48], "upload_pypi": 39, "upon": [6, 8, 17, 24, 27, 28, 61, 62], "upper": [6, 24], "upsid": 22, "upstag": 66, "upstream": [1, 12], "upward": 22, "urban": [17, 19, 29, 54], "urgent": 37, "url": [8, 9, 12, 14, 15, 22, 24, 29, 32, 33, 34, 35, 36, 44, 45, 48, 61, 62, 65, 68, 69], "us": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 31, 32, 33, 35, 37, 40, 42, 49, 52, 54, 56, 57, 58, 61, 62, 63, 65, 66, 68, 70, 71, 72], "us_president_exampl": 52, "usabl": [11, 46, 66], "usag": [12, 14, 15, 18, 24, 28, 29, 33, 34, 46, 51, 52, 56, 57, 60], "use_fast": 19, "use_fast_accum": 15, "use_mla_backend": 24, "user": [3, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 27, 29, 32, 33, 34, 36, 45, 49, 52, 54, 57, 60, 64, 65, 68], "usernam": 61, "userwarn": 15, "usr": [15, 41, 44], "usual": [27, 41, 45, 61], "utf": [33, 34], "util": [6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 33, 34, 43, 45, 54, 56, 65], "uv": [10, 22], "uvicorn": [24, 56], "v": [3, 11, 24, 38, 40, 41, 43, 44, 45, 48, 64, 67, 68, 71], "v0": [18, 23, 24, 40, 41, 43, 44, 56, 66, 70], "v01": 66, "v1": [8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 27, 28, 29, 32, 33, 34, 35, 56, 57, 60, 62, 64, 65, 66, 68, 69], "v1_5": 66, "v1alpha1": 60, "v2": [14, 24, 35, 66, 69], "v3": [1, 10, 11, 13, 14, 18, 30, 38, 60, 66, 68], "v32": 60, "v7": 44, "v_proj": [8, 14], "valid": [0, 2, 3, 11, 14, 16, 17, 18, 33, 36, 43, 50, 65], "valu": [5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 23, 27, 32, 33, 36, 37, 45, 50, 51, 56, 57, 60], "valuabl": 71, "value1": [14, 18], "value2": [14, 18], "value_st": 72, "valueerror": 24, "valuefrom": [57, 60], "var": [44, 60], "vari": [3, 17, 35], "variabl": [5, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 28, 29, 34, 35, 36, 40, 41, 42, 45, 54, 56, 61, 62, 67, 71], "varianc": 37, "variant": [13, 36, 66, 68, 70], "varieti": [1, 27, 54], "variou": [1, 6, 10, 11, 24, 27, 29, 50], "varlen": 21, "vast": 66, "ve": [17, 56], "vector": [15, 20, 37, 65], "veget": 54, "vehicl": [19, 25], "vendor": 12, "verbos": [9, 14], "veri": [7, 29, 32, 33, 37, 51, 71], "verif": [1, 15], "verifi": [1, 2, 3, 8, 14, 17, 35, 43, 45, 46, 48, 61, 64], "versail": 17, "versatil": [27, 66, 68], "version": [2, 14, 20, 24, 25, 37, 38, 41, 45, 48, 50, 56, 68], "versu": 15, "via": [8, 9, 10, 11, 12, 14, 21, 22, 24, 33, 35, 36, 45, 47, 48, 61, 62, 66, 68], "vibrant": [17, 25, 42], "vicuna": 68, "video": [40, 43, 55], "video_data": 68, "video_url": [32, 68], "view": [0, 17, 18, 19, 56, 61, 62], "vigor": 54, "virom": 17, "virtual": [8, 13, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 54], "visibl": [19, 36, 50], "vision": [26, 27, 32, 33, 34, 35, 42, 66, 68, 71, 72], "vision_end": 19, "vision_flat": 19, "vision_model": 19, "vision_process": 29, "vision_start": 19, "visionattent": 71, "visit": 11, "visitor": 25, "visual": [19, 36, 38, 62, 68], "visualstudio": 38, "vit": [65, 68, 71], "vitamin": 54, "vl": [11, 18, 29, 30, 35, 36, 54, 65, 68], "vl2": 68, "vllm": [11, 35, 36, 64], "vllm_tag": 44, "vllm_target_devic": 44, "vlm": [11, 25, 35, 68, 71], "vlm1": 68, "vm": [43, 44], "vocab": 14, "vocabulari": [14, 15], "volum": [38, 44, 56, 57, 60], "volumemount": [56, 57, 60], "vscode_cli_alpine_x64_cli": 38, "w": [15, 16, 17, 27, 33, 44, 54], "w2a16": 11, "w3a16": 11, "w4a16": 11, "w4a8_awq": 14, "w4afp8": 14, "w8a16": 11, "w8a8": [20, 44, 45], "w8a8_fp8": [11, 14], "w8a8_int8": [11, 14, 44, 45], "w8a8fp8config": 11, "wa": [8, 17, 18, 22, 27, 36, 56, 64], "wai": [0, 2, 17, 18, 25, 36, 48, 54, 71], "wait": [2, 5, 6, 12, 17, 24, 27, 28, 29, 36, 37, 50, 54, 56, 57, 58, 61], "wait_complet": [5, 6, 14], "wait_for_serv": [8, 13, 15, 16, 17, 18, 24, 27, 28, 29, 34, 54], "walk": 37, "walkthrough": 71, "wall": [17, 35], "wallet": 12, "walnut": 54, "wan": 42, "wand": 54, "want": [9, 11, 14, 17, 18, 24, 25, 27, 33, 36, 37, 41, 44, 45, 56, 62, 63, 68, 71], "warmup": [13, 14, 16, 17, 18, 19, 24, 25, 35, 36, 45, 50], "warmup_name1": 14, "warmup_name2": 14, "warn": [7, 8, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 29, 34, 35, 54], "warn_onc": 15, "washington": [8, 27, 34], "watch": [12, 14], "watchdog": 14, "watchdog_timeout": [13, 16, 17, 18, 19, 24, 25], "water": 17, "watsonx": 66, "wave": [1, 14], "we": [0, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 34, 36, 37, 38, 43, 44, 45, 51, 54, 56, 57, 62, 67, 71, 72], "wear": 54, "weather": [16, 17, 18, 20, 27], "web": [17, 61, 62], "web_search_preview": 22, "websit": 25, "week": [18, 37, 54], "weight": [2, 7, 11, 35, 36, 38, 40, 44, 46, 50, 71], "weight_load_func": 14, "weight_loader_disable_mmap": [13, 16, 17, 18, 19, 24, 25], "weight_vers": [13, 15, 16, 17, 18, 19, 24, 25, 27, 29, 34], "weilin": 15, "welcom": [5, 37, 49], "well": [6, 14, 15, 17, 22, 25, 54, 66, 71], "were": [17, 27], "western": 17, "wget": [38, 44], "what": [11, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 32, 34, 52, 54, 65, 68, 69, 71, 72], "whatev": 17, "wheel": [37, 44], "when": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 27, 32, 33, 35, 36, 37, 38, 41, 43, 45, 49, 50, 51, 61, 62, 64, 68, 71], "whenev": [36, 37], "where": [3, 6, 8, 10, 14, 16, 17, 18, 19, 20, 21, 25, 27, 32, 33, 36, 52, 71], "wherea": 6, "whether": [1, 6, 14, 24, 33, 36, 37, 50, 62], "which": [0, 3, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 25, 27, 33, 34, 35, 36, 37, 44, 45, 48, 49, 51, 54, 56, 62, 64, 66, 71, 72], "while": [3, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 24, 27, 28, 29, 34, 36, 40, 50, 51, 54, 58, 66], "whitespac": 14, "whl": [10, 44, 45, 48], "who": 27, "whole": [17, 54], "whose": 33, "why": 17, "wide": [6, 17, 20, 27, 42], "widespread": 42, "width": 11, "wild": 65, "window": [1, 12, 14, 66], "wish": 62, "with_stack": [36, 50], "within": [6, 8, 10, 11, 12, 14, 15, 17, 21, 27, 37, 38, 48, 54, 56, 61, 62], "without": [1, 6, 12, 14, 15, 24, 25, 27, 36, 37, 71], "won": 71, "wonder": 17, "wood": 54, "word": [27, 33, 54], "work": [1, 5, 11, 17, 18, 21, 25, 33, 37, 40, 44, 49, 56, 57, 60, 64, 72], "workaround": [10, 36], "worker": [2, 10, 14, 20, 50, 56, 57, 60], "worker1": 12, "worker2": 12, "worker_typ": 12, "workertempl": [56, 57], "workflow": [12, 24, 35, 37, 66], "workload": [6, 7, 8, 12, 15, 20, 31, 32, 35, 36, 43, 56, 60, 66], "workspac": [38, 57, 60], "world": [14, 17, 25, 27, 34, 66], "worldwid": 42, "worth": 45, "would": [8, 16, 17, 18, 25, 36, 44, 45, 62], "wrap": [15, 17, 35], "wrapper": [1, 14, 15], "write": [0, 1, 5, 14, 17, 25, 27, 33, 71], "write_back": [6, 14], "write_through": [5, 6, 13, 14, 16, 17, 18, 19, 24, 25], "write_through_select": [6, 14], "writer": 25, "written": [6, 57], "wrong": 24, "www": 55, "wx": 17, "x": [12, 13, 14, 16, 17, 18, 19, 24, 25, 36, 44, 55, 56, 57, 60, 65, 66, 71], "x1": [57, 60], "x64": 40, "x86_64": 36, "x_": 58, "xai": [12, 66], "xeon": [20, 41, 42, 45], "xf": 38, "xgrammar": [13, 14, 16, 17, 18, 19, 24, 25, 33, 48, 58], "xiaomi": [15, 66, 68], "xiaomimimo": [15, 66, 68], "xml": 12, "xpu": [1, 14, 41, 42], "xvers": 66, "xx": 10, "xxx": [5, 10, 40], "xxxx": 10, "xxxxx": 36, "xxxxxx": 18, "y": [0, 24, 27, 36, 40, 45, 48], "yaml": [14, 41, 56, 57, 61, 62], "ye": [3, 15, 17, 27, 50, 57, 60], "yeah": [17, 27], "year": [17, 22, 25], "yellow": [19, 29, 54], "yet": [35, 44, 56, 68], "yield": 6, "yml": [41, 60], "york": [16, 17, 18, 54], "you": [0, 1, 3, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 51, 54, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 71, 72], "your": [0, 1, 3, 5, 7, 8, 11, 14, 15, 16, 17, 18, 20, 22, 25, 27, 28, 29, 34, 35, 36, 37, 38, 41, 43, 45, 48, 51, 54, 56, 57, 58, 60, 61, 62, 68, 71], "your_exa_kei": 22, "your_model_path": 61, "your_module_path": 5, "your_user_nam": 37, "yourhicacheclassnam": 5, "yourkei": 35, "yourself": 25, "yuanmingyuan": 17, "yuanxiang": 66, "yugou": 17, "yum": 56, "z": [54, 58], "zai": [18, 68], "zealand": 27, "zero": [5, 6, 11, 18, 42, 50], "zhao": 15, "zhipu": 66, "zhipuai": 66, "zhousx": 15, "zip": [16, 17, 25, 71], "zmq": 62, "zsh": 38, "\u00e9lys\u00e9": 15, "\u00eele": 17, "\u016b": 17, "\u4e0d\u8fc7\u8981\u63a7\u5236\u8868\u60c5\u7b26\u53f7\u6570\u91cf": [57, 60], "\u4e5f\u53ef\u80fd\u662f\u60f3\u786e\u8ba4\u6211\u7684\u8eab\u4efd\u548c\u529f\u80fd\u8303\u56f4": [57, 60], "\u4f60\u53ef\u4ee5\u628a\u6211\u5f53\u6210\u4e00\u4e2a\u77e5\u8bc6\u4e30\u5bcc": [57, 60], "\u4f60\u662f\u8c01": [57, 60], "\u521a\u597d\u80fd\u4e2d\u548cai\u7684\u673a\u68b0\u611f": [57, 60], "\u529f\u80fd\u5b9a\u4f4d": [57, 60], "\u53c8\u80fd\u907f\u514d\u8ba9\u7528\u6237\u9762\u5bf9\u7a7a\u767d\u8f93\u5165\u6846\u65f6\u4e0d\u77e5\u6240\u63aa": [57, 60], "\u540c\u65f6\u7a81\u51fa\u5b9e\u7528\u4ef7\u503c\u6765\u964d\u4f4e\u964c\u751f\u611f": [57, 60], "\u540d\u5b57\u53eb": [57, 60], "\u5b66\u4e60": [57, 60], "\u5de5\u4f5c": [57, 60], "\u5e94\u8be5\u7528\u7b80\u4f53\u4e2d\u6587\u56de\u590d": [57, 60], "\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b": [57, 60], "\u6211\u662f\u4f60\u7684ai\u52a9\u624b": [57, 60], "\u65e2\u80fd\u4e86\u89e3\u9700\u6c42": [57, 60], "\u670d\u52a1\u8303\u56f4": [57, 60], "\u6df1\u5ea6\u6c42\u7d22": [57, 60], "\u751f\u6d3b": [57, 60], "\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u5f88\u57fa\u7840\u7684\u81ea\u6211\u4ecb\u7ecd\u95ee\u9898": [57, 60], "\u7531\u6df1\u5ea6\u6c42\u7d22\u516c\u53f8": [57, 60], "\u7ed3\u5c3e\u7528\u5f00\u653e\u6027\u95ee\u9898\u5f15\u5bfc\u5bf9\u8bdd\u5f88\u5173\u952e": [57, 60], "\u89e3\u7b54\u95ee\u9898": [57, 60], "\u8bed\u6c14\u7b80\u6d01\u4e2d\u6027": [57, 60], "\u8eab\u4efd\u5f52\u5c5e": [57, 60], "\u8fd9\u53ef\u80fd\u662f\u7b2c\u4e00\u6b21\u4e92\u52a8\u65f6\u7684\u5e38\u89c4\u5f00\u573a\u767d": [57, 60], "\u8fd9\u79cd\u573a\u666f\u4e0b\u65b0\u7528\u6237\u7684\u53ef\u80fd\u6027\u8f83\u9ad8": [57, 60], "\u907f\u514d\u663e\u5f97\u8f7b\u6d6e": [57, 60], "\u90a3\u4e2a\u7b11\u8138\u8868\u60c5": [57, 60], "\u91cd\u70b9\u8981\u8bf4\u660e\u4e09\u70b9": [57, 60], "\u968f\u53eb\u968f\u5230\u7684\u5c0f\u5e2e\u624b": [57, 60], "\u9700\u8981\u7ed9\u51fa\u6e05\u6670\u53cb\u597d\u7684\u81ea\u6211\u4ecb\u7ecd": [57, 60]}, "titles": ["SGLang Documentation", "Attention Backend", "Checkpoint Engine Integration", "Deterministic Inference", "Hierarchical KV Caching (HiCache)", "SGLang HiCache Best Practices", "HiCache System Design and Optimization", "Hyperparameter Tuning", "LoRA Serving", "Observability", "PD Disaggregation", "Quantization", "SGLang Model Gateway (formerly SGLang Router)", "Reasoning Parser", "Server Arguments", "Speculative Decoding", "Structured Outputs", "Structured Outputs For Reasoning Models", "Tool Parser", "Query Vision Language Model", "DeepSeek V3/V3.1/R1 Usage", "DeepSeek V3.2 Usage", "GPT OSS Usage", "Llama4 Usage", "SGLang Native APIs", "Offline Engine API", "OpenAI-Compatible APIs", "OpenAI APIs - Completions", "OpenAI APIs - Embedding", "OpenAI APIs - Vision", "Popular Model Usage (DeepSeeek, GPT-OSS, Llama, Qwen, and more)", "Qwen3-Next Usage", "Qwen3-VL Usage", "Sampling Parameters", "Sending Requests", "Bench Serving Guide", "Benchmark and Profiling", "Contribution Guide", "Development Guide Using Docker", "PyPI Package Release Process", "Set Up Self-Hosted Runners for GitHub Action", "Install SGLang", "SGLang Documentation", "AMD GPUs", "Ascend NPUs", "CPU Servers", "NVIDIA Jetson Orin", "TPU", "XPU", "Custom Chat Template", "Environment Variables", "Troubleshooting and Frequently Asked Questions", "Choices Methods in SGLang", "Frontend Language", "SGLang Frontend Language", "Learn More and Join the Community", "Deploy On Kubernetes", "LWS Based PD Deploy", "Multi-Node Deployment", "Multi-Node Deployment", "DeepSeekV32-Exp RBG Based PD Deploy", "Production Metrics", "Production Request Tracing", "Enabling cache for torch.compile", "Classification API", "Embedding Models", "Large Language Models", "Use Models From ModelScope", "Multimodal Language Models", "Rerank Models", "Reward Models", "How to Support New Models", "Transformers fallback in SGLang"], "titleterms": {"": [3, 71], "0": [3, 51, 57, 60], "1": [20, 38, 40, 41, 43, 44, 45, 57, 58, 60, 65], "16": 2, "2": [2, 15, 18, 21, 38, 40, 41, 44, 57, 60, 65], "3": [15, 18, 40, 41, 58], "30b": 3, "4": [18, 19, 23, 41], "405b": 58, "5": 41, "6": 41, "8": 20, "8b": 3, "A": [24, 27, 28, 29, 34, 54], "For": [14, 17], "In": [36, 60], "On": 56, "One": 60, "The": [3, 51], "With": 41, "a3b": 3, "abov": 32, "access": 51, "accuraci": [21, 23, 37], "achiev": 7, "action": 40, "adapt": 27, "adaptor": [8, 44], "add": [1, 37, 40, 62, 71], "adjust": 7, "advanc": [10, 11, 12, 25, 38, 42, 50], "all": 60, "amd": 43, "an": 71, "api": [8, 11, 12, 13, 14, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 34, 36, 64], "ar": [51, 61], "architectur": [2, 6, 12], "arg": 14, "argument": [3, 8, 14], "ascend": [10, 44], "ask": 51, "asynchron": 25, "asyncio": 25, "attent": [1, 20], "authent": [12, 35], "auto": [11, 43], "automat": 38, "avail": 11, "avoid": 7, "awar": 12, "b": 7, "back": [6, 18], "backend": [1, 3, 5, 6, 8, 12, 14, 18, 35], "balanc": [12, 43, 44], "base": [57, 60], "basic": [3, 27, 42, 54, 56], "batch": [7, 25, 54], "behavior": [3, 13], "being": 61, "bench": 35, "bench_offline_throughput": 36, "bench_serv": 36, "benchmark": [21, 23, 36, 37, 45, 48, 50, 71], "benefit": [2, 11], "best": 5, "bf16": 32, "bia": 27, "block": 20, "breaker": 12, "budget": 20, "bug": 36, "build": [21, 37], "built": 22, "cach": [4, 7, 12, 14, 24, 50, 63], "call": [18, 20, 21, 50], "capabl": 65, "capac": 7, "captur": 24, "case": 56, "caus": 3, "chat": [18, 27, 49], "check": [24, 61], "checkpoint": 2, "choic": [18, 52], "choos": [8, 35], "chunk": 7, "ci": [37, 50], "circuit": 12, "class": 64, "classif": 64, "classifi": 24, "client": [18, 28, 29, 34, 65, 69], "clone": 37, "cloud": 41, "co": 12, "code": [37, 39, 72], "collect": 61, "command": [1, 14, 32, 36, 66, 68, 69, 70, 72], "commit": 37, "common": [14, 41], "commun": [5, 55], "compat": [8, 13, 16, 17, 18, 26, 44, 64], "compil": [15, 63], "complet": 27, "complex": [54, 62], "compos": 41, "compressor": 11, "comput": 50, "concurr": 35, "config": 40, "configur": [2, 3, 5, 10, 12, 14, 21, 23, 27, 31, 40, 43, 50, 61], "connector": 12, "consider": 36, "constrain": [33, 54], "contain": [38, 40, 46], "content": [12, 20], "context": 21, "contribut": 37, "control": [7, 12, 54], "core": [5, 12, 33], "cpu": [44, 45], "crash": 9, "creat": 57, "cross": 24, "cuda": [7, 51], "curl": [28, 29, 34, 64], "current": 18, "custom": [5, 14, 33, 49], "data": [6, 12, 14, 20], "dataset": 35, "debug": [14, 38, 50, 56, 71], "debugg": 38, "decod": [1, 10, 12, 14, 15, 23, 31, 33, 36, 54, 57], "deepep": [44, 50], "deepgemm": 50, "deepseeek": 30, "deepseek": [10, 20, 21, 27, 43, 44, 45, 58], "deepseekv32": 60, "default": [3, 33, 38], "defin": 18, "demo": 22, "depend": 0, "deploi": [11, 56, 57, 60], "deploy": [5, 6, 12, 57, 58, 59], "deprec": 14, "design": 6, "detail": 64, "determin": 3, "determinist": [3, 14, 51], "detoken": 24, "dev": 38, "develop": [38, 42], "dialog": 54, "diamond": 21, "differ": [1, 65], "dimens": 65, "disabl": [43, 44], "disaggreg": [5, 6, 10, 12, 14, 21, 36], "discoveri": 12, "disk": 24, "distribut": [14, 24, 36, 50], "doc": 0, "docker": [21, 38, 40, 41, 43, 44, 45, 48], "document": [0, 37, 42, 71], "doe": 35, "doubl": 14, "download": 20, "dp": 7, "dsa": 21, "dump": [9, 14], "dynam": [5, 8, 12], "eagl": [15, 23, 31], "ebnf": [16, 17, 27, 33], "embed": [19, 24, 28, 65], "enabl": [5, 18, 36, 63], "encod": 24, "encount": 51, "end": 35, "end_profil": 36, "endpoint": [33, 35, 36, 64], "engin": [2, 13, 16, 17, 18, 19, 25, 45, 48, 71], "environ": 50, "error": [7, 51, 64], "evalu": 38, "even": 51, "exampl": [2, 3, 11, 18, 20, 24, 27, 32, 33, 35, 36, 43, 44, 45, 56, 64, 65, 66, 68, 69, 70, 71, 72], "execut": 18, "exp": 60, "experiment": [1, 21], "expert": [14, 24], "explain": 35, "export": 11, "express": [16, 17], "extend": 62, "extern": 71, "fallback": 72, "faq": [20, 57, 60], "fault": 12, "featur": [11, 42, 72], "field": 64, "file": [14, 36, 57, 60, 61], "flag": 32, "flow": [12, 54], "flush": 24, "forc": 18, "fork": 37, "format": [18, 35, 37, 49, 64], "formerli": 12, "fp8": [20, 32], "fraction": 7, "framework": [44, 62], "frequenc": 15, "frequent": 51, "from": [6, 21, 24, 37, 38, 41, 43, 44, 45, 48, 67, 71], "frontend": [53, 54], "full": 32, "function": [18, 20, 21, 50], "futur": 8, "gatewai": 12, "gener": [3, 24, 25, 33, 34, 37, 50, 54], "get": [24, 27, 42], "github": [39, 40], "gpqa": 21, "gpt": [22, 30], "gptqmodel": 11, "gpu": [8, 43], "graph": 7, "greedi": [3, 52], "grpc": 12, "grub": 43, "gsm8k": 21, "guid": [1, 35, 37, 38, 42, 61, 62], "guidelin": [0, 5], "h200": 20, "handl": [18, 64], "hang": 51, "hardwar": [32, 42], "head": 20, "health": 24, "hf3f": 5, "hicach": [4, 5, 6], "hierarch": [4, 14], "high": 7, "highlight": 15, "hiradixtre": 6, "histori": 12, "host": [38, 40], "how": [18, 37, 62, 71], "http": [12, 14, 36], "hybrid": 1, "hyperparamet": 7, "i": [6, 10], "id": [27, 28], "illeg": 51, "imag": [29, 32, 57, 60], "implement": [64, 71], "import": [32, 36], "increas": 7, "infer": [3, 7, 14, 25, 46, 58], "info": 24, "initi": 18, "input": [28, 29, 32, 68], "instal": [0, 2, 11, 21, 37, 41, 43, 44, 45, 46, 48], "integr": [2, 5, 6, 10], "interact": 71, "interest": 62, "interfac": 6, "intern": 50, "issu": [10, 56], "item": 14, "jetson": 46, "jinja": 49, "join": 55, "json": [16, 17, 27, 33, 49], "jsonl": 35, "k8": 57, "kei": [5, 35, 56], "kernel": [14, 37], "kubernet": [12, 41, 56], "kv": [4, 7], "l3": 6, "languag": [19, 53, 54, 66, 68, 71], "larg": [66, 71], "latent": 20, "launch": [1, 12, 13, 14, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 34, 45, 48, 54, 65, 66, 68, 69, 70, 72], "layer": 36, "layerwis": 36, "layout": 5, "lb": 57, "learn": 55, "length": 52, "librari": 44, "lifecycl": 12, "likelihood": 52, "limit": 12, "line": 36, "list": [45, 48], "llama": [3, 10, 18, 19, 23, 30, 58, 71], "llama3": 43, "llama4": 23, "llm": 11, "lm_eval": 23, "lmcach": 14, "load": [5, 8, 12], "loader": 14, "local": 6, "log": [9, 14], "logit": [27, 33], "long": 21, "lora": [8, 14, 27], "lw": 57, "make": [39, 65], "mamba": 14, "manag": 50, "manifest": [57, 60], "manual": 38, "marker": 36, "match": 6, "matrix": 1, "matryoshka": 65, "matter": [3, 5], "max": 7, "mcp": 12, "mem": 7, "memfabr": 44, "memori": [5, 7, 14, 44, 50, 51], "merg": 37, "merger": 36, "messag": 18, "metadata": 6, "method": [11, 41, 44, 52], "metric": [9, 35, 61], "mha": 1, "minilb": 57, "mla": [1, 20], "modal": [28, 54], "mode": [6, 10, 12, 18, 32, 36], "model": [3, 11, 12, 13, 14, 17, 18, 19, 20, 24, 27, 28, 30, 35, 42, 45, 48, 50, 64, 65, 66, 67, 68, 69, 70, 71], "modelopt": 11, "modelscop": 67, "moe": [3, 24], "mooncak": [5, 10], "more": [30, 55], "multi": [2, 6, 10, 14, 15, 20, 21, 28, 36, 54, 58, 59, 64], "multimod": [33, 65, 68, 71], "multipl": [3, 8, 29], "multiplex": 14, "nativ": [13, 16, 17, 18, 24, 34], "nest": 25, "new": [1, 13, 18, 71], "newcom": 37, "next": 31, "ngram": 14, "nixl": 10, "node": [2, 10, 14, 20, 36, 58, 59], "non": [3, 13, 18, 25, 32], "normal": [33, 52], "note": [22, 32, 33, 35, 36, 41, 68], "npu": 44, "nsight": 36, "numa": [43, 44], "nvidia": [11, 46], "nvlink": 10, "nvtx": 36, "observ": [9, 12], "offlin": [7, 11, 13, 16, 17, 18, 19, 25, 71], "offload": 14, "one": 20, "onlin": 11, "openai": [8, 12, 13, 16, 17, 18, 26, 27, 28, 29, 34], "optim": [5, 6, 14, 20, 21, 32, 45, 48, 50, 68], "option": [2, 7, 14, 18, 33, 35, 38, 50], "organ": 6, "orin": 46, "oss": [22, 30], "other": [7, 33, 35, 36], "our": 71, "out": [7, 44, 51], "output": [16, 17, 18, 27, 33, 35, 36, 46, 65], "overal": 6, "overrid": 14, "overview": [2, 12, 64], "packag": 39, "parallel": [2, 14, 20, 21, 54], "paramet": [5, 6, 27, 32, 33, 64], "parser": [13, 18, 21, 22], "pd": [5, 6, 10, 14, 21, 36, 57, 60], "penal": 33, "perform": [2, 15, 44, 50, 68], "pin": 8, "pip": 41, "plane": 12, "platform": 42, "polici": [5, 12], "pool": 7, "popular": 30, "port": 71, "possibl": 36, "power": 44, "practic": 5, "pre": 37, "precis": 32, "precomput": 19, "predict": [15, 20, 21], "prefetch": [5, 6], "prefil": [1, 7, 10, 12, 36, 57], "prepar": [57, 60], "prerequisit": [35, 44, 46, 56, 57, 60, 61], "prevent": 44, "privaci": 12, "process": 39, "processor": 33, "product": [9, 61, 62], "profil": [10, 36, 38, 50], "prompt": 54, "proxi": 12, "pypi": 39, "python": [11, 18, 22, 28, 29, 34, 44, 64], "pytorch": [36, 44], "quantis": 32, "quantiz": [11, 14, 46, 72], "queri": 19, "question": 51, "queu": 12, "queue": 7, "quick": [22, 35, 65], "qwen": [19, 30], "qwen3": [3, 27, 31, 32], "r1": [20, 58], "rank": [6, 15], "rate": [12, 35], "rbg": 60, "rdma": 56, "re": 62, "reason": [13, 17, 20, 21, 22, 27], "recommend": [32, 43], "refer": [2, 11, 12, 15, 42, 46], "regex": [27, 33], "regist": 71, "regular": [16, 17], "relat": [6, 14], "releas": 39, "reliabl": 12, "remain": 56, "remot": [38, 72], "replai": 9, "repositori": 37, "reproduc": 3, "req": 7, "request": [7, 9, 13, 18, 28, 29, 32, 34, 37, 45, 48, 62, 64, 65, 69], "requir": [10, 18], "rerank": [24, 69], "respons": [3, 22, 64], "result": [18, 21, 23, 51], "retri": 12, "review": 37, "reward": [24, 64, 70], "rich": 6, "roce": 56, "root": 3, "round": [11, 24], "router": [10, 12], "run": [7, 20, 37, 40, 41, 43, 44, 45, 46], "runner": 40, "runtim": [14, 16, 17, 18], "sampl": [3, 15, 33], "scale": 12, "scenario": [56, 62], "schedul": [10, 14], "schema": 13, "scheme": 44, "score": [14, 64], "search": 22, "secur": 12, "select": [24, 52], "self": 40, "send": [18, 19, 32, 34], "separ": 12, "sequenc": 21, "serv": [8, 14, 35, 45, 48, 71], "server": [2, 3, 10, 13, 14, 18, 24, 27, 28, 29, 32, 34, 36, 45, 51, 54, 65], "servic": [12, 57], "set": [12, 40, 43, 44], "setup": [2, 38, 61, 62], "sgl": 37, "sglang": [0, 2, 3, 5, 12, 13, 16, 17, 18, 20, 21, 23, 24, 31, 32, 36, 37, 38, 41, 42, 43, 44, 46, 52, 54, 71, 72], "sh": 40, "share": 36, "singl": [2, 8, 10, 64], "size": 7, "skypilot": 41, "slice": 62, "slurm": 58, "solut": 3, "sourc": [21, 37, 41, 43, 44, 45, 48], "sparsiti": 14, "specif": [13, 18, 32, 50], "specul": [1, 14, 15, 23, 31], "speed": [7, 37], "srt": [16, 17, 18], "start": [35, 38, 40, 42, 65], "start_profil": 36, "static": 7, "step": [1, 40, 43], "storag": [5, 6, 12, 36, 50], "stream": [13, 18, 25, 33, 34, 35, 54], "structur": [16, 17, 27, 33, 46], "style": [0, 37], "submiss": 7, "success": 56, "suit": 71, "support": [1, 3, 5, 13, 14, 17, 18, 27, 35, 42, 62, 64, 65, 66, 68, 69, 70, 71, 72], "surfac": 12, "swap": 44, "synchron": [6, 25], "system": [6, 36, 43, 44], "tabl": 12, "tag": [16, 17], "temperatur": [3, 51], "templat": [18, 49], "tensor": [2, 14, 20], "terminu": 45, "test": [21, 23, 37, 50, 64, 71], "text": 24, "think": [20, 27], "throughput": [7, 20], "tip": [21, 23, 31, 36, 37], "todo": 56, "token": [7, 14, 15, 20, 21, 24, 27, 35, 52], "toler": 12, "tool": [12, 18, 22, 50], "torch": [15, 63], "torchao": 46, "tp": [2, 7], "tpu": 47, "trace": [36, 62], "transfer": 6, "transform": 72, "transport": 10, "trigger": 37, "trip": 24, "triton": 44, "troubleshoot": [2, 12, 35, 51, 61], "try": 7, "tune": [7, 12, 50], "turn": 54, "type": 14, "uncondit": 52, "unifi": [6, 10], "unit": 37, "up": [38, 40], "updat": [0, 24, 37, 39, 43], "upload": 39, "us": [11, 27, 28, 29, 34, 36, 38, 41, 43, 44, 45, 48, 50, 64, 67], "usag": [2, 3, 7, 8, 10, 11, 13, 17, 20, 21, 22, 23, 25, 27, 30, 31, 32, 36, 42, 54, 61, 64, 68], "user": 1, "uv": 41, "v": 1, "v1": 24, "v3": [20, 21, 27, 43, 44, 45, 58], "variabl": 50, "verif": 3, "version": [39, 44], "via": [15, 19, 71], "video": [32, 68], "view": 36, "vision": [19, 29], "vl": [19, 32], "vllm": [44, 71], "vscode": 38, "warmup": 43, "web": 22, "weight": [14, 20, 24], "what": [6, 10, 35], "why": [3, 5, 6, 10], "wise": [20, 36], "without": 18, "work": 8, "worker": [12, 36], "workflow": [0, 6, 11, 36], "wrapper": 71, "write": [6, 37], "x": 20, "xgrammar": 46, "xpu": 48, "you": 62}})