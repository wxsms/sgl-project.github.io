Search.setIndex({"alltitles": {"--perf-dump-path (Stage/Step Timing Dump)": [[91, "perf-dump-path-stage-step-timing-dump"]], "/generate Endpoint": [[47, "generate-endpoint"]], "0. Prerequisites": [[81, "prerequisites"], [84, "prerequisites"]], "1. Background and implementation overview": [[12, "background-and-implementation-overview"]], "1. Commit Message Convention": [[91, "commit-message-convention"]], "1. Image Preparation": [[81, "image-preparation"], [84, "image-preparation"]], "1. Launch SGLang Server": [[39, "launch-sglang-server"]], "1. Launch a Matryoshka\u2011capable model": [[92, "launch-a-matryoshkacapable-model"]], "1. Raw Images - Simplest approach": [[29, "1.-Raw-Images---Simplest-approach"]], "1.1 Architecture / control path": [[12, "architecture-control-path"]], "2. All In One manifest file": [[84, "all-in-one-manifest-file"]], "2. Deployment Manifest Files": [[81, "deployment-manifest-files"]], "2. Idle-state requirement (strict)": [[12, "idle-state-requirement-strict"]], "2. Make requests with different output dimensions": [[92, "make-requests-with-different-output-dimensions"]], "2. Performance Reporting": [[91, "performance-reporting"]], "2. Processor Output - For custom preprocessing": [[29, "2.-Processor-Output---For-custom-preprocessing"]], "2. Use Ollama CLI": [[39, "use-ollama-cli"]], "2.1 DP (data parallel) semantics": [[12, "dp-data-parallel-semantics"]], "3. CI-Based Change Protection": [[91, "ci-based-change-protection"]], "3. How to use (HTTP Admin API)": [[12, "how-to-use-http-admin-api"]], "3. Precomputed Embeddings - For maximum performance": [[29, "3.-Precomputed-Embeddings---For-maximum-performance"]], "3. Use Ollama Python Library": [[39, "use-ollama-python-library"]], "3.1 Query current storage backend status": [[12, "query-current-storage-backend-status"]], "3.2 Attach (enable) a storage backend": [[12, "attach-enable-a-storage-backend"]], "3.3 Detach (disable) the storage backend": [[12, "detach-disable-the-storage-backend"]], "4. Behavior and caveats": [[12, "behavior-and-caveats"]], "AMD GPUs": [[59, null]], "API Endpoint": [[89, "api-endpoint"]], "API Reference": [[23, "api-reference"]], "API related": [[22, "api-related"]], "ASCEND": [[16, "ascend"]], "Accuracy": [[54, "accuracy"]], "Accuracy Impact": [[19, "accuracy-impact"]], "Accuracy Test with aime 2025": [[31, "accuracy-test-with-aime-2025"]], "Accuracy Test with gpqa-diamond": [[31, "accuracy-test-with-gpqa-diamond"]], "Accuracy Test with gsm8k": [[31, "accuracy-test-with-gsm8k"]], "Accuracy Test with lm_eval": [[35, "accuracy-test-with-lm-eval"]], "Achieve a high token usage": [[13, "achieve-a-high-token-usage"]], "Achieving high throughput for offline batch inference": [[13, "achieving-high-throughput-for-offline-batch-inference"]], "Add Tokenizer (Async)": [[23, "add-tokenizer-async"]], "Add Worker": [[23, "add-worker"]], "Add a Runner": [[56, "add-a-runner"]], "Add new kernels": [[49, "add-new-kernels"]], "Add the Model to the Test Suite": [[99, "add-the-model-to-the-test-suite"]], "Adjust the request submission speed to control #queue-req": [[13, "adjust-the-request-submission-speed-to-control-queue-req"]], "Admin and Health Endpoints": [[23, "admin-and-health-endpoints"]], "Adoption": [[85, "adoption"]], "Advanced Configuration": [[16, "advanced-configuration"], [16, "id5"], [91, "advanced-configuration"]], "Advanced Features": [[18, "advanced-features"], [58, null], [71, "advanced-features"]], "Advanced Usage": [[38, "Advanced-Usage"]], "Advanced: Speculative Decoding (EAGLE3)": [[71, "advanced-speculative-decoding-eagle3"]], "Architecture": [[2, "architecture"], [23, "architecture"], [23, "id7"]], "Areas for Contribution": [[71, "areas-for-contribution"]], "Args for multi-item scoring": [[22, "args-for-multi-item-scoring"]], "Arguments": [[91, "arguments"]], "Arguments for LoRA Serving": [[14, "Arguments-for-LoRA-Serving"]], "Ascend NPUs": [[66, null]], "Attention Backend": [[1, null]], "Attention Backend Comparison": [[71, "attention-backend-comparison"]], "Attention Backend Selection Guide (CUDA)": [[1, "attention-backend-selection-guide-cuda"]], "Attention Backends": [[91, "attention-backends"]], "Attention backend arguments": [[3, "attention-backend-arguments"]], "Authentication": [[50, "authentication"]], "Automatic Selection Logic": [[1, "automatic-selection-logic"]], "Available Quantization Methods": [[18, "available-quantization-methods"]], "Avoid out-of-memory errors by tuning --chunked-prefill-size, --mem-fraction-static, and --max-running-requests": [[13, "avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests"]], "Backend Compatibility": [[28, "Backend-Compatibility"]], "Backend options": [[91, "backend-options"]], "Backends for All-to-All Communication": [[7, "backends-for-all-to-all-communication"]], "Backends for MoE Computation": [[7, "backends-for-moe-computation"]], "Basic Example: Qwen-7B": [[71, "basic-example-qwen-7b"]], "Basic Offline Engine API Call": [[29, "Basic-Offline-Engine-API-Call"]], "Basic Profiling": [[91, "basic-profiling"]], "Basic Usage": [[4, "basic-usage"], [41, "Basic-Usage"], [58, null], [78, "Basic-Usage"], [91, "basic-usage"]], "Basic example": [[80, "basic-example"]], "Batch Tokenize Request": [[23, "batch-tokenize-request"]], "Batching": [[78, "Batching"]], "Bench Serving Guide": [[50, null]], "Benchmark": [[51, "benchmark"], [62, "benchmark"], [62, "id4"], [62, "id6"], [62, "id8"], [62, "id10"], [62, "id12"], [62, "id14"], [62, "id16"], [62, "id18"], [62, "id20"], [62, "id22"], [62, "id24"], [62, "id26"], [62, "id28"], [62, "id30"], [62, "id32"], [62, "id34"], [62, "id36"], [62, "id38"], [62, "id40"], [62, "id42"], [62, "id44"], [62, "id46"], [62, "id48"], [62, "id50"], [62, "id52"], [62, "id54"], [62, "id56"], [62, "id58"], [62, "id60"], [99, "benchmark"]], "Benchmark and Profiling": [[51, null]], "Benchmark the speed": [[52, "benchmark-the-speed"], [60, "benchmark-the-speed"]], "Benchmarking Results": [[31, "benchmarking-results"], [35, "benchmarking-results"]], "Benchmarking with Requests": [[68, "benchmarking-with-requests"], [71, "benchmarking-with-requests"], [72, "benchmarking-with-requests"]], "Benefits of ModelOpt": [[18, "benefits-of-modelopt"]], "Best Practice for Long Context": [[17, "best-practice-for-long-context"]], "Best Practice for Pipeline Parallelism with PD Disaggregation": [[17, "best-practice-for-pipeline-parallelism-with-pd-disaggregation"]], "Best Practice on Ascend NPU": [[62, null]], "Best Practices": [[19, "best-practices"]], "Block-wise FP8": [[30, "block-wise-fp8"]], "Build From Source": [[31, "build-from-source"]], "Build from source": [[52, "build-from-source"]], "Building Modules": [[23, "building-modules"]], "Built-in Tools": [[34, "built-in-tools"]], "C++ Implementation": [[49, "c-implementation"]], "C++ Utilities": [[49, "c-utilities"]], "CANN": [[61, "cann"]], "CI rate limits": [[52, "ci-rate-limits"], [60, "ci-rate-limits"]], "CPU Servers": [[68, null]], "CPU performance power scheme": [[61, "cpu-performance-power-scheme"]], "CUDA Error: Illegal Memory Access Encountered": [[75, "cuda-error-illegal-memory-access-encountered"]], "CUDA Out of Memory": [[75, "cuda-out-of-memory"]], "Cache-Aware Policy Tuning": [[23, "cache-aware-policy-tuning"]], "Cache-DiT Acceleration": [[91, "cache-dit-acceleration"]], "Call with Precomputed Embeddings": [[29, "Call-with-Precomputed-Embeddings"], [29, "id2"]], "Call with Processor Output": [[29, "Call-with-Processor-Output"], [29, "id1"]], "Capture expert selection distribution in MoE models": [[37, "Capture-expert-selection-distribution-in-MoE-models"]], "Case Study on NVIDIA H20": [[17, "case-study-on-nvidia-h20"]], "Chat Completions": [[41, "Chat-Completions"]], "Check if the metrics are being collected": [[86, "check-if-the-metrics-are-being-collected"]], "Checkpoint Engine Integration": [[2, null]], "Checkpoint Engine Options": [[2, "checkpoint-engine-options"]], "Choices Methods in SGLang": [[76, null]], "Choosing LoRA Backend": [[14, "Choosing-LoRA-Backend"]], "Choosing model and tokenizer": [[50, "choosing-model-and-tokenizer"]], "Chunked Prefill": [[71, "chunked-prefill"]], "Chunked Prefill Size and Smoothing Factor": [[17, "chunked-prefill-size-and-smoothing-factor"]], "Circuit Breaker": [[23, "circuit-breaker"]], "Circuit Breaker Flapping": [[23, "circuit-breaker-flapping"]], "Classification API": [[23, "classification-api"], [89, null]], "Classification Models (Multi-class)": [[89, "classification-models-multi-class"]], "Classify (reward model)": [[37, "Classify-(reward-model)"]], "Client Request": [[92, "client-request"]], "Co-launch Router and Workers": [[23, "co-launch-router-and-workers"]], "Code Structure": [[49, "code-structure"]], "Code style guidance": [[52, "code-style-guidance"], [60, "code-style-guidance"]], "Collaboration": [[85, "collaboration"]], "Combined Configuration Example": [[91, "combined-configuration-example"]], "Command Example": [[3, "command-example"], [5, "command-example"]], "Command Line Usage": [[51, "command-line-usage"]], "Common Notes": [[57, "common-notes"]], "Common Pitfalls": [[97, "common-pitfalls"], [97, "id3"]], "Common launch commands": [[22, "common-launch-commands"]], "Community and Support": [[10, "community-and-support"]], "Comparison": [[23, "comparison"]], "Compatibility": [[89, "compatibility"]], "Compatibility Matrix": [[91, "compatibility-matrix"]], "Compilation Long-Time": [[71, "compilation-long-time"]], "Completions": [[41, "Completions"]], "Complex Prompts": [[78, "Complex-Prompts"]], "Component Version Mapping For SGLang": [[61, "component-version-mapping-for-sglang"]], "Comprehensive Benchmark Script": [[71, "comprehensive-benchmark-script"]], "Computation and Communication Overlap": [[7, "computation-and-communication-overlap"]], "Configuration": [[23, "configuration"], [23, "id3"]], "Configuration Files": [[86, "configuration-files"]], "Configuration Guidelines": [[10, "configuration-guidelines"]], "Configuration Options": [[2, "configuration-options"]], "Configuration Reference": [[23, "configuration-reference"]], "Configuration Tips": [[31, "configuration-tips"], [35, "configuration-tips"], [45, "configuration-tips"]], "Configuration file support": [[22, "configuration-file-support"]], "Configuration overview": [[8, "configuration-overview"]], "Connection Issues": [[71, "connection-issues"]], "Constrained Decoding": [[78, "Constrained-Decoding"]], "Constrained decoding": [[47, "constrained-decoding"]], "Continue Generation": [[24, "continue-generation"]], "Contributing": [[71, "contributing"]], "Contributing to SGLang Diffusion": [[91, "contributing-to-sglang-diffusion"]], "Contribution Guide": [[52, null], [60, null]], "Control Plane": [[23, "control-plane"]], "Control flow": [[78, "Control-flow"]], "Conversation and Response APIs": [[23, "conversation-and-response-apis"]], "Core HiCache Parameters": [[10, "core-hicache-parameters"]], "Core Settings": [[23, "core-settings"]], "Core parameters": [[47, "core-parameters"]], "Crash Dump and Replay": [[15, "crash-dump-and-replay"]], "Create Docker": [[61, "create-docker"]], "Create a video": [[91, "create-a-video"]], "Create an image": [[91, "create-an-image"]], "Create decode k8s service": [[81, "create-decode-k8s-service"]], "Create prefill k8s service": [[81, "create-prefill-k8s-service"]], "Creating Service for Prefill and Decode": [[81, "creating-service-for-prefill-and-decode"]], "Cross-Encoder Rerank (embedding runner)": [[97, "cross-encoder-rerank-embedding-runner"]], "Cuda Graph for Multi-Modal Encoder in SGLang": [[3, null]], "Currently supported parsers:": [[28, "Currently-supported-parsers:"]], "Custom Attention Backends": [[71, "custom-attention-backends"]], "Custom Chat Template": [[73, null]], "Custom SCM Bins": [[91, "custom-scm-bins"]], "Custom Storage Backend Integration": [[10, "custom-storage-backend-integration"]], "Custom logit processor": [[47, "custom-logit-processor"]], "Custom weight loader": [[22, "custom-weight-loader"]], "CustomOps": [[61, "customops"]], "DBCache Parameters": [[91, "dbcache-parameters"]], "DP for Multi-Modal Encoder in SGLang": [[5, null]], "DSA long sequence context parallel optimization(experimental)": [[31, "dsa-long-sequence-context-parallel-optimization-experimental"]], "Data Parallelism Attention": [[30, "data-parallelism-attention"]], "Data Plane": [[23, "data-plane"]], "Data Transfer Optimization": [[11, "data-transfer-optimization"]], "Data Write-back": [[11, "data-write-back"]], "Data parallelism": [[22, "data-parallelism"]], "Datasets": [[50, "datasets"]], "Debug": [[80, "debug"]], "Debug Mode": [[94, "debug-mode"]], "Debug SGLang with VSCode Debugger": [[53, "debug-sglang-with-vscode-debugger"]], "Debug tensor dumps": [[22, "debug-tensor-dumps"]], "Debugging": [[23, "debugging"]], "Decode": [[81, "decode"]], "Decode Server Configuration": [[16, "decode-server-configuration"]], "DeepEP Configuration": [[74, "deepep-configuration"]], "DeepEP-compatible Library": [[61, "deepep-compatible-library"]], "DeepGEMM Configuration (Advanced Optimization)": [[74, "deepgemm-configuration-advanced-optimization"]], "DeepSeek Multi-Node": [[16, "deepseek-multi-node"], [16, "id4"], [16, "id8"]], "DeepSeek R1 High Performance 50ms 1": [[62, "deepseek-r1-high-performance-50ms-1"]], "DeepSeek R1 High Performance 50ms 2": [[62, "deepseek-r1-high-performance-50ms-2"]], "DeepSeek R1 High Performance 50ms 3": [[62, "deepseek-r1-high-performance-50ms-3"]], "DeepSeek R1 High Performance 50ms 4": [[62, "deepseek-r1-high-performance-50ms-4"]], "DeepSeek R1 High Performance 50ms 5": [[62, "deepseek-r1-high-performance-50ms-5"]], "DeepSeek R1 Low Latency 20ms 1": [[62, "deepseek-r1-low-latency-20ms-1"]], "DeepSeek R1 Low Latency 20ms 2": [[62, "deepseek-r1-low-latency-20ms-2"]], "DeepSeek R1 Low Latency 20ms 3": [[62, "deepseek-r1-low-latency-20ms-3"]], "DeepSeek R1 Low Latency 20ms 4": [[62, "deepseek-r1-low-latency-20ms-4"]], "DeepSeek Series Models": [[62, "deepseek-series-models"]], "DeepSeek V3.2 Usage": [[31, null]], "DeepSeek V3/R1": [[82, "deepseek-v3-r1"]], "DeepSeek V3/V3.1/R1 Usage": [[30, null]], "DeepSeek examples": [[63, null]], "DeepSeek-V3.1 with 128K Input Token Length": [[17, "deepseek-v3-1-with-128k-input-token-length"]], "DeepSeekV32-Exp RBG Based PD Deploy": [[84, null]], "Deepseek V32 Low Latency 30ms": [[62, "deepseek-v32-low-latency-30ms"]], "Default Behavior": [[4, "default-behavior"]], "Define Messages": [[28, "Define-Messages"]], "Define Tools for Function Call": [[28, "Define-Tools-for-Function-Call"]], "Define a Tool Function": [[28, "Define-a-Tool-Function"]], "Denoising Stage Profiling": [[91, "denoising-stage-profiling"]], "Deploy On Kubernetes": [[80, null]], "Deploy minilb and lb service": [[81, "deploy-minilb-and-lb-service"]], "Deploying Modules": [[23, "deploying-modules"]], "Deploying Quantized Models": [[18, "deploying-quantized-models"]], "Deployment Modes": [[23, "deployment-modes"]], "Deployment with HF3FS": [[10, "deployment-with-hf3fs"]], "Deployment with Mooncake": [[10, "deployment-with-mooncake"]], "Deployment with Python": [[36, "deployment-with-python"]], "Deprecated arguments": [[22, "deprecated-arguments"]], "Design and Restrictions": [[3, "design-and-restrictions"]], "Deterministic Inference": [[4, null], [24, "deterministic-inference"]], "Deterministic Inference with Non-Greedy Sampling (Temperature > 0)": [[4, "deterministic-inference-with-non-greedy-sampling-temperature-0"]], "Detokenize Request": [[23, "detokenize-request"]], "Detokenize Response": [[23, "detokenize-response"]], "Developer Guide": [[58, null]], "Development Guide Using Docker": [[53, null]], "Development Guide for JIT Kernels": [[49, null]], "Diffusers Backend": [[91, "diffusers-backend"]], "Diffusion LLM": [[22, "diffusion-llm"]], "Diffusion Language Models": [[90, null]], "Diffusion Models": [[91, null]], "Disable NUMA Auto-Balancing": [[59, "disable-numa-auto-balancing"]], "Disable NUMA balancing": [[61, "disable-numa-balancing"]], "Distributed Computing": [[74, "distributed-computing"]], "Distributed environment warning": [[91, "distributed-environment-warning"]], "Docker": [[23, "docker"], [31, "docker"]], "Docs Workflow": [[0, "docs-workflow"]], "Documentation": [[71, "documentation"], [99, "documentation"]], "Documentation Style Guidelines": [[0, "documentation-style-guidelines"]], "Double Sparsity": [[22, "double-sparsity"]], "Download Weights": [[30, "download-weights"]], "Download image content": [[91, "download-image-content"]], "Download video content": [[91, "download-video-content"]], "Duration Buckets": [[23, "duration-buckets"]], "Dynamic Backend Loading": [[10, "dynamic-backend-loading"]], "Dynamic LoRA loading": [[14, "Dynamic-LoRA-loading"]], "Dynamic batch tokenizer": [[22, "dynamic-batch-tokenizer"]], "Dynamic inputs to fit static constraints of CUDA Graph": [[3, "dynamic-inputs-to-fit-static-constraints-of-cuda-graph"]], "EAGLE Decoding": [[25, "EAGLE-Decoding"]], "EAGLE Speculative Decoding": [[32, "eagle-speculative-decoding"], [35, "eagle-speculative-decoding"], [45, "eagle-speculative-decoding"]], "EAGLE-2 Decoding via Frequency-Ranked Speculative Sampling": [[25, "EAGLE-2-Decoding-via-Frequency-Ranked-Speculative-Sampling"]], "EAGLE-2 Decoding with torch.compile": [[25, "EAGLE-2-Decoding-with-torch.compile"]], "EAGLE-2 decoding": [[25, "EAGLE-2-decoding"]], "EAGLE-3 Decoding": [[25, "EAGLE-3-Decoding"]], "EBNF": [[26, "EBNF"], [26, "id2"], [26, "id6"], [27, "EBNF"], [27, "id2"], [27, "id6"]], "EP with Spectulative Decoding": [[7, "ep-with-spectulative-decoding"]], "EPD Disaggregation": [[6, null]], "Easy To Postpone Generation": [[24, "easy-to-postpone-generation"]], "Edit an image": [[91, "edit-an-image"]], "Embedding Models": [[67, "embedding-models"], [92, null]], "Enable Dynamic Chunking and Adjust Smoothing Factor for Ultra-long ITL": [[17, "enable-dynamic-chunking-and-adjust-smoothing-factor-for-ultra-long-itl"]], "Enabling Quantized KV Cache": [[19, "enabling-quantized-kv-cache"]], "Enabling cache for torch.compile": [[88, null]], "Encode (embedding model)": [[37, "Encode-(embedding-model)"]], "Encode prefill disaggregation": [[22, "encode-prefill-disaggregation"]], "End-to-end examples": [[50, "end-to-end-examples"]], "Endpoints": [[39, "endpoints"], [91, "endpoints"]], "Environment Setup": [[49, "environment-setup"]], "Environment Variables": [[74, null], [91, "environment-variables"]], "Environment Verification": [[71, "environment-verification"]], "Error Handling": [[89, "error-handling"]], "Evaluating New Models with SGLang": [[54, null]], "Evaluation": [[53, "evaluation"]], "Example Client Code Snippet": [[90, "example-client-code-snippet"]], "Example Client Request": [[97, "example-client-request"]], "Example Client Request (supports optional instruct, top_n, and return_documents)": [[97, "example-client-request-supports-optional-instruct-top-n-and-return-documents"]], "Example Configuration File": [[90, "example-configuration-file"]], "Example Configurations": [[4, "example-configurations"]], "Example Launch Command": [[90, "example-launch-command"]], "Example Usage": [[89, "example-usage"]], "Example Usage Commands": [[68, "example-usage-commands"]], "Example launch Command": [[93, "example-launch-command"], [96, "example-launch-command"], [98, "example-launch-command"], [100, "example-launch-command"]], "Example usage with the above optimizations:": [[33, "example-usage-with-the-above-optimizations"], [46, "example-usage-with-the-above-optimizations"]], "Example workflow": [[51, "example-workflow"]], "Example: DeepSeek-V3 Models": [[41, "Example:-DeepSeek-V3-Models"]], "Example: Implementing and Serving a Llama Wrapper Model": [[99, "example-implementing-and-serving-a-llama-wrapper-model"]], "Example: Qwen3 Models": [[41, "Example:-Qwen3-Models"]], "Example: Required Tool Choice": [[28, "Example:-Required-Tool-Choice"]], "Example: Running DeepSeek-V3.1-Terminus": [[68, "example-running-deepseek-v3-1-terminus"]], "Example: Running Llama-3.2-3B": [[68, "example-running-llama-3-2-3b"]], "Example: Running Ovis-Image-7B": [[91, "example-running-ovis-image-7b"]], "Example: Specific Function Choice": [[28, "Example:-Specific-Function-Choice"]], "Example: Switching LoRAs": [[91, "example-switching-loras"]], "Examples": [[7, "examples"], [7, "id1"], [23, "examples"], [23, "id9"], [47, "examples"], [50, "examples"], [59, "examples"]], "Examples of Offline Model Quantization": [[18, "examples-of-offline-model-quantization"]], "Execute the Tool": [[28, "Execute-the-Tool"]], "Expert Parallelism": [[7, null]], "Explicitly select devices": [[94, "explicitly-select-devices"]], "Extensible EP Framework": [[7, "extensible-ep-framework"]], "External Resources": [[71, "external-resources"]], "Extra Diffusers Arguments": [[91, "extra-diffusers-arguments"]], "FAQ": [[30, "faq"], [81, "faq"], [84, "faq"], [91, "faq"]], "FP4 Accuracy": [[19, "fp4-accuracy"]], "FP4 Format": [[19, "fp4-format"]], "FP8 (quantised) mode": [[33, "fp8-quantised-mode"], [46, "fp8-quantised-mode"]], "FP8 Accuracy": [[19, "fp8-accuracy"]], "FP8 Format": [[19, "fp8-format"]], "Feature Support Matrix": [[71, "feature-support-matrix"]], "Features": [[23, "features"]], "Fine-Grained Engine Sleep and Wake Up": [[24, "fine-grained-engine-sleep-and-wake-up"]], "Flush Cache": [[37, "Flush-Cache"]], "For Multi-Modal": [[22, "for-multi-modal"]], "For PD-Multiplexing": [[22, "for-pd-multiplexing"]], "For checkpoint decryption": [[22, "for-checkpoint-decryption"]], "Forcing Pythonic Tool Call Output Without a Chat Template": [[28, "Forcing-Pythonic-Tool-Call-Output-Without-a-Chat-Template"]], "Fork and clone the repository": [[52, "fork-and-clone-the-repository"], [60, "fork-and-clone-the-repository"]], "Format code with pre-commit": [[52, "format-code-with-pre-commit"], [60, "format-code-with-pre-commit"]], "Forward hooks": [[22, "forward-hooks"]], "Framework Overview": [[7, "framework-overview"]], "Frequently Asked Questions": [[75, "frequently-asked-questions"]], "Frontend Language": [[77, null], [77, null]], "Full Pipeline Profiling": [[91, "full-pipeline-profiling"]], "Full TLS Configuration Example": [[23, "full-tls-configuration-example"]], "Function Call Parsing": [[23, "function-call-parsing"]], "Function Calling / Tool Use": [[74, "function-calling-tool-use"]], "Function Calling and Reasoning Parser": [[31, "function-calling-and-reasoning-parser"]], "Function calling for DeepSeek Models": [[30, "function-calling-for-deepseek-models"]], "Future Works": [[14, "Future-Works"]], "GLM-4.6V / GLM-4.5V Usage": [[33, null]], "GPT OSS Usage": [[34, null]], "General Configuration": [[74, "general-configuration"]], "Generate": [[91, "generate"]], "Generate (text generation model)": [[37, "Generate-(text-generation-model)"]], "Generating Multiple Reproducible Responses": [[4, "generating-multiple-reproducible-responses"]], "Get Model Info": [[37, "Get-Model-Info"]], "Get Model Information": [[91, "get-model-information"]], "Get Server Info": [[37, "Get-Server-Info"]], "Get Started": [[58, null]], "Getting Token IDs": [[41, "Getting-Token-IDs"]], "Go Bindings": [[23, "go-bindings"]], "Greedy Token Selection": [[76, "greedy-token-selection"]], "Guidance about Dynamic Chunking": [[17, "guidance-about-dynamic-chunking"]], "HTTP API Usage": [[51, "http-api-usage"]], "HTTP server": [[22, "http-server"]], "Handle Tools": [[28, "Handle-Tools"], [28, "id1"]], "Hardware Platforms": [[58, null]], "Hardware-specific notes / recommendations": [[33, "hardware-specific-notes-recommendations"], [46, "hardware-specific-notes-recommendations"]], "Health Check": [[37, "Health-Check"]], "Health Checks": [[23, "health-checks"]], "HiCache System Design and Optimization": [[11, null]], "HiRadixTree: Metadata Organization in HiCache": [[11, "hiradixtree-metadata-organization-in-hicache"]], "Hierarchical KV Caching (HiCache)": [[9, null]], "Hierarchical cache": [[22, "hierarchical-cache"]], "Hierarchical sparse attention": [[22, "hierarchical-sparse-attention"]], "High Availability": [[23, "high-availability"]], "High Throughput": [[62, "high-throughput"], [62, "id2"]], "High-Performance Configuration: Qwen3-8B": [[71, "high-performance-configuration-qwen3-8b"]], "History and Data Connectors": [[23, "history-and-data-connectors"]], "Hook lifecycle and behavior": [[8, "hook-lifecycle-and-behavior"]], "Hook spec schema": [[8, "hook-spec-schema"]], "How to Contribute": [[71, "how-to-contribute"]], "How to Extend the Tracing Framework to Support Complex Tracing Scenarios": [[87, "how-to-extend-the-tracing-framework-to-support-complex-tracing-scenarios"]], "How to Generate a Report": [[91, "how-to-generate-a-report"]], "How to Support New Diffusion Models": [[91, "how-to-support-new-diffusion-models"]], "How to Support New Models": [[99, null]], "How to Support a New Language Model": [[99, "how-to-support-a-new-language-model"]], "How to Support a New Multimodal Large Language Model": [[99, "how-to-support-a-new-multimodal-large-language-model"]], "How to Trigger CI Tests": [[52, "how-to-trigger-ci-tests"], [60, "how-to-trigger-ci-tests"]], "How to add Tracing for slices you\u2019re interested in?": [[87, "how-to-add-tracing-for-slices-you-re-interested-in"]], "How to enable": [[28, "How-to-enable"]], "How to support a new model?": [[28, "How-to-support-a-new-model?"]], "How to update sgl-kernel": [[52, "how-to-update-sgl-kernel"], [60, "how-to-update-sgl-kernel"]], "How to update sgl-kernel-npu": [[60, "how-to-update-sgl-kernel-npu"]], "Hybrid attention (different backends for prefill vs decode) (Experimental)": [[1, "hybrid-attention-different-backends-for-prefill-vs-decode-experimental"]], "Hyperparameter Tuning": [[13, null]], "Image Generation": [[91, "image-generation"]], "Image Generation Models": [[91, "image-generation-models"]], "Image Reranking (text query, image/mixed documents)": [[97, "image-reranking-text-query-image-mixed-documents"]], "Image input:": [[33, "image-input"], [46, "image-input"]], "Image/Video Configuration": [[91, "image-video-configuration"]], "Implementation Details": [[89, "implementation-details"]], "Implementation Refactoring based on Async Communication": [[17, "implementation-refactoring-based-on-async-communication"]], "Implementing New Backends": [[7, "implementing-new-backends"]], "Implementing Our Model": [[99, "implementing-our-model"]], "Important Notes": [[51, "important-notes"]], "Important Server Parameters and Flags": [[33, "important-server-parameters-and-flags"], [46, "important-server-parameters-and-flags"]], "In sequence splitting (default setting)": [[31, "in-sequence-splitting-default-setting"]], "Inference Endpoints": [[23, "inference-endpoints"]], "Initialize the Client": [[28, "Initialize-the-Client"]], "Install Dependency": [[0, "install-dependency"]], "Install From Source": [[68, "install-from-source"], [72, "install-from-source"]], "Install SGLang": [[57, null], [59, "install-sglang"], [69, "install-sglang"]], "Install SGLang from Source": [[52, "install-sglang-from-source"], [60, "install-sglang-from-source"]], "Install SGLang-diffusion": [[91, "install-sglang-diffusion"]], "Install Using Docker": [[68, "install-using-docker"], [72, "install-using-docker"]], "Install Using Docker (Recommended)": [[59, "install-using-docker-recommended"]], "Install from Source": [[59, "install-from-source"], [69, "install-from-source"]], "Installation": [[2, "installation"], [18, "installation"], [23, "installation"], [23, "id5"], [23, "id8"], [31, "installation"], [68, "installation"], [71, "installation"], [72, "installation"], [91, "installation"], [94, "installation"]], "Installing SGLang from source": [[61, "installing-sglang-from-source"]], "Installing and running SGLang with Jetson Containers": [[70, "installing-and-running-sglang-with-jetson-containers"]], "Integer Range": [[49, "integer-range"]], "Integration with PD Disaggregation": [[10, "integration-with-pd-disaggregation"]], "Integration with PD-Disaggregation Deployment Mode": [[11, "integration-with-pd-disaggregation-deployment-mode"]], "Interactive Debugging": [[99, "interactive-debugging"]], "Introduction": [[94, "introduction"]], "Issues with Unified Scheduling": [[16, "issues-with-unified-scheduling"]], "JSON": [[26, "JSON"], [26, "id1"], [26, "id5"], [27, "JSON"], [27, "id1"], [27, "id5"]], "JSON Format": [[73, "json-format"]], "JSONL output format": [[50, "jsonl-output-format"]], "Jinja Format": [[73, "jinja-format"]], "Kernel Backends (Attention, Sampling, Grammar, GEMM)": [[22, "kernel-backends-attention-sampling-grammar-gemm"]], "Kernel Launching": [[49, "kernel-launching"]], "Key Configurations with Storage Backends Enabled": [[10, "key-configurations-with-storage-backends-enabled"]], "Key Features": [[91, "key-features"]], "Key Inference Metrics (gRPC mode)": [[23, "key-inference-metrics-grpc-mode"]], "Keys to success": [[80, "keys-to-success"]], "Known supported models": [[3, "known-supported-models"], [5, "known-supported-models"]], "Ktransformers": [[22, "ktransformers"]], "Kubernetes Deployment": [[23, "kubernetes-deployment"]], "Kubernetes Discovery": [[23, "kubernetes-discovery"]], "LLMs": [[54, "llms"], [54, "id1"]], "LMCache": [[22, "lmcache"]], "LWS Based PD Deploy": [[81, null]], "Language Bindings": [[23, "language-bindings"]], "Large Language Models": [[67, "large-language-models"], [93, null]], "Latency Optimization": [[71, "latency-optimization"]], "Latency Testing": [[71, "latency-testing"]], "Launch A Server": [[37, "Launch-A-Server"], [41, "Launch-A-Server"], [42, "Launch-A-Server"], [43, "Launch-A-Server"], [48, "Launch-A-Server"], [78, "Launch-A-Server"]], "Launch Command": [[97, "launch-command"], [97, "id1"], [97, "id2"]], "Launch Command for Different Attention Backends": [[1, "launch-command-for-different-attention-backends"]], "Launch DeepSeek V3.1/V3/R1 with SGLang": [[30, "launch-deepseek-v3-1-v3-r1-with-sglang"]], "Launch DeepSeek V3.2 with SGLang": [[31, "launch-deepseek-v3-2-with-sglang"]], "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang": [[32, null]], "Launch Llama 4 with SGLang": [[35, "launch-llama-4-with-sglang"]], "Launch Qwen3-Next with SGLang": [[45, "launch-qwen3-next-with-sglang"]], "Launch Server": [[92, "launch-server"]], "Launch commands for SGLang": [[33, "launch-commands-for-sglang"], [46, "launch-commands-for-sglang"]], "Launch of the Serving Engine": [[68, "launch-of-the-serving-engine"], [71, "launch-of-the-serving-engine"], [72, "launch-of-the-serving-engine"]], "Launch with one node of 8 x H200": [[30, "launch-with-one-node-of-8-x-h200"]], "Launching the Server": [[21, "Launching-the-Server"], [28, "Launching-the-Server"]], "Layer-wise NVTX Profiling with Nsight Systems": [[51, "layer-wise-nvtx-profiling-with-nsight-systems"]], "Learn More and Join the Community": [[79, null]], "Limitations": [[91, "limitations"]], "List LoRA Adapters": [[91, "list-lora-adapters"]], "List Workers": [[23, "list-workers"]], "List videos": [[91, "list-videos"]], "Llama 3.1 405B": [[82, "llama-3-1-405b"]], "Llama 4 Basic Call": [[29, "Llama-4-Basic-Call"]], "Llama Models": [[4, "llama-models"]], "Llama Single Node": [[16, "llama-single-node"], [16, "id3"], [16, "id7"]], "Llama4 Usage": [[35, null]], "LoRA": [[22, "lora"]], "LoRA GPU Pinning": [[14, "LoRA-GPU-Pinning"]], "LoRA Management": [[91, "lora-management"]], "LoRA Overlap Loading": [[14, "LoRA-Overlap-Loading"]], "LoRA Serving": [[14, null]], "Load Balancing Policies": [[23, "load-balancing-policies"]], "Load Balancing Router": [[24, "load-balancing-router"]], "Load Imbalance / Hot Workers": [[23, "load-imbalance-hot-workers"]], "Local Match": [[11, "local-match"]], "Logging": [[15, "logging"], [22, "logging"], [23, "logging"]], "Logit Bias Support": [[41, "Logit-Bias-Support"], [41, "id1"]], "Low Latency": [[62, "low-latency"], [62, "id1"]], "Low Throughput": [[71, "low-throughput"]], "MCP Configuration File": [[23, "mcp-configuration-file"]], "MCP Integration": [[23, "mcp-integration"]], "MHA Backends": [[1, "mha-backends"]], "MLA Backends": [[1, "mla-backends"]], "Make a release in GitHub": [[55, "make-a-release-in-github"]], "Mamba Cache": [[22, "mamba-cache"]], "Mamba Radix Cache": [[45, "mamba-radix-cache"]], "Matryoshka Embedding Example": [[92, "matryoshka-embedding-example"]], "MemFabric-Hybrid": [[61, "memfabric-hybrid"]], "Memory Growth": [[23, "memory-growth"]], "Memory Layout Optimization": [[10, "memory-layout-optimization"]], "Memory Management": [[74, "memory-management"]], "Memory Optimization": [[71, "memory-optimization"]], "Memory Savings": [[19, "memory-savings"]], "Memory and scheduling": [[22, "memory-and-scheduling"]], "Merge LoRA Weights": [[91, "merge-lora-weights"]], "Method 1: Installing from source with prerequisites": [[61, "method-1-installing-from-source-with-prerequisites"]], "Method 1: Using PyPI (Recommended)": [[71, "method-1-using-pypi-recommended"]], "Method 1: With pip or uv": [[57, "method-1-with-pip-or-uv"], [91, "method-1-with-pip-or-uv"]], "Method 2: From Source": [[71, "method-2-from-source"]], "Method 2: From source": [[57, "method-2-from-source"], [91, "method-2-from-source"]], "Method 2: Using Docker Image": [[61, "method-2-using-docker-image"]], "Method 3: Using Docker": [[71, "method-3-using-docker"], [91, "method-3-using-docker"]], "Method 3: Using docker": [[57, "method-3-using-docker"]], "Method 4: Cloud TPU with SkyPilot": [[71, "method-4-cloud-tpu-with-skypilot"]], "Method 4: Using Kubernetes": [[57, "method-4-using-kubernetes"]], "Method 5: Using docker compose": [[57, "method-5-using-docker-compose"]], "Method 6: Run on Kubernetes or Clouds with SkyPilot": [[57, "method-6-run-on-kubernetes-or-clouds-with-skypilot"]], "Method 7: Run on AWS SageMaker": [[57, "method-7-run-on-aws-sagemaker"]], "Methods": [[76, "methods"]], "Metric Categories (40+ metrics)": [[23, "metric-categories-40-metrics"]], "Metrics explained": [[50, "metrics-explained"]], "MindSpore Models": [[94, null]], "MiniMax M2.1/M2 Usage": [[36, null]], "MoE": [[22, "moe"]], "Model Deployment": [[62, "model-deployment"], [62, "id3"], [62, "id5"], [62, "id7"], [62, "id9"], [62, "id11"], [62, "id13"], [62, "id15"], [62, "id17"], [62, "id19"], [62, "id21"], [62, "id23"], [62, "id25"], [62, "id27"], [62, "id29"], [62, "id31"], [62, "id33"], [62, "id35"], [62, "id37"], [62, "id39"], [62, "id41"], [62, "id43"], [62, "id45"], [62, "id47"], [62, "id49"], [62, "id51"], [62, "id53"], [62, "id55"], [62, "id57"], [62, "id59"]], "Model Hooks": [[8, null]], "Model Thinking/Reasoning Support": [[41, "Model-Thinking/Reasoning-Support"]], "Model and tokenizer": [[22, "model-and-tokenizer"]], "Model override args": [[22, "model-override-args"]], "Model-Specific Behaviors": [[21, "Model-Specific-Behaviors"]], "Model-Specific Options": [[74, "model-specific-options"]], "Models x Optimization": [[91, "models-x-optimization"]], "Monitoring with PromQL": [[23, "monitoring-with-promql"]], "Mooncake": [[16, "mooncake"]], "Moore Threads GPUs": [[69, null]], "Motivation": [[3, "motivation"]], "Multi Token Prediction": [[25, "Multi-Token-Prediction"]], "Multi-Modal Embedding Model": [[42, "Multi-Modal-Embedding-Model"]], "Multi-Model Inference Gateway": [[23, "multi-model-inference-gateway"]], "Multi-Node Deployment": [[82, null], [83, null], [83, null]], "Multi-Node Distributed Serving": [[71, "multi-node-distributed-serving"]], "Multi-Node Inference on SLURM": [[82, "multi-node-inference-on-slurm"]], "Multi-Node Profiling and Shared Storage Considerations": [[51, "multi-node-profiling-and-shared-storage-considerations"]], "Multi-Node Setup (2 Nodes)": [[2, "multi-node-setup-2-nodes"]], "Multi-Node Setup with Tensor Parallelism (TP=16)": [[2, "multi-node-setup-with-tensor-parallelism-tp-16"]], "Multi-Node Tensor Parallelism": [[30, "multi-node-tensor-parallelism"]], "Multi-Rank Synchronization": [[11, "multi-rank-synchronization"]], "Multi-head Latent Attention (MLA) Throughput Optimizations": [[30, "multi-head-latent-attention-mla-throughput-optimizations"]], "Multi-layer Eagle speculative decoding": [[22, "multi-layer-eagle-speculative-decoding"]], "Multi-modal Generation": [[78, "Multi-modal-Generation"]], "Multi-node distributed serving": [[22, "multi-node-distributed-serving"]], "Multi-token Prediction": [[30, "multi-token-prediction"], [31, "multi-token-prediction"]], "Multi-turn Dialog": [[78, "Multi-turn-Dialog"]], "Multimodal": [[47, "multimodal"]], "Multimodal Embedding Example": [[92, "multimodal-embedding-example"]], "Multimodal Inputs Limitation": [[96, "multimodal-inputs-limitation"]], "Multimodal Language Models": [[67, "multimodal-language-models"], [96, null]], "Multimodal Query Reranking (query with image)": [[97, "multimodal-query-reranking-query-with-image"]], "Multiple-Image Inputs": [[43, "Multiple-Image-Inputs"]], "NCCL as backend": [[20, "nccl-as-backend"]], "NIXL": [[16, "nixl"]], "NIXL Backend Selection": [[16, "nixl-backend-selection"]], "NSA Backend Configuration (For DeepSeek V3.2)": [[74, "nsa-backend-configuration-for-deepseek-v3-2"]], "NVFP4 Checkpoint": [[31, "nvfp4-checkpoint"]], "NVIDIA Jetson Orin": [[70, null]], "NVLink Transport Configuration": [[16, "nvlink-transport-configuration"]], "Native API and SGLang Runtime (SRT)": [[26, "Native-API-and-SGLang-Runtime-(SRT)"], [27, "Native-API-and-SGLang-Runtime-(SRT)"], [28, "Native-API-and-SGLang-Runtime-(SRT)"]], "Nest Asyncio": [[38, "Nest-Asyncio"]], "Ngram speculative decoding": [[22, "ngram-speculative-decoding"]], "Non-FP8 (BF16 / full precision) mode": [[33, "non-fp8-bf16-full-precision-mode"], [46, "non-fp8-bf16-full-precision-mode"]], "Non-Streaming Request": [[21, "Non-Streaming-Request"], [28, "Non-Streaming-Request"]], "Non-streaming Asynchronous Generation": [[38, "Non-streaming-Asynchronous-Generation"]], "Non-streaming Synchronous Generation": [[38, "Non-streaming-Synchronous-Generation"]], "Normal": [[47, "normal"]], "Note on defaults": [[47, "note-on-defaults"]], "Notes": [[23, "notes"], [34, "notes"], [50, "notes"], [91, "notes"]], "Notes for ROCm / MPS": [[91, "notes-for-rocm-mps"]], "Nsight Systems": [[91, "nsight-systems"]], "OOM (Out of Memory) Errors": [[71, "oom-out-of-memory-errors"]], "Observability": [[15, null], [23, "observability"]], "Obtain CANN Image": [[61, "obtain-cann-image"]], "Obtain Image": [[61, "obtain-image"]], "Offline Batch Inference": [[38, "Offline-Batch-Inference"]], "Offline Engine API": [[21, "Offline-Engine-API"], [26, "Offline-Engine-API"], [27, "Offline-Engine-API"], [28, "Offline-Engine-API"], [38, null]], "Offline Quantization": [[18, "offline-quantization"]], "Offline infer": [[94, "offline-infer"]], "Offloading": [[22, "offloading"]], "Ollama-Compatible API": [[39, null]], "Online Quantization": [[18, "online-quantization"]], "Open-To-Use Refit Functionality": [[24, "open-to-use-refit-functionality"]], "OpenAI APIs - Completions": [[41, null]], "OpenAI APIs - Embedding": [[42, null]], "OpenAI APIs - Vision": [[43, null]], "OpenAI Backend Proxy": [[23, "openai-backend-proxy"]], "OpenAI Compatible API": [[21, "OpenAI-Compatible-API"], [26, "OpenAI-Compatible-API"], [27, "OpenAI-Compatible-API"], [28, "OpenAI-Compatible-API"]], "OpenAI-Compatible APIs": [[40, null]], "OpenAI-compatible API usage": [[14, "OpenAI-compatible-API-usage"]], "OpenTelemetry Tracing": [[23, "opentelemetry-tracing"]], "Optimal Configuration": [[62, "optimal-configuration"]], "Optimization/debug options": [[22, "optimization-debug-options"]], "Optimizations": [[30, "optimizations"]], "Optimized Model List": [[68, "optimized-model-list"], [71, "optimized-model-list"], [72, "optimized-model-list"]], "Option 1. Use the default dev container automatically from VSCode": [[53, "option-1-use-the-default-dev-container-automatically-from-vscode"]], "Option 2. Start up containers manually (advanced)": [[53, "option-2-start-up-containers-manually-advanced"]], "Oracle Configuration": [[23, "oracle-configuration"]], "Other key options": [[50, "other-key-options"]], "Other options": [[47, "other-options"]], "Other tips": [[51, "other-tips"]], "Output Files": [[51, "output-files"]], "Output Location": [[91, "output-location"]], "Output Options": [[91, "output-options"]], "Overall Architecture": [[11, "overall-architecture"]], "Overall Workflow": [[11, "overall-workflow"]], "Overview": [[2, "overview"], [23, "overview"], [23, "id4"], [89, "overview"], [91, "overview"], [91, "id3"]], "PD Disaggregation": [[16, null], [31, "pd-disaggregation"]], "PD Disaggregation with PP + CP": [[31, "pd-disaggregation-with-pp-cp"]], "PD Mixed Scene": [[61, "pd-mixed-scene"], [61, "id1"]], "PD Mode Discovery": [[23, "pd-mode-discovery"]], "PD Separation Scene": [[61, "pd-separation-scene"]], "PD disaggregation": [[22, "pd-disaggregation"]], "Parallelism": [[78, "Parallelism"]], "Parameters": [[41, "Parameters"], [41, "id3"], [89, "parameters"]], "Parser Endpoints": [[23, "parser-endpoints"]], "Pause Generation": [[24, "pause-generation"]], "Penalizers": [[47, "penalizers"]], "Performance": [[23, "performance"], [54, "performance"]], "Performance Benefits": [[2, "performance-benefits"]], "Performance Considerations": [[19, "performance-considerations"]], "Performance Highlights": [[25, "Performance-Highlights"]], "Performance Optimization": [[71, "performance-optimization"], [96, "performance-optimization"]], "Performance Tips": [[91, "performance-tips"]], "Performance Tuning": [[74, "performance-tuning"]], "Pipeline Parallel + Context Parallel (PP + CP)": [[31, "pipeline-parallel-context-parallel-pp-cp"]], "Pipeline Parallelism for Long Context": [[17, null]], "Platform support matrix": [[91, "platform-support-matrix"]], "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)": [[44, null]], "Port a Model from vLLM to SGLang": [[99, "port-a-model-from-vllm-to-sglang"]], "Possible PyTorch bugs": [[51, "possible-pytorch-bugs"]], "Post-Training Integration": [[85, null]], "PostgreSQL Configuration": [[23, "postgresql-configuration"]], "Prefetch Policies": [[10, "prefetch-policies"]], "Prefetch from L3": [[11, "prefetch-from-l3"]], "Prefill": [[81, "prefill"]], "Prefill Server Configuration": [[16, "prefill-server-configuration"]], "Prefill-Decode Disaggregation": [[23, "prefill-decode-disaggregation"]], "Prefill/Decode": [[23, "prefill-decode"]], "Prepare Environment": [[60, "prepare-environment"]], "Preparing the Running Environment": [[61, "preparing-the-running-environment"]], "Prerequisites": [[23, "prerequisites"], [39, "prerequisites"], [50, "prerequisites"], [70, "prerequisites"], [80, "prerequisites"], [86, "prerequisites"], [91, "prerequisites"]], "Prevent swapping out system memory": [[61, "prevent-swapping-out-system-memory"]], "Production Metrics": [[15, "production-metrics"], [86, null]], "Production Recommendations": [[23, "production-recommendations"]], "Production Request Tracing": [[87, null]], "Profile": [[53, "profile"]], "Profile Decode Workers": [[51, "profile-decode-workers"]], "Profile In PD Disaggregation Mode": [[51, "profile-in-pd-disaggregation-mode"]], "Profile Prefill Workers": [[51, "profile-prefill-workers"]], "Profile a server with HTTP API endpoints": [[51, "profile-a-server-with-http-api-endpoints"]], "Profile a server with sglang.bench_offline_throughput": [[51, "profile-a-server-with-sglang-bench-offline-throughput"]], "Profile a server with sglang.bench_serving": [[51, "profile-a-server-with-sglang-bench-serving"]], "Profile a server with sglang.profiler": [[51, "profile-a-server-with-sglang-profiler"]], "Profile with Nsight": [[51, "profile-with-nsight"]], "Profile with PyTorch Profiler": [[51, "profile-with-pytorch-profiler"]], "Profiler Trace Merger for Distributed Traces": [[51, "profiler-trace-merger-for-distributed-traces"]], "Profiling & Benchmarking": [[74, "profiling-benchmarking"]], "Profiling Multimodal Generation": [[91, "profiling-multimodal-generation"]], "Profiling in PD Disaggregation Mode": [[16, "profiling-in-pd-disaggregation-mode"]], "Prometheus Metrics": [[23, "prometheus-metrics"]], "PyPI Package Release Process": [[55, null]], "PyTorch Profiler": [[91, "pytorch-profiler"]], "Python API Usage": [[18, "python-api-usage"]], "Python Bindings": [[23, "python-bindings"]], "Python Interface": [[49, "python-interface"]], "Python Package": [[23, "python-package"]], "Python Tool": [[34, "python-tool"]], "Python Version": [[61, "python-version"]], "Pythonic Tool Call Format (Llama-3.2 / Llama-3.3 / Llama-4)": [[28, "Pythonic-Tool-Call-Format-(Llama-3.2-/-Llama-3.3-/-Llama-4)"]], "Pytorch and Pytorch Framework Adaptor on Ascend": [[61, "pytorch-and-pytorch-framework-adaptor-on-ascend"]], "Quantization": [[18, null], [74, "quantization"], [100, "quantization"]], "Quantization and Export Workflow": [[18, "quantization-and-export-workflow"]], "Quantization and data type": [[22, "quantization-and-data-type"]], "Quantized KV Cache": [[19, null]], "Query VLM with Offline Engine": [[29, null]], "Querying Llama 4 Vision Model": [[29, "Querying-Llama-4-Vision-Model"]], "Querying Qwen2.5-VL Model": [[29, "Querying-Qwen2.5-VL-Model"]], "Queue Overflow (429)": [[23, "queue-overflow-429"]], "Quick Demo": [[34, "quick-demo"]], "Quick Start": [[23, "quick-start"], [39, "quick-start"], [92, "quick-start"]], "Quick start": [[50, "quick-start"]], "Qwen Series Models": [[62, "qwen-series-models"]], "Qwen VL": [[6, "qwen-vl"]], "Qwen3 235B High Throughput 50ms 1": [[62, "qwen3-235b-high-throughput-50ms-1"]], "Qwen3 235B High Throughput 50ms 2": [[62, "qwen3-235b-high-throughput-50ms-2"]], "Qwen3 235B High Throughput 50ms 3": [[62, "qwen3-235b-high-throughput-50ms-3"]], "Qwen3 235B High Throughput 50ms 4": [[62, "qwen3-235b-high-throughput-50ms-4"]], "Qwen3 235B Low Latency 10ms": [[62, "qwen3-235b-low-latency-10ms"]], "Qwen3 32B A2 High Throughput 50ms 1": [[62, "qwen3-32b-a2-high-throughput-50ms-1"]], "Qwen3 32B A2 High Throughput 50ms 2": [[62, "qwen3-32b-a2-high-throughput-50ms-2"]], "Qwen3 32B A2 Low Latency 11ms": [[62, "qwen3-32b-a2-low-latency-11ms"]], "Qwen3 32B A2 Low Latency 18ms": [[62, "qwen3-32b-a2-low-latency-18ms"]], "Qwen3 32B High Throughput 50ms 1": [[62, "qwen3-32b-high-throughput-50ms-1"]], "Qwen3 32B High Throughput 50ms 2": [[62, "qwen3-32b-high-throughput-50ms-2"]], "Qwen3 32B High Throughput 50ms 3": [[62, "qwen3-32b-high-throughput-50ms-3"]], "Qwen3 32B Low Latency 11ms": [[62, "qwen3-32b-low-latency-11ms"]], "Qwen3 32B Low Latency 12ms": [[62, "qwen3-32b-low-latency-12ms"]], "Qwen3 32B Low Latency 18ms": [[62, "qwen3-32b-low-latency-18ms"]], "Qwen3 480B High Throughput 50ms 1": [[62, "qwen3-480b-high-throughput-50ms-1"]], "Qwen3 480B High Throughput 50ms 2": [[62, "qwen3-480b-high-throughput-50ms-2"]], "Qwen3 480B High Throughput 50ms 3": [[62, "qwen3-480b-high-throughput-50ms-3"]], "Qwen3 Next High Throughput 50ms": [[62, "qwen3-next-high-throughput-50ms"]], "Qwen3 examples": [[65, null]], "Qwen3-235B Atlas 800I A3-8Card PD Mixed 2K-2K 100ms": [[62, "qwen3-235b-atlas-800i-a3-8card-pd-mixed-2k-2k-100ms"]], "Qwen3-235B-A22B-FP8 with 128K Input Token Length": [[17, "qwen3-235b-a22b-fp8-with-128k-input-token-length"]], "Qwen3-30B-A3B (MoE Model)": [[4, "qwen3-30b-a3b-moe-model"]], "Qwen3-8B": [[4, "qwen3-8b"]], "Qwen3-Next Usage": [[45, null]], "Qwen3-Reranker (decoder-only yes/no rerank)": [[97, "qwen3-reranker-decoder-only-yes-no-rerank"]], "Qwen3-VL Usage": [[46, null]], "Qwen3-VL-Reranker (multimodal decoder-only rerank)": [[97, "qwen3-vl-reranker-multimodal-decoder-only-rerank"]], "R-Fork": [[20, null]], "RDMA RoCE case": [[80, "rdma-roce-case"]], "ROCm quickstart for sgl-diffusion": [[91, "rocm-quickstart-for-sgl-diffusion"]], "Rate Limiting and Queuing": [[23, "rate-limiting-and-queuing"]], "Rate, concurrency, and streaming": [[50, "rate-concurrency-and-streaming"]], "Reasoning Content for DeepSeek R1 & V3.1": [[30, "reasoning-content-for-deepseek-r1-v3-1"]], "Reasoning Parser": [[21, null]], "Reasoning Parser Integration": [[23, "reasoning-parser-integration"]], "Redis Configuration": [[23, "redis-configuration"]], "Reference": [[18, "reference"]], "References": [[2, "references"], [25, "References"], [58, null], [70, "references"], [71, "references"], [91, "references"], [91, "id5"]], "Registering an External Model Implementation": [[99, "registering-an-external-model-implementation"]], "Regular HTTP Routing": [[23, "regular-http-routing"]], "Regular expression": [[26, "Regular-expression"], [26, "id3"], [26, "id7"], [27, "Regular-expression"], [27, "id3"], [27, "id7"]], "Related Parameters": [[11, "related-parameters"]], "Release Memory": [[24, "release-memory"]], "Reliability and Flow Control": [[23, "reliability-and-flow-control"]], "Remaining issues": [[80, "remaining-issues"]], "Remote code": [[100, "remote-code"]], "Reporting Results": [[54, "reporting-results"]], "Request": [[23, "request"]], "Request Dump and Replay": [[15, "request-dump-and-replay"]], "Request Format": [[89, "request-format"]], "Request ID Propagation": [[23, "request-id-propagation"]], "Request Parameters (Multimodal)": [[97, "request-parameters-multimodal"]], "RequestMetricsExporter configuration": [[22, "requestmetricsexporter-configuration"]], "Requesting a review for merge": [[52, "requesting-a-review-for-merge"], [60, "requesting-a-review-for-merge"]], "Requirements": [[16, "requirements"], [16, "id1"], [94, "requirements"]], "Rerank Models": [[67, "rerank-models"], [97, null]], "Response": [[23, "response"], [23, "id1"]], "Response Fields": [[23, "response-fields"], [89, "response-fields"]], "Response Format": [[89, "response-format"], [97, "response-format"]], "Responses API": [[34, "responses-api"]], "Responses API & Built-in Tools": [[34, "responses-api-built-in-tools"]], "Resume Memory": [[24, "resume-memory"]], "Retries": [[23, "retries"]], "Returning Routed Experts (MoE Models)": [[41, "Returning-Routed-Experts-(MoE-Models)"], [41, "id4"]], "Reward Models": [[67, "reward-models"], [98, null]], "Reward Models (Single score)": [[89, "reward-models-single-score"]], "RoCE scenario": [[80, "roce-scenario"]], "Rotary buffer management": [[3, "rotary-buffer-management"]], "Round robin splitting": [[31, "round-robin-splitting"]], "Router API Key": [[23, "router-api-key"]], "Router Integration": [[16, "router-integration"]], "Run Model": [[94, "run-model"]], "Run and add unit tests": [[52, "run-and-add-unit-tests"], [60, "run-and-add-unit-tests"]], "Running DeepSeek in PD mixed mode on 1 x Atlas 800I A3.": [[63, "running-deepseek-in-pd-mixed-mode-on-1-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation mode on 2 x Atlas 800I A3.": [[63, "running-deepseek-with-pd-disaggregation-mode-on-2-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3.": [[63, "running-deepseek-with-pd-disaggregation-on-4-x-atlas-800i-a3"]], "Running DeepSeek-V3": [[59, "running-deepseek-v3"], [63, "running-deepseek-v3"]], "Running Inference": [[70, "running-inference"]], "Running Llama3.1": [[59, "running-llama3-1"]], "Running Qwen3": [[65, "running-qwen3"]], "Running Qwen3-235B-A22B-Instruct-2507 MOE on 1 x Atlas 800I A3.": [[65, "running-qwen3-235b-a22b-instruct-2507-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-30B-A3B MOE on 1 x Atlas 800I A3.": [[65, "running-qwen3-30b-a3b-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-32B on 1 x Atlas 800I A3 with Qwen3-32B-Eagle3.": [[65, "running-qwen3-32b-on-1-x-atlas-800i-a3-with-qwen3-32b-eagle3"]], "Running Qwen3-32B on 1 x Atlas 800I A3.": [[65, "running-qwen3-32b-on-1-x-atlas-800i-a3"]], "Running Qwen3-VL-8B-Instruct on 1 x Atlas 800I A3.": [[65, "running-qwen3-vl-8b-instruct-on-1-x-atlas-800i-a3"]], "Running SGLang Service": [[61, "running-sglang-service"]], "Running Service For Large Language Models": [[61, "running-service-for-large-language-models"]], "Running Service For Multimodal Language Models": [[61, "running-service-for-multimodal-language-models"]], "Running examples on Multi-Node": [[30, "running-examples-on-multi-node"]], "Running quantization with TorchAO": [[70, "running-quantization-with-torchao"]], "Runtime Attach/Detach HiCache Storage Backend (No Restart)": [[12, null]], "Runtime Checking": [[49, "runtime-checking"]], "Runtime Configuration": [[23, "runtime-configuration"]], "Runtime options": [[22, "runtime-options"]], "Rust Binary": [[23, "rust-binary"]], "SCM (Step Computation Masking)": [[91, "scm-step-computation-masking"]], "SCM Policy": [[91, "scm-policy"]], "SCM Presets": [[91, "scm-presets"]], "SCM disabled for low step count": [[91, "scm-disabled-for-low-step-count"]], "SGLang Diffusion OpenAI API": [[91, "sglang-diffusion-openai-api"]], "SGLang Documentation": [[0, null], [58, null]], "SGLang Frontend Language": [[78, null]], "SGLang HiCache Best Practices": [[10, null]], "SGLang Kernels NPU": [[61, "sglang-kernels-npu"]], "SGLang Model Gateway": [[23, null]], "SGLang Native API": [[21, "SGLang-Native-API"]], "SGLang Native APIs": [[37, null]], "SGLang Server Options": [[2, "sglang-server-options"]], "SGLang diffusion CLI Inference": [[91, "sglang-diffusion-cli-inference"]], "SGLang for RL Systems": [[24, null]], "SGLang installation with NPUs support": [[61, null]], "SGLang\u2019s Solution": [[4, "sglang-s-solution"]], "STEP 1: Write the C++ kernel": [[49, "step-1-write-the-c-kernel"]], "STEP 2: Create Python Interfaces": [[49, "step-2-create-python-interfaces"]], "STEP 3: Use your kernel": [[49, "step-3-use-your-kernel"]], "Sampling Parameters": [[47, null], [91, "sampling-parameters"]], "Sampling parameters": [[47, "id1"]], "Scaling Factors": [[19, "scaling-factors"]], "Security Best Practices": [[23, "security-best-practices"]], "Security Configurations": [[23, "security-configurations"]], "Security and Authentication": [[23, "security-and-authentication"]], "Select a backend via CLI": [[91, "select-a-backend-via-cli"]], "Selection priority": [[91, "selection-priority"]], "Send Results Back to Model": [[28, "Send-Results-Back-to-Model"]], "Sending Image/Video Requests": [[33, "sending-image-video-requests"], [46, "sending-image-video-requests"]], "Sending Requests": [[48, null]], "Separate Launch (HTTP)": [[23, "separate-launch-http"]], "Separate Reasoning Request": [[23, "separate-reasoning-request"]], "Serve": [[91, "serve"], [91, "id1"]], "Server Arguments": [[4, "server-arguments"], [22, null], [91, "server-arguments"]], "Server flag": [[24, "server-flag"]], "Service Discovery (Kubernetes)": [[23, "service-discovery-kubernetes"]], "Serving Multiple Adaptors": [[14, "Serving-Multiple-Adaptors"]], "Serving Our Model Via SGLang\u2019s Offline Engine": [[99, "serving-our-model-via-sglang-s-offline-engine"]], "Serving Single Adaptor": [[14, "Serving-Single-Adaptor"]], "Set LoRA Adapter": [[91, "set-lora-adapter"]], "Set Up Self-Hosted Runners for GitHub Action": [[56, null]], "Setup Docker Container": [[53, "setup-docker-container"]], "Setup Guide": [[86, "setup-guide"], [87, "setup-guide"]], "Setup VSCode on a Remote Host": [[53, "setup-vscode-on-a-remote-host"]], "Single Node Setup": [[2, "single-node-setup"]], "Single-Batch Overlap (SBO)": [[7, "single-batch-overlap-sbo"]], "Smart Router": [[39, "smart-router"]], "Software Requirements": [[71, "software-requirements"]], "Some communication environment issues": [[94, "some-communication-environment-issues"]], "Some dependencies of protobuf": [[94, "some-dependencies-of-protobuf"]], "Special Requirements": [[91, "special-requirements"]], "Speculative Decoding": [[25, null], [34, "speculative-decoding"], [71, "speculative-decoding"]], "Speculative decoding": [[22, "speculative-decoding"]], "Speculative decoding with hybrid attention": [[1, "speculative-decoding-with-hybrid-attention"]], "Stable addresses": [[3, "stable-addresses"]], "Standard Usage": [[31, "standard-usage"]], "Start server": [[94, "start-server"]], "Start the server": [[91, "start-the-server"], [91, "id2"]], "Step 1: Start a docker container.": [[56, "step-1-start-a-docker-container"]], "Step 2: Configure the runner by config.sh": [[56, "step-2-configure-the-runner-by-config-sh"]], "Step 3: Run the runner by run.sh": [[56, "step-3-run-the-runner-by-run-sh"]], "Steps to add a new attention backend": [[1, "steps-to-add-a-new-attention-backend"]], "Storage & Caching": [[74, "storage-caching"]], "Storage and Privacy": [[23, "storage-and-privacy"]], "Streaming": [[47, "streaming"], [48, "Streaming"], [48, "id1"], [78, "Streaming"]], "Streaming Asynchronous Generation": [[38, "Streaming-Asynchronous-Generation"]], "Streaming Request": [[21, "Streaming-Request"], [28, "Streaming-Request"]], "Streaming Synchronous Generation": [[38, "Streaming-Synchronous-Generation"]], "Structural Tag": [[26, "Structural-Tag"], [26, "id4"], [26, "id8"], [27, "Structural-Tag"], [27, "id4"]], "Structured Outputs": [[26, null]], "Structured Outputs (JSON, Regex, EBNF)": [[41, "Structured-Outputs-(JSON,-Regex,-EBNF)"], [47, "structured-outputs-json-regex-ebnf"]], "Structured Outputs For Reasoning Models": [[27, null]], "Structured output with XGrammar": [[70, "structured-output-with-xgrammar"]], "Summary": [[8, "summary"], [39, "summary"]], "Support": [[94, "support"]], "Support Matrix": [[1, "support-matrix"]], "Support Models on Ascend NPU": [[67, null]], "Supported Arguments": [[91, "supported-arguments"]], "Supported Backends": [[4, "supported-backends"]], "Supported Backends and Selection Guidance": [[7, "supported-backends-and-selection-guidance"]], "Supported Formats": [[19, "supported-formats"], [23, "supported-formats"]], "Supported Models": [[27, "Supported-Models"], [36, "supported-models"], [58, null], [89, "supported-models"], [90, "supported-models"], [91, "supported-models"], [92, "supported-models"], [94, "supported-models"]], "Supported Models & Parsers": [[21, "Supported-Models-&-Parsers"]], "Supported Models and Configuration": [[41, "Supported-Models-and-Configuration"]], "Supported Parsers": [[23, "supported-parsers"]], "Supported TPU Hardware": [[71, "supported-tpu-hardware"]], "Supported Tool Choice Options": [[28, "Supported-Tool-Choice-Options"]], "Supported Transports": [[23, "supported-transports"]], "Supported backends and endpoints": [[50, "supported-backends-and-endpoints"]], "Supported features": [[100, "supported-features"]], "Supported models": [[93, "supported-models"], [96, "supported-models"], [98, "supported-models"]], "Supported rerank models": [[97, "supported-rerank-models"]], "Supporting New Reasoning Model Schemas": [[21, "Supporting-New-Reasoning-Model-Schemas"]], "System Configuration": [[59, "system-configuration"]], "System Design": [[11, "system-design"]], "System Requirements": [[36, "system-requirements"], [71, "system-requirements"]], "System Settings": [[61, "system-settings"]], "TLS (HTTPS) for Gateway Server": [[23, "tls-https-for-gateway-server"]], "TLS Configuration": [[23, "tls-configuration"]], "TODO": [[80, "todo"]], "TPU": [[71, null]], "TPU-Specific Optimizations": [[71, "tpu-specific-optimizations"]], "Table of Contents": [[23, "table-of-contents"]], "Targeted Stage Profiling": [[91, "targeted-stage-profiling"]], "TaylorSeer Configuration": [[91, "taylorseer-configuration"]], "Tensor Checking": [[49, "tensor-checking"]], "Test the accuracy": [[52, "test-the-accuracy"], [60, "test-the-accuracy"]], "Testing": [[23, "testing"], [89, "testing"]], "Testing & Debugging (Internal/CI)": [[74, "testing-debugging-internal-ci"]], "Testing Deployment": [[36, "testing-deployment"]], "Testing and Debugging": [[99, "testing-and-debugging"]], "Testing on TPU": [[71, "testing-on-tpu"]], "Text-Only Reranking (backward compatible)": [[97, "text-only-reranking-backward-compatible"]], "The Root Cause of Non-Determinism": [[4, "the-root-cause-of-non-determinism"]], "The results are not deterministic, even with a temperature of 0": [[75, "the-results-are-not-deterministic-even-with-a-temperature-of-0"]], "The server hangs": [[75, "the-server-hangs"]], "Thinking Budget for DeepSeek R1": [[30, "thinking-budget-for-deepseek-r1"]], "Thinking Budget for GLM-4.5 / GLM-4.6": [[32, "thinking-budget-for-glm-4-5-glm-4-6"]], "Thinking Budget for GLM-4.5V / GLM-4.6V": [[33, "thinking-budget-for-glm-4-5v-glm-4-6v"]], "Throughput Optimization": [[71, "throughput-optimization"]], "Throughput Testing": [[71, "throughput-testing"]], "Tips for newcomers": [[52, "tips-for-newcomers"], [60, "tips-for-newcomers"]], "Token Length Normalized": [[76, "token-length-normalized"]], "Tokenization Endpoints": [[23, "tokenization-endpoints"]], "Tokenize Request": [[23, "tokenize-request"]], "Tokenize Response": [[23, "tokenize-response"]], "Tokenize/Detokenize Example (Round Trip)": [[37, "Tokenize/Detokenize-Example-(Round-Trip)"]], "Tokenizer Caching": [[23, "tokenizer-caching"]], "Tokenizer Loading Failures": [[23, "tokenizer-loading-failures"]], "Tokenizer Management": [[23, "tokenizer-management"]], "Tokenizer Sources": [[23, "tokenizer-sources"]], "Tool & Reasoning Parser": [[34, "tool-reasoning-parser"]], "Tool Call Parsing": [[23, "tool-call-parsing"]], "Tool Choice Mode": [[28, "Tool-Choice-Mode"]], "Tool Parser": [[28, null]], "Top-level fields": [[8, "top-level-fields"]], "TransferEngine as backend": [[20, "transferengine-as-backend"]], "Transformers fallback in SGLang": [[100, null]], "Triton on Ascend": [[61, "triton-on-ascend"]], "Troubleshooting": [[2, "troubleshooting"], [23, "troubleshooting"], [50, "troubleshooting"], [71, "troubleshooting"], [75, "troubleshooting"], [86, "troubleshooting"], [91, "troubleshooting"], [94, "troubleshooting"]], "Troubleshooting and Frequently Asked Questions": [[75, null]], "Try other options": [[13, "try-other-options"]], "Tune --cuda-graph-max-bs": [[13, "tune-cuda-graph-max-bs"]], "Tune --dp-size and --tp-size": [[13, "tune-dp-size-and-tp-size"]], "Tune --mem-fraction-static to increase KV cache pool capacity": [[13, "tune-mem-fraction-static-to-increase-kv-cache-pool-capacity"]], "Tuning the Chunked Prefill Size": [[17, "tuning-the-chunked-prefill-size"]], "Two-Batch Overlap (TBO)": [[7, "two-batch-overlap-tbo"]], "Unconditional Likelihood Normalized": [[76, "unconditional-likelihood-normalized"]], "Understanding the Three Input Formats": [[29, "Understanding-the-Three-Input-Formats"]], "Unified Interfaces and Rich L3 Storage Backends": [[11, "unified-interfaces-and-rich-l3-storage-backends"]], "Unmerge LoRA Weights": [[91, "unmerge-lora-weights"]], "Update Documentation": [[0, "update-documentation"]], "Update GRUB Settings": [[59, "update-grub-settings"]], "Update Weights From Disk": [[37, "Update-Weights-From-Disk"]], "Update Weights from Disk": [[24, "update-weights-from-disk"]], "Update Weights from Distributed Group": [[24, "update-weights-from-distributed-group"]], "Update Weights from Tensor": [[24, "update-weights-from-tensor"]], "Update the version in code": [[55, "update-the-version-in-code"]], "Upload the PyPI package": [[55, "upload-the-pypi-package"]], "Usage": [[4, "usage"], [6, "usage"], [14, "Usage"], [16, "usage"], [16, "id2"], [16, "id6"], [19, "usage"], [20, "usage"], [21, "Usage"], [23, "usage"], [23, "id2"], [23, "id6"], [27, "Usage"], [41, "Usage"], [41, "id2"], [86, "usage"], [91, "usage"], [91, "id4"]], "Usage Examples": [[2, "usage-examples"]], "Usage Notes": [[96, "usage-notes"]], "Use Models From ModelScope": [[95, null]], "User Guide": [[1, "user-guide"]], "Using --enable-layerwise-nvtx-marker with Nsight Systems and /start_profile": [[51, "using-enable-layerwise-nvtx-marker-with-nsight-systems-and-start-profile"]], "Using /end_profile endpoint": [[51, "using-end-profile-endpoint"]], "Using /start_profile endpoint": [[51, "using-start-profile-endpoint"]], "Using Configuration Files": [[91, "using-configuration-files"]], "Using GPTQModel": [[18, "using-gptqmodel"]], "Using Input IDs": [[42, "Using-Input-IDs"]], "Using LLM Compressor": [[18, "using-llm-compressor"]], "Using LoRA Adapters": [[41, "Using-LoRA-Adapters"]], "Using NVIDIA ModelOpt": [[18, "using-nvidia-modelopt"]], "Using Native Generation APIs": [[48, "Using-Native-Generation-APIs"]], "Using OpenAI Python Client": [[42, "Using-OpenAI-Python-Client"], [43, "Using-OpenAI-Python-Client"], [48, "Using-OpenAI-Python-Client"]], "Using Python": [[89, "using-python"]], "Using Python Requests": [[42, "Using-Python-Requests"], [43, "Using-Python-Requests"], [48, "Using-Python-Requests"]], "Using Sliding Tile Attention (STA)": [[91, "using-sliding-tile-attention-sta"]], "Using Unsloth": [[18, "using-unsloth"]], "Using auto-round": [[18, "using-auto-round"]], "Using cURL": [[42, "Using-cURL"], [43, "Using-cURL"], [48, "Using-cURL"]], "Using curl": [[89, "using-curl"]], "VLMs": [[54, "vlms"]], "Verification": [[4, "verification"]], "Verified LoRA Examples": [[91, "verified-lora-examples"]], "Verified LoRAs by Base Model": [[91, "verified-loras-by-base-model"]], "Video Generation": [[91, "video-generation"]], "Video Generation Models": [[91, "video-generation-models"]], "Video Input Support": [[96, "video-input-support"]], "Video Input:": [[33, "video-input"], [46, "video-input"]], "View Traces": [[91, "view-traces"]], "View traces": [[51, "view-traces"]], "WASM Middleware": [[23, "wasm-middleware"]], "Warmup Step": [[59, "warmup-step"]], "Web Search Tool": [[34, "web-search-tool"]], "What it does": [[50, "what-it-does"]], "Why Deterministic Inference Matters": [[4, "why-deterministic-inference-matters"]], "Why Dynamic Chunking": [[17, "why-dynamic-chunking"]], "Why HiCache Matters": [[10, "why-hicache-matters"]], "Why Pipeline Parallelism?": [[17, "why-pipeline-parallelism"]], "Why SGLang for RL Lifecycle?": [[24, "why-sglang-for-rl-lifecycle"]], "Why and What is EPD Disaggregation?": [[6, "why-and-what-is-epd-disaggregation"]], "Why and What is HiCache?": [[11, "why-and-what-is-hicache"]], "Why and What is PD Disaggregation?": [[16, "why-and-what-is-pd-disaggregation"]], "Worker API Keys": [[23, "worker-api-keys"]], "Worker Management APIs": [[23, "worker-management-apis"]], "Workers Never Ready": [[23, "workers-never-ready"]], "Workload Balancer": [[7, "workload-balancer"]], "Write documentations": [[52, "write-documentations"], [60, "write-documentations"]], "Writing a hook factory": [[8, "writing-a-hook-factory"]], "XPU": [[72, null]], "config (optional)": [[8, "config-optional"]], "gRPC Connection Issues": [[23, "grpc-connection-issues"]], "gRPC Launch": [[23, "grpc-launch"]], "gRPC Routing": [[23, "grpc-routing"]], "hook_factory (required)": [[8, "hook-factory-required"]], "mTLS for Worker Communication": [[23, "mtls-for-worker-communication"]], "name (optional)": [[8, "name-optional"]], "quark_int4fp8_moe online quantization method": [[18, "quark-int4fp8-moe-online-quantization-method"]], "target_modules (required)": [[8, "target-modules-required"]], "test gsm8k": [[63, "test-gsm8k"]], "torchao online quantization method": [[18, "torchao-online-quantization-method"]], "v1/rerank (cross encoder rerank model)": [[37, "v1/rerank-(cross-encoder-rerank-model)"]], "v1/score (decoder-only scoring)": [[37, "v1/score-(decoder-only-scoring)"]]}, "docnames": ["README", "advanced_features/attention_backend", "advanced_features/checkpoint_engine", "advanced_features/cuda_graph_for_multi_modal_encoder", "advanced_features/deterministic_inference", "advanced_features/dp_for_multi_modal_encoder", "advanced_features/epd_disaggregation", "advanced_features/expert_parallelism", "advanced_features/forward_hooks", "advanced_features/hicache", "advanced_features/hicache_best_practices", "advanced_features/hicache_design", "advanced_features/hicache_storage_runtime_attach_detach", "advanced_features/hyperparameter_tuning", "advanced_features/lora", "advanced_features/observability", "advanced_features/pd_disaggregation", "advanced_features/pipeline_parallelism", "advanced_features/quantization", "advanced_features/quantized_kv_cache", "advanced_features/rfork", "advanced_features/separate_reasoning", "advanced_features/server_arguments", "advanced_features/sgl_model_gateway", "advanced_features/sglang_for_rl", "advanced_features/speculative_decoding", "advanced_features/structured_outputs", "advanced_features/structured_outputs_for_reasoning_models", "advanced_features/tool_parser", "advanced_features/vlm_query", "basic_usage/deepseek_v3", "basic_usage/deepseek_v32", "basic_usage/glm45", "basic_usage/glmv", "basic_usage/gpt_oss", "basic_usage/llama4", "basic_usage/minimax_m2", "basic_usage/native_api", "basic_usage/offline_engine_api", "basic_usage/ollama_api", "basic_usage/openai_api", "basic_usage/openai_api_completions", "basic_usage/openai_api_embeddings", "basic_usage/openai_api_vision", "basic_usage/popular_model_usage", "basic_usage/qwen3", "basic_usage/qwen3_vl", "basic_usage/sampling_params", "basic_usage/send_request", "developer_guide/JIT_kernels", "developer_guide/bench_serving", "developer_guide/benchmark_and_profiling", "developer_guide/contribution_guide", "developer_guide/development_guide_using_docker", "developer_guide/evaluating_new_models", "developer_guide/release_process", "developer_guide/setup_github_runner", "get_started/install", "index", "platforms/amd_gpu", "platforms/ascend_contribution_guide", "platforms/ascend_npu", "platforms/ascend_npu_best_practice", "platforms/ascend_npu_deepseek_example", "platforms/ascend_npu_quantization", "platforms/ascend_npu_qwen3_examples", "platforms/ascend_npu_support", "platforms/ascend_npu_support_models", "platforms/cpu_server", "platforms/mthreads_gpu", "platforms/nvidia_jetson", "platforms/tpu", "platforms/xpu", "references/custom_chat_template", "references/environment_variables", "references/faq", "references/frontend/choices_methods", "references/frontend/frontend_index", "references/frontend/frontend_tutorial", "references/learn_more", "references/multi_node_deployment/deploy_on_k8s", "references/multi_node_deployment/lws_pd/lws_pd_deploy", "references/multi_node_deployment/multi_node", "references/multi_node_deployment/multi_node_index", "references/multi_node_deployment/rbg_pd/deepseekv32_pd", "references/post_training_integration", "references/production_metrics", "references/production_request_trace", "references/torch_compile_cache", "supported_models/classify_models", "supported_models/diffusion_language_models", "supported_models/diffusion_models", "supported_models/embedding_models", "supported_models/generative_models", "supported_models/mindspore_models", "supported_models/modelscope", "supported_models/multimodal_language_models", "supported_models/rerank_models", "supported_models/reward_models", "supported_models/support_new_models", "supported_models/transformers_fallback"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["README.md", "advanced_features/attention_backend.md", "advanced_features/checkpoint_engine.md", "advanced_features/cuda_graph_for_multi_modal_encoder.md", "advanced_features/deterministic_inference.md", "advanced_features/dp_for_multi_modal_encoder.md", "advanced_features/epd_disaggregation.md", "advanced_features/expert_parallelism.md", "advanced_features/forward_hooks.md", "advanced_features/hicache.rst", "advanced_features/hicache_best_practices.md", "advanced_features/hicache_design.md", "advanced_features/hicache_storage_runtime_attach_detach.md", "advanced_features/hyperparameter_tuning.md", "advanced_features/lora.ipynb", "advanced_features/observability.md", "advanced_features/pd_disaggregation.md", "advanced_features/pipeline_parallelism.md", "advanced_features/quantization.md", "advanced_features/quantized_kv_cache.md", "advanced_features/rfork.md", "advanced_features/separate_reasoning.ipynb", "advanced_features/server_arguments.md", "advanced_features/sgl_model_gateway.md", "advanced_features/sglang_for_rl.md", "advanced_features/speculative_decoding.ipynb", "advanced_features/structured_outputs.ipynb", "advanced_features/structured_outputs_for_reasoning_models.ipynb", "advanced_features/tool_parser.ipynb", "advanced_features/vlm_query.ipynb", "basic_usage/deepseek_v3.md", "basic_usage/deepseek_v32.md", "basic_usage/glm45.md", "basic_usage/glmv.md", "basic_usage/gpt_oss.md", "basic_usage/llama4.md", "basic_usage/minimax_m2.md", "basic_usage/native_api.ipynb", "basic_usage/offline_engine_api.ipynb", "basic_usage/ollama_api.md", "basic_usage/openai_api.rst", "basic_usage/openai_api_completions.ipynb", "basic_usage/openai_api_embeddings.ipynb", "basic_usage/openai_api_vision.ipynb", "basic_usage/popular_model_usage.rst", "basic_usage/qwen3.md", "basic_usage/qwen3_vl.md", "basic_usage/sampling_params.md", "basic_usage/send_request.ipynb", "developer_guide/JIT_kernels.md", "developer_guide/bench_serving.md", "developer_guide/benchmark_and_profiling.md", "developer_guide/contribution_guide.md", "developer_guide/development_guide_using_docker.md", "developer_guide/evaluating_new_models.md", "developer_guide/release_process.md", "developer_guide/setup_github_runner.md", "get_started/install.md", "index.rst", "platforms/amd_gpu.md", "platforms/ascend_contribution_guide.md", "platforms/ascend_npu.md", "platforms/ascend_npu_best_practice.md", "platforms/ascend_npu_deepseek_example.md", "platforms/ascend_npu_quantization.md", "platforms/ascend_npu_qwen3_examples.md", "platforms/ascend_npu_support.rst", "platforms/ascend_npu_support_models.md", "platforms/cpu_server.md", "platforms/mthreads_gpu.md", "platforms/nvidia_jetson.md", "platforms/tpu.md", "platforms/xpu.md", "references/custom_chat_template.md", "references/environment_variables.md", "references/faq.md", "references/frontend/choices_methods.md", "references/frontend/frontend_index.rst", "references/frontend/frontend_tutorial.ipynb", "references/learn_more.md", "references/multi_node_deployment/deploy_on_k8s.md", "references/multi_node_deployment/lws_pd/lws_pd_deploy.md", "references/multi_node_deployment/multi_node.md", "references/multi_node_deployment/multi_node_index.rst", "references/multi_node_deployment/rbg_pd/deepseekv32_pd.md", "references/post_training_integration.md", "references/production_metrics.md", "references/production_request_trace.md", "references/torch_compile_cache.md", "supported_models/classify_models.md", "supported_models/diffusion_language_models.md", "supported_models/diffusion_models.md", "supported_models/embedding_models.md", "supported_models/generative_models.md", "supported_models/mindspore_models.md", "supported_models/modelscope.md", "supported_models/multimodal_language_models.md", "supported_models/rerank_models.md", "supported_models/reward_models.md", "supported_models/support_new_models.md", "supported_models/transformers_fallback.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [3, 6, 7, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 47, 48, 50, 52, 53, 54, 57, 59, 60, 61, 64, 70, 74, 76, 78, 80, 85, 86, 87, 89, 90, 91, 92, 93, 96, 97, 100], "0": [0, 2, 6, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 65, 67, 68, 70, 71, 72, 74, 78, 80, 82, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], "00": [14, 21, 25, 26, 27, 28, 29, 31, 37, 38, 41, 42, 43, 48, 78, 80, 82, 97], "000": [27, 31, 52, 58, 60], "0000": [13, 80], "00001": 18, "00002962350845336914": 42, "00004738569259643555": 42, "00005257129669189453": 42, "00006532669067382812": 42, "00008237361907958984": 42, "0000928044319152832": 42, "0000998377799987793": 42, "0001": 80, "00010514259338378906": 42, "0001322031021118164": 42, "00013875961303710938": 42, "00014603137969970703": 42, "0001493692398071289": 42, "0001697540283203125": 42, "00017774105072021484": 42, "00018644332885742188": 42, "0001951456069946289": 42, "0002": 25, "0002028942108154297": 42, "0002053976058959961": 42, "00021159648895263672": 42, "00021409988403320312": 42, "00023102760314941406": [37, 42], "0002351999282836914": 42, "00025582313537597656": 42, "0002701282501220703": 42, "00027441978454589844": 42, "00029540061950683594": 42, "00031065940856933594": 42, "00032067298889160156": 42, "0003418922424316406": 42, "0003495216369628906": 42, "00035071372985839844": 42, "0003693103790283203": 42, "0003848075866699219": 42, "00039005279541015625": 42, "0003972053527832031": 42, "0004031658172607422": 42, "00040984153747558594": 42, "0004382133483886719": 42, "0004413127899169922": 42, "00044417381286621094": 42, "0004513263702392578": 42, "0004620552062988281": 42, "0005130767822265625": 42, "0005335807800292969": 42, "0005621910095214844": 42, "0005698204040527344": 42, "0005784034729003906": 42, "0006489753723144531": 42, "0006608963012695312": 42, "0006771087646484375": 42, "0006952285766601562": 42, "0007076263427734375": 42, "0007262229919433594": 42, "000728607177734375": 42, "0007519721984863281": 42, "0007572174072265625": 42, "0007658004760742188": 42, "0007991790771484375": 42, "0008139610290527344": 42, "0008296966552734375": 42, "0008397102355957031": 42, "0008406639099121094": 42, "0008764266967773438": 42, "0009050369262695312": 42, "0009250640869140625": 42, "0009288787841796875": 42, "0009407997131347656": 42, "0009546279907226562": 42, "0009584426879882812": 42, "0009703636169433594": 42, "000988006591796875": 42, "0009918212890625": 42, "001": [81, 84, 86], "0010013580322265625": 42, "0010061264038085938": 42, "0010251998901367188": 42, "0010318756103515625": 42, "0010385513305664062": 42, "0010423660278320312": 42, "001056671142578125": 42, "0010623931884765625": 42, "0010852813720703125": 42, "0010995864868164062": 42, "0011196136474609375": 42, "0011234283447265625": 42, "0011415481567382812": 42, "0011529922485351562": 42, "0011587142944335938": 42, "001186370849609375": 42, "0011911392211914062": 42, "0011949539184570312": 42, "00119781494140625": 42, "0012035369873046875": 42, "00121307373046875": 42, "0012311935424804688": 42, "0012607574462890625": 42, "0012693405151367188": 42, "0012760162353515625": 42, "0012845993041992188": 42, "0012979507446289062": 42, "0013246536254882812": 42, "001338958740234375": 42, "0013513565063476562": 42, "001354217529296875": 42, "0013570785522460938": 42, "0013742446899414062": 42, "001377105712890625": 42, "0013799667358398438": 42, "0013914108276367188": 42, "0014181137084960938": 42, "001422882080078125": 42, "0014295578002929688": 42, "0014467239379882812": 42, "0014743804931640625": 42, "0014867782592773438": 42, "0014982223510742188": 42, "0015039443969726562": 42, "0015106201171875": 42, "001552581787109375": 42, "0015573501586914062": 42, "0015630722045898438": 42, "0015840530395507812": 42, "00159454345703125": 42, "0016031265258789062": 42, "0016222000122070312": 42, "0016231536865234375": 42, "0016326904296875": 42, "0016994476318359375": 42, "0017156600952148438": 42, "0017194747924804688": 42, "001720428466796875": 42, "0017271041870117188": 42, "0017423629760742188": 42, "0017652511596679688": 42, "0017824172973632812": 42, "00179290771484375": 42, "001811981201171875": 42, "0018157958984375": 42, "0018186569213867188": 42, "0018243789672851562": 42, "0018367767333984375": 42, "0018520355224609375": 42, "0018749237060546875": 42, "0018901824951171875": 42, "0019025802612304688": 42, "0019130706787109375": 42, "0019359588623046875": 42, "0019464492797851562": 42, "001983642578125": 42, "0019989013671875": 42, "002": [14, 21, 22, 26, 27, 28, 29, 37, 38], "00201416015625": 42, "002033233642578125": 42, "0020389556884765625": 42, "0020427703857421875": 42, "002044677734375": 42, "0020751953125": 42, "0020847320556640625": 42, "0021038055419921875": 42, "0021190643310546875": 42, "002124786376953125": 42, "00214385986328125": 42, "0021457672119140625": 42, "00217437744140625": 42, "002193450927734375": 42, "0021953582763671875": 42, "0022068023681640625": 42, "0022106170654296875": 42, "0022411346435546875": 42, "0022487640380859375": 42, "0022735595703125": 42, "002288818359375": 42, "0023021697998046875": 42, "0023040771484375": 42, "002338409423828125": 42, "002349853515625": 42, "0023708343505859375": 42, "0023746490478515625": 42, "00238800048828125": 42, "0024089813232421875": 42, "002460479736328125": 42, "0024623870849609375": 42, "0024738311767578125": 42, "002513885498046875": 42, "0025234222412109375": 42, "0025348663330078125": 42, "0025424957275390625": 42, "0025730133056640625": 42, "0025844573974609375": 42, "0025882720947265625": 42, "00261688232421875": 42, "0026378631591796875": 42, "0026416778564453125": 42, "00264739990234375": 42, "0026607513427734375": 42, "00270843505859375": 42, "002750396728515625": 42, "002765655517578125": 42, "00276947021484375": 42, "0027828216552734375": 42, "0027980804443359375": 42, "002826690673828125": 42, "002838134765625": 42, "0028438568115234375": 42, "002849578857421875": 42, "0028591156005859375": 42, "002864837646484375": 42, "00286865234375": 42, "002918243408203125": 42, "0029296875": 42, "0029582977294921875": 42, "0029697418212890625": 42, "00298309326171875": 42, "0029964447021484375": 42, "0030002593994140625": 42, "00301361083984375": 42, "0030498504638671875": 42, "0030574798583984375": 42, "0030612945556640625": 42, "003070831298828125": 42, "00307464599609375": 42, "0030803680419921875": 42, "003086090087890625": 42, "00308990478515625": 42, "0030918121337890625": 42, "003139495849609375": 42, "0031452178955078125": 42, "0031528472900390625": 42, "003154754638671875": 42, "0031948089599609375": 42, "003215789794921875": 42, "00322723388671875": 42, "0032444000244140625": 42, "0032711029052734375": [37, 42], "00328826904296875": 42, "003307342529296875": 42, "0033359527587890625": 42, "0033473968505859375": 42, "003353118896484375": 42, "00336456298828125": 42, "0033740997314453125": 42, "0033931732177734375": 42, "0034122467041015625": 42, "00342559814453125": 42, "0034503936767578125": 42, "0034637451171875": 42, "00347137451171875": 42, "003475189208984375": 42, "00350189208984375": 42, "0035037994384765625": 42, "003520965576171875": 42, "003574371337890625": 42, "003582000732421875": 42, "0036029815673828125": 42, "0036106109619140625": 42, "003631591796875": 42, "0036411285400390625": 42, "0036945343017578125": 42, "003711700439453125": 42, "0037212371826171875": 42, "0037288665771484375": 42, "0037326812744140625": 42, "003742218017578125": 42, "003753662109375": 42, "0037593841552734375": 42, "0037841796875": 42, "0037975311279296875": 42, "0038051605224609375": 42, "0038089752197265625": 42, "00382232666015625": 42, "003833770751953125": 42, "003917694091796875": 42, "00394439697265625": 42, "003948211669921875": 42, "003963470458984375": 42, "003971099853515625": 42, "003978729248046875": 42, "0039825439453125": 42, "003986358642578125": 42, "003993988037109375": 42, "00400543212890625": 42, "004016876220703125": 42, "004024505615234375": 42, "0040435791015625": 42, "00405120849609375": 42, "0040740966796875": 42, "004100799560546875": 42, "004123687744140625": 42, "004150390625": 42, "00415802001953125": 42, "004161834716796875": 42, "00417327880859375": 42, "004184722900390625": 42, "0041961669921875": 42, "004207611083984375": 42, "00424957275390625": 42, "004276275634765625": 42, "004283905029296875": 42, "0042877197265625": 42, "004390716552734375": 42, "00440216064453125": 42, "004413604736328125": 42, "004497528076171875": 42, "004512786865234375": 42, "0045318603515625": 42, "0045623779296875": 42, "00457000732421875": 42, "0045928955078125": 42, "00463104248046875": 42, "004642486572265625": 42, "00466156005859375": 42, "004665374755859375": 42, "004680633544921875": 42, "004688262939453125": 42, "00469207763671875": 42, "004695892333984375": 42, "00469970703125": 42, "0047149658203125": 42, "004726409912109375": 42, "0047607421875": 42, "004810333251953125": 42, "0048370361328125": 42, "00484466552734375": 42, "00487518310546875": 42, "004878997802734375": 42, "00493621826171875": 42, "0049591064453125": 42, "00496673583984375": 42, "004970550537109375": 42, "004974365234375": 42, "004985809326171875": 42, "005": 86, "0050048828125": 42, "005008697509765625": 42, "005023956298828125": 42, "005035400390625": 42, "005039215087890625": 42, "0050811767578125": 42, "005096435546875": 42, "005107879638671875": 42, "00513458251953125": 42, "005161285400390625": 42, "00521087646484375": 42, "005222320556640625": 42, "005237579345703125": 42, "00524139404296875": 42, "00525665283203125": 42, "005260467529296875": 42, "00527191162109375": 42, "00531005859375": 42, "005397796630859375": 42, "005405426025390625": 42, "00540924072265625": 42, "0054168701171875": 42, "00543975830078125": 42, "0054473876953125": 42, "00545501708984375": 42, "0054779052734375": 42, "00551605224609375": 42, "005519866943359375": 42, "005527496337890625": 42, "0055389404296875": 42, "005588531494140625": 42, "0055999755859375": 42, "00560760498046875": 42, "005626678466796875": 42, "005634307861328125": 42, "005657196044921875": 42, "00566864013671875": 42, "00569915771484375": 42, "0057220458984375": 42, "005725860595703125": 42, "005767822265625": 42, "0057830810546875": 42, "005794525146484375": 42, "00579833984375": 42, "00580596923828125": 42, "00583648681640625": 42, "005840301513671875": 42, "005847930908203125": 42, "005855560302734375": 42, "005859375": 42, "005878448486328125": 42, "005886077880859375": 42, "005893707275390625": 42, "0059051513671875": [37, 42], "00594329833984375": 42, "005962371826171875": 42, "005970001220703125": 42, "005992889404296875": 42, "00600433349609375": 42, "0060272216796875": 42, "00604248046875": 42, "00605010986328125": 42, "0060577392578125": 42, "006076812744140625": 42, "00611114501953125": 42, "006134033203125": 42, "006137847900390625": 42, "006145477294921875": 42, "0061492919921875": 42, "006160736083984375": 42, "00616455078125": 42, "006168365478515625": 42, "006175994873046875": 42, "00620269775390625": 42, "0062255859375": 42, "006229400634765625": 42, "0062408447265625": 42, "006256103515625": 42, "006259918212890625": 42, "006275177001953125": 42, "0063323974609375": 42, "00637054443359375": 42, "006374359130859375": 42, "00640106201171875": 42, "006420135498046875": 42, "006435394287109375": 42, "006450653076171875": 42, "0064544677734375": 42, "006465911865234375": 42, "006504058837890625": 42, "0065155029296875": 42, "006534576416015625": 42, "006542205810546875": 42, "0065765380859375": 42, "006580352783203125": 42, "00658416748046875": 42, "006587982177734375": 42, "006595611572265625": 42, "006618499755859375": 42, "006626129150390625": 42, "006633758544921875": 42, "006664276123046875": 42, "006687164306640625": 42, "00669097900390625": 42, "0066986083984375": 42, "006710052490234375": 42, "006717681884765625": 42, "00673675537109375": 42, "006755828857421875": 42, "00676727294921875": 42, "00679779052734375": 42, "006816864013671875": 42, "006908416748046875": 42, "006916046142578125": 42, "006923675537109375": 42, "006969451904296875": 42, "00698089599609375": 42, "006999969482421875": 42, "007007598876953125": 42, "007022857666015625": 42, "0070343017578125": 42, "00704193115234375": 42, "007106781005859375": 42, "007110595703125": 42, "007137298583984375": 42, "00717926025390625": 42, "007228851318359375": 42, "0072479248046875": 42, "00725555419921875": 42, "007289886474609375": 42, "007305145263671875": 42, "0073089599609375": 42, "00731658935546875": 42, "00733184814453125": 42, "00734710693359375": 42, "007373809814453125": 42, "00739288330078125": 42, "0074005126953125": 42, "00740814208984375": 42, "0074310302734375": 42, "007457733154296875": 42, "007465362548828125": 42, "00748443603515625": 42, "0074920654296875": 42, "00749969482421875": 42, "007507552643049313": 86, "007518768310546875": 42, "007534027099609375": 42, "0075531005859375": 42, "00759124755859375": 42, "00763702392578125": 42, "007678985595703125": 42, "007709503173828125": 42, "007720947265625": 42, "0077362060546875": 42, "00775146484375": 42, "007755279541015625": 42, "007778167724609375": 42, "007793426513671875": 42, "0077972412109375": 42, "00782012939453125": 42, "0078277587890625": 42, "00783538818359375": 42, "007843017578125": 42, "0078582763671875": 42, "007904052734375": 42, "0079193115234375": 42, "00794219970703125": 42, "007965087890625": 42, "00799560546875": 42, "00803375244140625": 42, "00807952880859375": 42, "00809478759765625": 42, "00811767578125": 42, "0081329345703125": 42, "0081634521484375": 42, "0081787109375": 42, "00820159912109375": 42, "00821685791015625": 42, "00824737548828125": 42, "0082550048828125": 42, "00826263427734375": 42, "0082855224609375": 42, "00829315185546875": 42, "00833892822265625": 42, "0083465576171875": 42, "00835418701171875": 42, "00836944580078125": 42, "0083770751953125": 42, "00838470458984375": 42, "0084228515625": 42, "00843048095703125": 42, "0084381103515625": 42, "00844573974609375": 42, "0084467": 26, "008453369140625": 42, "00847625732421875": 42, "008514404296875": 42, "0085296630859375": 42, "008544921875": 42, "00855255126953125": 42, "0085601806640625": 42, "00856781005859375": 42, "008575439453125": 42, "00860595703125": 42, "0086212158203125": 42, "0086669921875": 42, "0086822509765625": 42, "00868988037109375": 42, "008697509765625": 42, "00872039794921875": 42, "00872802734375": 42, "00873565673828125": 42, "0087432861328125": 42, "00878143310546875": 42, "00879669189453125": 42, "00881195068359375": 42, "008819580078125": 42, "00882720947265625": 42, "00884246826171875": 42, "00885772705078125": 42, "0088958740234375": 42, "0089111328125": 42, "0089263916015625": 42, "00893402099609375": 42, "00896453857421875": 42, "00897979736328125": 42, "009002685546875": 42, "0090179443359375": 42, "00902557373046875": 42, "00905609130859375": 42, "009063720703125": 42, "00907135009765625": 42, "0091094970703125": 42, "00911712646484375": 42, "00913238525390625": 42, "00914764404296875": 42, "00916290283203125": 42, "0091705322265625": 42, "00919342041015625": 42, "0092010498046875": 42, "00923919677734375": 42, "009246826171875": 42, "00925445556640625": 42, "00930023193359375": 42, "0093536376953125": 42, "00936126708984375": 42, "00939178466796875": 42, "0093994140625": 42, "00945281982421875": 42, "00946044921875": 42, "00948333740234375": 42, "009490966796875": 42, "00952911376953125": 42, "0095367431640625": 42, "00954437255859375": 42, "0095672607421875": 42, "00958251953125": 42, "00960540771484375": 42, "009613037109375": 42, "009674072265625": 42, "00968170166015625": 42, "0096893310546875": 42, "00970458984375": 42, "00975799560546875": 42, "00978851318359375": 42, "00980377197265625": 42, "00981903076171875": 42, "00982666015625": 42, "00983428955078125": 42, "009857177734375": 42, "00986480712890625": 42, "00988006591796875": 42, "00994110107421875": 42, "00995635986328125": 42, "00it": 14, "01": [13, 14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78, 80, 86, 97], "0100250244140625": 42, "010040283203125": 42, "010101318359375": 42, "01010894775390625": 42, "0101165771484375": 42, "0101318359375": 42, "01013946533203125": 42, "01015472412109375": 42, "010162353515625": 42, "01018524169921875": 42, "01019287109375": 42, "0102081298828125": 42, "010223388671875": 42, "0102386474609375": 42, "01024": 18, "01025390625": 42, "01026153564453125": 42, "0102691650390625": 42, "01031494140625": 42, "0103302001953125": 42, "010345458984375": 42, "01035308837890625": 42, "01038360595703125": 42, "0104522705078125": 42, "010467529296875": 42, "01052093505859375": 42, "01053619384765625": 42, "0105438232421875": 42, "0105743408203125": 42, "01058197021484375": 42, "01064300537109375": 42, "01065826416015625": 42, "0106658935546875": 42, "01068115234375": 42, "01068878173828125": 42, "010711669921875": 42, "0107269287109375": 42, "0107421875": 42, "01074981689453125": 42, "010772705078125": 42, "01078033447265625": 42, "01079559326171875": 42, "01080322265625": 42, "0108184814453125": 42, "01084136962890625": 42, "0108489990234375": 42, "0108795166015625": 42, "010894775390625": 42, "01097869873046875": 42, "01099395751953125": 42, "01100921630859375": 42, "011016845703125": 42, "0110321044921875": 42, "0110626220703125": 42, "011077880859375": [37, 42], "01110076904296875": 42, "0111083984375": 42, "01113128662109375": 42, "01114654541015625": 42, "0111846923828125": 42, "01119232177734375": 42, "01123046875": 42, "01123809814453125": 42, "0112457275390625": 42, "0112762451171875": 42, "01129913330078125": 42, "01131439208984375": 42, "01132965087890625": 42, "0113372802734375": 42, "0113525390625": 42, "01136016845703125": 42, "0113677978515625": 42, "01137542724609375": 42, "011383056640625": 42, "0113983154296875": 42, "01141357421875": 42, "01143646240234375": 42, "011444091796875": 42, "01145172119140625": 42, "011474609375": 42, "0114898681640625": 42, "011505126953125": 42, "01151275634765625": 42, "0115203857421875": 42, "01152801513671875": 42, "01153564453125": 42, "0115814208984375": 42, "01158905029296875": 42, "0115966796875": 42, "0116119384765625": 42, "011627197265625": 42, "01171875": 42, "01175689697265625": 42, "01177978515625": 42, "01178741455078125": 42, "01180267333984375": 42, "01184844970703125": 42, "0118560791015625": 42, "01189422607421875": 42, "01190948486328125": 42, "0119476318359375": 42, "01195526123046875": 42, "011962890625": 42, "01198577880859375": 42, "01200103759765625": 42, "0120391845703125": 42, "01207733154296875": 42, "0120849609375": 42, "01210784912109375": 42, "01212310791015625": 42, "01213836669921875": 42, "01214599609375": 42, "0121612548828125": 42, "01218414306640625": 42, "0121917724609375": 42, "01219940185546875": 42, "01220703125": 42, "01224517822265625": 42, "01226806640625": 42, "012298583984375": 42, "0123291015625": 42, "012359619140625": 42, "0123748779296875": 42, "01241302490234375": 42, "012420654296875": 42, "012451171875": 42, "01247406005859375": 42, "01248931884765625": 42, "0125274658203125": 42, "01253509521484375": 42, "012542724609375": 42, "0125579833984375": 42, "01256561279296875": 42, "01259613037109375": 42, "012603759765625": 42, "01262664794921875": 42, "01263427734375": 42, "01264190673828125": 42, "01276397705078125": 42, "012786865234375": 42, "01280975341796875": 42, "0128326416015625": 42, "01285552978515625": 42, "01287078857421875": 42, "01287841796875": 42, "0128936767578125": 42, "012908935546875": 42, "01300811767578125": 42, "0130157470703125": 42, "01302337646484375": 42, "01303863525390625": 42, "0130462646484375": 42, "01305389404296875": 42, "01308441162109375": 42, "01312255859375": 42, "01317596435546875": 42, "01320648193359375": 42, "01325225830078125": 42, "01326751708984375": 42, "01328277587890625": 42, "0132904052734375": 42, "0133056640625": 42, "01332855224609375": 42, "0133514404296875": 42, "01335906982421875": 42, "01336669921875": 42, "01340484619140625": 42, "01346588134765625": 42, "01348114013671875": 42, "01349639892578125": 42, "0135040283203125": 42, "01355743408203125": 42, "01360321044921875": 42, "01361083984375": 42, "0136260986328125": 42, "01364898681640625": 42, "01367950439453125": 42, "01371002197265625": 42, "0137176513671875": 42, "01372528076171875": 42, "01373291015625": 42, "01374053955078125": 42, "013763427734375": 42, "0137786865234375": 42, "0138092041015625": 42, "01381683349609375": 42, "01384735107421875": 42, "01386260986328125": 42, "01389312744140625": 42, "01392364501953125": 42, "0139312744140625": 42, "013946533203125": 42, "01397705078125": 42, "0140228271484375": 42, "0140533447265625": [37, 42], "0140838623046875": 42, "01409912109375": 42, "01412200927734375": 42, "014129638671875": 42, "0141448974609375": 42, "01415252685546875": 42, "01418304443359375": 42, "0142059326171875": 42, "0142364501953125": 42, "01427459716796875": 42, "014312744140625": 42, "0143280029296875": 42, "0143585205078125": 42, "014373779296875": 42, "01441192626953125": [37, 42], "01442718505859375": 42, "01445770263671875": 42, "0144805908203125": 42, "014495849609375": 42, "0145111083984375": 42, "0145263671875": 42, "01454925537109375": 42, "01456451416015625": 42, "01457977294921875": 42, "014617919921875": 42, "0146484375": 42, "0146636962890625": 42, "014678955078125": 42, "0146942138671875": 42, "01470184326171875": 42, "01471710205078125": 42, "01473236083984375": 42, "0147857666015625": 42, "0148162841796875": 42, "01483154296875": 42, "0148468017578125": 42, "01488494873046875": 42, "01490020751953125": 42, "01491546630859375": 42, "01495361328125": 42, "0149993896484375": 42, "015": 86, "0150146484375": 42, "01505279541015625": 42, "01506805419921875": 42, "01509857177734375": 42, "01513671875": 42, "0151519775390625": 42, "01519012451171875": 42, "01520538330078125": 42, "01522064208984375": 42, "01523590087890625": 42, "01525115966796875": 42, "0152740478515625": 42, "01531982421875": 42, "01535797119140625": 42, "01540374755859375": 42, "01541900634765625": 42, "0154266357421875": 42, "01544189453125": 42, "015472412109375": 42, "0154876708984375": 42, "01551055908203125": 42, "01557159423828125": 42, "01558685302734375": 42, "0156097412109375": 42, "0156707763671875": 42, "01568603515625": 42, "015716552734375": 42, "0157318115234375": 42, "0157470703125": 42, "015777587890625": 42, "0157928466796875": 42, "015838623046875": 42, "0158538818359375": 42, "015869140625": 42, "0158843994140625": 42, "015899658203125": 42, "0159149169921875": 42, "015960693359375": 42, "0159759521484375": 42, "0159912109375": [37, 42], "0160064697265625": 42, "016021728515625": 42, "0160675048828125": 42, "0160980224609375": 42, "016143798828125": 42, "01617431640625": 42, "0161895751953125": 42, "016265869140625": 42, "016326904296875": 42, "016357421875": 42, "016448974609375": 42, "016510009765625": 42, "0165252685546875": 42, "0166015625": 42, "0166168212890625": 42, "016632080078125": 42, "0166778564453125": 42, "016693115234375": 42, "0167236328125": 42, "0167388916015625": 42, "0167694091796875": 42, "01678466796875": 42, "016815185546875": 42, "0168304443359375": 42, "016845703125": 42, "0168609619140625": 42, "016876220703125": 42, "016937255859375": 42, "0169677734375": 42, "016998291015625": 42, "0170745849609375": 42, "01708984375": 42, "0171966552734375": 42, "0172119140625": 42, "0172271728515625": 42, "017242431640625": 42, "0172882080078125": 42, "017333984375": 42, "017364501953125": 42, "0173797607421875": 42, "0174102783203125": 42, "0174560546875": 42, "017486572265625": 42, "0175018310546875": 42, "01751708984375": 42, "0175323486328125": 42, "0175628662109375": 42, "017578125": 42, "0176239013671875": 42, "01763916015625": 42, "0176849365234375": 42, "0177001953125": 42, "017730712890625": 42, "0177764892578125": 42, "0178070068359375": 42, "0178375244140625": 42, "017852783203125": 42, "01788330078125": 42, "0178985595703125": 42, "017913818359375": 42, "0179290771484375": 42, "0180816650390625": 42, "01812744140625": 42, "018157958984375": 42, "0181732177734375": 42, "018218994140625": 42, "0182342529296875": 42, "01824951171875": 42, "018280029296875": 42, "0183258056640625": 42, "01837158203125": 42, "018402099609375": 42, "0184173583984375": 42, "0184326171875": 42, "018463134765625": 42, "0185394287109375": 42, "0185546875": 42, "018585205078125": 42, "0186004638671875": 42, "018707275390625": 42, "01873779296875": 42, "0187530517578125": 42, "018768310546875": 42, "0188446044921875": 42, "018890380859375": 42, "0189208984375": 42, "0189361572265625": 42, "018951416015625": 42, "0189666748046875": 42, "01898193359375": 42, "019012451171875": 42, "01904296875": 42, "019073486328125": 42, "01910400390625": 42, "019134521484375": 42, "0192413330078125": 42, "01934814453125": 42, "0193634033203125": 42, "0193939208984375": 42, "0194854736328125": 42, "01953125": 42, "0196075439453125": 42, "019622802734375": 42, "0196533203125": 42, "019683837890625": 42, "0196990966796875": 42, "01971435546875": 42, "019775390625": 42, "0198211669921875": 42, "0198516845703125": 42, "019927978515625": 42, "019989013671875": 42, "01it": [14, 21, 42], "02": [14, 21, 25, 26, 27, 28, 37, 42, 43, 48, 78, 80, 86], "0200": 80, "0200042724609375": 42, "020050048828125": 42, "0200653076171875": 42, "020111083984375": 42, "020172119140625": 42, "0202178955078125": 42, "020233154296875": 42, "02032470703125": 42, "0203399658203125": 42, "0204315185546875": 42, "02044677734375": 42, "020477294921875": 42, "0205535888671875": 42, "02056884765625": 42, "0206298828125": 42, "0207061767578125": 42, "020721435546875": 42, "0207977294921875": 42, "02081298828125": 42, "0208282470703125": 42, "020843505859375": 42, "0208587646484375": 42, "0208740234375": 42, "0208892822265625": 42, "0209503173828125": 42, "0210418701171875": 42, "02117919921875": 42, "0211944580078125": 42, "021209716796875": 42, "0212249755859375": 42, "0212860107421875": 42, "0213470458984375": 42, "021392822265625": 42, "02142333984375": 42, "0214385986328125": 42, "021453857421875": 42, "021484375": 42, "021514892578125": 42, "0215301513671875": 42, "0215911865234375": 42, "0216522216796875": 42, "02166748046875": 42, "0216827392578125": 42, "0217132568359375": 42, "0217742919921875": 42, "0218353271484375": 42, "021856000646948814": 25, "0218658447265625": 42, "021881103515625": 42, "0219": 25, "0219573974609375": 42, "0219879150390625": 42, "02203369140625": 42, "0222015380859375": 42, "022216796875": 42, "0222625732421875": 42, "0222930908203125": 42, "0223236083984375": 42, "0224": 25, "022431999444961548": 25, "0224456787109375": 42, "0224761962890625": 42, "022491455078125": 42, "0225": 80, "02264404296875": 42, "022735595703125": 42, "0228424072265625": [37, 42], "022857666015625": 42, "022918701171875": 42, "0229949951171875": 42, "023": 92, "0230": 25, "02304000034928322": 25, "023040771484375": 42, "0230712890625": 42, "0231170654296875": 42, "02313232421875": 42, "0231475830078125": 42, "023162841796875": 42, "0232391357421875": 42, "0232696533203125": 42, "0233": 25, "02332800067961216": 25, "0233306884765625": 42, "0233612060546875": 42, "0235137939453125": 42, "0235748291015625": 42, "02362060546875": 42, "0237": 37, "0238494873046875": 42, "02386474609375": 42, "0238800048828125": 42, "023956298828125": 42, "02398681640625": 42, "0240": 25, "024017333984375": 42, "02410888671875": 42, "0241546630859375": 42, "02423095703125": 42, "0242462158203125": 42, "024322509765625": 42, "0243988037109375": 42, "024505615234375": 42, "02471923828125": 42, "024749755859375": 42, "0247650146484375": 42, "0247802734375": 42, "0247955322265625": 42, "0248565673828125": 42, "0248870849609375": 42, "0249176025390625": 42, "025": 86, "0251617431640625": 42, "02520751953125": 42, "025238037109375": 42, "0252838134765625": 42, "025299072265625": 42, "0254058837890625": 42, "0255279541015625": 42, "025543212890625": 42, "0255584716796875": 42, "0255889892578125": 42, "0256500244140625": 42, "0256805419921875": 42, "025848388671875": 42, "025853395462036133": 26, "025970458984375": 42, "0260009765625": 42, "026031494140625": 42, "026092529296875": 42, "0261688232421875": 42, "02618408203125": 42, "026214599609375": 42, "0262451171875": 42, "0262603759765625": 42, "0262908935546875": 42, "02642822265625": 42, "0264739990234375": 42, "0266265869140625": 42, "0266876220703125": 42, "0267": 25, "0267181396484375": 42, "0268402099609375": 42, "0269775390625": 42, "0269927978515625": 42, "02716064453125": 42, "0272": 25, "0272064208984375": 42, "0272369384765625": 42, "02728271484375": 42, "0272979736328125": [37, 42], "0273284912109375": 42, "0274200439453125": 42, "0275421142578125": 42, "027618408203125": 42, "027923583984375": 42, "0279693603515625": 42, "028045654296875": 42, "028076171875": 42, "0280914306640625": 42, "0281524658203125": 42, "0282135009765625": 42, "028228759765625": 42, "0282745361328125": 42, "028289794921875": 42, "0283050537109375": 42, "0284": 37, "0284271240234375": 42, "0284423828125": 42, "028472900390625": 42, "0285491943359375": 42, "028656005859375": 42, "0286865234375": 42, "02874755859375": 42, "0288848876953125": 42, "0289154052734375": 42, "0289306640625": 42, "029052734375": 42, "0291595458984375": 42, "0291900634765625": 42, "029296875": 42, "02935791015625": 42, "0294036865234375": 42, "0294342041015625": 42, "0294952392578125": 42, "0295562744140625": 42, "029571533203125": 42, "029632568359375": 42, "0298004150390625": 42, "0298309326171875": 42, "029937744140625": 42, "03": [13, 14, 21, 25, 26, 28, 29, 37, 43, 48, 78, 86, 93], "030029296875": 42, "0300445556640625": 42, "0301055908203125": 42, "0301361083984375": 42, "0301666259765625": 42, "0302": 25, "030242919921875": 42, "030364990234375": 42, "0305023193359375": 42, "030670166015625": 42, "0307": 25, "0307769775390625": 42, "030975341796875": 42, "0310211181640625": 42, "0311431884765625": 42, "0311737060546875": 42, "03143310546875": 42, "03155517578125": 42, "031646728515625": 42, "032012939453125": 42, "032135009765625": 42, "0322": 25, "032318115234375": 42, "0324": [16, 28, 30], "032440185546875": 42, "032470703125": 42, "032501220703125": 42, "03271484375": 42, "032806396484375": 42, "03289794921875": 42, "03314208984375": 42, "03326416015625": 42, "0333251953125": 42, "033447265625": 42, "03375244140625": 42, "0338134765625": 42, "033935546875": 42, "0340576171875": 42, "03411865234375": 42, "03424072265625": 42, "0343017578125": 42, "034454345703125": 42, "03448486328125": 42, "0345458984375": 42, "034637451171875": 42, "03466796875": 42, "034759521484375": 42, "03509521484375": 42, "035247802734375": 42, "035308837890625": 42, "03570556640625": 42, "035888671875": 42, "03607177734375": 42, "03619384765625": 42, "0362548828125": 42, "036346435546875": 42, "036376953125": 42, "036468505859375": 42, "036529541015625": 42, "03668212890625": 42, "03692626953125": 42, "0369873046875": 42, "037078857421875": 42, "0372314453125": 42, "037506103515625": 42, "037841796875": 42, "0380859375": 42, "038116455078125": 42, "03826904296875": 42, "038604736328125": 42, "038787841796875": 42, "038818359375": 42, "038848876953125": 42, "0391": 25, "03924560546875": 42, "039276123046875": 42, "039435e": 86, "039459228515625": 42, "0397": 25, "039703369140625": 42, "0398": 25, "03it": [14, 27, 78], "04": [14, 25, 27, 37, 43, 56, 61, 78, 80, 86], "040252685546875": 42, "0404052734375": 42, "040618896484375": 42, "0406494140625": 42, "040802001953125": 42, "0409": 25, "0410": 25, "0413": 25, "041412353515625": 42, "041717529296875": 42, "041961669921875": 42, "0421": 25, "0423": 25, "04248046875": 42, "0429": 25, "042938232421875": 42, "0430": 25, "044219970703125": 42, "045166015625": 42, "045257568359375": 42, "04534912109375": 42, "0458984375": 42, "0467529296875": 42, "04758400097489357": 25, "0476": 25, "047698974609375": 42, "048248291015625": 42, "0483": 25, "04831999912858009": 25, "048370361328125": 42, "04840087890625": 42, "04848000034689903": 25, "048492431640625": 42, "0485": 25, "04854400083422661": 25, "04867200180888176": 25, "0487": 25, "0492": 25, "0494": 25, "04944000020623207": 25, "049652099609375": 42, "04986572265625": [37, 42], "049957275390625": 42, "05": [14, 21, 23, 25, 37, 41, 43, 80, 86], "05078125": 42, "0509": 25, "050944000482559204": 25, "0516": 25, "0517": 25, "0517439991235733": 25, "0523": 25, "0528": [7, 19, 21, 41, 67, 81], "052978515625": 42, "0530": 25, "053497314453125": 42, "05401611328125": 42, "0546875": 37, "0547": 25, "054706573486328125": 48, "0552": 25, "0554": 25, "0558": 25, "0562": 25, "056488037109375": 42, "0566": 25, "0569": 25, "057037353515625": 42, "057373046875": 42, "05792236328125": 42, "0582": 25, "0584": 25, "059112548828125": 42, "05987548828125": 42, "05it": [14, 37], "06": [14, 25, 26, 28, 37, 43, 86], "06072998046875": 42, "0611572265625": 42, "0619": 25, "0625": 42, "062744140625": 42, "0631103515625": 42, "0633544921875": 42, "0637": 37, "0643310546875": 42, "0647": 25, "0667": 25, "06707763671875": 42, "0677": 25, "0680": 25, "0683": 25, "068603515625": 42, "06927490234375": 42, "06it": 14, "07": [14, 25, 26, 37, 80], "0703": 25, "0713": 25, "07232666015625": 42, "073486328125": 42, "075": 86, "07500000000000001": 86, "0751": 25, "0751039981842041": 25, "0753": 25, "0756": 25, "0758": 25, "07606399804353714": 25, "0761": 25, "07611846923828125": 26, "07625599950551987": 25, "0763": 25, "0767": 25, "0775146484375": 42, "0782": 25, "07958984375": 42, "0796": 25, "07977294921875": 42, "07it": [14, 25], "08": [13, 14, 25, 26, 27, 37, 41, 43, 80, 86], "080": 27, "0801": 25, "08087158203125": 42, "08091306686401367": 26, "0828": 25, "0837": 25, "0852628": 27, "089599609375": 42, "08it": 14, "09": [14, 26, 27, 37, 43, 48, 75], "0900": 25, "0910": 25, "09197998046875": 42, "0922": 25, "0924": [67, 93], "0927": 25, "0930": 25, "0940": 25, "0941": 25, "0943603515625": 42, "0946044921875": 42, "0950": 25, "0951": 25, "09521484375": 42, "0957": 25, "0959": 25, "09625244140625": 42, "0969": 25, "0974": 25, "0978": 25, "09it": 43, "0dd7": 80, "0e9e39f249a16976918f6564b8830bc894c89659": 14, "0f8569343c294e74b04c04669c9ee859": 41, "0rc1": 56, "0x0": 80, "1": [0, 1, 2, 3, 4, 6, 8, 10, 11, 13, 14, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 60, 67, 70, 72, 74, 78, 80, 86, 87, 88, 89, 90, 93, 94, 96, 97, 98, 99], "10": [0, 13, 14, 16, 21, 22, 23, 25, 26, 27, 28, 29, 30, 34, 36, 37, 38, 41, 42, 43, 48, 51, 54, 61, 62, 63, 78, 80, 84, 85, 86, 89, 91, 93], "100": [10, 13, 14, 15, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 37, 38, 41, 42, 43, 48, 49, 50, 51, 54, 71, 78, 85, 86, 91], "1000": [7, 14, 21, 22, 23, 25, 26, 27, 28, 29, 37, 38, 50, 51, 54, 62, 74], "10000": [10, 23, 62], "1000000": 35, "10000000": [14, 21, 22, 26, 27, 28, 29, 37, 38], "100000000": 84, "1000000000": 84, "10000000149011612": 25, "10001": 23, "10011": 71, "1002": [14, 22, 25], "1004": [22, 25], "1007": 25, "10078": 19, "1008": [22, 37], "100b": [90, 93], "100m": 23, "100mb": 51, "101": 37, "1010": 25, "1011": 25, "1012": 27, "10146": 27, "1016": 22, "10161": 27, "1021": 25, "1024": [11, 14, 18, 21, 23, 26, 27, 28, 29, 30, 32, 37, 38, 50, 51, 54, 62, 68, 71, 72, 74, 81, 84, 86, 90, 91, 92], "1024x1024": 91, "1025": 25, "103": 14, "1030": 27, "1031": 25, "10326123237609863": 26, "10339": 37, "1035": [25, 27, 86], "1035199984908104": 25, "104": [21, 26, 27, 28, 29, 38], "1042": 27, "1045": [25, 27], "1046": 25, "1048576": 96, "1052": 27, "10542": 27, "1056901674": 21, "106": 14, "10696": 27, "106b": [67, 96], "107": 14, "1071994": 26, "1075": [27, 37], "1077": 37, "1079": [25, 27], "108": [14, 62], "1080p": 50, "1080x1920": 50, "10826": 27, "1083": 27, "1084": 48, "1088": 62, "109": [14, 31], "1091": [27, 37], "10912": 84, "1096": 27, "1097": [37, 42], "10997": 27, "109b": 35, "10a14172aa47420fbe0306c3b9cd1ffc": 25, "10b": 68, "10it": 14, "10m": [23, 35], "11": [13, 14, 22, 23, 25, 26, 27, 28, 29, 34, 37, 43, 48, 51, 61, 78, 80, 86, 91], "110": 14, "11000": 62, "11008": [25, 86], "11008x4096": 25, "1101": [25, 27], "11050": 37, "111": 14, "1111": 25, "11111": 41, "11136": 27, "11141": 27, "1116633415222168": 26, "1119": 27, "112": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "11228": 86, "1124": [27, 93], "1125": [86, 93], "1128": 27, "113": 14, "11368": 27, "114": 62, "1142": 27, "114688": 62, "115": 14, "1152": 62, "1158": 25, "11584": 26, "116": [30, 34], "1160": 25, "116093850019932e": 86, "1162": 25, "11649": 27, "11685": 86, "11689": 27, "1170": 25, "118": 14, "1181": 27, "1184": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "11852": 17, "119": 14, "1196": 27, "11b": [67, 96], "11it": [26, 37], "11k": 62, "11k1k": 62, "12": [1, 14, 16, 21, 22, 23, 25, 26, 27, 28, 29, 34, 37, 38, 43, 51, 56, 57, 62, 63, 68, 71, 72, 78, 82, 91, 93], "120": [21, 23, 26, 27, 28, 29, 38, 52, 60, 62, 74], "1200": [62, 84], "120000": [31, 54], "12065": 31, "12095": [27, 37, 48], "120b": [19, 28, 34, 67, 93], "12128": 27, "12159": 27, "12288": 17, "123": [41, 87], "12345": 41, "123456": 34, "1234567890": 91, "1234567890ab": 23, "12379": 37, "123859": 86, "1246": 37, "1247": 25, "125": 68, "1251": 27, "12612": 19, "1265": 27, "127": [6, 10, 12, 14, 16, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 37, 38, 41, 42, 47, 48, 50, 51, 54, 61, 62, 63, 71, 80, 89, 90, 92, 94, 97], "1273": 27, "128": [1, 4, 14, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 35, 37, 38, 41, 47, 50, 53, 59, 62, 63, 68, 70, 71, 72, 74, 83, 86, 90, 92, 96], "1280": [14, 21, 26, 27, 28, 29, 37, 38, 91], "128000": 31, "128009": [25, 26], "1280x720": 91, "1281": 27, "128902e": 86, "128e": 35, "128g": 56, "128k": [93, 96], "128x11008": 25, "128x128": 30, "128x4096": 25, "1290": [25, 27], "12943": 27, "1297662": 27, "12994": 27, "12b": 96, "12k": 17, "12t": 93, "13": [13, 14, 22, 23, 25, 26, 27, 28, 34, 37, 41, 42, 43, 48, 57, 62, 68, 78], "1303": 25, "130859375": 42, "130b": 93, "131072": [14, 25, 31, 37, 62, 84], "13126": 5, "13187": 27, "1319": 31, "132": 62, "13216": 27, "13289": 27, "132b": 93, "133": 62, "1330": 86, "13327": 7, "1335": 25, "13382": 27, "13388": 27, "1349": 27, "13530": 27, "13550": 31, "13580": 27, "135m": 93, "136": [21, 26, 27, 28, 29, 38, 81, 84], "1372": 27, "13724": 5, "1376": [27, 37], "138": [30, 34], "1380": 27, "13837": 27, "1384": 27, "139": 28, "13925": 5, "1395": 25, "13959": [31, 48], "13b": [67, 93, 96], "13d1924f38ef4aa68b96518b4e32e526": 27, "13it": [25, 38], "14": [14, 25, 26, 27, 28, 34, 37, 41, 43, 48, 62, 63, 68, 78, 81, 84, 86], "140": 86, "14006": 86, "14007": 86, "1401": 27, "14037": 27, "1408": 37, "14097": 5, "141": 62, "1414": [27, 37], "1416": 37, "14190": 27, "141fc3a09386a8baf0d7495c247ae2d1a565f69f": 14, "1429": 27, "1431": 27, "1438": 27, "144": [14, 21, 26, 27, 28, 29, 37, 38, 62], "14422": 3, "144gb": 36, "1459": 27, "14720": 27, "14744": 27, "1477": 27, "148": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "1482": 27, "1490": 27, "1492": 37, "1493": 27, "1495": 27, "1496": 37, "14989": 27, "14b": [1, 91, 93], "15": [14, 17, 22, 23, 25, 26, 27, 28, 34, 37, 38, 43, 48, 62, 78, 80, 86], "150": [41, 78], "1500": 62, "15040": 31, "151": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "1513": 86, "1513671875": 42, "151643": [27, 37], "151645": [25, 41, 43, 48], "151649": 27, "152": [21, 26, 27, 28, 29, 38], "1522": 23, "15320": 3, "15339": 23, "15358": 31, "1536": [14, 21, 26, 27, 28, 29, 37, 38, 62, 63, 65, 92], "154": [21, 26, 27, 28, 29, 38], "15423": 27, "156": 62, "1576": 27, "158": 25, "15934": 27, "15955": 27, "15b": [93, 96], "15b3": 80, "15it": [14, 28], "16": [1, 14, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 34, 37, 38, 41, 42, 43, 48, 50, 54, 62, 63, 65, 68, 71, 78, 80, 81, 82, 84, 93], "160": [13, 14, 21, 26, 27, 28, 29, 37, 38, 62], "1600": [62, 63], "16045": 27, "1616": 27, "1619398593902588": 27, "16194891929626465": 27, "16195297241210938": 27, "162": [14, 86], "1632": 31, "1633": 27, "1635": 27, "16380": 31, "16384": [13, 14, 21, 22, 26, 27, 28, 29, 31, 37, 38, 62, 63, 71, 80], "163840": 80, "164": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "1640": 62, "1650390625": 42, "1660": 27, "1661": 27, "1667": 27, "16686": 87, "167": 68, "1671": 25, "1673": 31, "1679": 25, "168": [21, 22, 26, 27, 28, 29, 38], "1681": 27, "16875": 86, "169": [81, 84], "1692": 25, "16card": 62, "16e": [28, 29, 35, 67, 93], "16g": [59, 61], "16it": 25, "16k": [17, 93], "16x": 22, "17": [13, 14, 21, 25, 26, 27, 28, 37, 43, 62, 78, 80], "17064": 27, "171": 68, "171662e": 86, "17194": 27, "172": [62, 81, 82, 84], "173": 14, "174": 27, "1741943359375": 42, "1744": 27, "1745383213": 89, "1745993638": 30, "175": 34, "1750": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "1750252498": [81, 84], "17504": 31, "17530": 27, "176": [14, 21, 26, 27, 28, 29, 37, 38], "1767034308": 23, "1769529815": 25, "1769529904": 25, "1769529966": 25, "1769530017": 25, "1769530053": 25, "1769530102": 26, "1769530103": 26, "1769530104": 26, "1769530187": 27, "1769530190": 27, "1769530202": 27, "1769530207": 27, "1769530273": 28, "1769530274": 28, "1769530290": 37, "1769530360": 28, "1769530467": 41, "1769530478": [37, 41], "1769530489": 43, "1769530490": 43, "1769530491": 43, "1769530518": 48, "1769530519": 48, "177": 14, "17724609375": 42, "17767": 27, "1779": 27, "178": 62, "17821": 27, "179": 14, "1792": [14, 21, 26, 27, 28, 29, 37, 38], "17b": [28, 29, 35, 67, 93], "17it": [14, 26], "18": [14, 21, 22, 25, 26, 27, 28, 29, 34, 37, 38, 41, 43, 62, 63, 80, 82], "180": 23, "1800": 62, "18000": 62, "1815": 86, "184": [21, 26, 27, 28, 29, 38], "18413": 27, "18432": 17, "1855": 27, "1868896484375": 42, "187": 34, "1879": [37, 48], "18it": 14, "18k": [17, 62], "18k4k": 62, "19": [14, 25, 26, 27, 28, 37, 41, 42], "19083": 27, "19091": 27, "1917": 23, "192": [14, 21, 22, 26, 27, 28, 29, 37, 38, 62], "19257": 27, "1935968": 14, "1940651": 37, "1948": 27, "19482": 27, "1970": 86, "19730": 2, "198": [27, 31, 54], "1988": 27, "1990": 27, "1995": [27, 37], "1_6b": 67, "1b": [18, 28, 53, 67, 93, 96, 100], "1b7d4c3a6e1f": 23, "1c7c4ec1003b497bafde38d65dcb89a0": 41, "1card": 62, "1d": 49, "1e9": 11, "1gb": 11, "1k": 62, "1m": [1, 23, 35, 93], "1mb": 23, "1p1d": 81, "1t": 93, "1v": 96, "1x": 25, "2": [0, 1, 5, 8, 10, 11, 14, 16, 17, 18, 19, 21, 22, 23, 26, 27, 30, 33, 34, 35, 37, 38, 41, 42, 43, 44, 47, 48, 50, 51, 52, 60, 65, 67, 72, 73, 78, 80, 82, 85, 86, 89, 93, 94, 96, 97, 98, 99, 100], "20": [2, 13, 14, 21, 23, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 41, 43, 54, 62, 63, 71, 74, 78, 80, 84, 86], "200": [14, 21, 26, 27, 28, 29, 34, 37, 38, 50, 52, 54, 60, 63, 80, 93], "2000": [13, 50, 53, 62], "20000": [23, 80, 82], "200b": 19, "200k": 93, "2010": 27, "20102": [31, 81, 84], "2014": 27, "202": [14, 23], "2020": [27, 36], "2021": 27, "2022": 37, "2023": 27, "2023todai": 26, "2024": 93, "2024userpari": 26, "2025": [13, 34, 75, 80, 93], "20251121": 61, "2026": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "2038": 27, "20474": 37, "2048": [13, 14, 21, 25, 26, 27, 28, 29, 31, 35, 37, 38, 50, 62, 71, 75, 81, 84], "20480": [14, 21, 26, 27, 28, 37, 38], "2055": 27, "206": 34, "2070": 27, "208": [14, 21, 26, 27, 28, 29, 37, 38, 78], "2086": 48, "20927": 27, "20b": [28, 68, 93], "20it": [14, 28, 78], "20m": 14, "21": [14, 25, 26, 27, 37, 42, 86], "210": [34, 68], "2100": 62, "21000000": 27, "210463": 48, "21303": 27, "214": 68, "2141000": 26, "2147000": 26, "2147483648": 84, "21500000": 26, "2154000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 27, "2155": 27, "216": [21, 26, 27, 28, 29, 38], "21600000": 27, "2163": 27, "2174300": 27, "2176": 27, "21b": [67, 93], "21it": [14, 28, 29], "22": [14, 26, 27, 30, 37, 62, 63, 75, 84], "220": [26, 27], "22049": 27, "221": [81, 84], "222": 78, "22259e9468534a2f93124243fd96059f": 25, "2229": 25, "224": [14, 21, 26, 27, 28, 29, 37, 38], "224gb": 82, "22573": 27, "22707": 27, "2290": 25, "2297": 27, "2299": 37, "22it": [28, 41], "22m": [81, 84], "23": [14, 25, 27, 37, 61, 78, 80], "230": 36, "2304": [14, 21, 26, 27, 28, 29, 37, 38], "2308": 27, "232": [21, 26, 27, 28, 29, 38], "2326": 86, "233": 13, "235": [31, 81, 84], "23560": 27, "235b": [10, 19, 21, 46, 67, 68, 96], "23949": 27, "23it": [28, 78], "24": [14, 21, 23, 25, 26, 27, 28, 29, 37, 38, 62, 63, 68, 80, 81, 91], "240": [14, 19, 21, 23, 26, 27, 28, 29, 37, 38], "2407": 28, "240gb": 11, "24155": 31, "2417": 86, "242": [14, 81, 84], "2427": 27, "244": 25, "2441": 27, "24576": 62, "24595": 27, "24667": 62, "24669": [62, 63], "247": 86, "2474": 27, "248": [21, 25, 26, 27, 28, 29, 38], "24824": 27, "2486572265625": 42, "2494": 27, "24b": [67, 96], "24card": 62, "24it": [21, 78], "25": [11, 14, 25, 26, 27, 28, 31, 37, 38, 41, 61, 78, 80, 86, 91], "25000": 22, "2503": [67, 96], "2504": 27, "2506": 27, "2507": [10, 21, 67], "250m": 23, "2511": 91, "2512": 91, "2513": 86, "253": 68, "2530": 27, "253125": 86, "253b": 93, "255b": 93, "256": [11, 12, 13, 14, 18, 21, 22, 23, 26, 27, 28, 29, 37, 38, 49, 50, 51, 53, 62, 71, 78, 91, 92, 96], "2560": [14, 21, 26, 27, 28, 29, 37, 38], "256622": 27, "256628": 27, "256631": 27, "256k": 93, "256mb": 23, "2578": 27, "2587": 25, "25it": 78, "25m": 23, "26": [14, 25, 26, 37, 42, 62, 63, 81, 84], "262144": [62, 81, 84], "26306266784668": 86, "264": [27, 37], "264404296875": 42, "26553": 27, "2658": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "266055e": 86, "266d5c0cb25f427b8bb97859e17e8507": 48, "2677": 27, "26792": 27, "26829": 27, "2696": 27, "2697": 27, "2699": 27, "26it": [25, 28, 37], "27": [14, 21, 25, 26, 27, 28, 29, 34, 37, 38, 41, 42, 43, 48, 78, 80, 86], "2704": 27, "271": 27, "2719": 27, "272": 62, "274": 25, "2750": 27, "2753": 37, "277": 34, "27748": 27, "2776": 27, "279": [26, 27, 37, 48], "2797": 27, "27989": 37, "27b": [67, 93, 96, 98], "28": [14, 21, 26, 27, 28, 29, 37, 38, 62, 63, 86, 93], "281": 28, "2814453125": 86, "2816": [14, 21, 26, 27, 28, 29, 37, 38], "282": 14, "2824": 25, "2826": 86, "2837": 25, "28590": 37, "28672": 62, "28680": [62, 63], "287": 27, "287439": 37, "288": [14, 21, 26, 27, 28, 29, 37, 38, 62], "28b": 96, "28it": 78, "28m": 14, "29": [21, 31, 34, 37, 41, 42, 84], "29000": 23, "2908": 27, "290b": 93, "29121": 37, "29138749187": 34, "2924": 27, "2938": 27, "29500": [2, 94], "296": 27, "296752e": 86, "2975": 27, "29it": 14, "2_6": [67, 96], "2a": [0, 22], "2b": [18, 22, 67, 92, 93, 96, 97], "2card": 62, "2f": [37, 97], "2f3a0c3": 23, "2k": 17, "2k2k": 62, "2m": [14, 23], "2t": 93, "2x": [7, 10, 22, 23, 80, 85, 91], "3": [0, 1, 4, 13, 14, 16, 17, 18, 19, 21, 22, 23, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 59, 61, 63, 67, 70, 72, 73, 78, 80, 81, 84, 86, 88, 93, 94, 96, 97, 98, 99, 100], "30": [11, 14, 21, 22, 23, 26, 27, 28, 29, 31, 37, 38, 52, 60, 62, 81, 84, 86, 91], "300": [14, 16, 21, 22, 23, 26, 27, 28, 29, 33, 37, 38, 43, 46, 84, 93, 96], "3000": [50, 62, 84, 86], "30000": [4, 6, 12, 15, 16, 17, 18, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 46, 47, 48, 50, 51, 53, 54, 57, 59, 68, 71, 73, 81, 82, 84, 86, 90, 91, 92, 93, 95, 96, 97, 98, 100], "300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 27, "30001": [6, 16, 23, 39, 51, 81], "30002": [6, 51], "30003": [6, 51], "3001": 62, "30010": 91, "30011": 23, "3003": 27, "30080": 84, "3010": 27, "3033": 27, "30339": 27, "304": [27, 48], "3042": 27, "30615": 27, "3069": 37, "307": 43, "3072": [14, 21, 26, 27, 28, 29, 37, 38, 62], "308": 27, "30800": [81, 84], "3082": 27, "30893": 37, "3090": 86, "30b": [28, 46, 61, 62, 67, 93, 96], "30gb": 11, "31": [14, 25, 26, 28, 31, 57, 74, 78], "31000": 23, "311": [27, 37], "3118": 27, "311832189559937": 37, "312": 62, "312226e": 86, "31378": 23, "314": 86, "3146": [27, 37], "314b": 93, "315": [26, 27, 37, 48], "3151": 27, "316": 27, "316000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 27, "317": 13, "31784": 14, "31it": [14, 37, 78], "32": [1, 14, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 37, 38, 47, 48, 49, 51, 62, 63, 65, 71, 72, 74, 80, 81, 84, 86, 90], "320": [14, 21, 26, 27, 28, 29, 37, 38, 62], "3200": 62, "3202": 19, "3207": 27, "3212": 25, "3213": 27, "3215": 25, "32166": 37, "322": 14, "323": [27, 48], "32313": 27, "3248779296875": 86, "326": 27, "32717": 41, "32768": [37, 62, 81, 84], "3278": 27, "3283": [27, 37, 48], "3298": 25, "32b": [67, 68, 71, 93], "32b_eagle3": 71, "32card": 62, "32exp": 84, "32g": [53, 57, 91], "32it": [14, 78], "33": [14, 29, 37, 43, 78], "330": [26, 27], "33201": 78, "33249": 78, "3328": [14, 21, 25, 26, 27, 28, 29, 37, 38], "336": [67, 92], "339675e": 86, "33it": 26, "34": [14, 21, 25, 26, 27, 28, 29, 34, 37, 38, 41, 42, 43, 48, 78], "3405": [27, 37], "3410": 27, "3430": 27, "343549966812134": 27, "3440": 62, "3460": 27, "34b": 67, "35": [14, 25, 78, 91], "3500": 62, "3500000": 27, "350x": 30, "3513": 25, "3518979474117756e": 86, "352": [14, 21, 26, 27, 28, 29, 37, 38, 63], "35212": 27, "3526": 27, "352891206741333": 37, "3533": 19, "3538783": 26, "353887": 26, "353891": 26, "35545": 37, "356": 37, "3561": 27, "3565": 37, "3566": 25, "35703": 27, "357747e": 86, "358": [27, 37], "3582": 25, "3583": 31, "3584": [14, 21, 26, 27, 28, 29, 37, 38, 62], "3598": 27, "36": [14, 21, 25, 27, 29, 34, 42, 48, 62], "3600": [17, 30, 31, 62], "360p": 50, "362": [14, 37], "36342": 37, "3643": 27, "3654": 27, "36879": 37, "369": 27, "3692": 37, "369873046875": 42, "36b": 93, "36it": [25, 28], "37": [14, 29, 41, 48], "37078": 37, "370959": 13, "371": 43, "372889757156372": 27, "373": 25, "374": [26, 27, 34, 37, 48], "377": 43, "3772": 27, "3786": 27, "3796875": 86, "37it": 25, "38": [25, 37], "380": 29, "3800": 27, "38137": 37, "382": [27, 86], "3825": 37, "38288": 27, "38296": 27, "384": [14, 21, 26, 27, 28, 29, 37, 38, 62], "3840": [14, 21, 26, 27, 28, 29, 37, 38], "386": 27, "387": [27, 37], "3871956": 26, "3880": 27, "389": [27, 37, 48], "389414e": 86, "38it": 28, "39": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 68, 78], "3900": 62, "390533738": 27, "3910": 27, "3916": 25, "3946": 27, "3950": 37, "3953": 27, "399937000": 29, "39it": 78, "3_1": 93, "3_3": 93, "3a7b": 23, "3b": [28, 29, 50, 67, 72, 91, 93], "3e": 2, "3e108f4887c64560917ae93a5cf89dcd": 37, "3e764d9c360a4d21b81fe35055f85dd6": 26, "3f": 11, "3ff79b0f": 27, "3k": 62, "3m": 36, "3moe": 93, "3next": 93, "3rd": 41, "3x": [11, 91], "4": [0, 1, 5, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 36, 37, 38, 41, 42, 43, 44, 45, 48, 51, 52, 60, 61, 65, 67, 68, 74, 78, 80, 81, 82, 84, 85, 86, 91, 93, 94, 96, 98], "40": [14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 43, 57, 68, 71, 78, 86, 93], "400": [12, 58, 62, 89, 91], "4000": [19, 59, 62], "40000": 80, "400757e": 86, "400b": [35, 93], "400k": 36, "401": 50, "402": 14, "403": 50, "4041": 27, "4049": 25, "405": 27, "407": 28, "408": 23, "4090": 91, "4092": 27, "4096": [3, 13, 14, 17, 21, 22, 25, 26, 27, 28, 29, 31, 37, 38, 54, 62, 71, 74, 75, 84], "4096x12288": 25, "4096x22016": 25, "4096x32000": 25, "4096x4096": 25, "40it": [26, 28], "41": [14, 25, 26, 37, 42], "410": 62, "4124": 27, "4126": 27, "4135": 27, "41517": 27, "416": [14, 21, 26, 27, 28, 29, 37, 38], "4172": 37, "419": 27, "41971": 27, "41d4": 23, "42": [4, 14, 21, 23, 25, 26, 29, 37, 41, 62, 68], "420": 28, "421": 27, "4226": 37, "4237": 25, "42430": 37, "42434": 37, "42446": 37, "42456": 37, "42466": 37, "424b": [93, 96], "425": 37, "4257": 27, "427": 28, "4278": 25, "429": [27, 37], "43": [4, 14, 25, 37, 68], "4300": 62, "4317": [14, 21, 22, 23, 26, 27, 28, 29, 37, 38, 87], "4318": 87, "432": 27, "4329": 27, "433413": 86, "4340292513370514": 89, "4354": 27, "43602": 27, "4378": 27, "438": [27, 37], "4396": 27, "43it": [26, 28], "44": [4, 14, 25, 28, 37, 48], "4411": 27, "4418": 31, "442": 14, "44292": 27, "44441": 27, "4453": 27, "4460": 27, "446655440000": 23, "448": [14, 21, 26, 27, 28, 29, 37, 38], "4486": 37, "448754b1c56242b8918fcb04fe6ed05b": 28, "44it": 14, "45": [4, 14, 23, 26, 28, 37, 91], "4505": 48, "450560": 62, "45541": 26, "458": 27, "4586": 27, "458880": 62, "4594": 13, "45de44314c7a421aaaa28052c38cf52": 27, "46": [4, 14, 26, 27, 28], "4608": [14, 21, 26, 27, 28, 29, 37, 38], "461101531982422": 27, "4623": 27, "4658": 27, "466": 28, "4686": 27, "46913": 27, "4695": 27, "46it": 14, "47": [14, 21, 26, 28, 37, 41, 78], "4710": [27, 37], "4712": 27, "4718": 27, "4734": 27, "4751": 27, "4755": 27, "476": [27, 37], "47b": 93, "47it": [28, 37], "48": [14, 21, 22, 25, 26, 27, 28, 29, 30, 31, 37, 38, 62], "480": [14, 21, 26, 27, 28, 29, 37, 38, 62], "480b": 67, "480p": 91, "481064319610596": 27, "482": 14, "486": 86, "487316894531251": 86, "48908": 80, "48924": 80, "48b": 93, "48f47a4892c64b059c3d67136541943": 25, "48it": 37, "49": [14, 25, 26, 48, 78, 86], "49152": 62, "4934": 19, "497": 27, "49730": 14, "49740": 14, "49748": 14, "49752": 14, "4977": [27, 37], "498": [26, 34, 37], "49b": 93, "49it": [14, 28], "4a": 50, "4b": [41, 50, 67, 91, 92, 93, 96], "4bit": 18, "4c3f": 23, "4c885ff5daeb42ee81c88392b372d13a": 41, "4card": 62, "4e25d98e647f49ca80a08bcada3a937c": 27, "4f": [37, 97], "4gb": 12, "4k": [17, 50, 62], "4k1": 62, "4th": 68, "4v": [93, 96], "4x": [23, 36, 91], "4xh100": 45, "5": [0, 1, 3, 5, 11, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31, 35, 37, 38, 39, 41, 42, 43, 44, 47, 48, 50, 51, 52, 54, 56, 59, 60, 61, 63, 67, 68, 71, 72, 78, 80, 81, 84, 86, 89, 91, 92, 93, 94, 95, 96, 98, 99], "50": [4, 13, 14, 21, 22, 23, 25, 26, 27, 28, 29, 31, 37, 41, 42, 78, 80, 86, 91], "500": [22, 23, 27, 50, 52, 54, 60, 74, 87, 89], "5000": [16, 23, 62, 63], "50000": [22, 62, 63], "500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 27, "50051": [10, 12], "5008": 27, "500m": 23, "50100": 26, "5018": 26, "502": 23, "5025": 25, "503": 23, "504": [23, 27], "5042": 27, "5067": 19, "5080": 27, "5081": 19, "50814177726902": 86, "5086": 27, "50it": [28, 37, 78], "50m": 23, "50mb": 23, "51": [14, 25, 28, 29, 37, 38], "5109": 27, "512": [11, 13, 14, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 37, 38, 50, 51, 62, 63, 71, 78, 92, 96], "5120": [14, 21, 26, 27, 28, 29, 37, 38], "5122": 37, "512x768": 50, "514771912145079": 86, "515": 27, "518": [27, 37], "5185": 27, "51it": 37, "52": [25, 82, 93], "522": 14, "5226": 31, "5230": 27, "524": 37, "524288": 81, "52428800": 23, "525": 27, "5257": 27, "527617": 26, "52844": 27, "5290": 27, "52b": 93, "52it": [25, 28], "53": [14, 25, 28, 37, 43], "5301995277404785": 26, "5302121639251709": 26, "5302183628082275": 26, "5338": 27, "53543": 27, "537": 27, "53it": 48, "54": [14, 25, 37, 38, 48, 62], "54231": 27, "5432": 23, "5434": 19, "544": 91, "545": 31, "5488": 27, "54it": 14, "55": [14, 25, 26, 29, 78], "550e8400": 23, "551": 27, "5512": 27, "5535": 27, "557572e": 86, "55942": 27, "55it": 14, "56": [19, 21, 25, 26, 27, 28, 29, 37, 38, 41, 62], "562": 14, "5632": [14, 21, 26, 27, 28, 29, 37, 38], "5646": 27, "5648": 27, "565": 28, "565970778465271": 89, "5678": 23, "56953125": 86, "56it": 14, "57": [25, 27, 28, 48], "570": 29, "5707": 37, "570dbdac89c3": 27, "5711": 27, "572": 27, "5724": 17, "57344": 19, "57406": 27, "576": [27, 37, 62], "5791549598": 86, "57it": [25, 28], "58": [14, 25, 34, 37, 43], "582": 37, "5837": 37, "5847": 27, "58it": 25, "59": [14, 25, 28, 37], "593": 86, "594": 27, "5944": 27, "595": 27, "59604": [27, 37], "596463012695313": 86, "5975": 27, "5978": 27, "5990": 27, "59924": 27, "5_step": 91, "5b": [0, 14, 23, 37, 38, 39, 41, 42, 48, 67, 72, 89, 91, 93, 98, 99], "5c1ba73a1f1449279977be2f1ae48154": 37, "5cabee2f367d4ec59b8dcb98e687a19c": 43, "5f2f9ca2b62d48848cb5b8dce20feeb9": 48, "5k": 62, "5k1": 62, "5k1k": 62, "5m": [23, 35], "5moe": [67, 93], "5t": 93, "5v": [5, 44, 67, 96], "5x": 30, "6": [14, 17, 21, 22, 23, 25, 26, 27, 28, 29, 33, 37, 38, 41, 42, 43, 44, 48, 50, 51, 59, 61, 62, 63, 67, 68, 70, 78, 80, 85, 86, 91, 93, 94, 96], "60": [21, 23, 25, 26, 37, 43, 51, 62, 78, 80, 84, 86, 96, 97], "600": [16, 23, 27, 62], "6000": [19, 62], "6017": 81, "602": 14, "602112": 96, "60410": 37, "606": 27, "60704": 26, "6072": 27, "608": 27, "609": 26, "6099": 27, "60it": 14, "61": [21, 25, 34, 43, 62, 78], "614": 27, "6144": [14, 17, 21, 26, 27, 28, 29, 37, 38], "6169": 27, "617": 31, "61it": 25, "62": [21, 27, 28, 37, 78], "62001": 31, "624": [27, 62], "6247": 37, "6290": 37, "63": [14, 21, 25], "6323": 37, "6364": 27, "6379": 23, "63it": 28, "64": [1, 10, 14, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 31, 33, 37, 38, 41, 42, 43, 46, 47, 48, 50, 51, 54, 62, 71, 72, 74, 78, 81, 84, 87], "640": [14, 21, 26, 27, 28, 29, 37, 38], "64000": [31, 62], "642": 14, "646": [27, 37], "64it": 25, "64k": 62, "64k3k": 62, "64mb": 23, "64x11008": 25, "64x4096": 25, "65": [1, 14, 17, 21, 25, 26, 27, 33, 46], "650": [62, 63], "6501ef8e2d874006bf555bc80cddc7c5": 30, "6540": 27, "65536": [13, 29, 35, 62], "66": [14, 62], "6617": 27, "6656": [14, 21, 26, 27, 28, 29, 37, 38], "665690": 13, "6688": [61, 62, 63], "6699": 62, "67": [21, 31, 37, 78], "6707": 27, "67108864": 23, "671b": 93, "6722": [27, 37], "6771": [27, 37], "6778": 19, "678": 27, "67890": 41, "68": [25, 37, 62, 63], "68000": 62, "6801": 27, "682": 14, "685": [37, 62], "6864": 26, "6894": 27, "6896": 27, "6899": 19, "69": [21, 25], "694586777a9c433fad54d3f2753292a3": 27, "695": 27, "6980p": [30, 68], "6a954cdcf03e4fb1b25dc145583498a3": 25, "6b": [57, 67, 92, 93, 97], "6k": [17, 62], "6k1": 62, "6lcbd": 81, "6th": 68, "6v": [5, 44], "7": [13, 14, 21, 22, 23, 25, 26, 27, 28, 29, 35, 37, 38, 41, 44, 48, 51, 61, 62, 67, 75, 78, 80, 81, 86, 89, 91, 93, 94, 96], "70": [14, 25, 28, 43, 51], "700": 27, "7007": 26, "7010": 19, "702": 27, "7025": 27, "7039": 27, "704": [14, 21, 26, 27, 28, 29, 37, 38], "7042": 27, "705": 27, "7050683": 26, "7071": 27, "7086": 27, "70874": 27, "70b": [28, 68], "70it": [14, 78], "71": [25, 28, 31, 62], "712400": 80, "714": 27, "7168": [14, 21, 26, 27, 28, 29, 37, 38], "718164012": 38, "7196": 27, "72": [14, 21, 25, 26, 27, 28, 29, 38, 41, 62], "720": [62, 63, 91], "720p": [50, 91], "722": 14, "7239": 62, "7273": 19, "728": 27, "72b": [67, 96, 98], "72it": 37, "73": [25, 62, 78, 86], "730666": 27, "730975341796876": 86, "7333": 19, "7339": 62, "73it": [14, 26], "74": [25, 35, 38, 62], "7402": 37, "7407": 48, "74124": 37, "742": 27, "7439": 62, "7448475": 27, "745589": 37, "7468": 27, "7482": 27, "748223003": 14, "7486296874999999": 29, "749": 34, "74it": 37, "74m": [81, 84], "75": [14, 16, 17, 25, 26, 28, 35, 37, 41, 62, 78, 86, 91, 93], "75046": 27, "752": [27, 37], "7533": 19, "756": 27, "75b": 93, "76": [25, 37, 38, 41, 48], "762": 14, "763837784": 26, "765301109": 37, "76602": 27, "7667": 19, "768": [13, 14, 21, 26, 27, 28, 29, 37, 38, 62], "7680": [14, 21, 26, 27, 28, 29, 37, 38], "7697": 19, "77": [14, 25, 27, 37, 48], "770": 37, "7707": 19, "773": 27, "7733": 19, "7771": 37, "7772": 48, "7789": 37, "7795": 27, "77it": 25, "77x": 85, "78": [14, 19, 25, 37, 62, 63], "7826": 27, "7827ec9a4ebd45c8b3a136a53dabc949": 26, "783": 31, "785": 27, "788": [27, 31], "79": [25, 37, 62], "793": 31, "794": 26, "797": 31, "7979": 17, "798": 31, "799": 31, "7ae557604adf67be50417f59c2c2f167def9a775": 37, "7b": [5, 18, 21, 25, 27, 28, 37, 43, 47, 52, 60, 67, 73, 78, 92, 93, 95, 96, 98], "7cc207aa55794c1b91dd0235323b108a": 43, "7f": 80, "7fa2af80": 51, "7x": 30, "8": [1, 2, 4, 7, 10, 11, 13, 14, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 41, 46, 47, 48, 50, 51, 53, 54, 59, 61, 62, 63, 65, 70, 71, 75, 78, 80, 81, 82, 84, 86, 91, 94], "80": [14, 21, 23, 25, 26, 27, 28, 29, 35, 37, 38, 43, 54, 62, 71, 78], "800": [27, 30], "8000": [6, 16, 23, 31, 36, 50, 51, 61, 62, 63, 81, 82, 84, 89], "8001": [23, 61, 62, 63, 97], "80022": 27, "800i": [30, 61], "802": 14, "803": [27, 31, 37], "804": 27, "807": 27, "808": 31, "8080": [0, 10, 23, 57, 84], "80b": [28, 45, 62, 67, 93], "80it": [25, 26, 78], "81": [25, 27, 62, 63], "813": [28, 31], "815": [62, 63], "816043786240": 10, "8166113": 26, "8173": 27, "8188": [62, 63], "8192": [13, 14, 21, 25, 26, 27, 28, 29, 33, 37, 38, 46, 54, 62, 63, 70, 71, 74, 80], "82": [13, 14, 27, 68], "821": 27, "824": 31, "82m": 14, "83": [14, 25, 31, 62], "8300": 27, "832": [14, 21, 26, 27, 28, 29, 37, 38, 62, 63], "835": [21, 26, 27, 28, 38], "835141583": 37, "8356": 37, "8365": [27, 37], "838": 31, "83it": [37, 41], "84": [14, 25, 62, 80], "840": 31, "841": [14, 37], "8411": 37, "842": 14, "84204177856446": 86, "8443": 23, "845": 86, "8458": 37, "847": 27, "848": 31, "849": [81, 84], "85": [10, 14, 17, 25, 28, 36], "85122": 37, "8542968750000001": 86, "855": 86, "85it": 14, "86": [25, 37, 62, 68, 86], "860": 62, "862": 27, "864018936": 28, "8651": 27, "866964": 86, "86it": 14, "87": [14, 25, 31], "879": 31, "87adf6a03d4e45639f29c3d79c79f148": 28, "87it": 48, "88": [21, 23, 26, 27, 28, 29, 37, 38, 62, 63], "882": 14, "8832519531250003": 86, "8833": 34, "8846": 17, "8884": [52, 60], "89": [25, 43, 80], "892": 27, "8926": 27, "894": 27, "89469451904297": 86, "896": [14, 21, 26, 27, 28, 29, 37, 38], "8965": 87, "8995": [61, 62], "8996": 63, "8998": [14, 21, 22, 26, 27, 28, 29, 31, 37, 38, 62, 63], "8999": [62, 63], "8abf": 27, "8b": [1, 2, 3, 6, 14, 16, 18, 22, 23, 25, 26, 28, 37, 47, 50, 51, 57, 59, 61, 67, 68, 70, 72, 86, 88, 93, 94, 96, 97, 98, 99], "8c70": 23, "8t": 93, "8th": 41, "8x": [30, 36], "8xh100": [32, 35], "8xh200": 31, "9": [13, 14, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 45, 50, 51, 56, 57, 68, 71, 72, 78, 80, 86, 91, 94], "90": [23, 25, 28, 31, 62], "9000": [62, 63, 65], "9001": 23, "902": 27, "9069": 27, "9090": 86, "90ab": 23, "90it": 25, "91": [14, 25, 43], "910b": 61, "911": [27, 37], "912": 27, "9120": 2, "9124": 19, "9152": 19, "9154": 19, "9157": 19, "916": 27, "9161": 19, "9163": 19, "9168": 19, "9181": 19, "9186": 19, "92": [25, 26, 27, 31], "92014": 27, "922": 14, "9220": [52, 60], "9221679687500002": 86, "9292": 27, "92999": 37, "93": [14, 29, 80], "933": 27, "9363": 37, "94": [25, 31], "941": 86, "944": 27, "94409": 37, "94451": 27, "94535": 37, "9454": 37, "94it": [28, 38], "95": [14, 18, 21, 23, 25, 26, 27, 28, 31, 37, 38, 41, 75, 90], "950195e": 86, "9521": 27, "956": 31, "95it": 25, "96": [14, 21, 25, 26, 27, 28, 29, 30, 31, 37, 38, 48, 62, 71, 83], "960": [14, 21, 26, 27, 28, 29, 37, 38, 91], "962": 14, "9625": [27, 37, 48], "9658": 27, "966": 27, "96g": 31, "96gb": 36, "97": 25, "9716": 37, "9720": [27, 37], "9733": 27, "9763": 37, "97771": 37, "979": 27, "97904": 27, "97it": 14, "97m": [81, 84], "98": [25, 37], "9806": 48, "9822": 26, "983": 51, "984": 22, "98it": [14, 27], "99": [14, 23, 25, 28, 37, 97], "990": 27, "992": 22, "9938343119433": 37, "996": 22, "998": 22, "9998": 13, "999999": 35, "9b": [67, 93, 96], "9bf17f2847b046c7b2d5495f4b4f9682": 89, "9c5dbfc57": [81, 84], "9dff": 80, "9fef7a8ff44f43278ade85618feaf1a3": 26, "9k": 62, "9k1k": 62, "9th": 41, "9x": 30, "A": [5, 8, 11, 13, 14, 16, 17, 21, 22, 23, 24, 25, 29, 30, 31, 38, 47, 49, 51, 52, 57, 60, 68, 70, 72, 80, 87, 91, 92, 93, 96, 97, 98, 100], "And": [17, 34, 38, 85], "As": [11, 13, 14, 17, 38, 43, 51], "At": [11, 31, 78, 80, 81, 84], "Be": 24, "But": [14, 25, 27, 31, 41], "By": [4, 7, 10, 11, 13, 14, 15, 16, 17, 22, 24, 25, 30, 34, 47, 57, 73, 78, 86, 91, 96, 99, 100], "For": [0, 1, 3, 7, 8, 10, 11, 12, 14, 16, 17, 18, 21, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 57, 58, 60, 68, 71, 76, 80, 84, 86, 87, 91, 92, 93, 94, 96, 97, 99], "If": [0, 1, 3, 8, 11, 12, 13, 14, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 30, 31, 33, 37, 38, 39, 41, 46, 47, 49, 50, 51, 52, 53, 57, 59, 60, 61, 62, 68, 69, 71, 73, 75, 80, 85, 86, 87, 88, 89, 91, 92, 93, 96, 97, 99], "In": [3, 5, 6, 8, 11, 14, 16, 17, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 37, 41, 42, 43, 48, 52, 53, 57, 59, 60, 68, 71, 74, 75, 78, 80, 81, 87, 91, 94, 99], "It": [1, 3, 5, 7, 11, 12, 13, 14, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 41, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 60, 68, 73, 76, 91, 92, 93, 96, 99], "Its": [30, 58], "NOT": [28, 73, 97], "No": [4, 8, 9, 14, 19, 21, 23, 25, 26, 27, 28, 29, 34, 37, 41, 42, 43, 48, 74, 78, 86, 91], "Not": [1, 19, 22, 38, 50, 74], "OFED": 80, "Of": 78, "On": [5, 11, 13, 17, 19, 24, 31, 33, 46, 57, 68, 83, 87], "One": [14, 22, 24, 38, 41, 47, 91], "Or": [3, 16, 18, 23, 25, 28, 50, 70, 91, 95], "Such": 78, "THE": 41, "That": [27, 99, 100], "The": [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 59, 61, 64, 68, 70, 71, 72, 74, 76, 78, 79, 80, 81, 84, 86, 87, 88, 89, 91, 93, 94, 96, 97, 99, 100], "Their": 87, "Then": [14, 18, 23, 31, 39, 52, 56, 60, 80, 82, 86, 99], "There": [45, 53, 73], "These": [7, 18, 22, 25, 34, 38, 41, 52, 60, 74, 85, 87, 93, 96, 98, 99], "To": [1, 4, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 60, 64, 68, 71, 75, 78, 81, 85, 86, 87, 91, 95, 96, 99], "Will": 1, "With": [0, 1, 14, 17, 23, 24, 30, 31, 36, 50, 51, 59, 71, 96], "_": [8, 31, 78], "____": 38, "__call__": [47, 99], "__future__": 49, "__global__": 49, "__init__": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 55, 78, 99], "__main__": [63, 90, 99], "__name__": [8, 63, 90, 99], "__post_init__": 91, "_attn_implement": 100, "_bootstrap_extern": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "_commun": 12, "_dynamo": 25, "_flash_3_hub": 91, "_forward_attn": 7, "_forward_combin": 7, "_forward_dispatch": 7, "_forward_mlp": 7, "_is_idle_for_hicache_storage_op": 12, "_is_no_request": 12, "_jit_add_constant_modul": 49, "_output_": 31, "_pp_commit_comm_work": 17, "_pp_launch_batch": 17, "_pp_process_batch_result": 17, "_pp_send_pyobj_to_next_stag": 17, "_supports_attention_backend": 100, "_work": 37, "a10": 57, "a100": [1, 30, 33, 46, 57, 58, 91], "a14b": 91, "a1b2c3d4": 23, "a2": [31, 37, 61, 67, 80], "a22b": [10, 19, 21, 46, 67, 68, 96], "a2a": [7, 16, 22, 62, 63, 74, 81, 84], "a2b26e557c514d6e80bc17459ca48894": 26, "a2b27aa70a66dc36ce71116f6c6a259dd1b23c17": 14, "a2dc": 80, "a2f59506bb2f4f66a092da03a6fd956c": 26, "a3": [30, 31, 61, 67], "a35b": 67, "a36b": [67, 93], "a3b": [28, 45, 46, 61, 62, 67, 93, 96], "a40": 1, "a716": 23, "a800": 30, "a800m": [67, 93], "aarch64": [57, 61], "ab": [23, 91], "ab19bd6a6fcd458aa87891df9653c5fb": 26, "abbrevi": [26, 27, 28], "abc": 11, "abi3": 57, "abil": [14, 38, 93], "abl": [14, 38, 86, 99], "abnorm": [18, 91], "abort": [22, 24, 27], "abort_al": 24, "abort_all_request": 24, "abort_on_priority_when_dis": [14, 21, 26, 27, 28, 29, 37, 38], "about": [8, 11, 13, 14, 20, 22, 26, 27, 34, 37, 38, 41, 53, 72, 73, 75, 78, 79, 91, 96, 99, 100], "abov": [10, 22, 25, 28, 29, 30, 38, 39, 41, 47, 50, 51, 52, 57, 60, 68, 72, 75, 76, 78, 80, 87, 99], "absolut": [0, 23], "absorpt": 30, "abstract": 7, "abus": [52, 60], "ac0cafb14d9a46dfaef1e779439ba4e2": 14, "acc": 22, "acc_typ": 25, "acceler": [2, 7, 13, 22, 25, 30, 57, 58, 63, 71], "accelerator_arg": 71, "accept": [16, 19, 22, 23, 25, 41, 47, 49, 50, 82, 90, 91, 93, 96, 99], "accept_length": 50, "access": [6, 11, 22, 23, 24, 26, 27, 30, 38, 41, 51, 57, 68, 71, 74, 80, 81, 84, 86, 87, 91, 99], "accommod": 87, "accomplish": [38, 41], "accord": [1, 16, 17, 18, 27, 28, 34, 45, 51, 68, 80, 81, 84], "accordingli": [0, 21, 28, 37], "account": [3, 19, 52, 60, 75], "accumul": [19, 74, 75], "accur": [22, 27, 38, 45, 92, 96], "accuraci": [18, 22, 24, 25, 27, 38, 63, 91, 93, 96, 97, 99], "achiev": [4, 7, 11, 14, 17, 24, 25, 30, 31, 41, 71, 75, 80, 85, 91, 93, 96], "across": [2, 4, 5, 7, 10, 11, 12, 14, 17, 19, 22, 23, 24, 30, 31, 49, 51, 58, 71, 74, 75, 76, 82, 85, 87, 91, 93], "act": [28, 34, 39], "action": [18, 23], "activ": [7, 8, 12, 13, 18, 22, 23, 24, 30, 36, 51, 58, 61, 64, 68, 71, 72, 74, 78, 80, 82, 91, 93], "actual": [8, 11, 14, 17, 21, 25, 26, 27, 28, 36, 37, 41, 42, 43, 48, 78, 81, 84, 86, 87, 89], "ad": [0, 4, 14, 15, 17, 21, 22, 23, 28, 34, 41, 49, 52, 57, 58, 60, 86, 87, 91], "ad1b": 27, "ada": 1, "adapt": [7, 14, 22, 31, 61, 71, 80, 99], "adapter_a": [14, 41], "adapter_b": 41, "adb": 23, "add": [0, 2, 7, 10, 18, 21, 22, 24, 26, 27, 28, 30, 32, 34, 35, 38, 42, 45, 47, 50, 51, 53, 54, 57, 59, 61, 64, 68, 75, 81, 84, 86, 91, 96], "add_const": 49, "add_constant_kernel": 49, "add_generation_prompt": [21, 26, 27, 28], "add_link": 87, "add_special_token": 37, "addit": [2, 4, 14, 17, 19, 21, 22, 24, 28, 38, 41, 52, 57, 60, 61, 71, 76, 87, 89, 91, 99], "addition": [6, 25, 30, 31, 38, 51, 68, 72, 80], "addr": [2, 16, 17, 22, 31, 62, 63, 71, 80, 81, 82, 84, 94], "address": [2, 6, 7, 10, 11, 16, 17, 20, 22, 23, 24, 38, 68, 72, 74, 75, 78, 80, 82], "adept": 93, "adjust": [22, 25, 29, 30, 35, 36, 37, 45, 50, 68, 71, 75, 81, 84, 86, 96], "admin": [10, 22, 86], "admin_api_kei": [14, 21, 22, 26, 27, 28, 29, 37, 38], "administr": [22, 27], "adopt": [22, 23, 58], "adv": 51, "advanc": [7, 14, 31, 34, 36, 47, 49, 51, 87, 93, 96], "adventur": 38, "adversari": 14, "advis": 26, "affect": [11, 14, 16, 18, 22, 61, 71], "affin": [17, 23, 61, 74], "afford": 38, "aflah02": 82, "afm": [67, 93], "aforement": [17, 31], "afraid": 38, "after": [0, 3, 5, 7, 11, 12, 14, 16, 18, 21, 22, 23, 24, 25, 30, 33, 36, 38, 46, 48, 49, 50, 51, 57, 70, 75, 81, 87, 91, 96, 99], "afterward": [3, 25, 59], "ag": [38, 80], "again": [11, 14, 18, 25, 28, 41, 52, 59, 60, 64, 91, 99], "against": [0, 11, 14, 18, 22, 50, 76, 97], "agenc": [27, 38, 93], "agent": [21, 23, 36, 48, 50, 93], "agglomer": 27, "aggreg": [11, 12, 50, 87], "aggress": [17, 23, 90], "agnost": 7, "agx": 70, "ahead": 49, "ai": [1, 7, 16, 17, 19, 21, 23, 26, 27, 28, 30, 31, 34, 38, 41, 48, 53, 59, 61, 67, 68, 70, 80, 81, 84, 91, 93, 94, 96, 99], "aibrix": [11, 12, 22], "aid": [14, 49, 78], "aidc": 91, "aig": 81, "ailuropoda": [37, 97], "aim": [25, 30, 37, 74, 78, 80], "aime25": [19, 31], "aiohttp": 50, "aiter": [1, 22, 31, 35, 74, 91], "aiter_attn": 22, "aiv": [62, 65], "ai\u52a9\u624b": [81, 84], "alert": 23, "alexand": 14, "algo": 45, "algoprog": 14, "algorithm": [11, 17, 18, 22, 25, 30, 31, 32, 34, 35, 38, 45, 62, 63, 65, 71, 81, 84, 90], "alia": [23, 59, 61], "alias": 91, "alibaba": [37, 41, 42, 46, 67, 92, 93, 96], "align": [17, 18, 22, 23, 24, 85, 93, 96, 98], "aliv": [24, 78], "all": [0, 1, 2, 4, 5, 8, 10, 11, 12, 14, 15, 17, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 41, 43, 47, 49, 50, 51, 52, 53, 54, 56, 57, 60, 61, 71, 74, 76, 78, 81, 87, 89, 91, 95, 97, 99], "all_attention_funct": 100, "all_hip": 59, "all_musa": 69, "all_npu": 61, "all_other_model": 99, "all_reduc": 11, "allen": 93, "allenai": [18, 67, 93], "allevi": 11, "allgath": 22, "alloc": [3, 11, 13, 14, 22, 37, 51, 71, 86], "allocator_ascend": [52, 60], "allow": [2, 3, 7, 10, 11, 15, 17, 19, 22, 23, 25, 27, 30, 33, 39, 41, 46, 49, 51, 53, 57, 71, 74, 81, 87, 89, 91, 92, 96, 97, 99], "allow_auto_trunc": [14, 21, 26, 27, 28, 29, 37, 38], "allow_tf32": 25, "allreduc": 22, "almanac": 27, "almost": [91, 99], "alon": [14, 91], "along": [14, 27, 34, 57, 59, 93, 96], "alongsid": [23, 51, 57, 96], "alpha": [71, 93], "alreadi": [11, 12, 14, 16, 17, 18, 30, 34, 39, 60, 64, 68, 86, 87, 92], "alright": 27, "also": [1, 3, 10, 11, 12, 13, 14, 17, 18, 21, 22, 24, 25, 27, 28, 30, 31, 34, 37, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 57, 59, 60, 70, 73, 75, 78, 80, 81, 82, 85, 87, 91, 96, 97, 99, 100], "altern": [0, 10, 11, 17, 18, 22, 43, 49, 74, 76, 98], "although": 17, "altogeth": 27, "alwai": [0, 1, 4, 13, 14, 19, 21, 22, 23, 26, 27, 28, 38, 41, 47, 52, 60, 71, 89, 91, 97], "am": [27, 38, 41], "amazon": [11, 57], "amazonaw": 57, "ambush": 14, "amd": [18, 31, 35, 56, 57, 58, 74, 91], "america": [26, 27], "among": [10, 11, 25, 30, 74, 85, 87], "amount": [14, 17, 41, 68], "amper": [1, 7], "amplifi": 91, "amx": [1, 22, 68], "amxint4": [14, 22, 37], "an": [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 14, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 39, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 62, 68, 69, 74, 75, 76, 78, 80, 85, 86, 87, 93, 94, 95, 96, 98], "analysi": [17, 21, 22, 28, 53, 71, 91], "analyst": 34, "analyz": [7, 17, 23, 37, 38, 51, 96], "ancient": [14, 38, 41], "angelslim": 71, "ani": [1, 8, 11, 14, 15, 16, 17, 18, 22, 23, 24, 27, 28, 30, 31, 41, 47, 49, 51, 52, 54, 57, 60, 61, 62, 78, 80, 89, 91, 92, 99, 100], "anim": 14, "annot": [22, 23, 25, 28, 41, 48, 49, 51], "annual": 38, "anonym": 87, "anoth": [1, 13, 14, 16, 17, 22, 27, 38, 43, 51, 59, 68, 72, 75, 78, 87], "answer": [21, 23, 25, 26, 27, 28, 37, 38, 41, 76, 78, 96, 97], "antidisestablishmentarian": 76, "anyth": [38, 41], "anywher": 37, "aot": 49, "apach": 93, "apart": 37, "apeach": [23, 67, 89, 98], "api": [8, 11, 24, 36, 47, 57, 58, 68, 71, 72, 73, 76, 78, 80, 81, 87, 90, 96], "api_kei": [14, 21, 23, 25, 26, 27, 28, 29, 30, 32, 34, 37, 38, 41, 42, 43, 47, 48, 91], "apigroup": 23, "apivers": [23, 80, 81, 84], "apolog": 37, "app": [22, 23, 81, 84], "appear": [22, 29, 41, 43, 47, 51, 52, 60, 78], "append": [4, 8, 28, 30, 36, 50, 59], "append_messag": 29, "appli": [0, 6, 7, 12, 14, 18, 22, 23, 29, 30, 36, 37, 38, 41, 50, 52, 53, 57, 60, 61, 68, 74, 80, 81, 91], "applic": [12, 14, 23, 29, 30, 36, 37, 38, 42, 43, 48, 51, 68, 80, 81, 84, 89, 90, 91, 97], "apply_chat_templ": [21, 26, 27, 28, 35, 37], "apply_softmax": 37, "appreci": [52, 60], "approach": [4, 11, 13, 14, 17, 30, 51, 57, 81], "appropri": [0, 11, 17, 18, 25, 28, 41, 50, 89], "approv": [52, 60], "approxim": [19, 27, 68], "april": 24, "apt": [0, 49, 51, 56], "aqueduct": 41, "ar": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 59, 60, 61, 67, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 84, 85, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100], "arbitrari": 8, "arc": 72, "arcane_jinx": 91, "arce": [67, 93], "arch": 56, "architectur": [1, 5, 6, 7, 17, 18, 19, 24, 30, 34, 37, 38, 41, 51, 71, 90, 91, 92, 93, 96, 99], "area": [27, 38], "areal": [58, 85], "arg": [16, 20, 23, 37, 49, 51, 53, 63, 74, 76, 92, 96], "argument": [1, 7, 18, 19, 20, 23, 26, 27, 28, 30, 31, 32, 33, 35, 37, 41, 45, 46, 47, 49, 50, 51, 52, 57, 58, 60, 64, 70, 87, 94, 99], "arguments_non_stream": 28, "aris": 75, "arm64": 23, "around": [23, 27, 28, 30, 91, 99], "arrai": [41, 47, 50, 89, 91], "arrang": [7, 37], "arriv": [21, 22, 50], "art": [14, 38, 52, 60, 85, 93], "articl": 34, "artifici": [38, 97, 99], "ascend": [1, 7, 22, 57, 58, 60, 63, 64, 65, 94], "ascend_attn": [22, 61, 65], "ascend_fuseep": [7, 22, 62], "ascend_home_path": 62, "ascend_instal": 61, "ascend_launch_block": [62, 63], "ascend_mf_store_url": [16, 61, 62, 63], "ascend_mf_transfer_protocol": 61, "ascend_npu_phy_id": 16, "ascend_rt_visible_devic": 94, "ask": [21, 25, 27, 28, 41, 52, 58, 60, 78], "aspect": [2, 22, 24], "aspect_ratio_id": 29, "aspect_ratio_mask": 29, "assert": [24, 37, 47, 51], "asset": [29, 33, 43, 46, 47, 78], "assign": [14, 47], "assist": [11, 25, 26, 27, 28, 29, 30, 34, 36, 37, 41, 43, 47, 48, 73, 76, 78, 81, 84, 90], "assistant_begin": 78, "assistant_end": 78, "associ": [4, 23, 30], "assum": [12, 21, 23, 27, 28], "assumpt": 24, "astral": 68, "async": [10, 22, 24, 38, 99], "async_gener": [38, 99], "async_send": 17, "async_stream_and_merg": 38, "asynchron": [14, 17, 22, 24, 33, 46, 85, 99], "asyncio": 99, "at_least_on": 26, "atb": [62, 63], "atla": [30, 61], "atp": 23, "atp_dsn": 23, "atp_password": 23, "atp_pool_max": 23, "atp_pool_min": 23, "atp_tns_alia": 23, "atp_us": 23, "atp_wallet_path": 23, "attach": [8, 9, 10, 23, 29, 96], "attach_point": 23, "attach_storage_backend": 12, "attachment_ep_statist": 81, "attact": 28, "attain": 13, "attempt": [11, 23, 29, 50], "atten_tp_s": 31, "attent": [4, 7, 11, 13, 14, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 29, 31, 33, 35, 37, 38, 41, 42, 43, 46, 48, 57, 58, 61, 62, 63, 65, 70, 72, 74, 78, 80, 81, 84, 92, 93, 94, 97, 99, 100], "attention_backend": [14, 21, 26, 27, 28, 29, 37, 38, 91, 94], "attention_interfac": 100, "attentionbackendenum": 91, "attn": [22, 62, 63, 91], "attn_output": 100, "attn_weight": 100, "attract": [27, 28, 38, 76], "attribut": [8, 87], "attributeerror": 8, "audio": [22, 25, 28, 37, 41, 47, 48, 96], "audio_data": 47, "audiodataitem": 47, "audit": 38, "aug": 34, "augment": [93, 96], "august": 34, "aura": 14, "auror": 78, "australia": [14, 25, 41, 48], "auth": [23, 50], "author": [22, 23, 50, 52, 60, 81, 84, 91], "auto": [0, 7, 14, 21, 22, 23, 25, 26, 27, 28, 29, 35, 37, 38, 49, 50, 62, 63, 74, 86, 88, 90, 91], "auto_awq": 18, "auto_gptq": 18, "auto_map": 100, "auto_next_anon": 87, "auto_round": 18, "autoencod": 91, "autograd": 51, "autom": [38, 59], "automat": [0, 7, 10, 11, 12, 14, 17, 18, 19, 22, 23, 24, 28, 29, 31, 33, 35, 37, 41, 45, 46, 47, 49, 50, 51, 52, 57, 60, 64, 68, 74, 86, 87, 89, 91], "autonom": [23, 38], "autoprocessor": 29, "autoregress": [6, 19, 25, 90], "autoround": 18, "autoroundmllm": 18, "autosc": 57, "autotag": 70, "autotoken": [18, 21, 26, 27, 28, 37, 42], "autotun": [22, 25, 88], "auxiliari": 16, "avail": [1, 11, 14, 16, 17, 20, 22, 24, 26, 27, 30, 31, 34, 37, 38, 39, 41, 42, 43, 48, 49, 50, 57, 59, 68, 71, 74, 75, 80, 86, 89, 91, 93, 100], "avail_mem": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 43, 48, 78], "available_gpu_mem": [13, 14, 37], "available_tool": 28, "averag": [22, 27, 76], "avg": 31, "avg_token": 31, "avid": 38, "avocado": 78, "avoid": [10, 11, 12, 14, 17, 18, 19, 22, 24, 27, 29, 31, 33, 35, 41, 46, 51, 52, 53, 60, 68, 71, 72, 75, 80, 91, 94, 95, 96, 97], "awai": 91, "await": [38, 99], "awar": [16, 24, 38, 85], "awk": [62, 63], "awq": [18, 22, 30, 58, 64], "awq_marlin": [18, 22], "aws_account": 57, "aws_region": 57, "a\u5de7": 78, "b": [4, 14, 21, 22, 25, 26, 27, 28, 29, 30, 31, 37, 38, 41, 42, 43, 48, 57, 59, 62, 63, 68, 72, 75, 78, 80, 81, 84, 87, 91], "b200": [1, 30, 31, 33, 35, 46, 91], "b300": [57, 58], "b580": 72, "b64_json": 91, "b64decod": 91, "b7fd05f5345f4bf9966ee4be2b1054ad": 27, "baai": [37, 67, 92, 93, 97], "back": [1, 7, 22, 23, 24, 31, 38, 43, 74, 89, 91, 100], "backbon": [58, 85, 96], "backend": [6, 9, 17, 19, 21, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 46, 47, 48, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 72, 76, 78, 81, 82, 84, 85, 86, 92, 94, 97, 99, 100], "backend_nam": [10, 11, 22], "backendfactori": 10, "background": [14, 23, 29, 43, 78, 86, 100], "backoff": 23, "backtrac": 51, "backu": 28, "backup": [12, 22], "backward": [14, 22, 41, 91], "bad": [8, 76, 89], "baichuan": [67, 93], "baichuan2": [67, 93], "baichuanai": 93, "baidu": [67, 93, 96], "bail": 71, "bake": 38, "balanc": [6, 10, 11, 16, 17, 22, 30, 34, 41, 43, 62, 63, 71, 78, 81, 85, 91], "balanced": [7, 22], "bandit": 14, "bandwidth": [2, 5, 6, 11, 16], "bank": [25, 27, 48], "bar": [53, 93, 96], "bare": 68, "base": [1, 5, 6, 7, 10, 11, 14, 16, 18, 19, 22, 23, 25, 27, 30, 31, 33, 34, 35, 36, 41, 46, 47, 50, 51, 61, 62, 67, 68, 71, 74, 76, 80, 82, 83, 87, 88, 92, 93, 96, 97, 98], "base64": [24, 29, 41, 47, 91], "base_config": 99, "base_gpu_id": [14, 21, 26, 27, 28, 29, 37, 38], "base_url": [21, 25, 26, 27, 28, 30, 32, 34, 35, 37, 41, 42, 43, 47, 48, 51, 91], "basedispatch": 7, "baseformatdetector": 28, "baselin": [11, 14, 17, 91, 99], "basemodel": [26, 27], "basemultimodalprocessor": 99, "basereasoningformatdetector": 21, "bash": [0, 31, 51, 55, 56, 57, 62, 68, 70, 71, 82], "bashrc": [51, 68], "basi": 31, "basic": [14, 50, 51, 93, 94], "basic_qa": 78, "basilisk": 78, "batch": [3, 4, 5, 11, 14, 16, 17, 21, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 41, 43, 47, 48, 50, 51, 52, 53, 54, 58, 60, 68, 71, 74, 75, 80, 81, 91, 96], "batch_get_v1": 10, "batch_set_v1": 10, "batch_siz": [18, 35], "batchspanprocessor": 74, "beach": 97, "beach_dog": 97, "bear": [37, 97], "bearer": [22, 23, 50, 81, 84, 91], "beast": 14, "beauti": [14, 91], "becam": 14, "becaus": [5, 11, 14, 24, 27, 28, 50, 63, 78, 99], "becom": [2, 3, 5, 12, 14, 17, 19, 22, 38, 85], "been": [11, 14, 17, 18, 24, 25, 27, 29, 31, 38, 41, 51, 64, 68, 71, 72, 80, 91], "befor": [0, 1, 2, 7, 11, 12, 13, 14, 15, 16, 19, 22, 23, 24, 27, 28, 30, 49, 50, 51, 52, 54, 60, 70, 71, 87, 91, 96, 99], "beforehand": [30, 68], "began": 14, "begin": [14, 26, 27, 37, 51, 78, 87], "behav": 1, "behavior": [7, 16, 22, 23, 24, 28, 33, 46, 47, 50, 74, 91, 96, 97, 98], "behind": [7, 14, 17, 22, 23, 39], "beij": [26, 27, 30], "being": [1, 5, 13, 14, 16, 17, 22, 27, 38, 41, 87], "believ": [14, 27], "belong": [11, 14], "below": [1, 12, 14, 22, 25, 28, 29, 31, 33, 37, 46, 47, 53, 56, 57, 59, 61, 68, 69, 78, 87, 90, 91, 92, 93, 96, 99], "bench": [25, 51, 58, 92], "bench_one_batch": [51, 53, 99], "bench_one_batch_serv": [51, 54, 71], "bench_serv": [50, 54, 59, 62, 68, 71, 72, 86], "bench_sglang": [31, 53, 54], "bench_specul": [25, 30, 31], "benchmark": [11, 14, 15, 16, 17, 18, 25, 37, 50, 53, 54, 58, 59, 86, 91, 96], "benchmark_and_profil": 99, "benefici": [13, 78], "benefit": [11, 14, 19, 23, 24, 51, 74, 78], "berlin": [26, 27, 37, 41, 76], "berlin2": 78, "bertforsequenceclassif": [23, 89], "besid": [10, 78, 91], "bespok": 76, "best": [1, 6, 9, 11, 12, 24, 25, 29, 30, 31, 33, 41, 46, 66, 71, 91, 97], "best_effort": [10, 11, 14, 21, 22, 26, 27, 28, 29, 37, 38], "best_kernel": 25, "best_kernel_desc": 25, "best_tim": 25, "best_triton_kernel": 25, "best_triton_kernel_desc": 25, "best_triton_po": 25, "best_triton_tim": 25, "better": [11, 13, 14, 17, 18, 19, 22, 23, 26, 30, 31, 37, 41, 47, 49, 57, 71, 90, 91, 92, 96], "between": [1, 2, 7, 10, 11, 13, 16, 17, 19, 20, 22, 27, 30, 31, 32, 34, 37, 39, 47, 50, 51, 71, 78, 81, 85, 92, 93], "bewar": 68, "beyond": [11, 23, 30, 31], "bf": [14, 21, 22, 26, 27, 28, 29, 37, 38], "bf16": [7, 19, 22, 28, 30, 31, 34, 62, 68, 72, 74, 91, 96], "bfloat16": [14, 18, 22, 25, 37, 45, 62, 63, 70, 71, 74], "bge": [37, 67, 92, 97], "bgererankmodel": 97, "bia": [38, 99], "bias": 99, "bidirect": 23, "big": [27, 38], "bigcod": 93, "biggest": 3, "bilingu": 93, "bill": 23, "billion": [36, 68, 93], "bin": [22, 31, 53, 56, 57, 62, 63, 68, 71, 82], "binari": [49, 94], "bind": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 49, 78], "birth": 27, "birthplac": 41, "bisheng": 61, "bisheng_nam": 61, "bisheng_toolkit": 62, "bisheng_url": 61, "bishengir": [62, 63], "bit": [18, 19, 27], "bitsandbyt": [18, 22], "black": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78, 91], "blackwel": [1, 7, 18, 22, 28, 30, 31, 35, 74], "blanch": 38, "blank": 50, "blinker": 31, "blob": [29, 33, 43, 46, 47, 78, 91], "block": [1, 3, 7, 11, 14, 17, 19, 23, 24, 27, 52, 60, 74, 78, 91], "block_input": 3, "block_k": 25, "block_m": 25, "block_n": 25, "block_output": 3, "block_siz": 90, "block_w": 3, "blockadapterregist": 91, "blockdim": 49, "blockidx": 49, "blockwis": [22, 74], "blog": [7, 11, 17, 20, 24, 30, 75, 79, 82], "blogpost": 76, "blood": 78, "blossom": [14, 91], "blue": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78], "bluefield": 80, "bmm": [30, 74], "bn": 91, "bnf": [26, 47], "board": 78, "bodi": [14, 23, 24, 50, 54], "bodili": 78, "bogart": 78, "bogor": 14, "bold": 91, "bond": 38, "bond0": 84, "book": [38, 43], "bookkeep": 24, "bool": [14, 22, 24, 47, 74, 99], "boolean": [52, 60], "boost": [5, 7, 33, 78], "boot": 20, "bootstrap": [16, 22, 23, 31, 61, 62, 63, 87], "bootstrap_host": 22, "bootstrap_room": [22, 87], "bootstrap_room_list": 87, "bootstrap_room_span": 87, "born": 78, "boston": 28, "bot": [26, 27], "both": [1, 2, 3, 11, 12, 13, 14, 21, 22, 23, 24, 27, 28, 29, 30, 31, 34, 35, 41, 47, 50, 51, 52, 53, 60, 74, 75, 86, 91, 92, 96, 99], "bottleneck": [7, 10, 14, 17, 22, 51, 91], "bottom": [34, 53], "bound": [22, 37], "boundari": [11, 17, 23, 28], "box": [21, 33, 46], "brain": 78, "branch": [0, 1, 22, 25, 45, 52, 57, 59, 60, 61, 69, 91, 97], "bras\u00edlia": [14, 25], "brave": 14, "brave_search": [26, 27], "brazil": [14, 25, 27], "breadth": 22, "break": [24, 27, 38, 41, 47, 48, 61, 62, 63, 91], "breakdown": [41, 50, 91], "breakpoint": 53, "breakthrough": 38, "bridg": 41, "brief": 90, "bring": 14, "brittl": 24, "broad": [58, 91, 93], "broadcast": [2, 22, 24], "broader": 27, "brought": 17, "brown": 78, "brows": 86, "browser": [0, 34, 51, 86, 87], "browser_serv": 34, "bubbl": 17, "bucket": 22, "bucket_e2e_request_lat": [14, 21, 26, 27, 28, 29, 37, 38], "bucket_inter_token_lat": [14, 21, 26, 27, 28, 29, 37, 38], "bucket_time_to_first_token": [14, 21, 26, 27, 28, 29, 37, 38], "budget": [11, 19], "buffer": [1, 13, 21, 22, 23, 45, 74], "bug": [10, 18, 52, 60, 71, 75], "build": [0, 3, 4, 11, 16, 18, 20, 27, 29, 38, 41, 43, 53, 55, 57, 59, 60, 61, 68, 70, 72, 74, 78, 87, 91, 96], "built": [3, 11, 14, 22, 23, 36, 51, 52, 54, 57, 59, 60, 91, 94, 96], "buliltin": 22, "bump": [52, 60], "bumper": 43, "burough": 27, "burst": [23, 50], "busi": [38, 67, 93, 97], "bustl": 38, "bypass": 7, "byte": 11, "bytesio": 29, "c": [4, 14, 28, 37, 38, 41, 48, 57, 59, 71, 80, 84, 87], "c2106980ce9f4c159b5f2365b28022e9": 28, "c341aeae92c04df2a5d7b79eb5e4a9b1": 26, "c383c6ae35724725a82f3f3b5911c9c6": 14, "c3ec": 80, "c4": 18, "c4ai": [67, 93], "c7": 80, "c79a": 80, "ca": [23, 26, 27, 28], "cab": 29, "cach": [1, 3, 4, 6, 10, 11, 14, 16, 17, 24, 25, 29, 30, 31, 33, 35, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 71, 75, 80, 81, 84, 85, 86, 93, 95, 96, 97], "cache_awar": [23, 61, 62, 63], "cache_control": 12, "cache_hit_r": 86, "cached_token": [26, 27, 37, 48], "cadenc": 23, "caf\u00e9": 89, "calcul": [16, 18, 19, 21, 22, 29, 34, 47, 78], "calibr": [18, 91], "calibration_dataset": 18, "calico": 91, "california": [26, 27, 28], "call": [1, 8, 12, 17, 21, 22, 24, 25, 26, 27, 32, 33, 34, 36, 37, 38, 41, 46, 49, 50, 51, 76, 78, 81, 87, 91, 93, 96, 97, 99], "call_09046360ce1e4eafbcaaa5b3": 28, "call_0c0639d0eaff480e986b1808": 28, "call_3078dac4dfd24cb9beb2e472": 28, "call_34f7ceefa2e949fd87cc868c": 28, "call_49660421585d41bab0458738": 28, "call_7477007dc2db439d9cd7271a": 28, "call_88cae1f3725e465ea167600c": 28, "call_c7b0d5ab44a342238b49bf7d": 28, "call_cb541d055b2c43b595640a39": 28, "call_ceb4e46f7f2a402cb0c7cdf0": 28, "callabl": 8, "caller": [24, 52, 60], "came": 14, "can": [0, 1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 84, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 99, 100], "canada": [41, 48, 78], "canberra": [14, 25, 41, 48], "cancel": 23, "candid": 25, "cann": 94, "cann8": 61, "cann_path": 62, "cannot": [1, 8, 14, 17, 21, 25, 26, 27, 28, 29, 31, 37, 38, 41, 42, 43, 48, 49, 51, 68, 71, 78, 80, 85, 97], "cano": 70, "cap": [50, 59], "capabl": [23, 35, 37, 45, 46, 54, 59, 81, 84, 85, 90, 91, 96], "capac": [10, 11, 17, 19, 22, 23, 25, 30, 31], "capit": [14, 18, 25, 26, 27, 28, 30, 32, 37, 38, 41, 47, 48, 76, 78, 92, 94, 99], "capital_info": 26, "capitalinfo": [26, 27], "capitol": 37, "caption": 96, "captur": [1, 2, 3, 8, 14, 18, 21, 22, 25, 26, 27, 28, 29, 30, 38, 41, 43, 48, 51, 74, 78, 80, 91], "capture_out": 8, "car": [29, 97], "cardio": 78, "cardnum": 62, "care": 34, "cargo": 23, "carniv": 38, "carv": 14, "cascad": [14, 23, 25], "case": [0, 1, 7, 11, 13, 14, 18, 22, 23, 27, 30, 31, 36, 38, 50, 51, 52, 57, 60, 71, 75, 93, 94, 96], "cast": [14, 22, 25, 30], "castl": 14, "cat": [22, 61, 91, 97], "categor": 27, "categori": 97, "cathedr": [25, 38], "caus": [8, 15, 16, 17, 19, 22, 24, 28, 51, 75], "causallm": 22, "cave": 14, "caveat": [14, 51], "cb": 23, "cbm": [81, 84], "ccccdd": [81, 84], "cd": [16, 23, 31, 55, 57, 59, 60, 61, 68, 69, 71, 72, 86, 91, 94], "cdef": 23, "cdna3": 18, "cdna4": 18, "cec7c857c0e3475391d61f2ca846204b": 14, "celsiu": [26, 27, 28], "censu": 27, "center": [7, 14, 25, 27, 38, 41], "central": 23, "cert": 23, "certain": [17, 25, 27, 59, 87, 91], "certif": 23, "cf": 81, "chain": [23, 49, 91], "challeng": [6, 14, 16, 19, 52, 60, 75], "chanc": 28, "chang": [0, 7, 17, 24, 25, 27, 31, 34, 37, 47, 51, 52, 53, 56, 59, 60, 61, 68, 75, 80, 84, 86, 92, 96, 99], "channel": [10, 18, 21, 22, 23, 28, 30, 52, 60, 68, 72], "char": 28, "char_count": 23, "charact": [38, 78, 91, 96, 99], "character": 38, "character_gen": 78, "character_lora": 91, "character_regex": 78, "characterist": [3, 11, 17], "charm": 14, "chart": 81, "chat": [14, 18, 21, 22, 23, 25, 26, 27, 30, 31, 32, 33, 35, 36, 37, 39, 43, 46, 47, 48, 50, 58, 67, 70, 71, 81, 84, 92, 93, 96, 97, 99], "chat_exampl": 78, "chat_templ": [14, 21, 26, 27, 28, 29, 30, 31, 37, 38, 73, 97], "chat_template_kwarg": [31, 41], "chatcomplet": [25, 28, 41, 48], "chatcompletionmessag": [25, 28, 41, 48], "chatcompletionmessagefunctiontoolcal": 28, "chatglm": [67, 93], "chatglm2": [67, 93], "chatml": [73, 96], "cheaper": 96, "check": [0, 2, 10, 12, 13, 14, 16, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 38, 39, 41, 42, 43, 47, 48, 50, 52, 57, 60, 61, 68, 71, 74, 78, 80, 100], "check_env": 71, "check_output": [42, 43, 48], "checker": 23, "checklist": 23, "checkout": [25, 68, 72], "checkpoint": [14, 18, 19, 21, 24, 25, 26, 27, 28, 29, 33, 37, 38, 41, 42, 43, 46, 48, 51, 58, 74, 78, 99], "checkpoint_engin": 2, "checkpoint_engine_wait_weights_before_readi": [14, 21, 26, 27, 28, 29, 37, 38], "checksum": 22, "cherri": 91, "chicken": 78, "child": 11, "children": [8, 74], "china": [26, 27, 37, 85, 97], "chines": 93, "chmod": 61, "chocol": 38, "choic": [21, 22, 25, 26, 27, 30, 31, 41, 43, 45, 48, 77, 78, 81, 84, 85], "choicedeltatoolcal": 28, "choicedeltatoolcallfunct": 28, "choices_method": 76, "choos": [1, 4, 10, 11, 19, 22, 24, 25, 26, 27, 53, 78], "chosen": [1, 14, 19, 22], "chrome": [51, 91], "chronic": 78, "chunk": [1, 4, 14, 21, 22, 28, 30, 31, 33, 37, 39, 41, 46, 47, 48, 58, 62, 63, 74, 75, 81, 84, 97], "chunked_prefill_s": [13, 14, 21, 26, 27, 28, 29, 37, 38, 80], "chunked_s": 62, "chunkedsgmv": [14, 22], "churn": 14, "ci": [0, 14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "ci_permiss": [52, 60], "cicero": 41, "circuitbreakeropen": 23, "circular": 22, "circumv": 17, "cite": 27, "citi": [14, 23, 25, 26, 27, 28, 29, 30, 37, 38, 43, 48, 97, 99], "cityscap": 91, "civil": 41, "ckpt": 22, "clangd": 49, "clariti": [14, 21, 25, 26, 27, 28, 30, 37, 41, 42, 43, 48, 78], "class": [1, 8, 10, 11, 22, 23, 26, 27, 28, 47, 91, 99, 100], "class_0": 89, "class_1": 89, "class_nam": [10, 11, 22], "classic": [1, 11], "classif": [37, 58, 98], "classifi": [23, 48, 89, 98], "clean": [0, 16, 78, 91], "cleaned_chunk": 38, "cleanup": 22, "clear": [8, 23, 24, 27, 91], "clearli": 21, "cli": [22, 23, 37, 51, 57, 58], "client": [13, 14, 20, 21, 23, 25, 26, 27, 30, 32, 34, 39, 41, 47, 51, 71, 74, 80, 91], "client_tool_choic": 28, "cliff": 14, "climb": 34, "clip": [64, 67, 74, 92, 96], "clone": [16, 31, 57, 59, 61, 68, 69, 70, 71, 72, 91, 94], "close": [18, 19, 23, 27, 31, 34, 45], "closer": [14, 27], "cloth": [29, 43, 78], "clotheslin": 29, "cloud": 41, "cloudi": 28, "cloudli": 28, "cluster": [11, 22, 57, 58, 61, 68, 71, 80, 81, 82], "clusterfirstwithhostnet": [80, 81, 84], "clusterip": [81, 84], "cm1": 80, "cn": 61, "cnbc": 34, "co": [24, 27, 92], "code": [0, 1, 10, 12, 13, 14, 16, 17, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 47, 48, 51, 53, 59, 61, 62, 63, 65, 68, 71, 72, 75, 78, 80, 81, 84, 87, 89, 91, 92, 93, 96, 97, 98, 99], "code_interpret": 34, "codebas": [0, 52, 60], "codeown": [52, 60], "coder": [28, 67], "coerc": 97, "cofeai": 93, "coffe": 89, "cognit": 38, "coher": [25, 93], "cohereforai": 67, "coherelab": 93, "collabor": 93, "collect": [5, 18, 22, 24, 31, 74], "collect_tokens_histogram": [14, 21, 26, 27, 28, 29, 37, 38], "collector": [12, 22, 87], "coloc": [6, 85], "color": [5, 14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 51, 78], "colosseum": 41, "column": [1, 28], "com": [0, 3, 16, 23, 29, 31, 33, 37, 43, 46, 47, 51, 52, 53, 55, 56, 57, 59, 60, 61, 68, 69, 70, 71, 72, 78, 79, 80, 81, 84, 87, 91, 94, 96, 97], "combin": [1, 2, 7, 14, 16, 21, 22, 23, 25, 26, 27, 28, 30, 31, 37, 41, 42, 43, 48, 51, 71, 74, 78, 85, 96], "combineinput": 7, "come": [14, 22, 23, 27, 37, 94, 96, 100], "comma": [22, 27], "command": [7, 15, 16, 18, 23, 28, 30, 31, 35, 36, 42, 48, 52, 53, 54, 56, 57, 59, 60, 61, 67, 70, 71, 72, 80, 81, 84, 86, 91, 99], "comment": [52, 60], "commerci": 93, "commit": [0, 22, 54], "common": [0, 1, 3, 11, 19, 27, 29, 38, 50, 52, 54, 60, 68, 75, 80, 91], "commonli": 28, "commun": [2, 5, 14, 20, 22, 24, 31, 51, 58, 63, 71, 80, 81, 91], "compact": [3, 22, 36, 93, 96], "compani": [38, 79, 81, 85], "companion": 14, "compar": [5, 11, 14, 17, 19, 24, 30, 31, 91, 93, 99], "compare_perf": 91, "comparison": [76, 91, 99], "compat": [4, 7, 10, 11, 17, 18, 19, 22, 23, 30, 34, 36, 37, 41, 42, 43, 45, 47, 50, 58, 71, 73, 80, 81, 84, 87, 96], "compet": 93, "compil": [0, 3, 7, 13, 22, 30, 49, 59, 62, 63, 68, 69, 74, 80], "compile_command": 49, "compile_deep_gemm": 30, "complementari": 91, "complet": [1, 10, 11, 14, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 50, 51, 52, 57, 60, 68, 70, 72, 78, 80, 81, 84, 89, 91, 93, 96], "completion_templ": [14, 21, 26, 27, 28, 29, 37, 38], "completion_token": [23, 25, 26, 27, 28, 30, 37, 41, 42, 43, 48, 81, 84, 89], "completion_tokens_detail": [25, 28, 41, 48], "completionchoic": 41, "completionusag": [25, 28, 41, 48], "complex": [0, 11, 17, 19, 24, 27, 38, 39, 52, 60, 93, 96], "complianc": 23, "compon": [2, 5, 7, 11, 13, 18, 23, 37, 38, 39, 52, 60, 81, 91, 99], "compos": [86, 87], "composedpipelin": 91, "composit": 3, "comprehens": [11, 23, 28, 30, 74, 96, 97], "compress": [22, 64], "compressedtensorsconfig": 18, "compressor": 64, "compris": 16, "comput": [6, 11, 14, 16, 17, 18, 19, 22, 25, 29, 30, 31, 37, 43, 45, 51, 70, 71, 75, 78, 97], "con": 1, "concaten": [12, 30, 37], "concept": 91, "conceptu": 49, "concern": 38, "concis": [25, 38, 41, 52, 60, 85, 99], "conclud": 21, "concret": 24, "concurr": [1, 11, 13, 14, 19, 22, 23, 24, 33, 46, 54, 62, 71, 75, 87], "conda": [57, 61, 72], "condit": [7, 11, 12, 14, 16, 17, 28, 49], "cone": 38, "confid": [27, 76, 90], "config": [7, 10, 11, 12, 14, 16, 18, 22, 23, 25, 37, 51, 53, 61, 63, 64, 68, 70, 74, 81, 86, 89, 90, 91, 92, 96, 99, 100], "config_file_path": 91, "configur": [0, 1, 7, 11, 12, 14, 17, 18, 24, 29, 30, 36, 37, 49, 50, 52, 53, 54, 60, 68, 80, 81, 84, 87, 99], "configure_log": 15, "confirm": [25, 27, 59, 86], "conflict": [72, 86], "confus": [25, 27], "connect": [2, 3, 14, 16, 21, 25, 26, 27, 28, 29, 34, 37, 38, 39, 41, 42, 43, 48, 50, 53, 78, 82, 86], "connect_data": 23, "connection_mod": 23, "connections_act": 23, "connectx": 80, "consecut": [11, 16, 19, 22, 23, 74], "consecutive_failur": 23, "consecutive_success": 23, "consensu": 11, "consequ": [14, 17, 38, 49], "conserv": [13, 17, 22, 71, 90], "consid": [0, 11, 18, 23, 25, 27, 38, 41, 47, 71, 91], "consider": [3, 23, 38], "consist": [2, 4, 5, 11, 12, 22, 23, 30, 33, 38, 52, 60, 78, 85, 87, 93], "consol": [50, 53, 91], "consolid": 74, "const": 49, "constant": [3, 47, 49], "constexpr": 49, "constrain": [22, 26], "constrained_json_disable_any_whitespac": [14, 21, 26, 27, 28, 29, 37, 38], "constrained_json_whitespace_pattern": [14, 21, 26, 27, 28, 29, 37, 38], "constraint": [1, 12, 24, 26, 27, 47, 74, 78, 87, 96], "construct": 50, "constructor": [22, 99], "consult": [22, 27], "consum": [11, 13, 19, 96], "consumpt": 25, "contact": 81, "contain": [2, 11, 14, 16, 22, 23, 30, 37, 41, 47, 49, 51, 57, 61, 68, 76, 80, 81, 84, 86, 87, 91, 97], "container": 80, "container_id": 86, "container_nam": 86, "containerd": 80, "containerport": [23, 80, 81, 84], "content": [3, 12, 14, 15, 21, 22, 25, 26, 27, 28, 29, 32, 33, 36, 37, 39, 41, 42, 43, 46, 47, 48, 50, 51, 68, 81, 84, 89, 90, 96, 97, 98], "context": [10, 11, 19, 22, 23, 24, 25, 29, 33, 35, 36, 46, 50, 58, 62, 63, 70, 72, 74, 81, 84, 87, 93, 96], "context_len": [13, 14, 37, 80], "context_length": [14, 21, 22, 25, 26, 27, 28, 29, 37, 38], "contigu": [7, 11, 49], "continu": [8, 10, 11, 22, 23, 25, 31, 37, 38, 51, 58, 71, 74, 85, 91], "continue_gener": 24, "contract": 21, "contrast": 11, "contribut": [10, 23, 25, 58, 66, 73, 81], "contributor": [0, 52, 60, 71, 93], "control": [1, 7, 10, 11, 14, 15, 16, 17, 22, 24, 25, 28, 31, 33, 38, 41, 46, 47, 50, 51, 74, 80, 85, 91, 97], "conv": [29, 37], "conveni": [18, 51, 59, 78], "convent": [10, 16, 17], "convers": [7, 10, 24, 29, 35, 50, 73, 93, 96, 99], "convert": [11, 18, 23, 26, 27, 41, 57, 87, 96, 99], "convert_dict_to_tool": 28, "cook": 38, "cool": [52, 60], "cooldown": [52, 60], "coordin": 71, "copi": [10, 11, 14, 20, 22, 27, 29, 33, 46, 57, 88, 96], "copy_stream": 17, "core": [7, 11, 14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 58, 68, 71, 78, 87], "corner": 22, "corpu": 93, "correct": [0, 14, 23, 24, 27, 28, 41, 51, 57, 99], "correctli": [25, 27, 41, 51, 60, 80, 99, 100], "correl": [7, 23], "correspond": [1, 11, 14, 18, 22, 27, 28, 42, 47, 52, 60, 87, 99], "cosmo": 41, "cosmopolitan": 38, "cost": [22, 23, 24, 36, 51, 71, 91, 92, 93, 96], "cot": [21, 23], "couch": 97, "could": [17, 22, 34, 38, 59, 61, 63, 65, 78, 80], "couldn": 14, "count": [3, 11, 22, 23, 27, 37, 41, 50, 54, 68, 71, 74], "counter": [23, 74, 86], "countri": [14, 25, 26, 27, 37, 38, 41, 47, 48, 78], "coupl": [6, 7], "cours": 78, "cover": [11, 12, 24, 41, 42, 43, 80, 91, 99], "coverag": [52, 60], "cp": [22, 68, 72], "cp310": 57, "cp311": 61, "cp8": 31, "cp_size": [22, 31], "cpp": 51, "cpp_func": 49, "cpu": [1, 2, 10, 11, 14, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 37, 38, 51, 52, 57, 58, 60, 62, 63, 74, 81, 82, 84, 91, 96], "cpu0": 61, "cpu_count": 16, "cpu_offload_gb": [14, 21, 26, 27, 28, 29, 37, 38], "cpufreq": [61, 62, 63], "cpuinfer": 22, "crash": [22, 84], "crash_dump": 15, "crash_dump_fold": [14, 21, 26, 27, 28, 29, 37, 38], "cream": 38, "creat": [0, 1, 3, 7, 8, 11, 12, 14, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 36, 37, 38, 41, 42, 43, 47, 48, 52, 53, 57, 59, 60, 68, 71, 72, 84, 87, 89, 99], "create_graph": 3, "creation": 38, "creativ": [41, 78], "credenti": 23, "critic": [1, 4, 11, 23, 51, 52, 60, 91], "cross": [10, 11, 17, 54, 92, 96], "cross_attention_kwarg": 91, "crt": 23, "crucial": [1, 17, 80], "crypto": 23, "crystal": 14, "cseti": 91, "csgmv": [14, 21, 22, 26, 27, 28, 29, 37, 38], "csrc": [49, 51], "cstddef": 49, "cstdint": 49, "csv": [22, 37], "ctrl": [14, 37, 80], "cu129": 57, "cu13": 57, "cu130": 57, "cu_full_len": 3, "cu_seqlen": 3, "cu_seqlens_kk": 3, "cu_window_len": 3, "cubla": 75, "cuda": [2, 4, 7, 11, 14, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 37, 38, 41, 42, 43, 46, 48, 49, 51, 53, 56, 57, 58, 62, 63, 70, 72, 74, 78, 80, 81, 84, 91], "cuda_fil": 49, "cuda_graph_b": [14, 21, 26, 27, 28, 29, 37, 38], "cuda_graph_max_b": [14, 21, 26, 27, 28, 29, 37, 38], "cuda_hom": 57, "cuda_launch_block": [81, 84], "cuda_profil": 51, "cuda_visible_devic": 56, "cuda_wrapp": 49, "cudaerror_t": 49, "cudagetlasterror": 49, "cudagraph": [22, 88], "cudamemcpyasync": 11, "cudaprofilerapi": 51, "cudaprofilerstart": 51, "cudaprofilerstop": 51, "cudart": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "cudastream": 49, "cudastream_t": 49, "cudnn": [22, 70], "cuh": 49, "cultur": [25, 27, 38], "cumul": [17, 47], "cup": 38, "curios": 14, "curiou": 91, "curl": [12, 15, 23, 30, 36, 37, 47, 51, 56, 68, 71, 72, 81, 84, 86, 90, 91, 97], "curl_command": [43, 48], "curl_id": 42, "curl_text": 42, "current": [7, 8, 11, 14, 16, 17, 18, 19, 22, 26, 27, 30, 34, 38, 47, 49, 50, 52, 60, 61, 62, 68, 71, 72, 74, 75, 81, 84, 87, 91, 94, 96, 97], "custom": [0, 7, 11, 14, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 37, 38, 41, 50, 58, 61, 62, 74, 85, 86], "custom_backend_nam": 10, "custom_logit_processor": [30, 32, 47], "custom_op": 61, "custom_param": [30, 32, 47], "custom_param_list": 47, "custom_serv": 38, "custom_sigquit_handl": [14, 21, 26, 27, 28, 29, 37, 38], "custom_weight_load": [14, 21, 26, 27, 28, 29, 37, 38], "customlogitprocessor": [30, 32, 33, 47], "cut": [18, 30], "cutedsl": 22, "cutlass": [1, 7, 14, 18, 22, 74], "cutlass_mla": [1, 22], "cutlassmla": 30, "cycl": [7, 23, 78], "d": [12, 14, 22, 23, 30, 36, 37, 38, 41, 42, 43, 48, 49, 51, 57, 78, 81, 82, 84, 86, 87, 89, 90, 91, 97], "d1e197b0b9c4417da090ca06392a7599": 26, "d2h": [17, 22, 33, 46], "d82225f6bf1749a7853aae86d05674a6": 27, "d_": 31, "d_ip": [62, 63], "dai": [14, 23, 28, 30, 34, 78], "dame": [25, 38], "dao": 30, "dark": 14, "dashboard": [23, 86], "data": [5, 7, 10, 13, 14, 16, 17, 19, 20, 21, 25, 27, 28, 29, 33, 34, 37, 38, 41, 42, 43, 46, 47, 48, 49, 51, 58, 59, 62, 71, 84, 86, 87, 89, 91, 92, 94, 96, 97, 99], "data0": 62, "data1": [80, 81, 84], "data_fil": 18, "data_path": 63, "data_ptr": 49, "databas": 23, "databrick": [67, 93], "dataclass": 23, "dataload": 22, "dataset": [18, 19, 31, 35, 51, 54, 59, 62, 68, 71, 72, 86, 92], "datasourc": 86, "date": [26, 27, 31, 34, 38], "davinci": [23, 61], "davinci0": 61, "davinci1": 61, "davinci10": 61, "davinci11": 61, "davinci12": 61, "davinci13": 61, "davinci14": 61, "davinci15": 61, "davinci2": 61, "davinci3": 61, "davinci4": 61, "davinci5": 61, "davinci6": 61, "davinci7": 61, "davinci8": 61, "davinci9": 61, "davinci_manag": 61, "dbazur": 53, "dbname": 23, "dbrx": [67, 93], "dc8cdfb21993a6cb46199d6b1d79f68a42b06439": 14, "dd": 91, "dd3382151e3646b69c478e5edfd50f": 48, "de": [27, 85], "deactiv": 57, "deadlock": [22, 91], "death": [27, 78], "deb": 51, "debian": 49, "debug": [2, 4, 7, 8, 15, 25, 49, 51, 97], "debug_tensor_dump_inject": [14, 21, 26, 27, 28, 29, 37, 38], "debug_tensor_dump_input_fil": [14, 21, 26, 27, 28, 29, 37, 38], "debug_tensor_dump_lay": [14, 21, 26, 27, 28, 29, 37, 38], "debug_tensor_dump_output_fold": [14, 21, 26, 27, 28, 29, 37, 38], "debugg": 4, "debugpi": 53, "dec": 22, "deceas": 78, "decemb": 26, "decentr": 7, "decid": [14, 22, 27, 91], "decis": [23, 91], "declar": [27, 99], "decod": [5, 6, 10, 11, 13, 14, 30, 31, 43, 48, 50, 58, 61, 62, 63, 68, 74, 75, 84, 87, 90, 91, 93, 96, 100], "decode1": 23, "decode_addr": 31, "decode_attention_backend": [14, 21, 26, 27, 28, 29, 37, 38], "decode_count": 23, "decode_host": 6, "decode_host_ip": 63, "decode_log_interv": [14, 21, 26, 27, 28, 29, 37, 38], "decode_master_ip": 16, "decode_round_robin": [62, 63], "decode_unicod": [47, 48], "decompos": 6, "decord": 96, "decoupl": [6, 7, 17, 24, 96], "decreas": [13, 23, 41, 45, 71, 75], "decrypted_config_fil": [14, 21, 26, 27, 28, 29, 37, 38], "decrypted_draft_config_fil": [14, 21, 26, 27, 28, 29, 37, 38], "dedic": [11, 16, 17, 24, 47, 51, 57, 68, 71, 72, 85, 91, 96, 99], "deduct": 38, "dee": [81, 84], "deep": [14, 24, 34, 97], "deep_gemm": [7, 22, 74], "deep_normal_mode_use_int8_qu": [62, 63], "deepep": [7, 16, 22, 31, 62, 63, 81, 84], "deepep_config": [14, 21, 26, 27, 28, 29, 37, 38], "deepep_mod": [14, 21, 26, 27, 28, 29, 37, 38], "deepep_normal_long_seq_per_round_token": 62, "deepep_normal_long_seq_round": 62, "deeper": [24, 25, 52, 60], "deepgemm": [7, 22, 30], "deepli": [23, 37], "deepmind": 24, "deepseek": [1, 2, 7, 10, 11, 13, 18, 19, 21, 22, 23, 25, 27, 28, 53, 54, 57, 58, 61, 66, 67, 70, 80, 81, 83, 84, 93, 94, 96], "deepseek_r1_0528": 81, "deepseek_v3": 53, "deepseek_v3_mo": 80, "deepseekr10528": 81, "deepseekr1thinkingbudgetlogitprocessor": 30, "deepseekv3": [22, 28, 30], "deepseekv31": [22, 28, 31], "deepseekv32": [28, 31, 83], "deepseekv32_pd": 31, "deepspe": 91, "deepstack": 3, "def": [8, 26, 27, 28, 38, 47, 49, 63, 76, 78, 90, 99, 100], "default": [1, 2, 6, 7, 8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 34, 35, 37, 38, 41, 42, 43, 45, 48, 50, 51, 52, 57, 59, 60, 61, 68, 69, 71, 73, 74, 76, 78, 80, 84, 86, 87, 89, 90, 91, 96, 97, 99, 100], "default_stream": 17, "defeat": 14, "defer": [17, 22, 71], "defin": [1, 7, 8, 21, 22, 26, 27, 33, 46, 47, 49, 52, 57, 60, 73, 78, 82, 86, 91, 99], "definit": [23, 25, 27, 86], "degrad": [14, 17, 19, 25, 63, 80], "degre": [17, 28, 91], "dejpeg": 91, "delai": [2, 16, 18, 22, 23, 34, 51, 91], "delay": 22, "delet": [12, 22, 23, 57], "delete_ckpt_after_load": [14, 21, 26, 27, 28, 29, 37, 38], "delici": 38, "delimit": [21, 22, 28], "deliv": [17, 31, 58, 71, 93], "delta": [21, 22, 28, 30, 41, 48, 93], "demand": [12, 14], "demo": 22, "demonstr": [7, 11, 14, 18, 28, 29, 37, 38, 41, 49, 93, 99], "denoise_steps_m": 91, "denot": [17, 22, 27], "dens": [22, 31, 62, 63, 68, 81, 84, 93, 94], "deocod": 5, "dep": [50, 57, 72], "depart": [27, 38], "depend": [1, 11, 16, 17, 18, 19, 22, 27, 50, 52, 57, 60, 61, 68, 72, 84, 87, 91], "deploi": [10, 16, 24, 30, 57, 62, 71, 83, 85, 88], "deploy": [2, 6, 7, 16, 17, 18, 22, 24, 30, 31, 33, 38, 46, 57, 58, 68, 71, 80, 84, 92, 93, 96, 97], "deploy_and_serve_endpoint": 57, "deploymod": 62, "deprec": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 74, 78], "depth": [22, 23, 25, 93], "dequant": 19, "deregistrations_tot": 23, "deriv": [19, 25, 98], "descend": 97, "describ": [8, 41, 43, 47, 52, 57, 59, 60, 62, 67, 69, 76, 86, 87, 89, 91], "descript": [4, 7, 8, 16, 22, 23, 24, 26, 27, 28, 30, 32, 35, 39, 45, 47, 51, 52, 60, 68, 71, 74, 90, 91, 92, 93, 96, 97, 98, 99], "descriptor": [23, 50], "design": [1, 6, 7, 9, 10, 16, 21, 23, 30, 37, 43, 58, 71, 85, 87, 89, 93, 96, 97], "desir": [26, 68, 72], "desktop": 86, "dessert": 38, "destin": [14, 16, 38], "destini": 14, "destroi": [12, 14, 24], "destroy_weights_update_group": 24, "detach": [9, 10, 29], "detach_storage_backend": 12, "detail": [1, 3, 7, 10, 11, 14, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 30, 31, 34, 35, 37, 38, 41, 45, 47, 50, 51, 52, 60, 68, 70, 71, 72, 75, 80, 85, 90, 91, 96, 99], "detailed_tip": 78, "detect": [14, 21, 22, 23, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 74, 78], "detector": 28, "determin": [11, 13, 14, 17, 22, 24, 28, 38, 68, 76, 87], "determinist": [22, 52, 58, 60, 85], "deterministiclogitprocessor": 47, "detoken": [47, 74], "detokenization_result": 37, "detokenize_payload": 37, "detokenize_respons": 37, "detokenize_url": 37, "detokenizermanag": [14, 37], "dev": [22, 49, 51, 56, 57, 59, 61, 68, 80, 81, 84, 91], "dev1": 37, "devcontain": 53, "devel": 56, "develop": [4, 7, 11, 14, 22, 23, 28, 31, 38, 39, 41, 51, 52, 57, 60, 71, 72, 79, 85, 87, 93], "developer_guid": 99, "devic": [7, 10, 11, 14, 16, 18, 21, 22, 26, 27, 28, 29, 30, 31, 33, 37, 38, 46, 49, 52, 56, 57, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 74, 80, 81, 84, 91, 93, 96], "device_": 49, "device_config": 18, "device_list": 10, "device_map": 18, "device_nam": [16, 37], "device_rdma": 61, "device_typ": 61, "deviceconfig": 18, "devkit": 70, "devtool": 51, "df": 22, "dfa7400c0d4a475480f8d8a78a58d82": 48, "dgx": 57, "diagnos": 80, "diagram": 53, "dialogu": [10, 93], "dict": [3, 8, 22, 26, 27, 28, 29, 47], "dictionari": [22, 27, 28, 41], "did": [14, 37, 91], "didn": [14, 27, 28], "diet": 78, "differ": [3, 4, 5, 7, 11, 14, 16, 17, 18, 22, 23, 24, 25, 27, 29, 30, 31, 33, 37, 38, 43, 46, 48, 50, 53, 59, 68, 71, 74, 75, 80, 81, 84, 86, 87, 88, 90, 91, 95, 97, 99], "differenti": [7, 11], "difficult": [14, 24], "diffus": [58, 59, 92], "diffusers_kwarg": 91, "diffusion_hip": 59, "digest": 78, "dim": 14, "dimens": [22, 49, 51], "dine": 38, "dip": 62, "dip1": 62, "dip2": 62, "dir": [18, 22, 23, 51, 71, 80], "direct": [2, 10, 11, 22, 23, 24, 38, 68], "directli": [0, 2, 3, 8, 11, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 41, 49, 51, 52, 60, 81, 91, 99], "directori": [2, 22, 23, 31, 49, 51, 53, 68, 74, 86, 87, 91, 95, 99], "directoryorcr": [81, 84], "disabl": [4, 7, 10, 14, 17, 18, 21, 22, 23, 25, 27, 30, 31, 37, 50, 51, 52, 53, 60, 62, 63, 68, 71, 72, 74, 75, 81, 84, 96, 97], "disable_chunked_prefix_cach": [14, 21, 26, 27, 28, 29, 37, 38], "disable_cuda_graph": [14, 21, 26, 27, 28, 29, 37, 38], "disable_cuda_graph_pad": [14, 21, 26, 27, 28, 29, 37, 38], "disable_custom_all_reduc": [14, 21, 26, 27, 28, 29, 37, 38], "disable_eagle3_qu": 62, "disable_fast_image_processor": [14, 21, 26, 27, 28, 29, 37, 38], "disable_flashinfer_autotun": [14, 21, 26, 27, 28, 29, 37, 38], "disable_flashinfer_cutlass_moe_fp4_allgath": [14, 21, 26, 27, 28, 29, 37, 38], "disable_hicache_numa_detect": [14, 21, 26, 27, 28, 29, 37, 38], "disable_hybrid_swa_memori": [14, 21, 26, 27, 28, 29, 37, 38], "disable_outlines_disk_cach": [14, 21, 26, 27, 28, 29, 37, 38], "disable_overlap_schedul": [14, 21, 26, 27, 28, 29, 37, 38], "disable_radix_cach": [14, 21, 26, 27, 28, 29, 37, 38], "disable_shared_experts_fus": [14, 21, 26, 27, 28, 29, 37, 38], "disable_tokenizer_batch_decod": [14, 21, 26, 27, 28, 29, 37, 38], "disagg": 12, "disaggreg": [24, 30, 58, 61, 62, 81, 83, 84, 85, 87], "disaggregation_bootstrap_port": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_decode_dp": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_decode_enable_fake_auto": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_decode_enable_offload_kvcach": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_decode_polling_interv": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_decode_tp": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_ib_devic": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_mod": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_prefill_pp": [14, 21, 26, 27, 28, 29, 37, 38], "disaggregation_transfer_backend": [14, 21, 26, 27, 28, 29, 37, 38], "disast": 24, "discard": [1, 24], "discourag": [41, 47], "discov": [14, 23], "discoveri": 84, "discrep": 24, "discuss": [10, 30, 52, 60, 71], "diseas": 78, "disjoint": 22, "disk": [2, 22, 74, 91, 95, 99], "dispatch": [1, 7, 12, 22, 24, 74, 75, 81, 84], "dispatchoutput": 7, "displai": [0, 14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 53, 59, 78], "dist": [2, 14, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 37, 41, 42, 43, 48, 62, 63, 71, 78, 80, 81, 82, 84, 94], "dist_init_addr": [14, 21, 26, 27, 28, 29, 37, 38], "dist_port": 31, "dist_timeout": [14, 21, 26, 27, 28, 29, 37, 38], "distil": [21, 27, 41, 68, 70, 91], "distinct": [3, 6, 16], "distinguish": 87, "distract": 14, "distrib_releas": 51, "distribut": [0, 2, 7, 11, 14, 16, 23, 31, 47, 57, 58, 80, 94], "distro": 59, "dit": 58, "dit_precis": 91, "div_ceil": 49, "dive": 24, "diverg": 85, "divers": [4, 7, 11, 24, 25, 38, 41, 47, 85], "divid": [19, 23, 50], "divis": [17, 22], "dkr": 57, "dlami": 53, "dlc": 57, "dldevic": 49, "dllm": [22, 90], "dllm_algorithm": [14, 21, 26, 27, 28, 29, 37, 38, 90], "dllm_algorithm_config": [14, 21, 26, 27, 28, 29, 37, 38], "dlpack": 49, "dmd": 91, "dn": 78, "dnspolici": [80, 81, 84], "do": [0, 1, 14, 18, 22, 28, 30, 38, 41, 49, 51, 52, 56, 57, 60, 62, 63, 68, 71, 75, 82, 97, 99], "doc": [11, 25, 26, 47, 48, 51, 52, 53, 57, 59, 60, 70, 76, 91, 93, 94, 99], "doc_patch": [14, 21, 25, 26, 27, 28, 37, 38, 41, 42, 43, 48, 78], "docker": [22, 30, 34, 51, 58, 60, 70, 74, 80, 86, 87, 95], "dockerfil": [57, 59, 61, 68, 91], "dockerhub": 61, "dockerx": 59, "document": [1, 10, 11, 12, 14, 22, 23, 24, 25, 28, 30, 31, 34, 37, 38, 39, 41, 48, 49, 53, 54, 57, 59, 68, 69, 70, 72, 73, 74, 80, 82, 89, 91, 94, 96], "doe": [8, 11, 12, 14, 15, 17, 22, 31, 51, 52, 53, 60, 91, 99], "doesn": [23, 31, 74, 80], "dog": 97, "domain": [2, 23], "domin": [6, 14, 91], "don": [1, 8, 17, 25, 27, 28, 29, 35, 38, 39, 41, 47, 51, 52, 53, 59, 60, 61, 78, 96, 99], "donald": 76, "done": [30, 38, 47, 48, 51, 56, 62, 63, 71, 82], "dot": [8, 96], "dotsvlm": 96, "doubl": [25, 27, 41], "down": [13, 14, 23, 27, 34, 38, 41, 52, 60, 74, 75, 76, 91], "down_mo": 37, "down_proj": [14, 22], "downcast": [37, 42], "download": [14, 18, 22, 25, 29, 37, 47, 49, 50, 51, 53, 57, 61, 64, 68, 71, 72, 94, 99], "download_cont": 91, "download_dir": [14, 21, 26, 27, 28, 29, 37, 38], "downstream": 23, "downward": [17, 80], "dp": [16, 22, 23, 30, 31, 33, 51, 58, 62, 63, 81, 84, 94], "dp_attent": 22, "dp_rank": 87, "dp_size": [12, 13, 14, 21, 26, 27, 28, 29, 31, 37, 38, 63, 94], "dpbudget": 74, "dpkg": 51, "dpo": 85, "dr": 41, "draft": [1, 7, 22, 25, 30, 31, 32, 34, 35, 45, 62, 63, 65, 71, 74], "drain": 12, "drainag": 41, "dramat": [3, 10], "drastic": [52, 60], "drawn": 14, "drench": 97, "dress": [78, 91], "dri": [56, 59, 91], "drift": 24, "drink": 78, "driven": 50, "driver": [61, 62, 80], "drop": [14, 19, 61, 71, 74], "drun": [59, 61], "ds_channel_config_path": [14, 21, 26, 27, 28, 29, 37, 38], "ds_heavy_channel_num": [14, 21, 26, 27, 28, 29, 37, 38], "ds_heavy_channel_typ": [14, 21, 26, 27, 28, 29, 37, 38], "ds_heavy_token_num": [14, 21, 26, 27, 28, 29, 37, 38], "ds_sparse_decode_threshold": [14, 21, 26, 27, 28, 29, 37, 38], "dsa": 1, "dshm": [80, 81, 84], "dsl": 7, "dst": 49, "dsv32": [31, 84], "dtype": [1, 14, 19, 21, 22, 24, 25, 26, 27, 28, 29, 31, 37, 38, 45, 49, 62, 63, 70, 71, 91], "dual": [1, 68, 91], "dual_chunk_flash_attn": [1, 22], "dublin": 26, "duck": 76, "ducx_path": 16, "due": [4, 13, 16, 17, 18, 22, 27, 51, 52, 53, 57, 60, 70, 71, 74, 76, 85, 87], "dummi": [2, 22, 47, 51], "dummy_hook_factori": 8, "dump": [26, 27, 42, 47, 84, 89], "dump_expert_distribution_record": 37, "duplic": [30, 38, 52, 60], "durat": [30, 33, 46, 50, 51, 91], "duration_m": 91, "dure": [1, 3, 6, 7, 8, 11, 13, 14, 16, 17, 18, 19, 22, 24, 29, 33, 36, 37, 46, 47, 51, 68, 74, 75, 85, 87, 91, 97], "dusti": 70, "dustin": 70, "dv": 53, "dvyio": 91, "dwell": 14, "dynam": [4, 7, 11, 12, 16, 18, 19, 23, 24, 25, 51, 64, 71, 75, 81, 84, 91, 96], "dynamic_batch_tokenizer_batch_s": [14, 21, 26, 27, 28, 29, 37, 38], "dynamic_batch_tokenizer_batch_timeout": [14, 21, 26, 27, 28, 29, 37, 38], "dynamic_smem": 49, "dynamo": [16, 22, 25], "e": [0, 1, 3, 4, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 37, 41, 46, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 68, 69, 71, 72, 78, 82, 86, 87, 91, 93, 94, 96, 97, 99], "e2": [22, 33, 46], "e29b": 23, "e2e_lat": [26, 27, 37, 48], "e2e_request_latency_second": 86, "e2e_request_latency_seconds_bucket": 86, "e2e_request_latency_seconds_count": 86, "e2e_request_latency_seconds_sum": 86, "e2m1": 19, "e4m3": [19, 30], "e5": [58, 67, 92], "e5m2": 19, "each": [0, 1, 2, 3, 4, 8, 11, 14, 16, 17, 19, 22, 23, 24, 27, 29, 30, 31, 33, 37, 38, 41, 45, 46, 47, 50, 51, 52, 54, 60, 68, 74, 80, 82, 87, 89, 91, 96, 97, 99], "eager": [3, 14, 21, 22, 26, 27, 28, 29, 37, 38], "eagl": [1, 30, 31, 62, 63, 65, 71], "eagle2": 22, "eagle3": [22, 25, 34, 35, 62], "ear": 14, "earli": [13, 24, 27, 93], "earlier": 76, "earn": 34, "eas": 91, "easi": [7, 14, 18, 27, 52, 58, 60, 78, 85], "easier": [23, 36, 53, 99], "easili": [27, 38, 99], "east": 61, "eater": 78, "ebnf": 28, "ebnf_grammar": [26, 27], "ec": [81, 84], "ec2a0e5e2e2e4fac9d32025f43b5d1ca": 25, "echo": [31, 51, 56, 57, 59, 61, 62, 63, 71, 82], "econom": [25, 38], "ecosystem": 72, "ecr": 57, "ecr_registri": 57, "edg": [18, 93, 96], "edit": [52, 53, 56, 57, 60], "effect": [1, 2, 11, 17, 19, 24, 25, 36, 38, 41, 71, 74, 80, 91], "effective_max_running_requests_per_dp": 37, "effici": [2, 7, 10, 11, 14, 16, 17, 20, 22, 23, 24, 25, 29, 30, 31, 33, 36, 37, 38, 46, 47, 49, 52, 58, 60, 68, 70, 71, 85, 91, 92, 93, 96, 97], "effort": [1, 10, 12], "eg": [14, 22, 33, 46], "eic": [12, 22], "eiffel": [25, 27, 38], "eight": [80, 96], "eighth": 41, "either": [8, 11, 18, 22, 31, 34, 47, 57, 91], "elabor": 18, "elaps": [14, 37, 80], "elast": [7, 22, 24], "elastic_ep_backend": [14, 21, 26, 27, 28, 29, 37, 38], "electr": 38, "element": [8, 14, 19, 22, 41, 49], "eleutherai": 76, "elif": 78, "elimin": [17, 24], "elit": [14, 36], "els": [8, 14, 26, 27, 37, 52, 60, 97], "elsiu": 28, "embed": [14, 22, 23, 40, 41, 47, 48, 58, 96, 98, 99], "embed_token": 14, "embedding_process": [37, 42], "embrac": 24, "emerg": 38, "emit": 51, "emphasi": 38, "emploi": [7, 11, 25, 47, 96], "empow": 24, "empti": [12, 22, 24, 28, 37, 41, 49, 51], "empty_lik": 49, "emptydir": [80, 81, 84], "emul": 1, "en": [18, 67, 92], "enabl": [1, 3, 4, 5, 6, 7, 11, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 46, 47, 49, 50, 53, 54, 59, 61, 62, 63, 65, 67, 68, 70, 71, 72, 74, 75, 81, 84, 85, 86, 87, 91, 92, 93, 94, 96, 97], "enable_ascend_moe_nz": 65, "enable_ascend_transfer_with_mooncak": 16, "enable_attn_tp_input_scatt": [14, 21, 26, 27, 28, 29, 37, 38], "enable_broadcast_mm_inputs_process": [14, 21, 26, 27, 28, 29, 37, 38], "enable_cache_report": [14, 21, 26, 27, 28, 29, 37, 38], "enable_cudagraph_gc": [14, 21, 26, 27, 28, 29, 37, 38], "enable_custom_logit_processor": [14, 21, 26, 27, 28, 29, 37, 38], "enable_deterministic_infer": [14, 21, 26, 27, 28, 29, 37, 38], "enable_double_spars": [14, 21, 26, 27, 28, 29, 37, 38], "enable_dp_attent": [14, 21, 26, 27, 28, 29, 37, 38], "enable_dp_lm_head": [14, 21, 26, 27, 28, 29, 37, 38], "enable_draft_weights_cpu_backup": [14, 21, 26, 27, 28, 29, 37, 38], "enable_dynamic_batch_token": [14, 21, 26, 27, 28, 29, 37, 38], "enable_dynamic_chunk": [14, 21, 26, 27, 28, 29, 37, 38], "enable_eplb": [14, 21, 26, 27, 28, 29, 37, 38], "enable_expert_distribution_metr": [14, 21, 26, 27, 28, 29, 37, 38], "enable_flashinfer_allreduce_fus": [14, 21, 26, 27, 28, 29, 37, 38], "enable_fp32_lm_head": [14, 21, 26, 27, 28, 29, 37, 38], "enable_fused_qk_norm_rop": [14, 21, 26, 27, 28, 29, 37, 38], "enable_hierarchical_cach": [14, 21, 26, 27, 28, 29, 37, 38], "enable_layerwise_nvtx_mark": [14, 21, 26, 27, 28, 29, 37, 38], "enable_lmcach": [14, 21, 26, 27, 28, 29, 37, 38], "enable_lora": [14, 21, 26, 27, 28, 29, 37, 38], "enable_lora_overlap_load": [14, 21, 26, 27, 28, 29, 37, 38], "enable_memory_sav": [14, 21, 26, 27, 28, 29, 37, 38], "enable_metr": [14, 21, 26, 27, 28, 29, 37, 38, 84], "enable_metrics_for_all_schedul": [14, 21, 26, 27, 28, 29, 37, 38], "enable_mixed_chunk": [14, 21, 26, 27, 28, 29, 37, 38], "enable_moe_nz": [62, 63], "enable_mscclpp": [14, 21, 26, 27, 28, 29, 37, 38], "enable_multi_layer_eagl": [14, 21, 26, 27, 28, 29, 37, 38], "enable_multimod": [14, 21, 26, 27, 28, 29, 37, 38], "enable_nan_detect": [14, 21, 26, 27, 28, 29, 37, 38], "enable_nccl_nvl": [14, 21, 26, 27, 28, 29, 37, 38], "enable_nsa_prefill_context_parallel": [14, 21, 26, 27, 28, 29, 37, 38], "enable_p2p_check": [14, 21, 26, 27, 28, 29, 37, 38], "enable_pdmux": [14, 21, 26, 27, 28, 29, 37, 38], "enable_piecewise_cuda_graph": [14, 21, 26, 27, 28, 29, 37, 38], "enable_precise_embedding_interpol": [14, 21, 26, 27, 28, 29, 37, 38], "enable_prefill_delay": [14, 21, 26, 27, 28, 29, 37, 38], "enable_prefix_mm_cach": [14, 21, 26, 27, 28, 29, 37, 38], "enable_priority_schedul": [14, 21, 26, 27, 28, 29, 37, 38], "enable_profile_cuda_graph": [14, 21, 26, 27, 28, 29, 37, 38], "enable_refresh": 23, "enable_request_time_stats_log": [14, 21, 26, 27, 28, 29, 37, 38], "enable_return_hidden_st": [14, 21, 26, 27, 28, 29, 37, 38], "enable_return_routed_expert": [14, 21, 26, 27, 28, 29, 37, 38], "enable_single_batch_overlap": [14, 21, 26, 27, 28, 29, 37, 38], "enable_symm_mem": [14, 21, 26, 27, 28, 29, 37, 38], "enable_think": [21, 41], "enable_tokenizer_batch_encod": [14, 21, 26, 27, 28, 29, 37, 38], "enable_torch_compil": [14, 21, 26, 27, 28, 29, 37, 38, 91], "enable_torch_compile_debug_mod": [14, 21, 26, 27, 28, 29, 37, 38], "enable_torch_symm_mem": [14, 21, 26, 27, 28, 29, 37, 38], "enable_trac": [14, 21, 26, 27, 28, 29, 37, 38], "enable_two_batch_overlap": [14, 21, 26, 27, 28, 29, 37, 38], "enable_weights_cpu_backup": [14, 21, 26, 27, 28, 29, 37, 38], "encapsul": [11, 24], "encod": [6, 29, 33, 41, 42, 47, 48, 58, 91, 96], "encoder_onli": [14, 21, 26, 27, 28, 29, 37, 38], "encoder_transfer_backend": [14, 21, 26, 27, 28, 29, 37, 38], "encoder_url": [14, 21, 26, 27, 28, 29, 37, 38], "encoding_for_model": 41, "encoding_format": 92, "encount": [13, 14, 17, 18, 30, 51, 57, 59, 61, 62, 68, 69, 71, 80, 86], "encourag": [13, 41, 47, 52, 60], "end": [3, 5, 7, 14, 17, 21, 22, 23, 26, 27, 33, 36, 37, 38, 39, 41, 47, 48, 49, 51, 78, 80, 86, 87, 91, 96, 99], "end_tag": [26, 27], "endem": [37, 97], "endpoint": [2, 6, 10, 22, 24, 26, 27, 37, 48, 57, 78, 86, 87, 99], "energi": 78, "enforc": [14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 49, 74, 78], "engin": [6, 11, 14, 16, 18, 20, 22, 23, 25, 30, 39, 41, 43, 51, 52, 58, 59, 60, 61, 64, 70, 75, 78, 81, 85, 90, 91, 94], "engine_metr": 23, "england": [26, 27, 47], "english": [27, 93], "enhanc": [7, 25, 38, 78, 93, 96], "enjoi": [38, 78, 97], "enjoy": 78, "enniu": 41, "enorm": 38, "enough": [8, 13, 22, 24], "ensembl": 50, "ensur": [0, 2, 4, 7, 10, 11, 14, 16, 17, 22, 23, 24, 25, 27, 28, 30, 31, 34, 38, 50, 51, 52, 53, 59, 60, 61, 68, 70, 71, 82, 84, 85, 86, 97, 99], "enter": [53, 68, 87], "enterpris": [11, 18, 23, 57, 85, 93], "enthusiast": 38, "entir": [5, 8, 16, 23, 24, 26, 27, 51, 59, 91], "entiti": [27, 38], "entri": [7, 8, 13, 23, 91], "entryclass": 99, "entrypoint": [2, 12, 89, 99], "enum": [26, 27, 28, 91], "enumer": [18, 47, 78], "env": [3, 16, 23, 25, 57, 59, 61, 68, 80, 81, 84, 87, 91, 95], "env_fold": 82, "envelop": 22, "environ": [10, 11, 14, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 42, 43, 48, 50, 51, 52, 54, 56, 57, 58, 68, 72, 78, 80, 81, 82, 84, 86, 87, 95], "environment": 17, "eo": [13, 47, 50, 71], "eof": 22, "eom": 28, "ep": [6, 22, 30, 31, 33, 36, 46, 51, 62, 81, 84], "ep_dispatch_algorithm": [14, 21, 26, 27, 28, 29, 37, 38], "ep_num_redundant_expert": [14, 21, 26, 27, 28, 29, 37, 38], "ep_siz": [7, 14, 21, 26, 27, 28, 29, 37, 38], "epd": 58, "eplb": [7, 22, 81, 84], "eplb_algorithm": [14, 21, 26, 27, 28, 29, 37, 38], "eplb_min_rebalancing_utilization_threshold": [14, 21, 26, 27, 28, 29, 37, 38], "eplb_rebalance_layers_per_chunk": [14, 21, 26, 27, 28, 29, 37, 38], "eplb_rebalance_num_iter": [14, 21, 26, 27, 28, 29, 37, 38], "equal": [14, 21, 22, 31, 49, 50, 78], "equip": [31, 68], "equival": [23, 48, 59, 75], "erni": [67, 93, 96], "ernie4": 96, "err": 82, "error": [0, 2, 8, 12, 14, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 38, 41, 42, 43, 48, 49, 50, 51, 52, 60, 61, 68, 78, 80, 82, 86, 91, 97], "error_messag": 14, "error_typ": 89, "errors_tot": 23, "esc": 68, "escap": 14, "especi": [2, 11, 13, 14, 17, 19, 22, 28, 34, 38, 52, 53, 60, 91], "essenti": [10, 14, 23, 80, 85, 86, 99], "establish": [21, 85], "estim": [17, 27, 74], "et": 34, "etc": [1, 3, 5, 8, 10, 12, 18, 22, 23, 28, 50, 51, 58, 59, 61, 89, 91, 93, 99], "eth": 80, "ethernet": 80, "ethic": 38, "ethnic": 38, "europ": [27, 48], "ev": 96, "eva": 91, "eval": [29, 31, 52, 54, 60, 99], "evalu": [4, 17, 19, 22, 24, 25, 31, 37, 50, 52, 58, 60, 71, 98], "evaluation_mod": 31, "even": [4, 12, 17, 24, 25, 27, 37, 38, 53, 74, 76, 93, 96], "even_k": 25, "evenli": 17, "event": [17, 22, 23, 28, 38, 51], "eventu": 99, "ever": 36, "everi": [0, 5, 7, 8, 11, 14, 15, 22, 49, 51, 52, 53, 60, 68, 78, 87, 91], "everydai": 29, "everyon": 14, "everyth": 3, "evict": [11, 14, 22, 23], "evolv": [7, 17, 23, 38], "exa": 34, "exa_api_kei": 34, "exact": [11, 23, 27, 34, 91], "exactli": [8, 14, 23, 27, 39, 51, 99], "exampl": [0, 1, 8, 10, 11, 12, 14, 16, 17, 22, 24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 38, 42, 43, 45, 49, 52, 53, 54, 56, 57, 60, 66, 72, 76, 78, 82, 86, 87, 94, 95], "example_function_nam": [26, 27], "example_imag": [29, 33, 43, 46, 47, 78], "example_nam": [26, 27], "example_valu": [26, 27], "exampleoutput": 41, "exaon": [67, 93], "exce": [11, 22, 23, 33, 46, 47, 52, 60, 68, 74, 99], "exceed": 63, "excel": [1, 52, 60, 93], "except": [1, 8, 22, 28, 31, 37, 71, 100], "excess": [14, 17, 23], "excit": 38, "exclud": [22, 38, 57], "exclus": [51, 91], "exec": [0, 51, 53, 91], "execut": [0, 6, 7, 11, 17, 18, 22, 23, 24, 26, 27, 34, 51, 57, 68, 80, 81, 87, 91, 92, 98], "exercis": 78, "exhaust": 23, "exhibit": 93, "exist": [0, 1, 6, 10, 11, 18, 22, 29, 52, 53, 60, 81, 84, 87, 91, 99], "exit": [68, 82], "exp": [28, 31, 67, 83], "expand": [1, 11, 38, 78, 99], "expandable_seg": [62, 63, 65], "expans": [7, 25, 91], "expect": [3, 4, 8, 14, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 38, 41, 42, 43, 48, 49, 51, 68, 71, 78, 91], "expens": [52, 60], "experi": [4, 17, 18, 19, 38, 81], "experienc": 30, "experiment": [17, 19, 22, 25, 30, 32, 34, 74], "expert": [13, 22, 30, 47, 58, 62, 63, 68, 74, 81, 83, 84, 90, 93], "expert_distribution_recorder_buffer_s": [14, 21, 26, 27, 28, 29, 37, 38], "expert_distribution_recorder_mod": [14, 21, 26, 27, 28, 29, 37, 38], "expert_record_server_process": 37, "expir": 23, "explain": [12, 34, 37, 38, 71, 87, 92, 99], "explan": [1, 28, 70, 72], "explicit": [8, 23, 24, 28], "explicitli": [14, 26, 35, 37, 68, 86, 87, 91], "exploit": 11, "explor": [1, 14, 38, 41, 96], "expon": 19, "exponenti": [19, 22, 23], "export": [8, 10, 16, 17, 22, 23, 31, 34, 49, 50, 51, 53, 56, 57, 59, 60, 61, 62, 63, 65, 68, 71, 87, 91, 94, 95, 99], "export_metrics_to_fil": [14, 21, 26, 27, 28, 29, 37, 38], "export_metrics_to_file_dir": [14, 21, 26, 27, 28, 29, 37, 38], "exported_model": 18, "expos": [11, 12, 15, 23, 24, 34, 41, 49, 50, 51, 81, 86, 91], "expr": [23, 62], "express": [38, 47, 49, 78, 93, 96], "extend": [10, 11, 22, 23, 25, 28, 30, 31, 41, 50, 54, 76, 91, 93, 97, 99], "extens": [49, 53, 58, 78, 91, 96], "extern": [8, 10, 19, 22, 23, 34, 37], "extra": [10, 11, 22, 31, 45, 49, 50, 54, 57], "extra_bodi": [21, 26, 27, 30, 32, 41, 47], "extra_buff": [22, 45], "extract": [5, 38, 49, 52, 60, 96, 99], "extrem": [3, 11, 14, 17, 19, 28, 52, 60], "ey": 14, "f": [8, 14, 18, 21, 25, 26, 27, 28, 29, 33, 37, 38, 41, 42, 43, 46, 47, 48, 49, 57, 59, 61, 62, 63, 68, 69, 78, 80, 81, 87, 91, 94, 97, 99], "f059c94ec0584b5189e20cfa81945add": 27, "f1": 53, "f2e221ec002d4e3396973eb009932df7": 43, "f5": 53, "f7ff": 80, "f_": 25, "f_1": 25, "f_k": 25, "fa": [71, 91], "fa3": [1, 3, 4, 10, 14, 17, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 41, 42, 43, 46, 48, 78, 91], "fa4": [1, 22, 91], "fabdb6a30b49f79a7aba0f2ad9df9b399473380f": 53, "face": [14, 18, 22, 41, 58, 73, 91, 93, 99], "facilit": [17, 24, 30, 68, 85, 92], "fact": [14, 38], "facto": 85, "factor": [18, 22, 23, 25, 36, 50, 75], "factori": [22, 85], "factory_nam": 8, "factual": [38, 99], "fahrenheit": [26, 27, 28], "fail": [0, 8, 12, 14, 18, 23, 24, 28, 37, 49, 50, 51, 52, 60, 76, 82, 91], "failur": [8, 12, 16, 18, 52, 57, 60], "failurethreshold": 84, "fair": [52, 60], "fairi": 14, "fake": [18, 22], "fal": 91, "fall": [1, 7, 22, 23, 31, 89, 91, 97, 100], "fallback": [22, 23, 26, 27, 35, 47, 58, 91], "fals": [14, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 41, 42, 47, 48, 51, 53, 74, 81, 84, 91, 97, 99], "famili": [1, 21, 23, 31, 38, 41, 46, 67, 71, 90, 91, 92, 93, 96, 97, 98], "familiar": 39, "famou": [27, 38], "far": [14, 47], "fascin": 41, "fashion": 38, "fast": [1, 8, 11, 12, 22, 23, 24, 34, 36, 39, 52, 58, 60, 91, 93, 96], "fastapi": 22, "fastapi_root_path": [14, 21, 26, 27, 28, 29, 37, 38], "faster": [11, 14, 25, 52, 57, 60, 71, 74, 85, 90, 91, 92, 93, 96], "fastest": 25, "fasthunyuan": 91, "fastsafetensor": 22, "fastvideo": 91, "fastwan": 91, "fastwan2": 91, "fat": 78, "fatal": [8, 57], "father": 14, "fault": [16, 23, 24], "favor": [13, 41], "favorit": 38, "fcf": [14, 16, 21, 22, 26, 27, 28, 29, 37, 38], "fe36": 80, "fe64": 80, "fe6e": 80, "fe73": 80, "fe80": 80, "feasibl": 22, "feather": 78, "featur": [0, 1, 2, 3, 4, 5, 7, 8, 10, 14, 17, 22, 25, 27, 28, 29, 30, 31, 32, 33, 35, 43, 45, 46, 47, 51, 52, 60, 74, 79, 80, 85, 87, 90, 93, 96, 99], "feed": [23, 99], "feedback": 10, "feel": [38, 41, 52, 60, 61, 68], "felt": 14, "feroci": 14, "fetch": [11, 26, 27, 28, 50, 51], "few": [3, 14, 29, 38, 52, 59, 60], "few_shot_gsm8k": [52, 54, 60, 63], "fewer": [17, 68], "ffi": [23, 49], "ffn": 22, "fi": [62, 63, 82], "fiber": 78, "fiction": [38, 99], "field": [14, 22, 24, 26, 27, 37, 41, 50, 91, 99], "fieldpath": [81, 84], "fieldref": [81, 84], "fifo": [14, 22, 23], "fight": 14, "figur": [27, 41, 53], "file": [0, 2, 11, 12, 15, 19, 29, 33, 37, 46, 47, 49, 50, 52, 60, 68, 71, 72, 73, 75, 80, 89, 96, 99], "file_path": 23, "file_storage_path": [14, 21, 26, 27, 28, 29, 37, 38], "filenam": 22, "filesystem": 23, "fill": [1, 14, 78], "fillmor": 76, "filter": [23, 28], "final": [12, 21, 22, 25, 28, 49, 75, 99], "final_hidden_st": 7, "final_respons": 28, "financ": 38, "find": [0, 14, 17, 21, 22, 25, 26, 27, 28, 31, 41, 47, 52, 57, 60, 71, 75, 80, 86, 87, 91, 97, 99], "fine": [7, 11, 16, 17, 28, 31, 33, 46, 51, 85, 91, 93, 96], "finer": 87, "finetun": 28, "finish": [14, 30, 51, 91], "finish_reason": [25, 26, 27, 28, 30, 37, 41, 43, 48, 81, 84], "finit": 14, "finn": 14, "fire": [14, 37, 59, 68, 80], "firewal": [23, 39, 71], "firm": 34, "firmwar": 61, "first": [0, 1, 2, 3, 8, 10, 11, 13, 14, 17, 18, 21, 22, 23, 27, 30, 31, 37, 41, 42, 43, 50, 51, 52, 53, 54, 57, 60, 61, 68, 71, 74, 82, 86, 87, 91, 94, 99], "first_answ": 78, "firstli": 51, "fish": 78, "fit": [11, 17, 22, 31, 38, 57, 96], "five": [24, 52, 60, 78], "fix": [0, 1, 3, 12, 17, 37, 52, 57, 60, 71, 91], "fla": 22, "flag": [2, 4, 7, 10, 22, 23, 27, 30, 31, 32, 41, 47, 50, 51, 53, 54, 68, 74, 87, 91, 92, 96], "flagship": 68, "flaki": [52, 60], "flash": [22, 33, 46, 74, 90, 91], "flash_attn": 31, "flash_attn_with_kvcach": 31, "flash_mla": 31, "flash_mla_sparse_fwd": 31, "flash_mla_with_kvcach": 31, "flash_rl": 22, "flashattent": [1, 4, 31, 71, 91], "flashattention3": 30, "flashattention_backend": 1, "flashinf": [1, 4, 7, 14, 21, 22, 25, 26, 27, 28, 29, 30, 37, 38, 57, 70, 74], "flashinfer_cudnn": 22, "flashinfer_cutedsl": [7, 22, 31, 74], "flashinfer_cutlass": [7, 22, 31, 74], "flashinfer_mla_disable_rag": [14, 21, 26, 27, 28, 29, 37, 38], "flashinfer_mxfp4": [7, 22], "flashinfer_mxfp4_moe_precis": [14, 21, 26, 27, 28, 29, 37, 38], "flashinfer_trtllm": [1, 7, 22, 31, 74], "flashmla": [1, 22, 30], "flashmla_auto": [22, 31], "flashmla_decod": 22, "flashmla_kv": [22, 31], "flashmla_prefil": 22, "flashmla_spars": [22, 31], "flashrl": 22, "flatten": [3, 29, 41, 47], "flattened_bucket": 24, "flavor": 38, "fleet": 23, "flex_attent": [1, 22], "flexattent": 1, "flexibl": [7, 14, 24, 48, 71, 78, 92, 97], "flexibli": 30, "flight": [17, 50], "flm": 93, "float": [4, 19, 22, 41, 47, 91, 92, 97], "float16": [18, 22, 25, 37, 42], "float32": [14, 18, 21, 22, 25, 26, 27, 28, 29, 37, 38, 42, 45], "float8": 18, "float8_e4m3fn": 19, "flow": [7, 24, 87], "fluctuat": 27, "fluenci": 41, "flush": [22, 24, 38, 39, 47, 48, 50, 78], "flush_cach": [23, 24, 37, 50], "flux": 91, "fly": [18, 19], "flymi": 91, "fn": 91, "fn_name": 8, "fnmatch": 8, "focal": 34, "focu": [24, 29, 38, 91], "focus": [7, 24, 38, 41], "folder": [0, 15, 22, 51, 53, 56, 68, 84, 86, 88], "follow": [0, 1, 3, 4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 30, 31, 33, 36, 37, 38, 41, 46, 47, 48, 49, 51, 52, 53, 56, 57, 59, 60, 61, 68, 70, 71, 75, 78, 79, 80, 81, 82, 86, 87, 89, 91, 93, 94, 96, 99, 100], "follow_bootstrap_room": 22, "foo": [26, 27], "food": [38, 78], "fool": 34, "footprint": [1, 19], "forc": [23, 47, 54, 57, 68, 74, 91], "foreign": 49, "forest": [14, 91], "forev": 56, "fork": [51, 58, 78, 91], "form": [6, 8, 14, 27, 28, 36, 38, 47, 51, 72, 91], "format": [2, 5, 7, 8, 14, 18, 20, 22, 24, 26, 27, 30, 37, 47, 51, 68, 71, 81, 86, 87, 91, 96], "former": [13, 16, 22, 63], "formerli": 79, "forum": 41, "forward": [1, 7, 8, 17, 23, 52, 60, 74, 99, 100], "forward_batch": 99, "forward_batch_info": 99, "forward_decod": [1, 99], "forward_extend": [1, 99], "forward_hook": [8, 14, 21, 26, 27, 28, 29, 37, 38], "forward_stream": 17, "forwardbatch": 99, "fought": 14, "found": [4, 11, 14, 16, 17, 19, 22, 37, 38, 63, 65, 70, 80], "foundat": 93, "four": [14, 30, 38, 87], "fp": [91, 96], "fp16": [22, 82, 91], "fp32": [22, 91], "fp4": [1, 7, 18, 22, 58, 74], "fp4_e2m1": [19, 22], "fp4_gemm_runner_backend": [14, 21, 26, 27, 28, 29, 37, 38], "fp8": [1, 7, 13, 18, 22, 31, 32, 58, 68, 74, 82], "fp8_dynam": 18, "fp8_e4m3": [1, 19, 22, 31], "fp8_e5m2": [19, 22], "fp8_gemm_runner_backend": [14, 21, 26, 27, 28, 29, 37, 38], "fp8_kernel": 18, "fp8dq": [18, 22], "fp8wo": [18, 22], "fr": 25, "frac": 51, "fraction": [10, 16, 17, 22, 25, 30, 31, 32, 33, 35, 36, 46, 62, 63, 65, 70, 71, 75, 80, 81, 84], "fragment": [3, 28, 30, 74], "frame": [91, 96], "framework": [11, 24, 52, 58, 60, 84, 85, 91, 94, 97], "franc": [14, 18, 25, 26, 27, 28, 30, 32, 37, 38, 41, 47, 48, 76, 78, 92, 94, 99], "francisco": [26, 27, 28], "franklin": 70, "free": [14, 23, 27, 38, 41, 52, 60, 61, 68], "freeli": 87, "french": [27, 38], "freq_32768": 25, "frequenc": [11, 33, 46, 47, 74, 78], "frequency_penalti": [41, 47], "frequent": [3, 11, 13, 14, 16, 17, 22, 58], "fridai": 34, "friend": 38, "friendli": 85, "friendship": 14, "from": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 34, 36, 38, 41, 42, 43, 47, 48, 49, 50, 51, 58, 63, 64, 70, 73, 74, 75, 78, 84, 85, 86, 87, 89, 90, 93, 94, 96, 97, 98, 100], "from_arg": 23, "from_pretrain": [18, 21, 26, 27, 28, 29, 37, 42, 91], "from_stat": 23, "front": [5, 11, 14], "frontend": [58, 73], "frontier": 85, "frozen": [3, 14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "fruit": [38, 78], "fsdp": 22, "full": [6, 7, 10, 13, 14, 22, 24, 30, 35, 37, 45, 51, 80, 85, 92, 93, 96], "full_argu": 28, "full_siz": 22, "fullattn": 91, "fulli": [0, 4, 6, 11, 18, 23, 28, 30, 31, 41, 52, 59, 60, 81, 84, 85, 91, 93], "func": 49, "func_latency_second": 86, "func_latency_seconds_bucket": 86, "func_latency_seconds_count": 86, "func_latency_seconds_sum": 86, "func_name1": 28, "func_name2": 28, "function": [0, 1, 7, 8, 11, 17, 22, 25, 26, 27, 41, 49, 52, 60, 71, 76, 78, 85, 86, 99], "function_cal": [23, 25, 28, 41, 48], "function_call_input": 28, "function_call_pars": 28, "function_call_respons": 28, "function_call_response_json": 28, "function_dict": 28, "function_nam": [26, 27], "functioncallpars": 28, "functool": [25, 49, 99], "fundament": 10, "furri": 91, "further": [6, 11, 17, 24, 25, 27, 38, 57, 87], "furthermor": 25, "fuse": [7, 18, 19, 22, 31, 74], "fused_moe_triton": [37, 81], "fusedmo": [7, 31], "fusion": [18, 22, 62, 63, 74], "futur": [11, 18, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 52, 60, 74, 78, 81, 94, 99], "futurewarn": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "futurist": 91, "fuzzi": 27, "g": [0, 1, 3, 4, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 26, 27, 28, 30, 33, 34, 37, 46, 49, 50, 51, 52, 53, 54, 56, 57, 60, 68, 72, 78, 86, 91, 93, 96, 97, 99], "g547e2d037": 37, "gain": [5, 7, 11, 29, 93], "garbag": 22, "garden": [14, 91], "gastronomi": 38, "gate": [18, 52, 60], "gate_proj": [14, 22], "gate_up_proj": 22, "gatewai": [13, 16, 22, 24, 58, 63, 89], "gather": [7, 22, 24, 31, 74, 96], "gaudi": 18, "gaug": 86, "gb": [10, 13, 14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 43, 48, 71, 74, 78, 80], "gb200": [30, 35, 57, 58, 74], "gb300": 57, "gc": [22, 71], "gc_warning_threshold_sec": [14, 21, 26, 27, 28, 29, 37, 38], "gcc": 68, "gcp": 71, "gd": 11, "gem": 14, "gemm": [7, 14, 74], "gemma": [58, 67, 71, 93, 96, 98], "gemma2forsequenceclassif": [89, 98], "gemma3": 43, "gen": [13, 14, 68, 76, 78, 93], "gen_data": [21, 28], "gen_respons": [21, 28], "gen_second": 31, "gen_throughput": 86, "gen_url": [21, 28], "gender": 38, "gener": [5, 6, 7, 11, 14, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 31, 34, 35, 36, 39, 41, 49, 50, 51, 58, 68, 71, 80, 85, 86, 87, 88, 89, 90, 93, 94, 96, 99], "general_inform": 27, "generate_request": 86, "generate_stream": 50, "generated_text": [21, 28, 50], "generatereqinput": 47, "generation_config": [22, 47], "generation_duration_second": 23, "generation_tokens_bucket": [14, 21, 26, 27, 28, 29, 37, 38], "generation_tokens_tot": 86, "generative_model": 99, "gentl": 14, "geographi": [26, 27], "germani": [26, 27, 41, 78], "get": [0, 8, 10, 12, 14, 22, 23, 24, 25, 26, 27, 28, 29, 30, 39, 42, 45, 50, 51, 52, 57, 60, 61, 62, 68, 72, 78, 80, 81, 84, 92, 97, 99], "get_current_d": [26, 27], "get_current_weath": [26, 27, 28], "get_embed": 99, "get_image_featur": 99, "get_load": 23, "get_max_total_num_token": 37, "get_memory_pool_s": 37, "get_messag": [26, 27, 28], "get_model_info": [22, 23, 37, 78, 80], "get_model_load": 18, "get_prompt": 29, "get_server_arg": 37, "get_server_info": [22, 23, 37, 50], "get_start": 0, "get_tourist_attract": 28, "get_weath": [23, 28], "getattr": 8, "gf_auth_anonymous_en": 86, "gf_server_http_port": 86, "ggml": [26, 47], "gguf": [18, 22, 100], "ghp_xxxxx": 23, "giant": [37, 97], "gibberish": 50, "gid": 80, "gigabyt": [11, 22], "git": [16, 31, 52, 56, 57, 59, 60, 61, 68, 69, 70, 71, 72, 91, 94], "github": [0, 3, 10, 16, 23, 29, 31, 33, 37, 43, 46, 47, 52, 57, 59, 60, 61, 68, 69, 70, 71, 72, 75, 78, 84, 87, 91, 93, 94, 96], "githubusercont": 43, "give": [14, 26, 27, 28, 56, 78, 99], "given": [8, 11, 17, 23, 25, 26, 27, 28, 29, 30, 31, 37, 47, 97], "glitter": 14, "glm": [5, 22, 23, 24, 28, 58, 67, 85, 91, 93, 96], "glm45": [22, 23, 32, 33], "glm47": [22, 32], "glm4moethinkingbudgetlogitprocessor": [32, 33], "glm4v": [29, 43, 78], "glm_ocr": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 78], "glm_ocr_nextn": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 78], "glmasr": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 78], "glmasrconfig": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 78], "glob": [8, 22], "global": [11, 23, 26, 27, 87, 91], "global_force_attn_backend": 91, "global_force_attn_backend_context_manag": 91, "global_segment_s": 12, "glog_v": 94, "gloo": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 74, 78], "gloo_socket_ifnam": [62, 63, 80, 84], "gme": [67, 92], "gnu": 68, "gnupg": 51, "go": [27, 34, 38, 41, 59, 61, 78, 86], "goal": 99, "golang": 23, "gold": 23, "golden": [14, 97], "good": [13, 14, 27, 30, 52, 59, 60, 91], "googl": [58, 67, 71, 78, 85, 93, 96], "got": 49, "govern": [27, 38], "gpqa": 54, "gpqa_diamond": 19, "gpt": [19, 21, 22, 23, 28, 41, 58, 67, 93], "gptoss": 67, "gptq": [18, 22, 58], "gptq_marlin": [18, 22], "gpu": [3, 4, 5, 7, 10, 11, 13, 16, 17, 18, 19, 20, 22, 24, 25, 29, 30, 31, 32, 33, 35, 36, 37, 39, 45, 46, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 72, 74, 80, 81, 82, 83, 84, 85, 91, 95, 96], "gpu_id_step": [14, 21, 26, 27, 28, 29, 37, 38], "grade": [18, 57, 85], "gradual": [17, 71], "grafana": 86, "grain": [7, 11, 16, 31, 51, 78, 85, 87, 91, 96], "grammar": [12, 26, 27, 28, 47, 82], "grammar_backend": [14, 21, 26, 27, 28, 29, 37, 38], "grammar_queu": 12, "granit": [67, 93], "granular": [11, 17, 51, 54], "graph": [1, 2, 4, 7, 14, 18, 22, 24, 25, 30, 31, 37, 51, 53, 58, 62, 63, 75, 80, 81, 84, 91], "graph_kei": 3, "graphic": 72, "gre": 82, "great": [89, 90], "greater": [2, 11, 14, 16, 17, 22, 25, 97], "greedi": 47, "greedy_token_select": 76, "greenctx": 22, "greet": 47, "grep": [80, 81, 84], "grew": 14, "grid": 22, "grid_siz": 49, "grok": [67, 71, 93], "group": [1, 4, 7, 11, 14, 20, 22, 23, 30, 31, 50, 56, 59, 70, 74], "group_m": 25, "group_nam": 24, "group_siz": [18, 22], "grouped_gemm": 7, "grow": [17, 27, 38, 47], "growth": 27, "grpc": [22, 24, 87], "grpc_mode": [14, 21, 26, 27, 28, 29, 37, 38], "grpo": [4, 85], "grub_cmdline_linux": 59, "gryffindor": 78, "gserver": 50, "gsm8k": [19, 52, 53, 54, 60, 62, 99], "gsp": 50, "gt": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "gte": [37, 42, 58, 67, 92], "gte_qwen2": 67, "guarante": [11, 24, 26, 47, 97], "guard": [14, 18], "gui": 51, "guid": [10, 16, 18, 22, 24, 26, 28, 30, 36, 47, 48, 51, 57, 59, 61, 66, 71, 80, 91, 94, 98], "guidanc": [23, 25, 68, 71, 75, 85, 99], "guidance_scal": 91, "guidelin": [38, 52, 60, 99], "gz": [18, 51, 53, 91], "h": [12, 23, 30, 31, 36, 42, 43, 48, 49, 51, 68, 72, 81, 84, 89, 90, 91, 97], "h100": [1, 25, 30, 33, 35, 46, 57, 58, 83, 91], "h20": [1, 2, 30, 31, 80], "h200": [1, 31, 32, 33, 35, 45, 46, 83, 91], "h2d": [14, 22], "ha": [1, 3, 8, 11, 13, 14, 17, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 38, 45, 51, 52, 54, 60, 64, 68, 80, 84, 85, 87, 91, 93, 100], "habit": 78, "had": [14, 17, 27, 41], "hadn": 51, "hair": 14, "half": [22, 23, 70, 78], "halt": 14, "hand": [5, 13, 17, 78], "handl": [7, 8, 10, 16, 17, 19, 21, 22, 23, 24, 29, 30, 37, 47, 48, 51, 71, 78, 80, 81, 92, 96, 99], "handler": [22, 52, 60], "handoff": 24, "handsom": 14, "hang": [22, 29], "happen": [12, 13, 18, 22, 24, 29, 33, 46, 96, 100], "happi": [14, 37, 52, 60, 85], "hard": [10, 80], "hardwar": [1, 7, 14, 17, 18, 22, 31, 35, 52, 54, 59, 60, 61, 62], "harm": 53, "harri": 78, "has_audio_understand": 37, "has_image_understand": 37, "hash": [23, 54, 74, 99], "hasn": 80, "hat": 93, "hatch": 14, "have": [14, 16, 17, 18, 22, 25, 26, 27, 29, 30, 34, 38, 41, 43, 51, 52, 57, 59, 60, 61, 62, 68, 69, 71, 72, 74, 76, 80, 81, 85, 87, 90, 91, 93, 96, 97, 99], "hazard": 17, "hbm": 71, "hccl_algo": 62, "hccl_buffsiz": [62, 63, 65], "hccl_op_expansion_mod": [62, 65], "hccl_socket_ifnam": [62, 63], "hdk": 61, "he": 14, "head": [1, 11, 22, 27, 31, 33, 39, 46, 51, 62, 63, 81, 82, 84, 96, 99], "head_nod": 82, "head_node_ip": 31, "header": [22, 23, 87, 89], "headlin": 34, "headshotx": 91, "heal": 14, "health": [16, 39, 71, 74, 78, 84], "health_checks_tot": 23, "health_gener": [23, 37], "healthcar": 38, "healthi": [13, 23, 24, 78], "hear": 27, "heard": [14, 27], "heart": 78, "heartbeat": 16, "heartbroken": 14, "heavi": [6, 14, 22], "heavili": 28, "hei": 47, "height": 91, "heightxwidth": 50, "helfpul": 34, "hellaswag": 54, "hello": [18, 23, 28, 38, 39, 47, 94, 99], "helm": 81, "help": [0, 11, 13, 14, 17, 22, 26, 27, 28, 29, 34, 36, 37, 41, 47, 50, 51, 52, 57, 59, 60, 71, 75, 78, 81, 84, 85, 86, 91, 96], "henc": 17, "her": [14, 41, 97], "here": [10, 11, 13, 14, 18, 24, 25, 26, 27, 28, 29, 30, 37, 38, 41, 47, 48, 52, 57, 59, 60, 61, 63, 65, 78, 80, 81, 85, 86, 91, 100], "heterogen": 23, "heurist": [13, 31], "hf": [14, 18, 22, 25, 37, 50, 73, 90, 93, 96, 98, 99], "hf3f": [11, 12, 22], "hf_chat_template_nam": [14, 21, 26, 27, 28, 29, 37, 38], "hf_home": [14, 37, 56], "hf_quant_config": 27, "hf_token": [23, 56, 57, 59, 61, 68, 91, 99], "hf_xxx": 56, "hh": 91, "hi": [14, 37, 47, 82, 97], "hicach": [22, 58], "hicache_io_backend": [14, 21, 26, 27, 28, 29, 37, 38], "hicache_mem_layout": [14, 21, 26, 27, 28, 29, 37, 38], "hicache_ratio": [11, 14, 21, 22, 26, 27, 28, 29, 37, 38], "hicache_s": [11, 14, 21, 26, 27, 28, 29, 37, 38], "hicache_storage_backend": [12, 14, 21, 26, 27, 28, 29, 37, 38], "hicache_storage_backend_extra_config": [11, 12, 14, 21, 26, 27, 28, 29, 37, 38], "hicache_storage_backend_extra_config_json": 12, "hicache_storage_pass_prefix_kei": 12, "hicache_storage_prefetch_polici": [12, 14, 21, 26, 27, 28, 29, 37, 38], "hicache_write_polici": [14, 21, 26, 27, 28, 29, 37, 38], "hicachecontrol": 12, "hicachefil": 11, "hicachestorag": 11, "hidden": [8, 14, 22, 25, 38, 47], "hidden_st": [99, 100], "hide": [7, 11, 14], "hierarch": [10, 11, 58], "hierarchi": [11, 51, 87], "hierarchical_sparse_attention_extra_config": [14, 21, 26, 27, 28, 29, 37, 38], "high": [7, 11, 14, 18, 22, 24, 25, 27, 28, 29, 30, 33, 34, 39, 46, 47, 54, 58, 70, 76, 85, 91, 92, 93, 94, 96, 97], "higher": [1, 7, 10, 11, 13, 14, 17, 19, 22, 24, 25, 27, 34, 41, 47, 52, 60, 61, 71, 90, 91, 96, 97], "higherrorr": 23, "highest": [23, 47, 76], "highest_token_prob": 47, "highlat": 23, "highli": [6, 7, 24, 47], "highlight": [14, 21, 26, 27, 28, 37, 41, 42, 43, 48, 78], "hilab": 96, "him": 14, "hint": 7, "hiradix_cach": 12, "hiradixcach": 12, "hisi_hdc": 61, "histogram": [22, 23, 31, 86], "histogram_quantil": 23, "histor": [25, 74], "histori": [28, 38, 41, 91], "historian": 41, "hit": [10, 11, 13, 23, 47, 80, 86], "hmm": [27, 41], "hobbi": 38, "hold": 11, "holist": 96, "home": [23, 25, 38, 53, 59, 68, 81], "honest": 14, "hood": [24, 75], "hook": 7, "hook_cal": 8, "hook_factori": 22, "hook_factory_path": 8, "hook_spec": 8, "hope": 14, "hopper": [1, 7, 18, 22, 30, 31, 35, 74, 91], "horizon": [38, 93], "horizont": [6, 23], "host": [2, 10, 11, 12, 14, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 54, 57, 59, 61, 62, 63, 68, 70, 71, 72, 74, 78, 80, 81, 84, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], "hostipc": [80, 81, 84], "hostnam": [22, 62, 63, 82], "hostnetwork": [80, 81, 84], "hostpath": [80, 81, 84], "hot": 11, "hottest": 11, "hour": [14, 30], "hous": 78, "how": [0, 1, 11, 13, 14, 17, 18, 22, 23, 24, 25, 27, 29, 30, 37, 41, 50, 51, 58, 59, 68, 69, 72, 76, 82, 86, 96], "howee": 67, "howev": [5, 6, 11, 13, 14, 23, 27, 28, 38, 45, 75, 80, 85, 87, 99, 100], "hpu": [22, 31], "html": [0, 26, 51, 88, 99], "http": [0, 2, 3, 4, 6, 10, 14, 15, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 68, 69, 70, 71, 72, 75, 78, 79, 80, 81, 84, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 99], "http_proxi": 62, "http_server": [12, 37, 89, 99], "http_worker_ipc": 14, "httpget": 84, "https_proxi": 62, "hub": [14, 22, 23, 27, 31, 37, 38, 57, 59, 91, 100], "hufflepuff": 78, "hug": [18, 22, 41, 58, 73, 91, 93, 99], "huge": 25, "huggingfac": [14, 18, 22, 23, 27, 29, 37, 47, 53, 56, 57, 59, 68, 91, 92, 93, 95, 96, 97, 98, 99], "huggingface_hub": 99, "huggingfacetb": [67, 93], "huihui": 67, "human": [8, 22, 38, 90, 98], "human_ev": 54, "humanev": 54, "humor": 43, "hundr": 68, "hunyuan": 91, "hunyuanvideo": 91, "hybrid": [5, 7, 16, 21, 22, 35, 41, 45, 93, 96], "hybrid_attn_backend": 1, "hydrat": 78, "hyperparamet": [17, 22, 58], "i": [0, 1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 73, 74, 75, 76, 78, 80, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100], "i2v": 91, "ib": [10, 16, 22, 24, 31, 80, 81, 84], "ibdev2netdev": 80, "ibm": [67, 93], "ibstatu": 80, "ibv_devic": 80, "ibv_devinfo": 80, "ic": 38, "icon": [25, 38, 41, 43], "id": [16, 21, 22, 24, 25, 26, 27, 28, 30, 37, 43, 47, 48, 49, 50, 51, 61, 62, 81, 84, 89, 91], "id2label": [23, 89], "idea": [11, 52, 60, 78], "ideal": [10, 17, 23, 78, 97], "idempot": 12, "ident": [3, 4, 11, 12, 17, 24, 59], "identif": 51, "identifi": [2, 10, 21, 22, 27, 38, 51, 68, 72, 89, 91, 93, 96, 97, 98], "idl": [7, 11, 22, 24, 30], "idle_timeout": 23, "idx": 49, "ifnam": 62, "ignor": [14, 18, 21, 22, 25, 26, 27, 28, 29, 31, 37, 41, 42, 43, 48, 50, 71, 78, 91], "ignore_eo": 47, "igw": 23, "ii": 30, "iic": 67, "illustr": [68, 91], "im_end": [29, 47, 73, 78], "im_start": [29, 47, 73, 78], "imag": [3, 6, 22, 23, 31, 37, 47, 50, 53, 57, 58, 59, 68, 70, 78, 80, 86, 92, 93, 96, 99], "image_byt": [78, 91], "image_data": [29, 47], "image_featur": 29, "image_fil": 78, "image_grid_thw": 29, "image_id": [57, 91], "image_nam": [61, 70], "image_output": 29, "image_pad": 29, "image_path": 92, "image_qa": 78, "image_tag": 57, "image_token": 29, "image_uri": 57, "image_url": [33, 43, 46, 78, 91, 97], "imagedataitem": 47, "imbal": [7, 16, 74], "img": 91, "imit": 99, "immedi": [11, 12, 14, 22, 23, 24, 50, 51, 52, 60], "immigr": 38, "impact": [11, 23, 51, 91, 96], "imper": 91, "impl": [22, 94, 100], "implement": [1, 8, 10, 11, 19, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 38, 41, 50, 61, 71, 74, 75, 76, 81, 87, 91, 93, 94, 96, 100], "impli": 34, "import": [0, 4, 8, 13, 14, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 37, 38, 39, 41, 42, 43, 47, 48, 49, 63, 71, 78, 89, 90, 91, 92, 94, 96, 97, 99, 100], "import_model_class": 99, "import_modul": 8, "import_new_model_class": 99, "importlib": [8, 14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "impos": 87, "imposs": 38, "impress": 41, "improv": [3, 4, 6, 7, 10, 11, 14, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 41, 42, 43, 45, 46, 48, 71, 78, 91, 93, 96, 97], "in_plac": 24, "inaccur": 51, "inc": [67, 93], "includ": [3, 6, 7, 11, 12, 14, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 30, 31, 37, 38, 41, 49, 50, 51, 54, 58, 67, 68, 71, 75, 78, 86, 89, 91, 92, 93, 97, 99], "inclus": 51, "inclusionai": [67, 90, 93], "incom": [11, 16, 22], "incompat": [1, 91], "incomplet": 24, "inconsist": [11, 28, 50], "incorpor": [14, 25, 84, 93, 97], "incorrect": [25, 76], "incorrectli": 3, "increas": [2, 3, 7, 11, 14, 16, 17, 22, 23, 25, 27, 28, 30, 31, 38, 41, 45, 71, 91, 93, 96], "increasingli": 38, "increment": [11, 13, 23, 74], "incur": [5, 76], "inde": 27, "indent": [49, 89], "independ": [6, 23, 24, 30, 94], "indetermin": 75, "index": [0, 14, 23, 25, 28, 30, 31, 37, 41, 42, 43, 48, 51, 57, 61, 62, 68, 72, 81, 84, 89, 91, 97], "indic": [1, 13, 16, 19, 27, 38, 74, 80], "individu": [51, 99], "induct": 38, "inductor": 22, "inductor_root_cach": 88, "industri": [23, 35, 38, 58, 85], "ineffici": [6, 16, 51], "inexplic": 14, "inf": [47, 50, 68, 72, 86], "infer": [2, 6, 7, 11, 14, 16, 18, 22, 29, 30, 31, 33, 39, 45, 46, 50, 52, 57, 58, 59, 60, 68, 71, 72, 75, 80, 84, 85, 93, 96, 99], "inference_mod": 74, "infiniband": [22, 80, 81, 84], "infinit": [17, 22, 50], "influenti": 41, "info": [8, 10, 14, 21, 22, 23, 25, 26, 27, 28, 29, 33, 38, 41, 42, 43, 46, 48, 61, 78, 80, 82, 94, 97], "inform": [16, 22, 23, 25, 26, 27, 28, 31, 34, 37, 38, 39, 47, 49, 51, 57, 68, 71, 78, 89, 100], "infra": [57, 71], "infrastructur": [16, 17, 23, 24, 52, 60, 85, 91], "ing": 30, "ingredi": 38, "inher": [11, 17], "inherit": [1, 28, 99], "init": [2, 14, 16, 17, 22, 23, 31, 37, 62, 63, 71, 80, 81, 82, 84, 94], "init_cuda_graph_st": 1, "init_expert_loc": [14, 21, 26, 27, 28, 29, 37, 38], "init_forward_metadata": 1, "init_forward_metadata_capture_cuda_graph": 1, "init_forward_metadata_replay_cuda_graph": 1, "init_weights_update_group": 24, "initi": [1, 2, 6, 8, 11, 14, 16, 17, 21, 22, 23, 24, 25, 37, 41, 42, 43, 47, 49, 68, 75, 76, 78, 82, 87, 91, 94], "initialdelaysecond": [80, 84], "inject": [22, 23], "inner": [8, 19], "innov": [24, 30], "input": [4, 6, 7, 8, 11, 14, 16, 21, 22, 23, 25, 28, 31, 34, 37, 47, 49, 50, 51, 52, 53, 54, 57, 59, 60, 62, 63, 68, 71, 72, 75, 86, 89, 91, 92, 93, 97, 99], "input_emb": [22, 47, 99], "input_hidden_st": 7, "input_id": [22, 28, 29, 42, 47, 99], "input_ids_embed": 42, "input_item": 23, "input_len": 50, "input_seq_len": 71, "input_text": 37, "insepar": 14, "insert": [38, 68, 87], "insid": [3, 23, 29, 51, 53, 56, 57], "inspect": [13, 23, 51], "inspir": 11, "inst": 96, "instal": [16, 22, 34, 39, 48, 49, 50, 51, 53, 54, 55, 56, 58, 66, 74, 80, 81, 84, 86, 87], "installationguid": 51, "instanc": [10, 11, 12, 14, 16, 18, 20, 22, 23, 24, 41, 47, 51, 62, 68, 71, 76, 86], "instanti": 23, "instantli": 51, "instead": [8, 11, 14, 17, 19, 21, 22, 25, 26, 27, 28, 29, 34, 37, 38, 41, 42, 43, 47, 48, 50, 52, 60, 74, 75, 78, 86, 89, 91, 99], "instinct": [59, 91], "institut": 38, "instruct": [0, 1, 3, 4, 5, 6, 10, 14, 16, 18, 22, 23, 25, 26, 27, 28, 29, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 57, 59, 60, 61, 62, 67, 68, 70, 72, 78, 80, 82, 86, 88, 91, 92, 93, 95, 96, 99, 100], "instruct_lora_4_alpha_16": 14, "instrument": 87, "int": [3, 16, 22, 23, 24, 26, 27, 47, 49], "int32": [41, 47, 49], "int32_t": 49, "int4": [18, 58, 70, 74, 93], "int4_awq": 22, "int4wo": [18, 22, 70], "int64_t": 49, "int8": [18, 30, 68], "int8_kernel": 18, "int8dq": [18, 22], "int8wo": [18, 22], "integ": [22, 26, 27, 47, 50, 89], "integr": [6, 7, 18, 22, 24, 29, 34, 49, 52, 58, 60, 74, 80, 91, 92, 93, 96, 99], "integratedtermin": 53, "intel": [1, 18, 35, 57, 58, 68, 72], "intel_amx": 22, "intel_xpu": [1, 35, 72], "intellig": [10, 36, 38, 39, 91, 93, 96, 97, 99], "intend": 12, "intens": [6, 16, 24, 78], "intention": 14, "inter": [20, 22, 50, 71], "interact": [0, 22, 24, 38, 39, 51, 91], "interconnect": 5, "interest": [38, 52, 60, 81, 85], "interfac": [7, 23, 86, 89, 91, 92, 97, 99], "interface_v1": 10, "interleav": [7, 43], "intermedi": [8, 22], "intern": [8, 23, 38, 41, 51, 53, 54, 80, 86, 89, 99], "internal_st": 37, "internlm": [67, 93, 98], "internlm2": [67, 93, 98], "internlm2forrewardmod": 98, "internlm2forrewardmodel": 89, "internvl": 5, "interpol": 22, "interpret": [21, 28, 34, 38], "interrupt": [16, 24, 29], "interv": [16, 22, 23, 52, 60, 74], "intervent": 7, "intervitensinc": 68, "intfloat": [67, 92], "intra": 17, "introduc": [6, 7, 11, 13, 14, 16, 17, 19, 22, 24, 30, 37, 52, 60, 72, 75, 80], "introduct": [38, 52, 60, 90, 99], "introductori": 99, "invalid": [8, 31, 89], "invari": [4, 22], "inventori": 23, "invest": 38, "investig": [38, 75], "invoc": 31, "invok": [8, 18, 28], "involv": [5, 11, 30, 87, 99], "io": [0, 10, 11, 22, 23, 29, 61, 79, 80, 81, 84, 99], "io_struct": [28, 47], "iommu": 59, "ip": [2, 20, 22, 34, 61, 62, 74, 78, 82, 86], "ip1": [62, 63], "ip2": [62, 63], "ipc": [33, 46, 53, 57, 59, 61, 68, 91, 95], "ipc_lock": [81, 84], "ipynb": [0, 14], "ipython": 38, "irang": 49, "ireland": [26, 27], "iron": [43, 78], "is_async": 24, "is_embed": [14, 21, 26, 27, 28, 29, 37, 38], "is_gener": 37, "is_healthi": 23, "is_matryoshka": 92, "is_multimodal_model": 99, "isl": 71, "isn": 80, "isol": [18, 23, 80], "issu": [4, 10, 11, 12, 14, 17, 18, 19, 22, 24, 30, 31, 35, 38, 52, 57, 59, 60, 61, 62, 68, 69, 72, 75, 78, 86, 87, 91, 97], "itali": [26, 27, 41, 78], "itd": 53, "item": [8, 23, 29, 37, 38, 52, 60, 91, 97], "item1": 22, "item2": 22, "item_first": 37, "item_id": 23, "items_stor": 23, "iter": [2, 17, 22, 37, 51], "iter_lin": [47, 48], "itl": 50, "its": [3, 7, 11, 14, 17, 22, 23, 25, 26, 27, 34, 37, 38, 41, 47, 51, 52, 60, 74, 76, 87, 91, 92, 93, 99], "itself": [24, 27], "j": 82, "j_master": 82, "j_node": 82, "jacket": 29, "jaeger": 87, "jamesliu1": 25, "janeiro": 27, "janu": [67, 96], "japan": [14, 25, 37, 41, 78], "japanes": [91, 93], "jason9693": [23, 89, 98], "jax": [22, 71, 85], "jax_compilation_cache_dir": 71, "jean": 43, "jenkin": 41, "jet": [93, 96], "jetpack": 70, "jetson": [57, 58], "jetvlm": 96, "jinja": [23, 28, 30, 31, 97], "jit": [7, 22, 71, 74], "jit_cach": 71, "jit_kernel": 49, "jitter": 23, "job": [23, 38, 41, 52, 60, 82], "jobs_presenting_ipod": [33, 46, 96], "johnni": 70, "joi": 14, "join": [8, 10, 28, 58, 71], "jointli": 93, "joke": 4, "journei": 38, "joy": 97, "jpeg": [50, 97], "jpg": [91, 92], "json": [4, 8, 10, 11, 12, 14, 18, 19, 21, 22, 23, 25, 28, 30, 33, 36, 37, 42, 43, 46, 48, 49, 50, 51, 52, 53, 60, 64, 78, 81, 84, 86, 87, 89, 90, 91, 92, 96, 97, 99], "json_data": 14, "json_model_override_arg": [14, 21, 26, 27, 28, 29, 37, 38], "json_output": 78, "json_schema": [26, 27, 47], "judg": 39, "judgment": 11, "jul": 26, "jule": 38, "jump": [21, 34], "jupyt": 0, "just": [11, 13, 14, 22, 25, 27, 36, 38, 49, 56, 71, 73, 74, 90, 91, 99, 100], "justmycod": 53, "k": [14, 25, 27, 37, 47, 68], "k2": [21, 23, 28, 67, 83, 93], "k8": [23, 57, 80, 84], "k_cach": [31, 49], "k_proj": [14, 22], "k_scale": 19, "kblocksiz": 49, "kconstant": 49, "kda": 93, "kdlcpu": 49, "kdlcuda": 49, "keep": [0, 5, 12, 22, 23, 24, 27, 33, 34, 41, 46, 52, 53, 60, 78, 82, 91, 96, 99], "keep_mm_feature_on_devic": [14, 21, 26, 27, 28, 29, 37, 38], "keep_paus": 24, "keepal": 23, "kei": [1, 6, 7, 8, 11, 16, 17, 19, 22, 24, 26, 27, 29, 30, 34, 37, 41, 47, 51, 59, 71, 78, 81, 84, 96, 99], "kept": 34, "kernel": [1, 3, 4, 7, 10, 11, 14, 18, 19, 21, 24, 26, 27, 28, 29, 30, 31, 37, 38, 51, 57, 59, 62, 63, 68, 69, 71, 74, 75, 85, 91], "kernel_ascend": 22, "key_stat": 100, "keyword": 99, "kfd": [56, 59, 91], "kill": 51, "kimi": [21, 22, 23, 28, 41, 58, 67, 83, 93, 96], "kimi_k2": [21, 22, 28], "kind": [14, 23, 80, 81, 84], "king": 14, "kingdom": [14, 41, 78], "kit": 70, "kk": 3, "kl": 85, "klein": 91, "knew": [14, 41], "knob": 12, "know": [27, 37, 38, 39, 41, 99], "knowledg": [26, 27, 38, 41], "known": [18, 27, 38, 58, 93], "korean": 93, "kt": 22, "kt_cpuinfer": [14, 21, 26, 27, 28, 29, 37, 38], "kt_max_deferred_experts_per_token": [14, 21, 26, 27, 28, 29, 37, 38], "kt_method": [14, 21, 26, 27, 28, 29, 37, 38], "kt_num_gpu_expert": [14, 21, 26, 27, 28, 29, 37, 38], "kt_threadpool_count": [14, 21, 26, 27, 28, 29, 37, 38], "kt_weight_path": [14, 21, 26, 27, 28, 29, 37, 38], "kubectl": [57, 80, 81, 84], "kubernet": [11, 22, 83], "kv": [1, 6, 10, 11, 12, 14, 16, 17, 22, 24, 30, 31, 35, 37, 45, 51, 58, 61, 71, 75, 93], "kv16": 19, "kv4": [1, 19], "kv8": 19, "kv_cach": [19, 24], "kv_cache_dtyp": [14, 21, 26, 27, 28, 29, 31, 37, 38], "kv_events_config": [14, 21, 26, 27, 28, 29, 37, 38], "kvcach": [10, 11, 16, 17, 22, 35, 37, 49, 50], "kwarg": 100, "l": [17, 27, 39, 47, 82, 91], "l0": 23, "l1": [11, 23], "l12": 34, "l15": 34, "l2": 11, "l27": 34, "l2a": 37, "l3": 12, "l31": 34, "l34": 34, "l38": 34, "l4": [23, 57], "l40": [30, 57], "l53": 34, "l57": 34, "l7": 23, "la": 38, "lab": [4, 47, 67, 85, 91, 94, 96], "label": [14, 21, 22, 23, 24, 26, 27, 28, 29, 37, 38, 51, 52, 56, 60, 80, 81, 84, 86, 87, 89, 97], "label1": 22, "label2": 22, "label_0": [23, 89], "label_1": [23, 89], "label_n": 23, "label_token_id": 37, "lack": [18, 50], "landmark": [25, 27, 38], "landscap": 91, "lang": 78, "languag": [5, 6, 11, 14, 16, 17, 22, 36, 38, 41, 43, 46, 48, 49, 57, 58, 68, 71, 73, 85, 100], "language_onli": [14, 21, 26, 27, 28, 29, 37, 38], "larg": [1, 2, 3, 7, 11, 13, 14, 16, 17, 19, 22, 23, 24, 27, 30, 33, 36, 38, 41, 46, 50, 51, 57, 58, 68, 71, 83, 85, 91, 92, 96, 97], "larger": [3, 11, 13, 14, 16, 17, 19, 22, 27, 29, 30, 31, 47, 68, 71, 72, 74, 91, 93, 96], "largest": [27, 38, 48, 93], "last": [8, 21, 22, 25, 49, 56, 57, 59, 61, 87, 89, 91], "last_gen_throughput": 37, "last_hidden_st": 29, "lastli": 99, "late": 34, "latenc": [3, 7, 11, 14, 16, 22, 23, 24, 30, 31, 33, 46, 50, 51, 52, 54, 58, 60, 86, 91, 92, 96, 97], "latent": [1, 22], "later": [3, 8, 13, 15, 24, 28, 56, 70, 76], "latest": [17, 23, 26, 27, 31, 34, 35, 46, 57, 61, 62, 68, 71, 79, 80, 84, 85, 86, 91, 92, 93, 95], "latter": 11, "launch": [0, 2, 3, 6, 7, 10, 15, 18, 19, 24, 26, 27, 34, 38, 44, 47, 51, 52, 53, 54, 57, 59, 60, 61, 70, 73, 74, 82, 86, 87, 88, 91, 94, 95, 99], "launch_rout": [6, 16, 23, 31, 51, 61, 62, 63, 81, 84, 87], "launch_serv": [1, 2, 3, 4, 5, 6, 7, 10, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 57, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 73, 78, 80, 81, 82, 84, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100], "launch_server_cmd": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78], "launcher": 23, "launchkernel": 49, "law": [30, 41], "layer": [1, 3, 5, 7, 8, 10, 11, 14, 17, 18, 19, 23, 25, 30, 35, 37, 52, 60, 74, 75, 81, 84, 91, 97, 99], "layer_first": [10, 11, 14, 21, 22, 26, 27, 28, 29, 37, 38], "layer_id": 99, "layerwis": 22, "layerwise_profil": 51, "layout": [5, 7, 11, 12, 22, 71], "lb": [62, 63, 87], "lccl": 94, "ld_library_path": [62, 68], "ld_preload": 68, "le": [23, 86], "lead": [3, 4, 6, 11, 14, 16, 17, 18, 24, 25, 35, 36, 38, 47, 50, 75, 85], "leader": [14, 80, 81, 84], "leadercr": 81, "leadertempl": [80, 81], "leaderworkerset": [80, 81, 84], "leaderworkertempl": [80, 81], "leaf": 11, "leak": 23, "lean": 78, "learn": [0, 1, 4, 14, 20, 22, 27, 38, 41, 58, 59, 85, 92, 93, 96, 97, 98, 99], "least": [1, 14, 17, 22, 28, 47, 78, 80], "leav": [47, 61], "led": [3, 14], "left": [14, 25, 53], "legum": 78, "len": [8, 47, 48, 50, 51, 54, 62, 68, 71, 72], "length": [3, 4, 11, 14, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 41, 42, 43, 46, 47, 48, 49, 50, 51, 62, 63, 70, 74, 78, 81, 84, 91], "less": [13, 16, 29, 50, 51, 85], "let": [8, 21, 22, 23, 24, 25, 27, 28, 37, 38, 41, 99], "letter": [26, 27, 28, 41, 43], "level": [1, 5, 10, 11, 14, 15, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 37, 41, 42, 43, 46, 47, 48, 51, 59, 74, 78, 87, 91, 93, 94], "level0": 62, "level1": 62, "leverag": [7, 11, 20, 37, 59, 85, 93, 100], "lfu": 22, "lg": 93, "lgai": [67, 93], "li": 87, "lib": [14, 21, 23, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 62, 68, 72, 78], "lib64": 68, "libfabr": 16, "libiomp5": 68, "librari": [7, 22, 23, 24, 30, 31, 57, 68, 85, 99], "libtbbmalloc": 68, "libtcmalloc": 68, "licens": 93, "lid": 80, "life": [1, 14, 29, 78], "lifecycl": 23, "lift": 34, "light": [14, 27, 38], "lighter": 23, "lightn": [31, 91], "lightweight": [5, 91], "lightx2v": 91, "like": [1, 2, 3, 4, 7, 8, 11, 12, 13, 14, 17, 18, 21, 24, 25, 27, 28, 29, 30, 33, 37, 38, 41, 45, 49, 51, 52, 60, 61, 68, 74, 78, 80, 86, 90, 91, 92, 97], "likelihood": 41, "limit": [6, 10, 11, 13, 14, 16, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 37, 38, 41, 42, 43, 46, 48, 50, 51, 70, 74, 75, 76, 78, 80, 81, 84], "limit_mm_data_per_request": [14, 21, 26, 27, 28, 29, 37, 38], "line": [7, 14, 16, 18, 22, 26, 27, 28, 33, 34, 37, 38, 46, 52, 60, 68, 72, 86, 91], "linear": [11, 18, 45, 64, 93], "linearli": 47, "ling": [67, 93], "linguist": 96, "link": [0, 16, 61, 80, 99], "link_lay": 80, "link_up": 80, "linkedin": 79, "linkup": 80, "lint": [0, 52, 60], "linux": [53, 56, 61, 68], "linux64cli": 53, "linux_aarch64": 61, "list": [4, 8, 14, 20, 21, 22, 24, 25, 28, 30, 34, 37, 39, 41, 42, 47, 48, 51, 52, 60, 74, 75, 78, 85, 87, 89, 97, 99], "list_lora": 91, "listen": [20, 22, 91], "lite": [67, 93, 96], "liter": 28, "literatur": 41, "littl": [5, 91], "liuhaotian": [92, 96], "live": [14, 23, 38, 51], "livenessprob": 84, "ll": [21, 27, 28, 41, 51, 80, 91], "llada2": 90, "llada2moemodellm": 90, "llama": [1, 14, 18, 22, 23, 25, 26, 37, 43, 47, 50, 51, 53, 57, 58, 59, 61, 67, 70, 71, 72, 73, 85, 86, 88, 92, 93, 96, 98, 100], "llama2": [25, 96], "llama3": [22, 23, 25, 28, 67, 96], "llama4": [28, 44], "llama4forconditionalgener": 29, "llama_ckpt": 99, "llama_dir": 99, "llama_wrapp": 99, "llamaattent": 99, "llamaconfig": 99, "llamaforcausallm": [14, 99], "llamaforsequenceclassif": [89, 98], "llamaforsequenceclassificationwithnormal_weight": 89, "llamamlp": 99, "llamawrapp": 99, "llava": [43, 47, 67, 92, 96], "llavavid": 96, "llguidanc": [22, 26], "llm": [4, 5, 7, 11, 16, 17, 19, 21, 23, 25, 26, 27, 28, 29, 31, 33, 35, 38, 39, 50, 57, 59, 62, 64, 67, 68, 71, 72, 76, 85, 90, 93, 94, 96, 99], "llmcompressor": 18, "llvm": 49, "lm": [22, 62, 63, 81, 84], "lm_head": [14, 18, 25, 99], "lmcach": 11, "lmdeploi": 50, "lmhead": 25, "lmm": [47, 67, 96], "lmsy": [25, 28, 34, 75, 79, 82, 85], "lmsysorg": [23, 31, 53, 56, 57, 59, 61, 79, 81, 84, 91, 95], "ln": 3, "lo": [62, 63], "load": [2, 6, 7, 8, 11, 13, 16, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 37, 38, 41, 42, 43, 47, 48, 49, 50, 51, 62, 63, 64, 68, 73, 78, 81, 85, 86, 91, 100], "load_balance_method": [14, 21, 26, 27, 28, 29, 37, 38], "load_config": 18, "load_dataset": 18, "load_decod": 91, "load_encod": 91, "load_format": [14, 21, 22, 24, 26, 27, 28, 29, 37, 38], "load_imag": [47, 78], "load_jit": 49, "load_lora_adapt": 14, "load_model": 18, "loadconfig": 18, "loaded_adapt": [14, 91], "loader": [18, 20, 24, 99], "local": [0, 14, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 37, 39, 41, 42, 43, 48, 50, 52, 53, 57, 60, 61, 62, 63, 68, 71, 78, 90, 91, 93, 94, 96, 98, 99], "local_attention_s": 22, "local_dir": 99, "local_host": 62, "local_host1": [62, 63], "local_host2": [62, 63], "local_input_imag": 91, "local_ip": [16, 31], "localattent": 91, "localhost": [2, 4, 14, 15, 21, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 71, 78, 86, 91, 96], "locat": [0, 11, 22, 23, 24, 26, 27, 28, 38, 47, 48, 49, 51, 53, 68, 81, 84], "lock": 23, "lof": 22, "log": [2, 8, 10, 13, 14, 21, 25, 26, 27, 28, 33, 37, 41, 42, 43, 46, 47, 48, 57, 68, 74, 78, 80, 84, 86, 91, 94], "log_level": [14, 21, 26, 27, 28, 29, 37, 38], "log_level_http": [14, 21, 26, 27, 28, 29, 37, 38], "log_request": [14, 21, 26, 27, 28, 29, 37, 38], "log_requests_format": [14, 21, 26, 27, 28, 29, 37, 38], "log_requests_level": [14, 21, 26, 27, 28, 29, 37, 38], "log_requests_target": [14, 21, 26, 27, 28, 29, 37, 38], "logger": [8, 22], "logic": [3, 7, 8, 17, 23, 24, 28, 41, 47, 89], "login": [57, 86], "logit": [22, 23, 30, 32, 33, 74, 99], "logit_bia": 41, "logits_processor": 99, "logitsprocessor": 99, "logitsprocessoroutput": 99, "logo": [43, 91], "logprob": [4, 22, 25, 28, 30, 41, 43, 47, 48, 75, 76, 81, 84, 97], "logprob_start_len": [47, 75], "london": [26, 27, 37, 38, 41, 76, 78], "long": [0, 3, 10, 11, 13, 14, 19, 22, 23, 24, 25, 30, 50, 51, 58, 75, 78, 93, 96], "longer": [11, 16, 17, 19, 22, 41, 52, 53, 60, 74, 76], "longest": 13, "look": [3, 8, 13, 26, 27, 29, 31, 38, 49, 50, 52, 60, 72, 73, 99], "lookout": 38, "loop": [17, 23, 24, 38, 78, 91], "lora": [47, 50, 58, 71, 85, 96], "lora0": 14, "lora0_new": 14, "lora1": [14, 91], "lora2": [14, 91], "lora3": 14, "lora_1": 91, "lora_2": 91, "lora_a": 91, "lora_b": 91, "lora_backend": [14, 21, 26, 27, 28, 29, 37, 38], "lora_eviction_polici": [14, 21, 26, 27, 28, 29, 37, 38], "lora_id": 14, "lora_nam": [14, 22, 91], "lora_nicknam": 91, "lora_path": [14, 21, 22, 26, 27, 28, 29, 37, 38, 41, 47, 50, 91], "lora_target_modul": [14, 21, 26, 27, 28, 29, 37, 38], "loraref": 14, "lorrain": 38, "lose": 16, "loss": [14, 18, 91], "lot": [27, 52, 60], "louvr": [25, 38], "love": [14, 23, 38, 89], "low": [3, 7, 11, 13, 22, 25, 27, 30, 34, 41, 47, 50, 51, 54, 58, 75, 97], "low_lat": [7, 22, 62, 63, 84], "lowconfid": [22, 90], "lower": [1, 5, 11, 13, 18, 19, 22, 23, 29, 30, 33, 41, 52, 60, 71, 74, 75, 90, 91, 99], "lowercas": 91, "lpm": [13, 22], "lru": [14, 21, 22, 26, 27, 28, 29, 37, 38], "lru_cach": [25, 99], "lsb": 51, "lsof": 86, "lspci": 80, "lssf": 68, "lt": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "lustr": 51, "lw": [31, 80, 83, 84], "lws_group_siz": [80, 81, 84], "lws_leader_address": [80, 81, 84], "lws_worker_index": [80, 81, 84], "lyon": [25, 27], "m": [1, 2, 3, 4, 5, 6, 7, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 73, 74, 78, 80, 81, 82, 84, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100], "m2": [44, 54, 93], "m3": [37, 67, 97], "ma": 28, "maas_hosted_model": 81, "machin": [1, 4, 22, 31, 38, 52, 53, 57, 59, 60, 61, 86, 88, 97, 99], "made": [14, 17], "madrid": 41, "madrid3": 78, "magic": [14, 78], "magnific": 14, "mai": [11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 28, 31, 34, 41, 50, 51, 52, 53, 54, 59, 60, 68, 75, 78, 80, 81, 84, 87, 91, 92, 95, 96, 97, 98], "main": [2, 4, 5, 17, 25, 27, 29, 33, 37, 38, 43, 46, 47, 50, 52, 60, 61, 68, 72, 78, 81, 84, 87, 90, 91, 92, 96, 99], "main_doc": [81, 84], "mainli": [11, 22, 37], "mainstream": [62, 67], "maintain": [4, 11, 17, 19, 22, 36, 52, 60, 71, 87, 91, 99], "mainten": 22, "major": [11, 25, 26, 27, 31, 38, 41, 52, 60, 80, 85, 99], "make": [0, 1, 3, 4, 12, 13, 22, 23, 24, 25, 26, 27, 28, 30, 36, 38, 41, 51, 52, 60, 61, 78, 80, 85, 89, 90, 97, 99], "make_cpp_arg": 49, "make_hook": 22, "makeshift": 29, "malform": 8, "mamba": [93, 96], "mamba_full_memory_ratio": [14, 21, 26, 27, 28, 29, 37, 38], "mamba_scheduler_strategi": [14, 21, 26, 27, 28, 29, 37, 38], "mamba_ssm_dtyp": [14, 21, 26, 27, 28, 29, 37, 38], "mamba_track_interv": [14, 21, 26, 27, 28, 29, 37, 38], "mambaradixcach": 45, "man": [14, 29, 38, 43], "manag": [2, 7, 10, 12, 14, 15, 16, 17, 18, 22, 24, 28, 38, 57, 68, 71, 78], "mani": [1, 3, 11, 13, 14, 17, 22, 23, 24, 30, 38, 41, 50, 51, 52, 60, 68, 75, 76, 88, 97, 99], "manifest": 22, "manner": [25, 47], "mantissa": 19, "manual": [0, 24, 30, 35, 51, 52, 60, 70, 87, 91, 95], "manufactur": 38, "manylinux2014_aarch64": 57, "manylinux2014_x86_64": 57, "map": [22, 23, 24, 25, 53, 86, 89], "marbl": 14, "margin": 11, "mark": [16, 22, 27, 87], "markdown": [0, 91], "marker": 22, "market": 34, "marlin": [18, 22, 74], "marri": 14, "marseil": 27, "mask": [7, 47, 74], "mask_strategi": 91, "mask_strategy_file_path": 91, "massachusett": 28, "master": [2, 12, 24], "master_address": 24, "master_node_ip": 17, "master_port": 24, "master_server_address": 12, "match": [1, 3, 8, 13, 22, 23, 24, 26, 27, 28, 31, 35, 37, 39, 47, 49, 54, 57, 71, 74, 86, 91, 99], "matched_stop": [25, 28, 30, 41, 43, 48, 81, 84], "matchlabel": [23, 81], "materi": [38, 79], "math": [50, 67, 78, 93, 98], "mathemat": 75, "mathematician": 38, "matrix": [7, 30, 58, 74], "matryoshka_dimens": 92, "matter": [19, 91], "maturin": 23, "maverick": 35, "max": [3, 7, 14, 16, 17, 22, 23, 25, 30, 31, 33, 37, 45, 46, 50, 54, 61, 62, 63, 68, 71, 74, 75, 80, 81, 84, 88, 91, 96], "max_concurr": [50, 71], "max_connect": 23, "max_content_len": 3, "max_delay_pass": 22, "max_execution_time_m": 23, "max_export_batch_s": 74, "max_fram": 96, "max_gen_tok": 35, "max_len": 3, "max_loaded_lora": [14, 21, 26, 27, 28, 29, 37, 38], "max_lora_chunk_s": [14, 21, 26, 27, 28, 29, 37, 38], "max_lora_rank": [14, 21, 26, 27, 28, 29, 37, 38], "max_loras_per_batch": [14, 21, 26, 27, 28, 29, 37, 38], "max_mamba_cache_s": [14, 21, 26, 27, 28, 29, 37, 38], "max_memory_pag": 23, "max_model_len": 37, "max_new_token": [4, 13, 14, 18, 21, 26, 27, 28, 47, 48, 63, 90], "max_pixel": 96, "max_position_embed": 25, "max_prefill_token": [13, 14, 21, 26, 27, 28, 29, 37, 38, 80], "max_queued_request": [14, 21, 26, 27, 28, 29, 37, 38], "max_req_input_len": 37, "max_running_request": [13, 14, 21, 26, 27, 28, 29, 37, 38, 80, 90], "max_stack_s": 23, "max_token": [25, 26, 27, 28, 30, 32, 33, 41, 43, 46, 47, 48, 54, 78, 81, 84, 96], "max_total_num_token": [13, 14, 37, 80], "max_total_token": [14, 21, 26, 27, 28, 29, 37, 38], "maxim": [1, 7, 11, 13, 14, 23, 24, 25, 71], "maximum": [1, 3, 13, 14, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 33, 37, 38, 41, 42, 43, 46, 47, 48, 54, 68, 71, 74, 75, 78, 91, 97], "maxium": 85, "maxsurg": 81, "maxunavail": 81, "mayb": [25, 27], "mb": 74, "mc": 91, "mc_force_mnnvl": 16, "mc_te_metr": [81, 84], "mcdse": 58, "mcp": 34, "md": [0, 31, 33, 52, 60, 99], "me": [4, 23, 25, 26, 27, 37, 38, 39, 41, 78], "mean": [7, 11, 12, 13, 16, 17, 22, 23, 26, 27, 28, 31, 50, 59, 68, 74, 91, 96, 97, 100], "meaning": 89, "measur": [38, 47, 50, 54, 71], "mechan": [11, 17, 18, 24, 30, 31, 92, 98], "medatada": 1, "median": [14, 50], "mediev": 38, "medium": [34, 54, 80, 81, 84, 91], "meet": [11, 14, 22, 38, 79, 99], "megatron": [85, 93], "meituan": 68, "melanoleuca": [37, 97], "mellanox": 80, "mem": [10, 11, 14, 16, 17, 22, 25, 30, 31, 32, 33, 35, 36, 37, 46, 51, 62, 63, 65, 70, 71, 74, 75, 80, 81, 82, 84], "mem_cach": 12, "mem_fraction_stat": [13, 14, 21, 26, 27, 28, 29, 37, 38], "member": [14, 81, 99], "memfabr": [16, 63], "memfabric_hybrid": 16, "memori": [1, 3, 6, 7, 11, 12, 14, 16, 17, 25, 30, 33, 35, 37, 45, 46, 51, 68, 70, 80, 81, 84, 91, 96], "memory_usag": 37, "mention": 27, "mere": [14, 20], "merg": [23, 30, 37, 50, 51, 61, 96], "merge_lora_weight": 91, "merge_profil": 51, "merged_output": 38, "merger": 3, "messag": [8, 12, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 36, 37, 39, 41, 43, 46, 47, 48, 50, 81, 84, 89, 96], "messages_requir": 28, "messages_specif": 28, "met": [12, 14], "meta": [1, 2, 4, 14, 16, 18, 22, 23, 25, 26, 28, 29, 35, 47, 50, 51, 53, 57, 59, 61, 67, 68, 70, 72, 73, 82, 86, 88, 93, 96, 99, 100], "meta_info": [26, 27, 37, 48, 97], "metadata": [1, 2, 8, 10, 12, 17, 22, 23, 25, 28, 41, 43, 48, 51, 74, 80, 81, 84, 96], "metal": 68, "method": [2, 7, 10, 17, 22, 23, 24, 25, 30, 31, 38, 39, 41, 47, 49, 51, 59, 62, 63, 64, 69, 77, 85, 96, 99], "methodologi": [20, 93], "metric": [10, 12, 22, 31, 33, 46, 54, 58, 63, 74, 91], "metropolitan": 27, "mha": [11, 19, 31], "mha_one_shot": 31, "mi300": [31, 58], "mi300x": [30, 59, 91], "mi30x": [31, 91], "mi325x": 91, "mi350": 31, "mi355": [31, 58], "mi355x": 30, "mi35x": 31, "micro": [7, 17, 22], "microsc": 19, "microservic": 23, "microsoft": [53, 67, 93, 96], "mid": [25, 34], "might": [14, 15, 18, 22, 27, 37, 47, 53, 57, 72, 74, 75, 86], "migrat": [27, 89], "mild": [41, 97], "mile": [24, 58, 85], "millard": 76, "million": [27, 38], "mimo": [25, 67, 93, 96], "min": [0, 11, 22, 34, 47, 52, 60], "min_new_token": 47, "min_p": 47, "mind": [0, 52, 60], "mindspor": 58, "miner": 78, "mini": [62, 63, 87, 90, 93, 96], "minicpm": [67, 93, 96], "minicpm3": [67, 93], "minim": [7, 8, 11, 17, 19, 25, 52, 60, 71, 91, 96], "minimax": [23, 54, 58, 93], "minimaxai": 36, "minimum": [18, 22, 23, 30, 31, 52, 60, 91], "minist": 27, "ministri": 78, "minor": [14, 22, 52, 60], "minut": [13, 14, 15, 16, 20, 23, 30, 37, 52, 60, 78], "mirror": 23, "misalign": 17, "misconfigur": 8, "mislead": 76, "mismatch": [24, 37, 94], "miss": [8, 37, 50, 73, 89], "misti": 14, "mistral": [22, 23, 28, 58, 67, 92, 93, 96], "mistralai": [28, 67, 93, 96], "mitig": [11, 14, 17, 24, 35], "mix": [1, 7, 18, 22, 27, 29, 71, 78], "mix_ip": 62, "mixtral": 93, "mixtur": [7, 30, 68, 90, 93], "ml": [57, 80, 91], "mla": [11, 19, 22, 71, 93], "mlc": 26, "mllm": [22, 99], "mlp": [3, 8, 18, 22, 74, 96], "mlx5_0": [10, 22, 81, 84], "mlx5_1": [22, 84], "mlx5_2": 84, "mlx5_3": 84, "mlx5_4": 84, "mlx5_5": [81, 84], "mlx5_6": [81, 84], "mlx5_7": 84, "mlx5_bond_0": [31, 80, 81], "mlx5_bond_1": [31, 80, 81], "mlx5_bond_2": [31, 80, 81], "mlx5_bond_3": [31, 80, 81], "mlx5_roce0": 16, "mm": [1, 5, 22, 25, 33, 46, 61, 65, 91, 96], "mm_attention_backend": [14, 21, 26, 27, 28, 29, 37, 38], "mm_enable_dp_encod": [14, 21, 26, 27, 28, 29, 37, 38], "mm_fp4": 74, "mm_item": 29, "mm_max_concurrent_cal": [14, 21, 26, 27, 28, 29, 37, 38], "mm_per_request_timeout": [14, 21, 26, 27, 28, 29, 37, 38], "mm_process_config": [14, 21, 26, 27, 28, 29, 37, 38], "mmap": 22, "mmlu": [35, 54, 99], "mmlu_pro": 35, "mmmu": [50, 54, 99], "mnt": 62, "mobil": [93, 96], "mocked_fake_id_for_offline_gener": 91, "mod_part": 8, "modal": [33, 35, 38, 46, 50, 58, 74, 92, 96], "mode": [1, 2, 4, 6, 7, 8, 10, 17, 21, 22, 24, 31, 35, 37, 38, 41, 50, 53, 54, 61, 62, 68, 70, 74, 75, 80, 81, 84, 88], "model": [0, 1, 2, 6, 7, 10, 11, 13, 14, 16, 17, 19, 20, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 43, 45, 46, 47, 48, 51, 52, 53, 56, 57, 59, 60, 63, 64, 65, 66, 70, 73, 76, 78, 80, 81, 82, 84, 85, 86, 88, 100], "model_arch_name_to_cl": 99, "model_arg": 35, "model_checksum": [14, 21, 26, 27, 28, 29, 37, 38], "model_class": 99, "model_config": [18, 25, 37, 42, 99], "model_dump_json": 26, "model_executor": 99, "model_id": [18, 23], "model_id_or_path": [68, 72], "model_impl": [14, 21, 26, 27, 28, 29, 37, 38, 94], "model_info": [14, 37, 78], "model_json_schema": [26, 27], "model_load": [18, 99], "model_loader_extra_config": [14, 21, 26, 27, 28, 29, 37, 38], "model_nam": [18, 21, 28, 31, 37, 86, 89, 99], "model_name_tool_choic": 28, "model_path": [10, 14, 18, 21, 24, 26, 27, 28, 29, 37, 38, 62, 63, 71, 82, 90, 91, 94, 99], "model_path_or_id": 91, "model_typ": 37, "model_valid": 26, "model_validate_json": 26, "modelconfig": 18, "modelcontextprotocol": 23, "modelopt": [7, 19, 22], "modelopt_checkpoint_restore_path": [14, 18, 21, 26, 27, 28, 29, 37, 38], "modelopt_checkpoint_save_path": [14, 18, 21, 26, 27, 28, 29, 37, 38], "modelopt_export_path": [14, 18, 21, 26, 27, 28, 29, 37, 38], "modelopt_fp4": [1, 18, 22, 31], "modelopt_fp8": [18, 22], "modelopt_qu": [14, 21, 26, 27, 28, 29, 37, 38], "modelopt_quantize_and_export": 18, "modelregistri": 99, "modelrunn": [8, 99], "modelscop": [50, 58, 67, 74], "modelslim": [22, 62, 63, 64], "moder": [41, 78, 98], "modern": [6, 11, 85], "modif": [23, 52, 60, 80], "modifi": [3, 7, 8, 12, 18, 23, 24, 41, 51, 52, 53, 57, 60, 61, 80, 81, 86, 91, 99], "modul": [7, 8, 10, 11, 14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 49, 51, 53, 78, 91, 99, 100], "modular": [7, 85, 91], "module_cache_s": 23, "module_nam": 8, "module_path": [10, 11, 22], "module_typ": [8, 23], "module_uuid": 23, "moe": [1, 16, 18, 24, 30, 31, 36, 47, 62, 63, 64, 67, 68, 71, 74, 81, 84, 85, 90, 93, 94, 96], "moe_a2a_backend": [14, 21, 26, 27, 28, 29, 31, 37, 38], "moe_dense_tp_s": [14, 21, 26, 27, 28, 29, 31, 37, 38], "moe_runn": 7, "moe_runner_backend": [14, 21, 26, 27, 28, 29, 37, 38], "moe_wna16": 22, "moerunn": 7, "moerunnercor": 7, "moment": [29, 97], "momentari": 29, "monitor": [2, 24, 84, 86, 87], "mont": 53, "mood": [78, 91], "mooncak": [6, 7, 11, 12, 14, 21, 22, 26, 27, 28, 29, 37, 38, 50, 61], "mooncake_devic": 10, "mooncake_global_segment_s": 10, "mooncake_ib_devic": [14, 21, 26, 27, 28, 29, 37, 38], "mooncake_mast": 10, "mooncake_protocol": 10, "mooncake_te_meta_data_serv": 10, "moonshot": 93, "moonshotai": [28, 93, 96], "more": [2, 3, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 41, 43, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 60, 68, 72, 74, 75, 78, 80, 87, 90, 91, 92, 94, 96, 97, 99, 100], "morgan": 34, "mortal": 14, "moscow": 38, "most": [0, 1, 5, 11, 13, 14, 27, 28, 30, 34, 41, 51, 52, 58, 60, 68, 73, 78, 80, 91, 99, 100], "mostli": 75, "motiv": 78, "motlei": 34, "mount": [53, 56], "mountain": 91, "mountpath": [80, 81, 84], "move": [10, 11, 17, 24, 74, 96], "movement": [11, 14], "mp4": [33, 46, 91, 96], "mrl": 92, "ms_enable_lccl": 94, "mscclpp": 22, "msg": 25, "mt": 25, "mt43244": 80, "mtp": [7, 25, 30, 31, 74], "much": [0, 11, 13, 17, 27, 52, 60, 99], "muggl": 78, "mul": 74, "multi": [1, 10, 14, 17, 24, 29, 33, 35, 38, 46, 57, 58, 72, 74, 80, 91, 94, 96, 99], "multi_item_scoring_delimit": [14, 21, 26, 27, 28, 29, 37, 38], "multi_modal_item": 29, "multi_modal_projector": 29, "multi_node_deploy": 31, "multi_turn_qa": 78, "multifacet": 38, "multiformatpars": 28, "multilingu": [92, 93, 98], "multimod": [1, 3, 6, 22, 29, 33, 35, 43, 46, 58, 65, 78, 93], "multimodal_gen": 91, "multimodal_language_model": 99, "multimodal_processor": 99, "multimodaldataitem": 74, "multipart": 91, "multipl": [1, 2, 5, 6, 7, 11, 16, 17, 22, 23, 25, 28, 30, 31, 34, 41, 47, 50, 51, 52, 60, 71, 74, 78, 82, 87, 91, 93, 94, 96, 99], "multipli": [17, 23], "multiprocessingseri": 24, "mundan": [14, 29], "municip": 27, "muscl": 78, "museum": [25, 27, 38], "music": 38, "must": [1, 6, 8, 11, 12, 14, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 29, 31, 39, 47, 49, 51, 52, 60, 80, 87, 91, 99], "mutual": [23, 51, 91], "mv": [59, 61, 69], "mvbench": 54, "mxfp4": [7, 18, 19, 22, 30], "my": [2, 22, 27, 38, 52, 60, 94, 99], "my_checkpoint": 18, "my_middlewar": 23, "my_model": 73, "my_model_templ": 73, "my_packag": 22, "my_project": 8, "myattent": 100, "myhuaweicloud": 61, "mymodel": 100, "mystic": 14, "n": [1, 4, 11, 14, 21, 22, 23, 25, 26, 27, 28, 31, 37, 38, 39, 41, 47, 48, 49, 50, 68, 72, 78, 81, 82, 84, 91, 92, 97], "n1": [25, 41, 48], "n10": 41, "n2": [25, 41, 48], "n3": [25, 41, 48], "n4": 41, "n5": 41, "n6": 41, "n7": 41, "n8": 41, "n9": 41, "na": [61, 62], "naltern": 27, "name": [0, 2, 10, 11, 14, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 68, 71, 72, 73, 76, 78, 80, 81, 84, 86, 87, 89, 91, 94, 99], "name1": 50, "name2": 50, "name_non_stream": 28, "name_to_modul": 8, "named_modul": [8, 22], "named_tensor": 24, "namespac": [23, 49, 84, 91], "nan": [22, 37], "nano": [93, 96], "nanoth": 27, "narrow": 14, "nation": [25, 38], "nativ": [1, 7, 11, 14, 23, 24, 34, 47, 50, 58, 71, 80, 85, 91, 93, 96], "natur": [6, 11, 14, 24, 38, 41, 52, 60], "naur": 28, "navig": 86, "navit": 96, "nbstripout": 0, "nc": 82, "ncapit": 25, "nccl": [14, 21, 22, 24, 26, 27, 28, 29, 30, 37, 38, 74, 75, 80, 81, 82, 84], "nccl_debug": 80, "nccl_ib_gid_index": [53, 59, 80, 84], "nccl_ib_hca": [81, 84], "nccl_ib_qps_per_connect": [81, 84], "nccl_ib_sl": [81, 84], "nccl_ib_split_data_on_qp": [81, 84], "nccl_ib_tc": [81, 84], "nccl_ib_timeout": 84, "nccl_init_addr": 82, "nccl_min_nchannel": [81, 84], "nccl_net_plugin": [81, 84], "nccl_port": [14, 21, 26, 27, 28, 29, 37, 38], "nccl_socket_ifnam": [80, 84], "ncontent": 27, "ndescrib": 47, "ndetoken": 37, "ndr": 80, "ndv5": 59, "nearest": 17, "nearli": 59, "necessari": [11, 27, 57, 60, 75, 78, 80, 99], "necessarili": [27, 91], "necessit": 17, "need": [1, 2, 3, 4, 7, 10, 11, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 35, 36, 37, 38, 39, 41, 49, 50, 51, 52, 53, 56, 59, 60, 61, 64, 68, 71, 73, 75, 78, 80, 81, 84, 85, 86, 87, 91, 92, 94, 95, 96, 99, 100], "neg": [41, 47, 74, 91], "negat": 19, "neighbor": [14, 27], "nemo": [28, 31, 93], "nemo_skills_aime25_": 31, "nemo_skills_disable_uncommitted_changes_check": 31, "nemotron": [93, 96], "nest": 87, "nest_asyncio": [29, 38], "netdev": 80, "network": [2, 23, 37, 38, 53, 59, 61, 68, 70, 75, 80, 81, 84, 86, 97], "networkconfig": 81, "neural": [37, 97], "neuralmag": 18, "neutral": [38, 99], "never": 14, "new": [0, 3, 10, 11, 13, 14, 20, 22, 23, 24, 26, 27, 29, 34, 37, 38, 41, 47, 52, 55, 56, 58, 60, 68, 71, 74, 80, 81, 87, 89, 93], "new2": 91, "new_token_ratio": 13, "new_york": [26, 27], "newer": [57, 68], "newest": 31, "newli": [11, 31, 99], "newmodeldetector": 28, "next": [11, 17, 21, 24, 25, 27, 28, 38, 44, 47, 49, 67, 87, 91, 93, 96, 97, 99], "next_token_logit": 99, "nextn": [22, 45, 62, 63, 74], "nf": 51, "nfinal": 27, "nfirst": 27, "ngener": [26, 27, 38], "nhmm": 27, "nhttp": 37, "ni": 27, "nic": [11, 80], "nicknam": 91, "night": 14, "nightli": [57, 61, 91], "nimag": 29, "ninth": 41, "nixl": [11, 12, 22], "nlp": [37, 42, 67, 92, 93], "nn": [8, 80, 100], "nnal": [61, 62, 63], "nnext": 27, "nnode": [2, 14, 16, 17, 21, 22, 26, 27, 28, 29, 31, 37, 38, 62, 63, 71, 80, 81, 82, 84, 94], "nnow": 27, "no_answ": 31, "no_buff": [14, 21, 22, 26, 27, 28, 29, 37, 38, 45], "no_grad": 99, "no_proxi": 23, "no_stop_trim": [28, 47], "node": [10, 11, 17, 20, 23, 24, 25, 31, 37, 57, 58, 62, 63, 74, 80, 81, 84, 87, 91, 94], "node0_ip": 71, "node1": 80, "node_rank": [14, 21, 26, 27, 28, 29, 37, 38, 62, 63], "nodeport": [81, 84], "nodeselector": [81, 84], "nohealthywork": 23, "nois": [4, 23, 91], "nokai": 25, "non": [1, 8, 17, 22, 23, 24, 39, 41, 49, 50, 52, 60, 74, 78, 89, 90, 99], "nondeterminist": 75, "none": [7, 8, 14, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 47, 48, 63, 74, 81, 84, 91, 99], "norm": 22, "normal": [1, 7, 21, 22, 23, 28, 37, 62, 63, 71, 84, 87, 91], "normal_text": [23, 28], "normalci": 29, "northern": 38, "notabl": 68, "note": [10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 35, 37, 38, 39, 41, 42, 43, 48, 49, 52, 53, 56, 59, 60, 68, 71, 72, 73, 74, 78, 80, 81, 82, 84, 87, 89, 94, 95, 97, 99], "notebook": [0, 14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78], "noth": 22, "notic": [17, 61, 75, 80, 81], "notr": [25, 38], "nousresearch": 59, "novel": [20, 41], "now": [1, 14, 22, 25, 27, 34, 37, 41, 49, 51, 53, 59, 78, 89, 99], "nowadai": [52, 60], "npcach": 22, "nproc": 2, "nprompt": [38, 99], "npu": [1, 7, 22, 31, 57, 58, 63, 65, 94], "nput": 27, "npx": 23, "nrememb": 37, "nround": 37, "nsa": [1, 22, 31, 62], "nsa_decode_backend": [14, 21, 26, 27, 28, 29, 37, 38], "nsa_prefill_backend": [14, 21, 26, 27, 28, 29, 37, 38], "nsa_prefill_cp_mod": [14, 21, 26, 27, 28, 29, 37, 38], "nsight": 22, "nsy": [51, 53, 91], "ntask": 82, "nthe": [25, 27], "ntoken": 37, "null": [14, 21, 22, 26, 27, 28, 29, 30, 37, 38, 42, 43, 57, 81, 84, 89, 91], "num": [22, 25, 30, 31, 32, 35, 45, 50, 51, 52, 53, 54, 59, 60, 62, 63, 65, 68, 71, 72, 81, 84, 86, 91], "num_block": 49, "num_choic": 25, "num_class": [23, 89], "num_concurr": 35, "num_continuous_decode_step": [14, 21, 26, 27, 28, 29, 37, 38], "num_el": 49, "num_entri": 31, "num_fewshot": 35, "num_fram": [91, 96], "num_gpu": 91, "num_hidden_lay": 51, "num_inference_step": 91, "num_key_value_head": 51, "num_lay": [41, 47], "num_lora_layers_with_weight": 91, "num_paused_request": [24, 37], "num_prompt": 71, "num_prompts_per_concurr": 71, "num_quest": 63, "num_queue_req": 86, "num_reserved_decode_token": [14, 21, 26, 27, 28, 29, 37, 38], "num_running_req": 86, "num_shot": 63, "num_stag": 25, "num_step": 51, "num_thread": 49, "num_token": [41, 47], "num_token_to_fetch": 11, "num_triton_choic": 25, "num_used_token": 86, "num_warp": 25, "numa": [22, 68], "numa_balanc": [59, 61, 62, 63], "numa_nod": [14, 21, 26, 27, 28, 29, 37, 38], "number": [1, 2, 3, 11, 13, 14, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 41, 42, 43, 46, 47, 48, 50, 51, 52, 54, 60, 68, 71, 74, 78, 86, 87, 89, 90, 91, 97], "numer": [30, 37, 75], "numexpr": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "numexpr_max_thread": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "numpi": [22, 50], "nurgaliyev": 70, "nut": 78, "nutanix": 14, "nutrient": 78, "nv": 70, "nvda": 34, "nvfp4": [7, 18, 19, 22, 30, 74], "nvfp4_awq": 22, "nvidia": [1, 7, 19, 22, 30, 31, 34, 35, 51, 52, 56, 57, 58, 60, 74, 80, 81, 84, 91, 93, 96], "nvidia_h100_80gb_hbm3": 37, "nvidia_h100_80gb_hbm3_down": 37, "nvila": 96, "nvl": 22, "nvl72": [16, 30], "nvme": 53, "nvpmodel": 70, "nvrtc": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 74, 78], "nvshmem_bootstrap_uid_sock_ifnam": 84, "nvshmem_disable_p2p": 84, "nvshmem_enable_nic_pe_map": 81, "nvshmem_hca_list": 81, "nvshmem_hca_pe_map": 81, "nvshmem_ib_gid_index": [81, 84], "nvshmem_ib_sl": 84, "nvshmem_ib_traffic_class": [81, 84], "nvtx": 22, "nwait": 27, "nwould": 37, "ny": [26, 27, 28], "nyc": 23, "nyou": 47, "nyour": 37, "n\u00fa\u00f1ez": 70, "n\u4f60\u597d\u5440": [81, 84], "n\u55ef": [81, 84], "n\u6211\u7684\u4efb\u52a1\u5c31\u662f\u966a\u4f60\u804a\u5929": [81, 84], "n\u7528\u6237\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u80cc\u666f\u4fe1\u606f": [81, 84], "n\u7528\u6ce2\u6d6a\u7ebf\u7ed3\u5c3e\u53ef\u4ee5\u8f6f\u5316\u8bed\u6c14": [81, 84], "n\u8003\u8651\u5230\u4e2d\u6587\u7528\u6237": [81, 84], "o": [10, 11, 16, 23, 24, 25, 26, 27, 42, 47, 51, 53, 56, 61, 67, 82, 91, 96], "o_proj": [14, 22], "oai": [50, 62], "oai_serv": 23, "oak": 78, "ob": 61, "object": [5, 8, 11, 22, 23, 25, 26, 27, 28, 30, 41, 42, 43, 47, 48, 49, 50, 81, 84, 89, 91, 97], "observ": [12, 19, 25, 58, 87], "obstacl": [3, 14], "obtain": [11, 17, 25, 28, 37, 76, 80, 87], "occasion": [13, 97], "occup": [38, 51, 78], "occur": [13, 14, 37, 47, 75], "ocp": 19, "ocr": 96, "odd": 50, "odel": 21, "ofassistantgener": 26, "ofed_info": 80, "off": [7, 14, 23, 25, 30, 45, 59, 74, 90, 91, 92, 94], "offer": [7, 17, 27, 47, 78, 93, 96, 97, 98], "offic": 27, "offici": [22, 23, 27, 30, 31, 35, 52, 53, 59, 60, 68, 73, 81, 94], "offlin": [16, 19, 43, 51, 54, 58, 61, 64], "offload": [10, 11, 24, 91], "offload_group_s": [14, 21, 26, 27, 28, 29, 37, 38], "offload_mod": [14, 21, 26, 27, 28, 29, 37, 38], "offload_num_in_group": [14, 21, 26, 27, 28, 29, 37, 38], "offload_prefetch_step": [14, 21, 26, 27, 28, 29, 37, 38], "offset": 24, "often": [7, 11, 14, 23, 24, 27, 30, 37, 38, 74, 98], "ok": [14, 23, 37, 80], "okai": [13, 27, 41], "old": [38, 41], "older": 80, "ollama": 58, "ollama_host": 39, "olmo": [67, 93], "om": 57, "omit": [24, 41, 49, 76, 92], "omni": 96, "onboard": 23, "onc": [1, 8, 11, 14, 24, 28, 37, 41, 42, 43, 48, 52, 53, 60, 61, 68, 76, 80, 88, 91], "oncal": [52, 60], "ondemand": 61, "one": [1, 8, 11, 14, 16, 17, 21, 22, 23, 26, 27, 28, 29, 31, 34, 35, 37, 38, 41, 43, 47, 48, 50, 51, 52, 57, 59, 60, 61, 68, 69, 74, 75, 76, 86, 91, 92, 100], "oneshot": 18, "onevis": [43, 47, 67, 96], "ongo": [16, 24, 35, 51], "onli": [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 39, 47, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 70, 72, 74, 75, 76, 78, 80, 91, 93, 94, 96, 99], "onlin": [30, 50, 51, 82], "only_run": 99, "onrequest": 23, "onrespons": 23, "onto": 57, "oom": [13, 35, 75, 96], "op": [5, 11, 22, 61], "op_api": 62, "open": [0, 19, 23, 25, 29, 35, 51, 52, 53, 54, 57, 58, 59, 60, 62, 68, 69, 85, 86, 91, 93, 96], "openai": [22, 25, 30, 32, 34, 36, 37, 47, 50, 58, 67, 68, 71, 72, 73, 76, 78, 89, 92, 93, 96], "openai_api_complet": 14, "openai_api_kei": [50, 56], "openapi": 48, "openbmb": [67, 93, 96], "openssl": 23, "opentelemetri": [22, 87], "oper": [1, 3, 4, 7, 10, 11, 12, 16, 19, 22, 23, 24, 25, 30, 31, 37, 38, 51, 52, 57, 60, 61, 63, 68, 71, 74, 81, 84, 92], "operation": 12, "operation_duration_second": 23, "operations_tot": 23, "opp": [61, 62], "opportun": [38, 71], "oppos": 14, "opt": [18, 53, 57, 59, 68], "optic": 96, "optim": [1, 2, 4, 7, 9, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 29, 35, 37, 45, 52, 57, 59, 60, 81, 85, 93, 94, 97], "option": [3, 10, 14, 16, 18, 21, 23, 24, 25, 27, 30, 34, 41, 49, 51, 57, 71, 76, 78, 86, 87, 89, 90, 99], "oraclecloud": 23, "orang": 43, "orchestr": [7, 23, 91], "order": [3, 4, 14, 22, 23, 37, 78, 91, 96, 97], "org": [28, 32, 33, 49, 57, 61, 68, 72, 75, 82, 85, 88, 91, 93, 96], "organ": [10, 23, 38], "organiz": 23, "orient": 11, "orig_logit": 99, "origin": [1, 14, 17, 18, 21, 25, 26, 27, 28, 30, 31, 37, 41, 42, 43, 48, 78, 89, 91, 97], "orin": 58, "orion": 93, "orionstarai": 93, "oserror": 57, "osl": 71, "oss": [19, 21, 22, 28, 41, 58, 67, 93], "ostri": 91, "otel_exporter_otlp_traces_protocol": 87, "otel_trac": 87, "other": [0, 1, 2, 5, 12, 14, 15, 17, 18, 22, 25, 27, 28, 29, 30, 31, 35, 37, 38, 41, 43, 45, 52, 54, 57, 59, 60, 61, 71, 74, 75, 76, 78, 82, 86, 87, 88, 90, 93, 96, 99], "otherwis": [1, 3, 12, 22, 31, 50, 51, 87, 91, 92, 100], "otlp": [22, 23, 87], "otlp_traces_endpoint": [14, 21, 26, 27, 28, 29, 37, 38, 87], "ottawa": [37, 41, 48, 78], "our": [0, 14, 18, 25, 31, 34, 38, 47, 52, 60, 61, 75, 81, 85, 89], "out": [14, 21, 22, 23, 25, 27, 28, 29, 33, 35, 37, 38, 41, 46, 51, 52, 57, 60, 68, 78, 82, 85, 95], "outcomes_tot": 23, "outdat": 68, "outer": [8, 19, 27], "outer_linear_hook": 8, "outgo": 38, "outlin": [22, 26, 28, 30, 47, 74, 91], "output": [0, 4, 5, 7, 8, 11, 14, 18, 21, 22, 23, 25, 30, 31, 34, 37, 38, 42, 43, 48, 49, 52, 53, 54, 58, 59, 60, 62, 68, 71, 72, 74, 75, 78, 80, 81, 82, 86, 90, 93, 94, 96, 98, 99], "output_dir": [18, 31, 51], "output_hidden_st": 29, "output_id": [26, 27, 37, 48], "output_len": 50, "output_path": 91, "output_seq_len": 71, "output_text": 34, "outweigh": 22, "ov": [47, 67, 96], "over": [0, 7, 8, 11, 14, 16, 18, 22, 23, 27, 31, 38, 51, 58, 74, 91], "overal": [7, 12, 29, 30, 71, 78], "overcom": 14, "overgrown": 14, "overhead": [3, 5, 11, 13, 14, 19, 22, 23, 24, 25, 29, 31, 38, 51, 52, 58, 60, 74, 91, 96], "overlap": [2, 11, 12, 17, 22, 25, 30, 31, 32, 34, 38, 45, 51, 63, 68, 71, 72, 74, 76, 81], "overload": 23, "overrid": [10, 11, 23, 25, 35, 47, 50, 51, 52, 57, 60, 73, 91, 92, 96], "overview": [11, 26, 30, 42, 52, 60], "overweight": 34, "overwrit": [74, 91], "ovis_garden": 91, "own": [22, 23, 25, 31, 52, 57, 60, 61, 68, 72, 82], "p": [22, 25, 31, 34, 47, 57, 59, 68, 81, 86, 91, 95], "p2p": [2, 17, 22, 74], "p2pwork": 17, "p50": 23, "p95": [23, 50], "p99": [23, 50], "p_": 25, "p_ip": [62, 63], "packag": [2, 8, 14, 21, 25, 26, 27, 28, 29, 34, 37, 41, 42, 43, 48, 52, 57, 59, 60, 61, 68, 69, 71, 72, 74, 78, 81, 87, 91, 94], "pad": [1, 22, 74, 99], "pad_input_id": 99, "page": [1, 10, 11, 14, 17, 22, 31, 34, 42, 45, 57, 58, 71, 72, 74, 75, 81, 84, 91, 100], "page_first": [10, 11, 12, 22], "page_first_direct": [10, 11, 12, 22], "page_first_kv_split": 22, "page_head": [12, 22], "page_s": [1, 11, 14, 21, 22, 26, 27, 28, 29, 37, 38], "pai": 80, "pain": 24, "pair": [10, 11, 19, 27, 43, 50], "pairwis": 37, "palac": [25, 27], "panda": [37, 97], "pandoc": 0, "pantheon": 41, "paper": [1, 14, 25], "paragraph": 78, "parallel": [0, 5, 11, 13, 14, 16, 19, 25, 28, 29, 33, 46, 51, 53, 58, 62, 63, 68, 71, 74, 80, 81, 83, 84, 90, 91, 94, 98], "param": [14, 19, 22, 28, 37, 50, 93], "param1": 28, "param2": 28, "param_dict": 47, "paramet": [2, 3, 13, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 36, 37, 48, 49, 51, 52, 53, 54, 57, 58, 60, 61, 68, 71, 72, 74, 75, 81, 82, 84, 93, 96, 99], "parameter": 8, "pari": [14, 25, 26, 27, 28, 30, 32, 37, 38, 41, 47, 48, 76, 78, 97], "paris2": 78, "park": [29, 43], "pars": [12, 18, 21, 28, 34, 41, 57, 64, 74, 89, 91], "parse_function_cal": 28, "parse_non_stream": [21, 28], "parse_streaming_incr": 28, "parse_url": [21, 28], "parser": [22, 27, 29, 30, 32, 36, 41, 57, 58, 93], "part": [1, 3, 8, 11, 27, 30, 38, 43, 75, 78, 81, 97], "partern": 85, "parti": 38, "partial": [12, 22, 23, 24, 28, 85], "particip": 2, "particular": [27, 28], "particularli": [4, 7, 19, 27, 51], "partit": [17, 22, 24, 30, 74, 82], "partli": 28, "partnership": 85, "pass": [0, 7, 8, 11, 14, 17, 22, 24, 25, 29, 31, 39, 41, 49, 50, 52, 54, 60, 74, 91, 96, 99], "passag": 97, "passion": 38, "password": [23, 57, 86], "past": [68, 91], "patch": [3, 57, 87], "patch14": [67, 92], "patchleadertempl": 84, "patchworkertempl": 84, "path": [1, 2, 4, 5, 6, 7, 8, 10, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 54, 57, 59, 60, 61, 62, 63, 65, 68, 70, 71, 73, 74, 76, 78, 80, 81, 82, 84, 86, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100], "patronu": 78, "pattern": [3, 8, 11, 16, 22, 24, 26, 27, 47, 51, 52, 60, 80, 91], "pattern1": 8, "pattern2": 8, "paus": [7, 53, 71], "pause_gener": 24, "payload": [23, 24, 26, 27, 50, 84, 92, 97], "pci": 59, "pcie": 14, "pd": [6, 30, 58, 83, 87], "pd_role": 84, "pdmux": 22, "pdmux_config_path": [14, 21, 26, 27, 28, 29, 37, 38], "peac": 14, "peak": [7, 13, 17, 22, 30, 75], "pedal": 29, "pedestrian": 97, "peer": [2, 14, 17, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 74, 78], "pem": 23, "penalti": 41, "pend": [23, 24], "peopl": [14, 25, 27, 29, 38, 52, 60], "per": [1, 2, 11, 13, 14, 16, 18, 19, 22, 23, 24, 25, 30, 33, 37, 46, 47, 50, 51, 52, 60, 71, 74, 78, 82, 84, 86, 91, 96], "per_row": [18, 22], "per_tensor": [18, 22], "perfect": 17, "perfectli": 4, "perfetto": [51, 87, 91], "perform": [1, 3, 5, 6, 7, 10, 11, 12, 14, 17, 18, 21, 22, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 48, 51, 52, 58, 59, 60, 63, 68, 70, 72, 76, 78, 80, 85, 87, 92, 93, 94, 97, 99], "perhap": [27, 37], "period": [7, 23, 38, 52, 60, 74], "periodsecond": [80, 81, 84], "perman": [14, 86], "permiss": [23, 52, 60], "permut": 7, "permutemethodpool": 7, "persimmon": [67, 93], "persist": [23, 91], "person": [14, 29, 38, 78], "petit_nvfp4": 22, "phase": [1, 11, 16, 17, 22, 25, 30, 71, 74, 87], "phenomenon": 17, "phi": [67, 93, 96], "philosophi": [24, 41], "philschmid": 14, "phoenix": 78, "phrase": 41, "phy": 80, "physic": [24, 74], "physical_st": 80, "piano": 91, "pick": [23, 50, 52, 60, 74], "pickl": 15, "piec": [14, 43], "piecewis": [3, 22], "piecewise_cuda_graph_compil": [14, 21, 26, 27, 28, 29, 37, 38], "piecewise_cuda_graph_max_token": [14, 21, 26, 27, 28, 29, 37, 38], "piecewise_cuda_graph_token": [14, 21, 26, 27, 28, 29, 37, 38], "pil": [29, 47], "pillow": 50, "pin": [22, 91], "ping": 45, "pip": [0, 2, 16, 18, 22, 23, 31, 39, 51, 54, 55, 56, 59, 61, 62, 68, 69, 71, 72, 87, 94], "pip1": 62, "pip2": 62, "pip3": [31, 52, 57, 60, 72], "pipelin": [0, 22, 23, 25, 29, 58, 74, 98], "pipeline_class": 91, "pipeline_nam": 91, "pipelineconfig": 91, "pipelinestag": 91, "piqu": 14, "pixel": 29, "pixel_art_style_lora_z_image_turbo": 91, "pixel_valu": 29, "place": [5, 7, 11, 14, 27, 28, 33, 38, 41, 49, 52, 60, 78], "plai": [91, 97], "plain": 23, "plan": [1, 14, 23, 28, 37, 53, 57, 71, 74, 91], "plane": 24, "plate": 38, "platform": [1, 29, 35, 57, 68, 94], "playground": [15, 99], "pleas": [1, 14, 16, 18, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 41, 42, 43, 47, 48, 51, 52, 53, 54, 57, 59, 60, 61, 62, 68, 69, 70, 71, 72, 74, 75, 78, 80, 82, 84, 87, 91, 94, 96, 99], "plenti": 78, "plu": [21, 33, 46, 91, 93], "plugin": [11, 16, 28, 71, 80], "png": [29, 33, 43, 46, 47, 50, 78, 91], "po": [81, 84], "pod": 23, "point": [4, 7, 8, 19, 22, 23, 24, 27, 34, 81, 84, 86, 87, 99], "poisson": 50, "pole": 29, "polici": [4, 11, 13, 14, 16, 22, 24, 25, 61, 62, 63, 84], "polit": 25, "poll": [22, 74, 91], "pong": 45, "pool": [3, 11, 14, 22, 23, 33, 37, 46, 74, 75], "pool_siz": 23, "poorli": 76, "popul": [26, 27, 38, 47, 99], "popular": [18, 38, 41, 58, 68], "port": [0, 2, 6, 10, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 50, 51, 53, 54, 57, 59, 61, 62, 63, 71, 73, 74, 78, 80, 81, 82, 84, 86, 87, 90, 91, 92, 93, 95, 96, 97, 98, 100], "port_tool_choic": 28, "portion": [2, 3, 19, 28, 75], "posit": [17, 23, 41, 45, 47, 74, 96, 99], "possibl": [0, 11, 13, 17, 22, 38, 52, 60, 99], "possibli": [78, 87], "post": [4, 7, 14, 18, 21, 23, 24, 25, 26, 27, 28, 33, 37, 39, 42, 43, 46, 47, 48, 50, 51, 58, 75, 80, 81, 82, 84, 87, 89, 90, 91, 92, 96, 97], "post2": [57, 59, 91], "postgr": 23, "postgres_db_url": 23, "postpon": 85, "potenti": [17, 19, 22, 25, 38, 72, 87, 90], "potter": 78, "power": [14, 23, 24, 31, 36, 38, 39, 51, 58, 59, 85, 96], "power_of_two": 23, "pp": [12, 17, 22, 51], "pp_async_batch_depth": [14, 21, 26, 27, 28, 29, 37, 38], "pp_max_micro_batch_s": [14, 21, 26, 27, 28, 29, 37, 38], "pp_proxy_tensor": 99, "pp_size": [14, 21, 26, 27, 28, 29, 37, 38], "ppo": 85, "ppproxytensor": 99, "pprint": [30, 32], "pr": [0, 7, 14, 19, 31, 35, 45, 52, 60, 84, 91, 99], "practic": [9, 14, 24, 29, 30, 51, 52, 60, 66, 91], "pre": [0, 1, 7, 18, 19, 22, 23, 29, 47, 59, 61, 86], "prealloc": 74, "preced": [41, 52, 60, 91], "preciou": 14, "precis": [3, 7, 11, 18, 19, 22, 27, 30, 68, 71, 91], "precompil": [25, 30, 74], "precomput": [47, 74], "precomputed_embed": [29, 47], "predefin": [22, 99], "predic": 38, "predict": [17, 23, 50, 76, 89, 90, 93], "predictor": 17, "preempt": [22, 52, 60], "preemption": 22, "prefer": [0, 11, 12, 19, 22, 23, 28, 31, 37, 50, 52, 53, 60, 68, 91, 98], "preferred_sampling_param": [14, 21, 26, 27, 28, 29, 37, 38], "prefetch": [12, 22, 91], "prefetch_threshold": [11, 12], "prefetch_timeout_bas": [11, 12], "prefetch_timeout_per_ki_token": [11, 12], "prefil": [4, 6, 7, 10, 11, 14, 21, 26, 27, 28, 29, 30, 31, 33, 37, 38, 46, 58, 61, 62, 63, 74, 75, 80, 84, 86, 87, 97, 99], "prefill1": 23, "prefill_addr": 31, "prefill_attention_backend": [14, 21, 26, 27, 28, 29, 37, 38], "prefill_count": 23, "prefill_delayer_forward_passes_bucket": [14, 21, 26, 27, 28, 29, 37, 38], "prefill_delayer_max_delay_pass": [14, 21, 26, 27, 28, 29, 37, 38], "prefill_delayer_token_usage_low_watermark": [14, 21, 26, 27, 28, 29, 37, 38], "prefill_delayer_wait_seconds_bucket": [14, 21, 26, 27, 28, 29, 37, 38], "prefill_head_ip": 31, "prefill_host": 6, "prefill_host_ip": 63, "prefill_in1024": 81, "prefill_ip": 62, "prefill_master_ip": 16, "prefill_max_request": [14, 21, 26, 27, 28, 29, 37, 38], "prefix": [1, 4, 11, 13, 17, 22, 23, 30, 31, 45, 50, 51, 57, 58, 71, 74, 75, 91, 99], "preliminari": [2, 19], "premis": 38, "prepar": [4, 14, 17, 22, 31, 49, 74, 80], "prepare_data": 31, "prepend": 11, "preprocess": [6, 22], "prereleas": 91, "prerequisit": 51, "presence_penalti": [41, 47], "present": [11, 21, 27, 68, 96, 97], "preserv": [24, 28], "preset": [50, 81], "presid": [27, 38, 76], "press": [14, 37, 53, 68, 80], "pressur": [11, 24], "pretrain": 93, "pretrainedmodel": 100, "pretti": [27, 30, 32], "prev": [47, 48], "preval": 38, "prevent": [11, 12, 13, 14, 16, 17, 22, 23, 41, 52, 53, 60, 72, 75, 80], "preview": 0, "previou": [17, 30, 34, 86, 87, 93], "previous": [19, 22, 38, 47, 91], "price": 34, "primari": [23, 72, 91], "primarili": [19, 52, 57, 60, 74, 91, 93], "prime": 27, "primit": [23, 76], "princ": 14, "princess": 14, "principl": [24, 87], "print": [4, 14, 18, 27, 28, 29, 33, 34, 37, 38, 39, 41, 42, 46, 47, 48, 50, 51, 62, 63, 78, 89, 90, 91, 92, 94, 96, 97, 99], "print_highlight": [21, 25, 26, 27, 28, 37, 41, 42, 43, 47, 48, 78], "prior": [7, 61, 68], "priorit": [52, 60], "prioriti": [22, 23, 52, 60, 89], "priority_scheduling_preemption_threshold": [14, 21, 26, 27, 28, 29, 37, 38], "prithivmlmod": 91, "privaci": [38, 41, 85], "privat": [3, 11, 22, 23], "privileg": [53, 59, 61, 68, 80, 81, 84], "pro": [1, 35, 67, 72, 96, 99], "proactiv": 11, "prob": [22, 23, 89], "probabl": [22, 23, 24, 25, 27, 37, 47, 89], "probe": 23, "problem": [16, 18, 21, 24, 57, 61, 80], "proc": [59, 61], "proce": 23, "proceed": 11, "process": [2, 5, 6, 11, 12, 14, 16, 17, 22, 23, 24, 25, 29, 30, 31, 33, 37, 38, 41, 46, 50, 51, 52, 54, 57, 60, 68, 71, 74, 80, 86, 87, 89, 91, 93, 96, 97], "process_tracing_init": 87, "processor": [22, 30, 32, 33, 41, 43, 68, 78, 96, 99], "processor_output": [29, 47], "produc": [4, 28, 50, 86, 93], "product": [4, 11, 17, 18, 22, 24, 31, 34, 38, 57, 58, 71, 85, 100], "profici": 14, "profil": [17, 22, 24, 50, 52, 58, 60, 71], "profile_id": 51, "profile_log": 51, "profiler_python": 51, "program": [27, 41, 53, 92, 96, 97], "programmat": [18, 23, 51], "progress": [17, 23], "progress_bar": 78, "prohibit": 17, "proj": 91, "project": [0, 3, 5, 18, 19, 23, 29, 31, 33, 34, 37, 43, 46, 47, 55, 56, 57, 59, 61, 68, 69, 71, 72, 73, 78, 79, 84, 87, 91, 93, 96], "projector": [29, 96], "prometheu": [15, 22, 86], "promis": [17, 90], "prompt": [1, 4, 13, 18, 21, 22, 23, 26, 27, 28, 29, 30, 34, 37, 38, 41, 47, 50, 51, 54, 59, 62, 68, 71, 72, 75, 86, 90, 91, 94, 96, 99], "prompt_token": [23, 25, 26, 27, 28, 30, 37, 41, 42, 43, 48, 81, 84, 89], "prompt_tokens_bucket": [14, 21, 26, 27, 28, 29, 37, 38], "prompt_tokens_detail": [22, 25, 28, 30, 41, 42, 43, 48, 81, 84, 89], "prompt_tokens_tot": 86, "pronounc": 19, "propag": [17, 87], "proper": [27, 49, 50, 52, 60, 68, 80, 96], "properli": [19, 27, 49, 59, 71, 80, 87], "properti": [26, 27, 28, 30, 47, 49], "propos": [11, 17, 28], "prosper": 14, "protect": 23, "protein": 78, "proto": [23, 87], "protobuf": 87, "protocol": [12, 23, 80, 81, 84, 89], "protocol_buffers_python_implement": 94, "protocolerror": 27, "prototyp": [22, 29], "proud": 38, "proven": [24, 58], "provid": [2, 4, 7, 11, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 47, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 68, 71, 74, 78, 82, 86, 87, 89, 91, 92, 93, 94, 96, 98, 99], "proxi": [22, 61], "prss": 53, "prune": [23, 96], "pt": [22, 25, 29, 59, 67, 93, 96], "pth": 18, "ptq": 18, "ptxa": 57, "pub": 51, "public": [38, 78, 79], "public_sglang_ci": 37, "publish": 22, "pull": [0, 3, 23, 31, 34, 52, 53, 56, 60, 61], "punica": 14, "pure": [22, 31, 52, 60, 78], "purpos": [7, 11, 14, 15, 17, 22, 39, 49], "push": [0, 52, 57, 60], "put": [12, 17, 23, 24, 26, 27], "pwd": [18, 60], "py": [1, 2, 7, 12, 14, 15, 18, 21, 22, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 41, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60, 69, 73, 78, 89, 91, 99], "py3": 61, "pybase64": 50, "pydant": [26, 27], "pyo3": 23, "pypi": [23, 52, 60], "pyproject": [52, 55, 59, 60, 61, 68, 69, 72], "pyproject_cpu": 68, "pyproject_npu": 61, "pyproject_oth": [59, 69], "pyproject_xpu": 72, "python": [1, 2, 6, 7, 8, 10, 11, 12, 16, 20, 21, 22, 24, 26, 27, 31, 33, 35, 37, 38, 41, 46, 47, 50, 51, 52, 53, 54, 55, 57, 59, 60, 62, 63, 65, 68, 69, 70, 71, 72, 73, 78, 81, 82, 86, 87, 90, 91, 93, 94, 95, 96, 99, 100], "python3": [1, 3, 4, 5, 10, 14, 15, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 59, 60, 61, 62, 63, 71, 78, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100], "python_execution_backend": 34, "python_serv": 34, "python_tag": 28, "pythonpath": 60, "pytorch": [1, 8, 18, 22, 49, 57, 68, 72, 74, 75, 88], "pytorch_npu_alloc_conf": [62, 63, 65], "pytorch_vers": 61, "p\u8282\u70b9": 62, "q": [30, 31, 96], "q2": 34, "q4_k_m": 18, "q_b_proj": 74, "q_proj": [14, 22], "qa": 11, "qdrep": 51, "qingdao": 30, "qk": [14, 21, 22, 26, 27, 28, 29, 37, 38], "qkv": [3, 18, 22], "qkv_proj": [22, 51], "qlora": 85, "qoq": 22, "qperf": 80, "quad": 21, "quadrat": 17, "quai": 61, "qualiti": [18, 25, 26, 37, 71, 78, 90, 91, 92, 93], "quant": [18, 22], "quant_config": [18, 99], "quant_method": 7, "quant_model_descript": 64, "quant_path": 18, "quantiz": [1, 7, 13, 14, 21, 26, 27, 28, 29, 30, 31, 37, 38, 58, 62, 63, 64, 68, 71, 93, 99], "quantization_param_path": [14, 21, 26, 27, 28, 29, 37, 38], "quantizationconfig": 99, "quantizationmodifi": 18, "quantize_and_sav": 18, "quantize_and_serv": [14, 21, 26, 27, 28, 29, 37, 38], "quantizeconfig": 18, "quantized_model": 18, "quantized_tinyllama_fp4": 18, "quantized_tinyllama_fp8": 18, "quark_int4fp8_mo": 22, "quarot": 67, "queri": [0, 11, 15, 22, 26, 27, 28, 37, 50, 58, 96], "query_st": 100, "query_weath": 30, "quest": 14, "question": [21, 25, 27, 30, 31, 32, 37, 38, 41, 50, 52, 53, 54, 58, 59, 60, 62, 69, 78, 96, 97], "queu": [12, 22], "queue": [12, 14, 16, 24, 37, 74, 80, 86], "queue_schedul": 61, "quick": [29, 48, 51, 52, 57, 60, 71, 91], "quickli": [0, 14, 51, 52, 60, 91], "quickstart": 58, "quiet": 61, "quinoa": 78, "quintu": 41, "quit": [14, 27, 37, 80], "quot": [27, 34], "quotat": 27, "qwen": [0, 1, 2, 3, 4, 5, 14, 17, 18, 21, 22, 23, 27, 28, 29, 37, 38, 39, 41, 43, 45, 46, 48, 50, 51, 52, 57, 58, 60, 65, 67, 68, 72, 78, 91, 92, 93, 95, 96, 97, 98, 99], "qwen1": 37, "qwen2": [0, 1, 3, 5, 14, 18, 23, 28, 37, 38, 39, 41, 42, 43, 47, 48, 50, 52, 60, 67, 72, 78, 81, 84, 89, 92, 95, 96, 98, 99], "qwen25": [22, 28], "qwen2_5_vlforconditionalgener": [29, 96], "qwen2forcausallm": 37, "qwen2forrewardmodel": [89, 98], "qwen2forsequenceclassif": [23, 89, 98], "qwen2vl": 99, "qwen3": [2, 3, 5, 6, 10, 19, 21, 22, 23, 28, 44, 54, 57, 61, 66, 67, 68, 85, 92, 93, 94, 96], "qwen3_cod": [22, 28], "qwen3_rerank": 97, "qwen3_vl_rerank": 97, "qwen3forcausallm": 93, "qwen3forsequenceclassif": 89, "qwen_image_edit_inpaint": 91, "qwen_vl": 96, "qwenimag": 91, "qwenimage_denois": 91, "qwq": [27, 67, 68], "r": [0, 23, 25, 26, 27, 41, 67, 78, 89, 91, 93], "r1": [1, 2, 7, 10, 18, 19, 21, 22, 23, 27, 41, 44, 54, 57, 59, 67, 68, 70, 80, 81, 93, 94], "r7b": 93, "raccoon": 91, "race": 16, "radix": [4, 17, 22, 23, 31, 37, 50, 51, 61, 62, 63, 71, 75, 81, 84, 97], "radix_cach": 4, "radix_eviction_polici": [14, 21, 26, 27, 28, 29, 37, 38], "radixattent": [10, 11, 22, 58, 99], "radixtre": 11, "rag": [22, 31], "rai": 85, "rain": 97, "rais": [8, 22, 34, 37, 50, 87], "raise_for_statu": 37, "ralli": 34, "ram": 22, "ramp": 29, "ran": 99, "random": [22, 23, 25, 50, 51, 54, 59, 62, 68, 71, 72, 84, 86, 91], "random_se": [14, 21, 26, 27, 28, 29, 37, 38], "randomli": [47, 50], "rang": [11, 13, 14, 17, 18, 19, 22, 25, 35, 37, 41, 47, 50, 51, 58, 62, 68, 71, 72, 78, 86, 90], "rank": [2, 12, 14, 16, 17, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 37, 38, 41, 42, 43, 48, 51, 62, 63, 68, 71, 74, 78, 80, 81, 82, 84, 94, 97, 98], "rank0": 91, "rank_offset": 24, "rapid": 11, "rapidli": 38, "rate": [8, 10, 11, 25, 34, 62, 68, 72, 80, 86], "rate_limit": 23, "rate_limit_tot": 23, "rather": [13, 18, 23, 27], "ratio": [7, 10, 11, 19, 22, 23, 35, 45, 50, 62, 68, 71, 72, 86, 91], "ravenclaw": 78, "raw": [17, 19, 33, 43, 46, 47, 78, 91, 96, 99], "raw_tool": 28, "rbac": 23, "rbg": [31, 83], "rbg_pd": 31, "rc": 51, "rc1": 61, "rc2": [61, 94], "rc_rdma_write_bw": 80, "rdma": [7, 10, 11, 53, 59, 61, 81, 84], "re": [0, 22, 30, 37, 38, 52, 53, 57, 60, 71, 80, 85, 91, 99], "reach": [11, 34, 74, 85], "reachabl": 50, "react": [52, 60], "reaction": [52, 60], "read": [11, 22, 27, 47, 53, 59, 71, 91, 96], "readabl": [8, 22, 37, 49], "reader": 38, "readi": [2, 11, 13, 14, 18, 22, 31, 37, 51, 59, 68, 80, 82, 93, 99], "readinessprob": [80, 81, 84], "readm": [52, 60, 99], "real": [11, 18, 22, 26, 27, 28, 51, 93], "realism": 91, "realismlora": 91, "realiti": 38, "realloc": [3, 59], "rear": 43, "reasoing_cont": 27, "reason": [3, 15, 17, 19, 22, 24, 28, 32, 36, 38, 45, 46, 54, 57, 58, 74, 93, 96], "reasoning_cont": [21, 25, 27, 28, 30, 41, 43, 48, 81, 84], "reasoning_effort": 34, "reasoning_pars": [14, 21, 26, 27, 28, 29, 37, 38], "reasoning_text": [21, 23], "reasoning_token": [25, 28, 41, 42, 43, 48], "reasoningpars": 21, "rebal": [22, 84], "rebalanc": [7, 22, 23], "reboot": 59, "rebuild": [0, 24], "recal": 27, "recaptur": 24, "recapture_cuda_graph": 24, "receiv": [11, 16, 23, 30, 87, 99], "recent": [14, 22, 25, 27, 34, 52, 60, 75], "recip": [18, 88], "recogn": [21, 35, 49, 93, 99], "recognit": 96, "recommend": [0, 1, 2, 7, 10, 11, 14, 16, 17, 18, 19, 22, 24, 28, 30, 31, 34, 35, 36, 41, 49, 51, 52, 54, 57, 60, 61, 68, 91, 94], "recompil": 23, "recomput": 24, "reconstruct": [30, 37], "reconstructed_text": 37, "record": [11, 22, 37, 74, 87], "record_shap": 74, "recoveri": [23, 24, 57], "recreategrouponpodrestart": [80, 81], "recv": [22, 74], "recycl": 24, "red": [91, 93], "redefin": 36, "redesign": 17, "redhatai": 68, "redirect": 24, "redis_pool_max": 23, "redis_retention_dai": 23, "redis_url": 23, "rednot": 96, "redoc": 48, "reduc": [0, 1, 2, 3, 4, 5, 7, 11, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 41, 42, 43, 47, 48, 51, 52, 60, 71, 75, 78, 87, 91, 92, 96], "reduct": [4, 14, 19, 23, 30, 57, 93], "redund": [11, 17, 18, 19, 22, 29, 81, 84, 91, 96], "redundantli": 11, "ref": [33, 46, 96], "refactor": 7, "refer": [7, 10, 11, 13, 16, 19, 22, 27, 28, 30, 31, 34, 41, 42, 43, 47, 48, 49, 51, 52, 54, 57, 59, 60, 68, 72, 75, 80, 82, 84, 94, 96, 99], "reference_hf": 99, "reference_imag": 97, "refin": [97, 98], "refit": 85, "reflect": 91, "refresh_interv": 23, "refus": [25, 28, 41, 48], "regard": 87, "regardless": [22, 50], "regex": [22, 26, 27, 78], "region": [23, 24, 25, 38, 51, 57], "regist": [7, 8, 10, 22, 23, 51, 91], "register_forward_hook": 8, "register_fused_func": 7, "register_post_permut": 7, "register_pre_permut": 7, "registr": [8, 23], "registrations_tot": 23, "registri": [23, 99], "regress": [18, 52, 60, 90], "regul": 23, "regular": [8, 14, 25, 47, 49, 78], "regular_count": 23, "regular_expression_gen": 78, "reinforc": [4, 85, 93, 96, 98], "reiniti": 14, "reinstal": [23, 57, 68], "reject": [12, 23, 25], "rel": [0, 4, 5, 19, 23, 91], "relat": [14, 31, 43, 49, 52, 57, 60, 68, 73, 80, 81, 84, 91], "relationship": [11, 14, 87], "relaunch": 97, "relax": 16, "releas": [14, 21, 23, 25, 26, 27, 28, 29, 34, 37, 38, 41, 42, 43, 48, 51, 52, 57, 59, 60, 61, 78, 81, 91], "release_memory_occup": [22, 24], "release_weights_occup": 22, "relev": [0, 14, 25, 26, 27, 54, 97], "reli": [24, 52, 60, 99], "reliabl": [4, 27, 28, 93], "relianc": 38, "reload": 14, "remain": [1, 14, 17, 37, 75, 87, 96], "remax": 85, "rememb": [0, 25, 27, 42], "remind": [26, 27], "remot": [1, 12, 14, 16, 17, 20, 22, 25, 27, 30, 31, 33, 35, 36, 37, 39, 46, 59, 61, 62, 63, 65, 68, 71, 72, 80, 81, 84, 91, 92, 96, 97, 98], "remote_inst": [20, 22], "remote_instance_weight_loader_backend": [14, 21, 26, 27, 28, 29, 37, 38], "remote_instance_weight_loader_seed_instance_ip": [14, 21, 26, 27, 28, 29, 37, 38], "remote_instance_weight_loader_seed_instance_service_port": [14, 21, 26, 27, 28, 29, 37, 38], "remote_instance_weight_loader_send_weights_group_port": [14, 21, 26, 27, 28, 29, 37, 38], "remote_instance_weight_loader_start_seed_via_transfer_engin": [14, 21, 26, 27, 28, 29, 37, 38], "remotedisconnect": 27, "remov": [0, 8, 14, 21, 23, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 47, 48, 53, 59, 61, 78, 96, 99], "render": 91, "renderd176": 56, "renderd184": 56, "renown": [25, 38, 41], "reorder": [13, 30], "rep": 51, "repeat": [14, 23, 24, 29, 31, 33, 38, 46, 47, 53, 54], "repetit": [41, 47], "repetition_penalti": [14, 37, 47], "replac": [14, 18, 22, 38, 48, 57, 59, 61, 68, 71, 82, 86, 87, 91, 99], "replai": [1, 3, 24, 51], "replay_request_dump": 15, "repli": [26, 27], "replic": [5, 7], "replica": [23, 80, 81, 84], "repo": [22, 25, 51, 52, 53, 60, 91, 93, 96], "repo_id": 99, "report": [10, 22, 31, 33, 46, 49, 50, 51, 71, 75, 99], "repositori": [2, 7, 10, 37, 53, 61, 68, 70, 71], "repository_nam": 57, "repres": [11, 14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 49, 78, 87, 92], "represent": [22, 92], "reproduc": [17, 41, 91], "reput": 14, "req": [12, 14, 22, 37, 50, 80, 87], "req_id": 87, "req_root_span": 87, "request": [0, 4, 5, 6, 7, 10, 11, 12, 14, 16, 17, 19, 22, 24, 25, 26, 27, 29, 30, 31, 32, 37, 41, 45, 47, 50, 51, 53, 54, 58, 59, 62, 63, 74, 75, 80, 81, 82, 84, 86, 90, 96, 99], "request_duration_second": 23, "request_errors_tot": 23, "request_r": 50, "requestexcept": 37, "requests_act": 23, "requests_tot": 23, "requir": [0, 1, 3, 6, 7, 10, 11, 14, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 34, 38, 41, 45, 47, 49, 50, 53, 54, 57, 59, 61, 67, 68, 75, 80, 87, 89, 90, 92, 97, 98, 99, 100], "require_reason": 27, "rerank": [23, 25, 58], "reranker_process": 37, "rerun": [52, 60], "research": [67, 93], "reserv": [5, 13, 14, 22], "resid": [11, 14, 23, 27, 38], "residu": [3, 22, 91], "resiz": 22, "resolut": [3, 50, 57, 91, 96], "resolv": [0, 8, 16, 18, 23, 27, 30, 49, 52, 60, 75, 80, 91, 92], "resolve_cal": 8, "resolve_devic": 49, "resort": 89, "resourc": [6, 11, 14, 16, 17, 23, 29, 52, 57, 60, 70, 80, 81, 84, 85, 92, 99], "resp": 91, "respect": [30, 41, 48, 87], "respond": [23, 28], "respons": [5, 11, 12, 14, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 39, 41, 42, 43, 46, 47, 48, 76, 91, 92, 96, 98], "response1": 37, "response2": 37, "response_cont": 26, "response_data": 26, "response_format": [26, 27, 91], "response_json": [37, 97], "response_non_stream": [21, 28], "response_requir": 28, "response_sent_to_client_t": [26, 27, 37, 48], "response_specif": 28, "response_stream": [21, 28], "responses_tot": 23, "responsibli": 38, "rest": [27, 90, 91], "restart": [9, 10, 24, 30, 37, 49, 53, 56, 80], "restartpolici": [80, 81, 84], "restaur": 38, "restor": [18, 22, 91], "restrict": [14, 23, 27, 31, 49, 50], "result": [3, 4, 11, 14, 16, 17, 19, 21, 22, 23, 24, 26, 27, 30, 34, 37, 41, 42, 45, 50, 51, 52, 60, 68, 71, 76, 89, 91, 93, 96, 97, 98, 99], "resume_memory_occup": [22, 24], "resume_weights_occup": 22, "retain": [33, 46], "retent": 23, "reth0": 80, "reth2": 80, "reth4": 80, "reth6": 80, "retoken": 50, "retract": [13, 22, 24, 74], "retracted_req": 13, "retri": [0, 12, 27], "retries_exhausted_tot": 23, "retries_tot": 23, "retriev": [10, 11, 23, 49, 92, 93, 97], "retry_backoff_second": 23, "retryabl": 23, "return": [8, 11, 12, 17, 22, 23, 24, 26, 27, 28, 37, 47, 49, 78, 89, 91, 92, 97, 99], "return_dict": [21, 26, 27, 28, 37], "return_hidden_st": 47, "return_logprob": [26, 27, 47], "return_routed_expert": [41, 47], "return_tensor": 29, "return_text_in_logprob": 47, "reus": [0, 1, 10, 11, 18, 22, 23, 31, 45, 52, 60, 99], "reusabl": [11, 49], "reuter": 34, "rev": 80, "revel": 14, "reveng": 14, "revert": 17, "revis": [14, 21, 22, 26, 27, 28, 29, 37, 38], "reward": [24, 48, 58], "reward_process": 37, "rf": [57, 59], "rice": 78, "rich": [30, 32, 38], "rid": [14, 47, 81, 84, 87, 89], "right": [19, 25, 27, 41, 75], "rigid": 24, "rigor": [52, 60], "ring": [23, 62, 91], "ring_degre": 91, "rio": 27, "risen": 34, "risk": [13, 14, 25, 38, 78], "river": 38, "rl": [4, 22, 25, 58, 67, 85, 93, 96], "rl2": 85, "rl_on_policy_target": [14, 21, 26, 27, 28, 29, 37, 38], "rl_quant_profil": [14, 21, 26, 27, 28, 29, 37, 38], "rl_team": 85, "rlhf": [85, 98], "rlimit_nofil": 50, "rm": [56, 57, 59, 61, 67, 69, 70, 98], "rmsnorm": [22, 99], "road": 41, "roadmap": [4, 7, 14, 30, 31, 35, 71, 79], "roar": 61, "robin": [22, 62, 63], "robot": 38, "robust": [24, 50, 92], "roce": [53, 59], "rocki": 14, "rocm": [1, 22, 31, 58, 59], "rocm630": 56, "rocm700": [31, 91], "role": [21, 23, 25, 26, 27, 28, 29, 30, 32, 33, 36, 37, 39, 41, 43, 46, 47, 48, 80, 81, 84, 90, 96], "role_end": 90, "rolebasedgroup": 84, "rolebind": 23, "roleref": 23, "roll": [14, 37, 59, 68, 80, 85], "rollback": 12, "rollingupd": 81, "rollingupdateconfigur": 81, "rollout": [24, 58, 85], "rolloutstrategi": 81, "roman": 41, "romanc": 14, "rome": [26, 27, 41], "rome3": 78, "rooflin": 17, "room": [17, 87], "root": [11, 22, 26, 27, 31, 47, 51, 53, 57, 59, 61, 68, 80, 81, 84, 87, 88, 91, 95, 99], "rope": [22, 74], "rotari": [22, 96], "rotat": 23, "roughli": [34, 75], "round": [22, 28, 50, 62, 63], "round_robin": [14, 21, 22, 23, 26, 27, 28, 29, 37, 38, 62, 63], "rout": [7, 16, 22, 24, 39, 47, 50, 89, 93, 96], "routed_expert": 41, "router": [6, 7, 13, 22, 31, 51, 61, 63, 84, 85, 87], "router_api_kei": 23, "router_log": 23, "routerarg": 23, "routin": [14, 57, 78], "rst": 0, "rule": [13, 22, 23, 29, 71, 91], "run": [0, 1, 2, 3, 4, 8, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 41, 42, 43, 45, 46, 48, 49, 50, 51, 53, 54, 58, 62, 69, 71, 72, 74, 75, 78, 80, 81, 82, 84, 86, 88, 95, 96, 97, 99], "run_batch": 78, "run_ev": [31, 54, 63], "run_llm": 99, "runnabl": [0, 49], "runner": [1, 3, 7, 22, 31, 37, 74], "runner_allow_runasroot": 56, "runnerinput": 7, "runneroutput": 7, "running_queu": 24, "runtim": [7, 9, 10, 14, 17, 18, 21, 24, 25, 29, 37, 38, 41, 42, 43, 47, 48, 51, 52, 57, 58, 60, 70, 71, 72, 74, 78, 91, 96, 99], "runtime_vers": 71, "runtimecheck": 49, "runtimedevicecheck": 49, "runtimeendpoint": [76, 78], "runtimeerror": 51, "rust": [81, 89], "rustc": 23, "rustl": 23, "rustup": 23, "ruthless": 14, "s3": 11, "safe": [14, 21, 23, 24, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "safeguard": 91, "safest": 24, "safetensor": [14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78, 91], "safeti": 12, "sage": 91, "sage_attn": 91, "sage_attn_3": 91, "sageattent": 91, "sageattention3": 91, "sai": [14, 27, 41, 78], "same": [3, 4, 10, 11, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 37, 38, 41, 47, 49, 51, 52, 60, 61, 71, 75, 78, 87, 89, 91, 97, 99], "sampl": [1, 8, 14, 23, 30, 31, 32, 37, 38, 48, 50, 57, 58, 61, 75, 96, 99], "sampler": 96, "sampling_arg": 91, "sampling_backend": [14, 21, 26, 27, 28, 29, 37, 38], "sampling_default": [14, 21, 26, 27, 28, 29, 37, 38], "sampling_param": [4, 14, 18, 21, 26, 27, 28, 38, 47, 48, 90, 91, 94, 99], "sampling_se": 4, "samplingparam": [47, 91], "san": [26, 27, 28], "sandbox": [23, 34], "saniti": [52, 60], "sarah": [38, 41], "sat": 14, "satisfi": [12, 17, 27], "satur": [17, 24], "save": [2, 13, 18, 22, 24, 37, 45, 51, 53, 68, 71, 74, 75, 91, 96], "save_dir": 18, "save_pretrain": 18, "saver": [22, 24], "saw": 14, "sbatch": 82, "sbin": 61, "scalabl": [6, 7, 68, 96], "scalar": [19, 98], "scale": [6, 7, 11, 16, 17, 18, 22, 23, 24, 30, 31, 36, 47, 50, 57, 83, 85, 91, 93, 97], "scaled_dot_product_attent": 91, "scaling_factor": 19, "scaling_governor": [61, 62, 63], "scarc": [5, 14], "scatter": [22, 62, 63, 87], "scenario": [1, 4, 7, 10, 11, 14, 17, 19, 22, 29, 30, 31, 54, 81, 84, 96], "scene": [29, 38, 43, 78, 96, 97], "sched_migration_cost_n": [62, 63], "schedul": [3, 6, 10, 11, 12, 13, 14, 17, 23, 24, 25, 30, 31, 32, 34, 38, 45, 50, 52, 58, 60, 68, 71, 72, 74, 84, 87, 91], "schedule_conserv": [14, 21, 26, 27, 28, 29, 37, 38], "schedule_delay_milli": 74, "schedule_low_priority_values_first": [14, 21, 26, 27, 28, 29, 37, 38], "schedule_polici": [14, 21, 26, 27, 28, 29, 37, 38], "scheduler_output_processor_mixin": [52, 60], "scheduler_recv_interv": [14, 21, 26, 27, 28, 29, 37, 38], "schema": [14, 22, 24, 26, 27, 47, 78], "schema_get_current_d": [26, 27], "schema_get_current_weath": [26, 27], "scheme": [7, 11, 18], "school": 27, "scienc": 93, "scontrol": 82, "scoop": 38, "scope": [23, 91], "score": [24, 31, 54, 97, 98, 99], "score_process": 37, "scout": [28, 29, 35, 67, 93], "scrape": [23, 86], "scratch": 96, "screenshot": 87, "script": [15, 18, 30, 31, 34, 38, 50, 51, 52, 53, 54, 57, 59, 60, 68, 70, 72, 74, 82, 89, 91, 94, 99], "sd": 91, "sdk": [23, 57, 87, 91], "sdpa": [1, 22, 91], "seamless": [6, 7, 18, 89], "seamlessli": [10, 85], "search": [11, 14, 22, 26, 27, 30, 31, 78, 92, 93, 96, 97], "seat": [27, 38], "sec": [22, 23, 80, 84], "seccomp": 59, "second": [2, 14, 16, 20, 21, 22, 23, 25, 33, 37, 43, 46, 48, 50, 52, 54, 60, 71, 74, 86, 91, 93], "second_answ": 78, "secret": [14, 23, 57, 59, 61, 68, 91], "section": [7, 14, 16, 23, 24, 27, 29, 41, 47, 49, 61, 62, 67, 75, 80, 81, 84, 86, 87, 91, 96, 99], "secur": [22, 38, 51, 57, 59, 80], "securitycontext": [80, 81, 84], "see": [1, 3, 7, 10, 11, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 30, 38, 39, 41, 42, 47, 48, 51, 57, 68, 71, 72, 75, 78, 80, 86, 91, 93, 96, 97, 99, 100], "seed": [4, 20, 22, 41, 71, 78, 91], "seed_instance_ip": 20, "seed_instance_service_port": 20, "seek": [3, 14], "seem": [14, 27, 28, 29, 37, 41, 50], "seen": [14, 35, 45], "segment": [3, 22, 87], "sein": 38, "seldom": 17, "select": [6, 8, 11, 14, 17, 18, 22, 23, 24, 25, 31, 35, 41, 47, 50, 57, 74, 81, 84], "select_expert": 7, "selection_tot": 23, "selector": [23, 24, 80, 81, 84, 91], "self": [7, 8, 38, 41, 42, 43, 47, 99, 100], "self_attn": 51, "semant": [92, 97], "send": [0, 12, 13, 15, 20, 22, 23, 26, 27, 43, 47, 50, 51, 58, 59, 75, 82, 87, 96], "send_on": 51, "send_weights_nccl_group_ports_list": 20, "sender": 87, "seneca": 41, "sens": 14, "sensetim": 93, "sensit": [11, 14, 23, 54], "sent": [23, 50, 68, 72], "sentenc": [27, 34, 41, 43, 47], "sep": 73, "sep_styl": 73, "separ": [2, 6, 14, 16, 17, 21, 22, 25, 26, 27, 28, 37, 41, 42, 43, 48, 51, 52, 60, 62, 71, 78, 81, 87, 96], "separate_reason": [21, 41], "separate_reasoning_data": 21, "separate_reasoning_response_json": 21, "seq": [14, 21, 22, 26, 27, 28, 29, 31, 37, 38, 80], "seq_len": 3, "seqlen": 3, "sequenc": [3, 6, 11, 14, 16, 17, 19, 22, 23, 24, 25, 30, 41, 47, 51, 67, 71, 91, 98], "sequenti": [81, 93], "seren": 91, "seri": [17, 21, 27, 28, 30, 36, 67, 68, 72, 91, 93, 98], "serial": [23, 24, 47], "serialized_named_tensor": 24, "serv": [0, 7, 11, 12, 17, 23, 24, 25, 29, 30, 31, 32, 35, 38, 41, 45, 51, 57, 58, 78, 80, 82, 85, 92, 97], "served_model_nam": [14, 21, 26, 27, 28, 29, 37, 38], "server": [0, 3, 6, 10, 11, 12, 13, 14, 15, 18, 19, 20, 25, 26, 27, 30, 31, 32, 34, 38, 45, 47, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 70, 71, 73, 74, 80, 82, 86, 87, 88, 89, 90, 95, 99], "server_address": 31, "server_arg": [8, 12, 14, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78, 91, 99], "server_info": 37, "server_ip": 80, "server_nam": 87, "server_process": [14, 21, 25, 26, 27, 28, 37, 41, 48, 78], "server_process_tool_choic": 28, "server_typ": 31, "serverarg": [8, 14, 21, 26, 27, 28, 29, 37, 38, 91], "servers_act": 23, "servic": [3, 6, 12, 20, 22, 34, 41, 42, 43, 51, 57, 68, 80, 84, 86, 89], "service_nam": 23, "service_ti": [25, 28, 41, 48], "serviceaccount": 23, "servicenow": 93, "serving_classifi": 89, "session": [23, 28, 51, 87], "set": [1, 3, 5, 7, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 57, 60, 63, 68, 70, 71, 72, 73, 74, 75, 78, 80, 82, 86, 87, 88, 90, 92, 94, 95, 96, 98, 99, 100], "set_default_backend": 78, "set_env": [62, 63], "set_lora": 91, "setenv": 62, "setup": [7, 16, 22, 24, 41, 51, 57, 58, 68, 71, 78, 80, 91, 97], "setup_musa": 69, "setup_rocm": 59, "setuptool": [68, 72], "sever": [11, 14, 18, 20, 23, 37, 38, 47, 51, 68, 78, 99], "sft": 85, "sgl": [0, 3, 5, 10, 18, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 37, 38, 43, 46, 47, 49, 53, 55, 56, 57, 58, 59, 61, 68, 69, 71, 72, 76, 78, 79, 81, 82, 84, 87, 89, 90, 93, 94, 96, 99], "sgl_": 74, "sgl_cach": 81, "sgl_cache1": 81, "sgl_cache4": 84, "sgl_dg_use_nvrtc": 74, "sgl_enable_jit_deepgemm": 84, "sgl_ext": 41, "sgl_grpc_endpoint": 23, "sgl_jax": 71, "sgl_kernel": [49, 57], "sgl_tokenizer_path": 23, "sgl_use_deepgemm_bmm": 74, "sglang": [1, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 25, 29, 34, 36, 38, 41, 42, 43, 44, 47, 48, 49, 50, 55, 56, 62, 63, 65, 66, 68, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98], "sglang_": 74, "sglang_allow_overwrite_longer_context_len": 74, "sglang_blackwell_overlap_shared_experts_outside_sbo": 74, "sglang_block_nonzero_rank_children": 74, "sglang_cache_dit_bn": 91, "sglang_cache_dit_en": 91, "sglang_cache_dit_fn": 91, "sglang_cache_dit_mc": 91, "sglang_cache_dit_rdt": 91, "sglang_cache_dit_scm_cache_bin": 91, "sglang_cache_dit_scm_compute_bin": 91, "sglang_cache_dit_scm_polici": 91, "sglang_cache_dit_scm_preset": 91, "sglang_cache_dit_taylors": 91, "sglang_cache_dit_ts_ord": 91, "sglang_cache_dit_warmup": 91, "sglang_chunked_prefix_cache_threshold": [74, 81], "sglang_clip_max_new_tokens_estim": 74, "sglang_cpu_omp_threads_bind": 68, "sglang_cutlass_mo": 74, "sglang_data_parallel_budget_interv": 74, "sglang_debug_memory_pool": 74, "sglang_deepep_bf16_dispatch": [65, 74], "sglang_deepep_ll_combine_send_num_sm": 74, "sglang_deepep_num_max_dispatch_tokens_per_rank": [62, 63, 65, 74], "sglang_detokenizer_max_st": 74, "sglang_dev": 53, "sglang_dg_cache_dir": 74, "sglang_diffusion_attention_config": 91, "sglang_disable_consecutive_prefill_overlap": 74, "sglang_disable_fa4_warmup": 74, "sglang_disable_outlines_disk_cach": 74, "sglang_disable_request_log": 74, "sglang_disaggregation_bootstrap_timeout": [16, 62, 84], "sglang_disaggregation_heartbeat_interv": 16, "sglang_disaggregation_heartbeat_max_failur": 16, "sglang_disaggregation_nixl_backend": 16, "sglang_disaggregation_queue_s": 16, "sglang_disaggregation_thread_pool_s": 16, "sglang_disaggregation_waiting_timeout": [16, 84], "sglang_dp_round_robin": [62, 63], "sglang_dynamic_chunking_smooth_factor": 17, "sglang_enable_flashinfer_fp8_gemm": [22, 74], "sglang_enable_jit_deepgemm": [30, 74, 81], "sglang_enable_overlap_plan_stream": [62, 63, 65], "sglang_enable_spec_v2": [25, 30, 31, 32, 34, 62, 63, 65], "sglang_enable_torch_compil": 74, "sglang_enable_torch_inference_mod": 74, "sglang_enable_tp_memory_inbalance_check": 74, "sglang_eplb_heatmap_collection_interv": 74, "sglang_flashinfer_fp4_gemm_backend": [22, 74], "sglang_flashinfer_num_max_dispatch_tokens_per_rank": 74, "sglang_force_fp8_marlin": 74, "sglang_forward_unknown_tool": 74, "sglang_fused_mla_enable_rope_fus": 74, "sglang_hack_deepep_new_mod": 81, "sglang_hack_deepep_num_sm": 81, "sglang_health_check_timeout": 74, "sglang_host_ip": 74, "sglang_imag": 59, "sglang_in_deepgemm_precompile_stag": 74, "sglang_int4_weight": 74, "sglang_is_first_rank_on_nod": 74, "sglang_is_flashinfer_avail": 74, "sglang_is_in_ci": [56, 74], "sglang_is_in_ci_amd": 74, "sglang_jit_deepgemm_compile_work": 74, "sglang_jit_deepgemm_precompil": 74, "sglang_logging_config_path": 74, "sglang_mm_buffer_size_mb": 74, "sglang_mm_precompute_hash": 74, "sglang_moe_nvfp4_dispatch": 74, "sglang_moe_pad": 74, "sglang_mooncake_custom_mem_pool": 16, "sglang_mooncake_trans_thread": 81, "sglang_nccl_all_gather_in_overlap_scheduler_sync_batch": 74, "sglang_npu": 61, "sglang_npu_use_mlapo": [62, 63], "sglang_npu_use_multi_stream": 62, "sglang_nsa_enable_mtp_precompute_metadata": 74, "sglang_nsa_fuse_topk": 74, "sglang_nvfp4_ckpt_fp8_gemm_in_attn": 74, "sglang_nvfp4_ckpt_fp8_nextn_mo": 74, "sglang_one_visible_device_per_process": 74, "sglang_otlp_exporter_max_export_batch_s": [74, 87], "sglang_otlp_exporter_schedule_delay_milli": [74, 87], "sglang_per_token_group_quant_8bit_v2": 74, "sglang_port": 74, "sglang_pp_layer_partit": [17, 31, 74], "sglang_profile_record_shap": 74, "sglang_profile_with_stack": [51, 74], "sglang_queued_timeout_m": 74, "sglang_random": 50, "sglang_record_step_tim": 74, "sglang_request_dump": 15, "sglang_rout": [6, 16, 22, 23, 31, 51, 61, 62, 63, 81, 84, 87], "sglang_scheduler_decrease_prefill_idl": 62, "sglang_scheduler_max_recv_per_pol": 74, "sglang_scheduler_recv_skipper_weight_decod": 74, "sglang_scheduler_recv_skipper_weight_default": 74, "sglang_scheduler_recv_skipper_weight_non": 74, "sglang_scheduler_recv_skipper_weight_verifi": 74, "sglang_scheduler_skip_all_gath": [62, 63], "sglang_server_host": 86, "sglang_set_cpu_affin": [61, 62, 63, 65, 74, 81, 84], "sglang_skip_p2p_check": 74, "sglang_skip_sgl_kernel_version_check": 84, "sglang_storag": [14, 21, 22, 26, 27, 28, 29, 37, 38], "sglang_support_cutlass_block_fp8": [22, 74], "sglang_symm_mem_prealloc_gb_s": 74, "sglang_test_request_time_stat": 74, "sglang_test_retract": 74, "sglang_test_retract_no_prefill_b": 74, "sglang_tool_strict_level": 74, "sglang_torch_profiler_dir": [50, 51, 74], "sglang_use_ait": 74, "sglang_use_cpu_engin": 68, "sglang_use_cuda_ipc_transport": [33, 46], "sglang_use_custom_triton_kernel_cach": 74, "sglang_use_fia_nz": [62, 63], "sglang_use_modelscop": [50, 74, 95], "sglang_vit_enable_cuda_graph": 3, "sglang_vlm_cache_size_mb": [33, 46], "sglang_wait_weights_ready_timeout": 74, "sglang_zhync": 53, "sglangtracepropagatecontext": 87, "sglangtracereqcontext": 87, "sglangtracethreadcontext": 87, "sglroutertestatp_high": 23, "sgmv": 14, "sh": [0, 23, 55, 57, 59, 62, 63, 68, 70, 84], "shadow": 14, "shakhizat": 70, "shall": 38, "shanghai_ai_laboratori": 67, "shape": [3, 8, 14, 18, 24, 29, 38, 41, 47, 49, 51, 74], "shard": [14, 16, 21, 24, 25, 26, 27, 28, 29, 31, 37, 38, 41, 42, 43, 48, 78], "sharded_st": 22, "share": [1, 7, 10, 11, 13, 14, 16, 19, 22, 23, 24, 26, 27, 33, 34, 38, 46, 50, 52, 56, 60, 62, 63, 71, 74, 79, 80, 81, 85, 87, 91, 97], "sharegpt": [50, 51], "sharpli": 34, "she": [14, 41], "shell": [42, 43, 48, 51, 53], "ship": 88, "shirt": 78, "shm": [22, 53, 56, 57, 59, 61, 68, 80, 81, 84, 91], "shone": 14, "short": [22, 31, 34, 38, 41, 47, 50, 91, 99], "shorter": 76, "shorthand": 22, "shot": [28, 31, 52, 53, 54, 60], "should": [4, 11, 13, 14, 17, 19, 21, 22, 24, 25, 27, 28, 30, 31, 32, 34, 36, 38, 41, 49, 51, 53, 68, 73, 80, 81, 86, 87, 91, 97, 99], "show": [2, 4, 14, 17, 19, 22, 28, 29, 31, 34, 39, 41, 43, 57, 59, 61, 78, 80, 82, 91, 96], "show_time_cost": [14, 21, 26, 27, 28, 29, 37, 38], "showcas": 82, "shown": [1, 14, 28, 29, 51, 59, 90, 91], "shrub": 14, "shuffl": [7, 22], "shut": 91, "shutdown": [21, 22, 26, 27, 28, 29, 38, 99], "sick": 14, "side": [3, 12, 14, 22, 51, 89, 96], "sig": [80, 81, 84], "sigmoid": 37, "sign": 19, "signal": 34, "signatur": [8, 99], "signific": [2, 5, 7, 16, 17, 19, 30, 38, 52, 60, 75, 93], "significantli": [2, 11, 17, 20, 31, 33, 34, 46, 57, 63, 71, 78, 91], "sigquit": 22, "silent": [12, 24, 25], "silu": 74, "siluandmul": 99, "similar": [1, 37, 41, 47, 49, 97, 99], "similar_imag": 97, "similarli": [11, 68, 75, 93, 99], "simpl": [11, 13, 18, 19, 23, 25, 29, 31, 39, 49, 78, 80, 91, 99], "simplenamespac": 63, "simpler": [19, 51], "simplest": 24, "simpli": [18, 26, 37, 57, 64, 76, 91, 92, 97], "simplic": 24, "simplifi": [7, 30, 51, 71], "simul": [7, 54], "simultan": [16, 17, 71, 91], "sin_cos_w": 3, "sinc": [5, 11, 14, 17, 21, 25, 26, 27, 28, 29, 34, 35, 37, 38, 41, 42, 43, 45, 48, 52, 57, 60, 78], "singl": [4, 11, 19, 22, 23, 27, 28, 29, 30, 31, 41, 47, 51, 52, 54, 57, 58, 59, 60, 68, 71, 74, 82, 91, 99], "singleprocess": 25, "sink": 23, "size": [1, 2, 3, 4, 5, 7, 10, 11, 14, 16, 18, 19, 22, 23, 24, 29, 30, 31, 32, 33, 34, 36, 37, 45, 46, 49, 50, 51, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 70, 71, 72, 74, 75, 80, 81, 82, 84, 91, 92, 93, 94, 96, 97, 98], "size_t": 49, "sk": [34, 50, 56, 91], "skew": 47, "skill": [14, 31, 41], "skip": [0, 8, 14, 18, 22, 37, 50, 51, 53, 54, 59, 71, 74, 88, 91], "skip_server_warmup": [14, 21, 26, 27, 28, 29, 37, 38], "skip_special_token": [21, 23, 28, 37, 47], "skip_tokenizer_init": [14, 21, 26, 27, 28, 29, 37, 38], "skipper": 74, "sky": [14, 57, 71], "skyserv": 57, "skywork": [37, 58, 67, 98], "slack": [10, 52, 60, 71, 79], "slash": [52, 60], "sleep": [2, 22, 56, 82, 85, 91, 97], "sleep_on_idl": [14, 21, 26, 27, 28, 29, 37, 38], "sleev": 78, "slice": 91, "slice_span": 87, "slide": [1, 30, 71, 79, 85], "sliding_tile_attn": 91, "slight": 75, "slightli": [41, 75], "slime": [58, 85], "slo": 11, "slot": 14, "slow": [13, 19, 22, 24, 75, 88, 91], "slowdown": 50, "slower": [11, 22, 90], "slowli": 13, "slurm_log": 82, "slurm_nodeid": 82, "slurm_nodelist": 82, "slurm_procid": 82, "slytherin": 78, "sm": [22, 74, 80], "sm10": 22, "sm100": [22, 31, 74], "sm103": 57, "sm120": 91, "sm75": 57, "sm80": 91, "sm86": 91, "sm89": 91, "sm90": [22, 31, 74, 91], "sm_103a": 57, "sm_group_num": [14, 21, 26, 27, 28, 29, 37, 38], "sm_sglang_": 57, "sm_sglang_input_argu": 57, "sm_sglang_model_path": 57, "sm_sglang_reasoning_pars": 57, "small": [0, 3, 5, 11, 13, 14, 17, 22, 24, 25, 30, 31, 34, 51, 52, 60, 67, 75, 93, 96], "small3": 93, "smaller": [11, 13, 14, 17, 19, 22, 23, 52, 57, 60, 71, 75, 91, 98], "smallest": 47, "smg": 23, "smg_db_": 23, "smg_discovery_": 23, "smg_http_": 23, "smg_http_rate_limit_tot": 23, "smg_http_request_duration_seconds_bucket": 23, "smg_http_requests_tot": 23, "smg_http_responses_tot": 23, "smg_mcp_": 23, "smg_mcp_servers_act": 23, "smg_mcp_tool_calls_tot": 23, "smg_mcp_tool_duration_seconds_bucket": 23, "smg_router_": 23, "smg_router_generation_duration_second": 23, "smg_router_generation_duration_seconds_bucket": 23, "smg_router_requests_tot": 23, "smg_router_tokens_tot": 23, "smg_router_tpot_second": 23, "smg_router_tpot_seconds_bucket": 23, "smg_router_ttft_second": 23, "smg_router_ttft_seconds_bucket": 23, "smg_worker_": 23, "smg_worker_cb_": 23, "smg_worker_cb_st": 23, "smg_worker_cb_transitions_tot": 23, "smg_worker_connections_act": 23, "smg_worker_health_checks_tot": 23, "smg_worker_pool_s": 23, "smg_worker_requests_act": 23, "smg_worker_retries_exhausted_tot": 23, "smg_worker_retries_tot": 23, "smollm": [67, 93], "smooth": [41, 42, 43, 52, 60], "smoother": 22, "smoothli": 51, "snapshot": [14, 33, 37, 46, 99], "snapshot_download": 99, "snc": 68, "sneak": 14, "snippet": [28, 34, 51, 52, 60], "so": [0, 1, 3, 8, 13, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 37, 38, 41, 42, 43, 47, 48, 51, 52, 60, 68, 78, 91, 99], "social": 38, "socket": [2, 68, 80], "soft": [14, 22, 50], "soft_watchdog_timeout": [14, 21, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78], "softmax": [23, 37], "softwar": 94, "solar": 93, "solut": [3, 11, 17, 21, 22, 24, 57], "solv": [3, 17, 21], "some": [0, 1, 12, 13, 17, 18, 24, 25, 27, 28, 30, 38, 41, 49, 50, 51, 52, 53, 56, 57, 60, 80, 81, 86, 87, 91, 92, 93, 97, 98, 99], "somehow": 14, "someth": [14, 25, 27, 49], "sometim": [3, 15, 25, 27, 37, 75, 80, 97], "somewhat": [29, 43], "somewher": 27, "soon": [14, 18, 94, 96, 100], "sophia": 14, "sophist": [36, 38, 41], "sort": [14, 47, 97], "sota": 93, "sound": 14, "sourc": [4, 16, 24, 25, 26, 27, 34, 35, 38, 47, 49, 51, 54, 58, 62, 63, 78, 82, 86, 93, 96, 99], "south": [38, 48], "sp": 91, "sp_size": 91, "space": [11, 41, 45, 47, 50, 92, 95], "spaces_between_special_token": 47, "spain": [41, 78], "spam": [52, 60], "span": [11, 23, 51, 87, 93], "spark": [57, 58], "sparkl": 14, "spars": [31, 91, 93], "sparseautomodelforcausallm": 18, "speak": 75, "spec": [1, 22, 23, 25, 48, 63, 71, 80, 81, 84, 89], "spec_nam": 8, "speci": [37, 97], "special": [7, 21, 24, 27, 28, 31, 47, 54, 89, 93, 94, 96, 98], "specif": [1, 8, 10, 11, 17, 18, 19, 22, 23, 27, 30, 41, 47, 51, 52, 57, 60, 61, 72, 91, 93, 94, 96], "specifi": [1, 4, 6, 7, 11, 14, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 41, 42, 43, 46, 47, 48, 51, 56, 57, 59, 61, 68, 71, 73, 76, 78, 86, 87, 91, 92, 97], "specific_funct": 28, "specul": [7, 30, 31, 50, 58, 62, 63, 65, 85], "speculative_accept_threshold_acc": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_accept_threshold_singl": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_algorithm": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_attention_mod": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_draft_attention_backend": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_draft_load_format": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_draft_model_path": [14, 21, 25, 26, 27, 28, 29, 37, 38], "speculative_draft_model_quant": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_draft_model_revis": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_eagle_topk": [14, 21, 25, 26, 27, 28, 29, 37, 38], "speculative_moe_a2a_backend": [14, 21, 25, 26, 27, 28, 29, 37, 38], "speculative_moe_runner_backend": [14, 21, 25, 26, 27, 28, 29, 37, 38], "speculative_ngram_branch_length": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_capac": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_match_typ": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_max_bfs_breadth": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_max_match_window_s": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_min_bfs_breadth": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_ngram_min_match_window_s": [14, 21, 26, 27, 28, 29, 37, 38], "speculative_num_draft_token": [14, 21, 22, 25, 26, 27, 28, 29, 37, 38], "speculative_num_step": [14, 21, 25, 26, 27, 28, 29, 37, 38], "speculative_token_map": [14, 21, 26, 27, 28, 29, 37, 38], "speech": 93, "speed": [11, 22, 24, 25, 30, 31, 34, 45, 50, 75, 80, 91, 96], "speedup": [29, 30, 31, 85, 91], "spell": [25, 41], "spend": 38, "spent": 14, "spike": [7, 91], "split": [1, 4, 7, 8, 11, 14, 18, 21, 22, 23, 26, 27, 28, 29, 37, 38, 50, 52, 60], "split_kv": 1, "spoke": 14, "spot": 71, "spread": [14, 38], "sql": [14, 41], "sqrt": 99, "squar": 99, "src": [23, 49, 53, 84, 89], "srt": [1, 2, 12, 14, 15, 18, 21, 23, 25, 29, 30, 32, 37, 41, 42, 43, 47, 48, 78, 81, 89, 93, 96, 99, 100], "srun": 82, "ss": 91, "sse": [23, 34], "ssf": 23, "ssh": [39, 53], "ssm": [22, 45], "st": 57, "st_attn": 91, "stabil": [7, 17, 24, 30, 31, 85], "stabilityai": [67, 93], "stabl": [4, 41, 53, 57, 59, 91, 93], "stablelm": [67, 93], "stack": [23, 24, 25, 51, 74, 84, 85, 86, 91, 96], "stag": 78, "stage": [6, 7, 16, 17, 22, 23, 30, 31, 32, 34, 52, 60], "stage_duration_second": 23, "stai": [0, 17, 72, 74, 78], "stall": 24, "stand": [13, 14, 22, 29, 43, 78], "standalon": 22, "standard": [1, 4, 7, 8, 11, 21, 23, 38, 41, 71, 80, 89, 91, 99], "stanlei": 34, "star": [14, 41, 58], "starcod": 93, "starcoder2": 93, "starsfridai": 91, "start": [0, 12, 14, 15, 17, 18, 20, 21, 22, 28, 30, 31, 34, 37, 41, 47, 48, 51, 52, 57, 59, 60, 61, 64, 68, 70, 71, 72, 78, 80, 86, 87, 95, 99], "start_expert_distribution_record": 37, "start_profil": 50, "start_step": 51, "start_tag": [26, 27], "startswith": [47, 48], "startup": [8, 10, 14, 22, 23, 25, 31, 36, 37, 53, 59, 71, 80, 81, 84, 94], "startuppolici": 81, "starvat": 14, "stat": [22, 23, 25, 37], "state": [8, 11, 13, 14, 22, 23, 24, 25, 26, 27, 28, 30, 38, 41, 45, 47, 48, 52, 60, 74, 78, 80, 85, 91, 93], "statefulset": 57, "statement": [38, 99], "static": [7, 10, 16, 17, 22, 24, 25, 30, 31, 32, 33, 35, 36, 46, 49, 51, 62, 63, 64, 65, 70, 71, 75, 80, 81, 84, 91], "static_cast": 49, "static_config": 86, "statist": [7, 18, 23, 50, 74], "statu": [23, 24, 26, 27, 37, 49, 53, 57, 71, 78, 80, 86, 89, 91], "status_cod": 14, "std": 50, "stdin": 57, "stdio": 23, "stdout": 22, "steadi": 13, "steadili": 27, "step": [0, 11, 14, 17, 18, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 35, 38, 45, 51, 52, 53, 57, 60, 62, 63, 65, 68, 71, 74, 80, 88, 99], "step3": [22, 23, 28], "still": [6, 12, 13, 14, 16, 22, 27, 28, 31, 34, 37, 41, 81, 87, 91], "stochast": 4, "stock": 34, "stop": [11, 12, 13, 22, 25, 26, 27, 37, 41, 43, 47, 48, 51, 78, 86], "stop_after_first": 26, "stop_expert_distribution_record": 37, "stop_profil": 50, "stop_regex": 47, "stop_str": 73, "stop_token_id": 47, "storag": [9, 19, 22], "storagebackendfactori": 12, "store": [8, 10, 11, 12, 22, 23, 45, 49, 51, 63, 87], "stori": [29, 39, 41], "str": [8, 14, 22, 23, 24, 26, 27, 28, 47, 99], "straightforward": [13, 23, 25, 27], "strateg": 7, "strategi": [11, 13, 14, 16, 17, 22, 23, 24, 45, 90, 91], "strawberri": [38, 41], "stream": [17, 22, 23, 26, 27, 30, 39, 41, 49, 74, 90, 99], "stream_and_merg": 38, "stream_interv": [14, 21, 26, 27, 28, 29, 37, 38], "stream_output": [14, 21, 26, 27, 28, 29, 37, 38], "stream_reason": 21, "streamabl": 23, "streamlin": [18, 36, 92], "streams_per_devic": [62, 63, 65], "street": [25, 29, 43, 91, 97], "strength": [78, 91], "stretch": 78, "strict": [50, 74], "stricter": 12, "strictli": [12, 14, 17, 22], "stride": [25, 49], "string": [4, 8, 11, 13, 14, 22, 23, 24, 26, 27, 28, 29, 30, 37, 41, 47, 89, 91, 97], "strip": [47, 48], "strong": [7, 11, 14, 34, 38, 46, 76, 93, 96], "strongest": 11, "strongli": [7, 18, 41, 49, 54, 59], "struct": 49, "structal": 47, "structur": [7, 11, 17, 22, 23, 24, 28, 58, 74, 78, 87, 91, 96], "structural_tag": [26, 27, 47], "stuck": [23, 80], "student": 78, "studi": 14, "studio": 53, "stumbl": 14, "stun": 38, "stunt": 78, "style": [22, 23, 24, 25, 41, 50, 91, 100], "style_lora": 91, "styliz": 43, "sub": [30, 37, 68], "subclass": [7, 21], "subcommand": 91, "subdirectori": 0, "subdomainpolici": 81, "subject": [23, 38, 91], "submit": [13, 50, 52, 54, 60, 82], "submodul": 8, "suboptim": 6, "subprocess": [22, 42, 43, 48], "subsequ": [3, 11, 17, 24, 71], "subset": [76, 91, 97], "substanti": [11, 16], "suburb": 27, "succe": 81, "succeed": [12, 24, 37], "success": [12, 14, 23, 24, 37, 53, 59], "successfulli": [11, 14, 57, 61, 80, 86], "successor": 93, "successthreshold": 84, "sudo": [59, 61, 70], "suffer": 24, "suffici": [11, 13, 49, 71, 96], "suffix": [52, 60], "suggest": [10, 13, 18, 26, 29, 33, 46, 54, 63, 70], "suit": 91, "suitabl": [11, 17, 22, 97], "sum": [21, 23, 34, 37], "summar": [78, 90, 93, 96], "summari": [23, 50, 78], "sun": 97, "sunni": 41, "sunset": [91, 97], "super": [93, 99], "supercharg": 59, "superior": [71, 93], "suppli": [19, 22, 23, 30, 76], "support": [2, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 42, 43, 45, 46, 47, 49, 51, 52, 57, 59, 60, 64, 66, 70, 72, 74, 76, 78, 80, 85], "suppos": [14, 49], "sure": [0, 3, 21, 25, 27, 28, 41, 48, 51, 52, 60, 61, 78, 80, 99], "surg": 34, "surpass": 93, "surprisingli": 93, "surround": 14, "sustain": 78, "suv": 78, "svc": [81, 84], "swa": [22, 35], "swa_full_tokens_ratio": [14, 21, 26, 27, 28, 29, 37, 38], "swa_siz": 22, "swagger": 48, "swap": 3, "swappi": [61, 62, 63], "switch": [7, 10, 12, 14, 17, 21, 22, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 50, 57, 78, 80, 100], "switzerland": [37, 38], "sy": [59, 61, 62, 63, 84], "symbol": [27, 49, 91], "symbolic_correct": 31, "symbolicdevic": 49, "symbolicdtyp": 49, "symbolics": 49, "symm": [22, 74], "symmetr": [22, 74], "sync": [17, 24, 53, 74], "sync_duration_second": 23, "synchron": [10, 14, 17, 23, 30, 52, 60], "syntact": 22, "syntax": [14, 23, 27, 41], "synthet": 50, "sys_ptrac": 59, "sysctl": [61, 62, 63], "system": [2, 7, 9, 10, 14, 16, 18, 22, 26, 27, 28, 29, 34, 38, 41, 47, 49, 50, 54, 58, 62, 63, 68, 73, 74, 78, 80, 81, 84, 85, 86, 90, 93, 97, 99], "system_fingerprint": [25, 28, 41, 48], "systemat": 71, "systemcut": 26, "systemprompt": 10, "t": [1, 8, 14, 17, 22, 23, 25, 27, 28, 29, 31, 34, 35, 38, 39, 41, 47, 51, 52, 53, 57, 59, 60, 61, 68, 74, 78, 80, 96, 99], "t2v": 91, "t4": 57, "t_": 25, "t_2": 25, "tabl": [1, 4, 22, 68, 72, 74, 90, 91, 93, 96, 99], "tag": [8, 21, 22, 23, 24, 28, 31, 39, 47, 52, 60, 61, 74], "tail": [17, 24], "tailgat": 78, "tailor": [16, 33, 46], "taint": [81, 84], "take": [0, 1, 8, 13, 14, 16, 17, 18, 22, 23, 25, 30, 37, 41, 51, 52, 53, 59, 60, 68, 71, 80, 91, 95, 99], "taken": 38, "tale": 14, "talk": 14, "tall": [14, 29], "taller": 14, "tar": 53, "target": [1, 7, 8, 14, 17, 18, 22, 23, 25, 34, 50, 51, 74, 86], "target_modul": 22, "target_pattern": 8, "targetport": [80, 81, 84], "tarn59": 91, "task": [2, 19, 24, 35, 36, 37, 38, 39, 41, 52, 60, 82, 89, 91, 92, 93, 96, 97, 98], "task_queue_en": [62, 63], "task_typ": 91, "taxi": [29, 43, 78], "taylor": 91, "tbo": 22, "tbo_token_distribution_threshold": [14, 21, 26, 27, 28, 29, 37, 38], "tcp": [12, 16, 23, 61, 62, 63, 80, 81, 84], "tcpsocket": [80, 81], "teacach": 91, "teach": 14, "teacher": 78, "team": [18, 24, 30, 53, 91], "tech": 31, "technic": [14, 26, 31, 85], "techniqu": [7, 11, 14, 17, 18, 19, 22, 71, 91, 92], "technologi": [23, 38, 80], "tee": [51, 61, 62, 63], "tele": 93, "teleai": 93, "tell": [4, 34, 38, 39, 41, 51, 86], "temp": 4, "temperatur": [14, 18, 21, 22, 25, 26, 27, 28, 30, 31, 37, 38, 41, 43, 47, 48, 50, 78, 90, 94, 99], "templat": [14, 21, 22, 23, 30, 31, 35, 37, 41, 47, 49, 50, 58, 81, 84, 92, 96, 97, 99], "tempor": 96, "temporari": [16, 49], "temporarili": [23, 74], "tenant": 23, "tend": 80, "tensor": [3, 5, 8, 11, 13, 14, 17, 19, 20, 33, 46, 51, 52, 58, 60, 64, 68, 71, 74, 80, 81, 84, 91, 94, 96, 98, 99], "tensormatch": 49, "tensorrt": [7, 22, 50], "tensorview": 49, "term": [11, 22], "termin": [2, 10, 11, 14, 21, 23, 24, 25, 26, 27, 28, 33, 37, 41, 42, 43, 46, 48, 51, 53, 57, 59, 68, 72, 78], "terminate_process": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78], "terminu": 31, "terrain": 14, "terrifi": 14, "test": [1, 2, 4, 14, 19, 21, 22, 25, 26, 27, 28, 33, 34, 37, 38, 41, 42, 43, 46, 48, 49, 51, 54, 56, 62, 64, 68, 70, 78, 80, 82, 91, 96, 97], "test_add_const": 49, "test_classify_api": 89, "test_determinist": 4, "test_eagle_infer_a": [52, 60], "test_eagle_infer_b": [52, 60], "test_eval_accuracy_larg": [52, 60], "test_generation_model": 99, "test_gpt_oss_1gpu": 52, "test_moe_eval_accuracy_larg": 60, "test_oth": 99, "test_vision_openai_server_": 99, "test_vision_openai_server_a": 99, "test_vision_openai_server_b": 99, "testgenerationmodel": 99, "text": [4, 5, 14, 18, 21, 22, 23, 25, 26, 27, 28, 29, 33, 36, 38, 39, 41, 42, 43, 46, 47, 48, 50, 89, 90, 91, 92, 93, 94, 96, 99], "text_complet": 41, "text_embed": 42, "text_encod": 91, "text_encoder_precis": 91, "text_input": 92, "text_it": 78, "text_qa": 78, "textual": [5, 99], "textur": 5, "th": 22, "than": [11, 13, 14, 16, 17, 18, 19, 22, 23, 25, 27, 31, 36, 37, 47, 52, 57, 60, 68, 78, 91, 95, 97, 99], "thank": [25, 52, 60, 70, 80, 82], "theater": 38, "thei": [0, 7, 8, 14, 16, 17, 27, 29, 41, 43, 47, 68, 74, 80, 86, 93, 96, 98, 99], "them": [1, 5, 7, 15, 18, 24, 30, 34, 37, 50, 52, 53, 59, 60, 68, 74, 75, 81, 86, 87, 91, 96, 99], "themselv": [14, 29], "therebi": 11, "therefor": [11, 13, 14, 17, 21, 37, 41, 91], "thi": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 62, 63, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100], "thing": [13, 38, 99, 100], "think": [4, 21, 22, 23, 24, 25, 27, 28, 31, 36, 45, 54, 67, 81, 84, 90, 93, 96], "think_end_token": 27, "thinking_budget": [30, 32], "third": [34, 38, 41], "thorough": 27, "thoroughli": 99, "those": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78, 91], "though": [12, 17, 27, 29], "thought": [23, 38], "thousand": 11, "thread": [12, 14, 16, 21, 22, 23, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 48, 78, 87], "thread_finish_flag": 87, "thread_label": 87, "thread_span": 87, "threadidx": 49, "threadpool": 22, "three": [1, 4, 6, 10, 11, 24, 25, 26, 27, 41, 47, 48, 78], "threshold": [11, 15, 22, 23, 31, 74, 90, 91], "threshold_acc": 22, "thrill": 14, "thrive": 38, "throne": 14, "through": [7, 11, 14, 17, 23, 28, 29, 30, 31, 41, 49, 50, 51, 52, 59, 60, 61, 68, 71, 79, 91, 96], "throughout": 23, "throughput": [5, 7, 14, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 37, 41, 42, 43, 46, 48, 50, 52, 54, 58, 60, 75, 78, 85, 86, 91, 93, 96, 97, 99], "thrown": 27, "thu": [14, 17, 31, 41, 53, 91, 96, 99, 100], "thudm": 93, "thumb": 13, "thunlp": 25, "ti2v": 91, "tier": [6, 10, 11, 23], "tightli": 6, "tiktoken": [23, 41], "tile": 22, "tile_sample_min_height": 91, "tile_sample_min_width": 91, "tilelang": [22, 31], "time": [0, 1, 2, 3, 7, 11, 13, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 30, 31, 33, 37, 38, 41, 42, 46, 47, 49, 50, 51, 52, 53, 54, 60, 68, 74, 75, 80, 82, 86, 99], "time_per_output_token_second": 86, "time_per_output_token_seconds_bucket": 86, "time_per_output_token_seconds_count": 86, "time_per_output_token_seconds_sum": 86, "time_to_first_token_second": 86, "time_to_first_token_seconds_bucket": 86, "time_to_first_token_seconds_count": 86, "time_to_first_token_seconds_sum": 86, "timelin": 51, "timeout": [10, 11, 12, 16, 17, 22, 23, 30, 31, 33, 35, 46, 62, 63, 65, 74, 84], "timeoutsecond": 84, "timestamp": [50, 89], "timestep": [25, 91], "timezon": [26, 27], "tin": 38, "tini": 91, "tinyllama": 18, "tip": [0, 12, 17, 49, 75, 78], "tip_suggest": 78, "tire": 14, "titl": [38, 99], "tl": 25, "tlsv1": 23, "tmp": [15, 22, 23, 51, 56, 71, 74, 87], "tmp_autoround": 18, "tn": 23, "to_stat": 23, "to_str": [30, 32, 47], "todai": [28, 30, 36, 41], "todo": [12, 61], "tofu": 78, "togeth": [3, 11, 14, 16, 18, 21, 22, 23, 25, 26, 27, 28, 31, 37, 41, 42, 43, 48, 74, 78, 91, 96], "tok": [50, 54], "token": [1, 3, 6, 7, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 28, 32, 35, 36, 42, 45, 47, 54, 57, 59, 62, 63, 65, 68, 71, 73, 74, 80, 81, 84, 86, 87, 89, 90, 91, 93, 96, 97, 99], "token_capac": 37, "token_id": [37, 41, 47], "token_ids_logprob": 47, "token_idx": [22, 31], "token_length_norm": 76, "token_step": 24, "token_usag": 86, "tokenization_result": 37, "tokenize_payload": 37, "tokenize_respons": 37, "tokenize_url": 37, "tokenizer_communicator_mixin": 12, "tokenizer_free_server_process": 37, "tokenizer_manag": 28, "tokenizer_metrics_allowed_custom_label": [14, 21, 26, 27, 28, 29, 37, 38], "tokenizer_metrics_custom_labels_head": [14, 21, 26, 27, 28, 29, 37, 38], "tokenizer_mod": [14, 21, 26, 27, 28, 29, 37, 38], "tokenizer_path": [14, 21, 26, 27, 28, 29, 37, 38], "tokenizer_worker_num": [14, 21, 26, 27, 28, 29, 37, 38], "tokenizermanag": [12, 14, 37], "tokenizers_parallel": [26, 27, 42], "tokens_to_gener": 31, "tokens_tot": 23, "tokyo": [14, 25, 28, 41, 78], "tokyo3": 78, "told": 14, "toler": [16, 19, 23, 24, 81, 84], "tolist": 29, "toml": [11, 22, 52, 55, 59, 60, 61, 68, 69, 72], "tone": 38, "tongyi": 91, "too": [13, 14, 17, 23, 27, 30, 38, 50, 52, 60, 71], "took": [14, 37], "tool": [8, 21, 22, 24, 26, 27, 30, 31, 32, 36, 38, 51, 57, 58, 78, 87, 93, 96], "tool_cal": [25, 28, 30, 41, 43, 48, 81, 84], "tool_call_id": 28, "tool_call_pars": [14, 21, 26, 27, 28, 29, 37, 38], "tool_calls_tot": 23, "tool_chat_template_deepseekv3": [28, 30], "tool_chat_template_deepseekv31": 28, "tool_chat_template_deepseekv32": 31, "tool_chat_template_llama4_python": 28, "tool_choic": 28, "tool_dict": 28, "tool_duration_second": 23, "tool_get_current_d": [26, 27], "tool_get_current_weath": [26, 27], "tool_iterations_tot": 23, "tool_nam": 28, "tool_serv": [14, 21, 26, 27, 28, 29, 37, 38], "tool_to_cal": 28, "tool_ttl": 23, "tool_us": [22, 78], "toolcallitem": 28, "toolchain": 23, "toolkit": [61, 62, 63, 70], "toolkit_aarch64_20251121": 61, "tools_tag_list": 28, "top": [11, 25, 28, 31, 38, 47, 52, 60, 85, 93], "top_k": [14, 37, 41, 47, 99], "top_logprobs_num": 47, "top_p": [14, 18, 21, 22, 26, 27, 28, 31, 37, 38, 41, 47, 50, 94], "topk": [1, 7, 22, 25, 30, 31, 32, 35, 45, 62, 63, 65, 71, 74], "topkoutput": 7, "topo": 84, "topologi": [23, 84], "torch": [1, 7, 13, 14, 16, 22, 24, 30, 37, 42, 49, 51, 57, 61, 68, 72, 74, 80, 99, 100], "torch_compile_caching_tutori": 88, "torch_compile_max_b": [14, 21, 26, 27, 28, 29, 37, 38], "torch_dtyp": [18, 29], "torch_empty_cach": 24, "torch_log": 25, "torch_memory_sav": 24, "torch_n": [1, 22, 37, 92, 97], "torch_npu": 61, "torch_npu_vers": 61, "torch_sdpa": 91, "torchao": [22, 68, 72], "torchao_config": [14, 21, 26, 27, 28, 29, 37, 38], "torchaudio": [68, 72], "torchinductor_cache_dir": [22, 88], "torchinductor_root": 22, "torchrun": 2, "torchvis": [57, 61, 68, 72], "torchvision_vers": 61, "total": [11, 13, 14, 16, 17, 22, 23, 24, 31, 36, 41, 50, 51, 62, 68, 89, 93, 97], "total_input_token": 50, "total_kv_token": 31, "total_output_token": 50, "total_q_token": 31, "total_request": 22, "total_retract": [26, 27, 37, 48], "total_token": [22, 23, 25, 28, 30, 41, 42, 43, 48, 81, 84, 89], "toulous": 27, "tourism": 38, "tourist": [27, 28, 38], "toward": [17, 34, 47, 96, 98], "tower": [25, 27, 38], "town": [27, 37], "tp": [1, 5, 7, 10, 11, 16, 17, 22, 23, 24, 28, 30, 31, 32, 33, 34, 35, 36, 41, 45, 46, 51, 53, 54, 59, 61, 62, 63, 65, 68, 71, 72, 80, 81, 82, 84, 91, 94, 98], "tp0": 80, "tp1": 80, "tp16": 82, "tp2": 80, "tp3": 80, "tp4": 80, "tp5": 80, "tp6": [68, 80], "tp7": 80, "tp8": 30, "tp_rank": 87, "tp_size": [7, 11, 14, 21, 26, 27, 28, 29, 31, 37, 38, 62, 82, 91, 94], "tpot": [50, 62], "tpot_second": 23, "tpu": [57, 58], "tpu_vm": 71, "tpuv6": 71, "tqdm": 50, "tr": 51, "trace": [15, 22, 25, 50, 58, 74, 80], "trace_context": 87, "trace_get_proc_propagate_context": 87, "trace_get_remote_propagate_context": 87, "trace_req_finish": 87, "trace_req_start": 87, "trace_set_proc_propagate_context": 87, "trace_set_remote_propagate_context": 87, "trace_set_thread_info": 87, "trace_slice_end": 87, "trace_slice_start": 87, "tracing_compos": 87, "track": [11, 22, 23, 24, 31, 35, 37, 51, 87, 89], "trade": [7, 23, 24, 34, 45, 92], "tradeoff": 22, "tradit": [10, 17, 29], "tradition": 16, "traffic": [12, 23, 24, 54, 71, 86], "trail": 27, "train": [4, 18, 22, 24, 25, 28, 31, 37, 38, 51, 58, 78, 92, 93, 96], "trainer": 24, "trait": [3, 38], "trajectori": 34, "transfer": [2, 6, 7, 10, 14, 16, 17, 20, 22, 53, 61, 62, 63, 87], "transfer_engin": [20, 22], "transferengin": 11, "transform": [3, 5, 14, 17, 18, 21, 22, 25, 26, 27, 28, 29, 34, 37, 38, 41, 42, 43, 48, 50, 58, 73, 78, 91, 93, 96, 99], "transformer_2": 91, "transformersmodel": 100, "transit": [23, 41, 42, 43], "transitions_tot": 23, "transpar": [27, 38], "transport": [33, 38, 46], "travel": [28, 38], "travers": 11, "treacher": 14, "treat": [37, 38, 74], "tree": [14, 22, 23, 25, 37, 71], "tree_cach": 12, "trend": [38, 99], "trial": 4, "tricki": 27, "trigger": [11, 22, 26, 27, 37, 51, 68, 74], "triggered_tag": 26, "trillion": [17, 93], "trim": [28, 47], "triniti": 93, "trip": 28, "triton": [1, 4, 7, 14, 22, 30, 35, 37, 57, 68, 72, 74, 92, 97], "triton_3_5_1": 37, "triton_ascend": 61, "triton_attention_num_kv_split": [14, 21, 26, 27, 28, 29, 37, 38], "triton_attention_reduce_in_fp32": [14, 21, 26, 27, 28, 29, 37, 38], "triton_attention_split_tile_s": [14, 21, 26, 27, 28, 29, 37, 38], "triton_attn": 22, "triton_backend": 1, "triton_kernel": [7, 22], "triton_mm_10": 25, "triton_mm_102": 25, "triton_mm_103": 25, "triton_mm_106": 25, "triton_mm_107": 25, "triton_mm_11": 25, "triton_mm_111": 25, "triton_mm_113": 25, "triton_mm_114": 25, "triton_mm_115": 25, "triton_mm_116": 25, "triton_mm_119": 25, "triton_mm_12": 25, "triton_mm_120": 25, "triton_mm_123": 25, "triton_mm_124": 25, "triton_mm_128": 25, "triton_mm_130": 25, "triton_mm_133": 25, "triton_mm_136": 25, "triton_mm_137": 25, "triton_mm_139": 25, "triton_mm_14": 25, "triton_mm_140": 25, "triton_mm_141": 25, "triton_mm_142": 25, "triton_mm_145": 25, "triton_mm_147": 25, "triton_mm_148": 25, "triton_mm_149": 25, "triton_mm_150": 25, "triton_mm_153": 25, "triton_mm_154": 25, "triton_mm_157": 25, "triton_mm_158": 25, "triton_mm_162": 25, "triton_mm_167": 25, "triton_mm_17": 25, "triton_mm_170": 25, "triton_mm_171": 25, "triton_mm_172": 25, "triton_mm_173": 25, "triton_mm_174": 25, "triton_mm_175": 25, "triton_mm_176": 25, "triton_mm_179": 25, "triton_mm_18": 25, "triton_mm_20": 25, "triton_mm_22": 25, "triton_mm_23": 25, "triton_mm_26": 25, "triton_mm_27": 25, "triton_mm_30": 25, "triton_mm_31": 25, "triton_mm_36": 25, "triton_mm_37": 25, "triton_mm_4": 25, "triton_mm_45": 25, "triton_mm_46": 25, "triton_mm_47": 25, "triton_mm_48": 25, "triton_mm_49": 25, "triton_mm_50": 25, "triton_mm_54": 25, "triton_mm_55": 25, "triton_mm_56": 25, "triton_mm_58": 25, "triton_mm_60": 25, "triton_mm_61": 25, "triton_mm_64": 25, "triton_mm_65": 25, "triton_mm_68": 25, "triton_mm_69": 25, "triton_mm_7": 25, "triton_mm_74": 25, "triton_mm_75": 25, "triton_mm_8": 25, "triton_mm_83": 25, "triton_mm_84": 25, "triton_mm_85": 25, "triton_mm_87": 25, "triton_mm_88": 25, "triton_mm_89": 25, "triton_mm_92": 25, "triton_mm_93": 25, "triton_mm_94": 25, "triton_mm_96": 25, "triton_mm_97": 25, "triton_mm_98": 25, "triton_mm_99": 25, "triton_ptxas_path": 57, "tritonattn": 3, "tritonrunnercor": 7, "trivial": [14, 21, 22, 24, 26, 27, 28, 29, 37, 38], "troubleshoot": [58, 80], "trt": [7, 31, 50], "trtllm": [1, 22, 30], "trtllm_mha": [1, 22, 35], "trtllm_mla": [1, 22], "truck": 29, "true": [1, 12, 13, 14, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 37, 38, 39, 41, 42, 43, 46, 47, 48, 50, 51, 56, 62, 63, 65, 71, 74, 78, 80, 81, 84, 86, 87, 90, 91, 92, 95, 97, 99, 100], "truncat": [22, 25, 51, 92], "truss": 50, "trust": [1, 14, 16, 17, 22, 23, 25, 30, 31, 33, 35, 36, 46, 52, 53, 59, 60, 61, 62, 63, 65, 68, 71, 72, 80, 81, 84, 85, 91, 92, 96, 97, 98], "trust_remote_cod": [14, 18, 21, 26, 27, 28, 29, 37, 38, 90, 100], "trustworthi": 27, "truth": 24, "try": [8, 11, 18, 22, 27, 30, 37, 52, 57, 60, 61, 75, 80], "tse": 22, "ttft": [5, 14, 16, 17, 31, 33, 50, 54, 71, 99], "ttft_second": 23, "tune": [7, 11, 14, 22, 25, 28, 31, 33, 46, 58, 59, 72, 81, 85, 88, 91, 93, 98], "tuned_8sm": 81, "tunix": [58, 85], "tunnel": [39, 53], "tupl": 8, "turbo": [41, 91], "turn": [8, 10, 23, 24, 30, 62], "tutori": [26, 29, 41, 42, 43, 88], "tvm": 49, "tvm_ffi": 49, "twice": [11, 75], "twine": 55, "twitter": 79, "two": [1, 2, 5, 8, 10, 11, 13, 14, 16, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 38, 43, 45, 47, 53, 57, 73, 74, 75, 78, 80, 81, 82, 87, 91, 97, 99, 100], "txt": 0, "type": [4, 7, 8, 12, 14, 19, 23, 24, 26, 27, 28, 30, 33, 34, 36, 37, 38, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 60, 63, 71, 81, 84, 86, 89, 90, 91, 96, 97, 99], "type_check": 49, "typic": [3, 5, 6, 13, 14, 17, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 35, 37, 38, 41, 42, 43, 48, 49, 50, 52, 57, 60, 61, 68, 71, 78, 80, 91], "typo": [25, 27], "u": [3, 14, 28, 34, 71, 76, 81, 85, 99], "ubuntu": [49, 51, 61, 68, 80], "ubuntu1804": 51, "ubuntu22": [56, 61], "ucx": 16, "ud": 2, "ui": [48, 51, 86, 87, 91], "ultra": [11, 91, 93], "ulyss": 91, "ulysses_degre": 91, "ulyssesattent": 91, "unabl": 99, "unavail": [22, 91], "uncach": 4, "unchang": 47, "unconditional_likelihood_norm": 76, "unconfin": 59, "undaunt": 14, "under": [0, 6, 8, 11, 14, 22, 24, 28, 38, 51, 52, 60, 71, 72, 74, 75, 86, 91, 93, 99], "underli": [3, 17], "understand": [0, 11, 14, 37, 52, 60, 71, 87, 93, 96], "understood": 5, "underutil": 17, "unexpect": 14, "unicod": 23, "unifi": [6, 7, 14, 23, 30, 41, 85, 91], "uniform": [17, 22, 23, 91], "uniformli": 31, "unintend": [38, 47], "union": [14, 22, 47], "uniqu": [4, 29, 38, 89, 91], "unit": [14, 23, 26, 27, 28, 38, 41, 48, 78], "unittest": [52, 60, 99], "univers": 41, "unix": [2, 89], "unknown": 74, "unless": [1, 25, 50], "unlik": [19, 24, 25, 49, 90], "unload": 14, "unload_lora_adapt": 14, "unlock": [7, 23], "unmerge_lora_weight": 91, "unnecessari": 38, "unpermut": 7, "unpin": 14, "unquant": 62, "unrel": 11, "unrestrict": 47, "unset": [22, 62, 63], "unsloth": 85, "unspecifi": [1, 22, 50], "unstabl": 3, "unsuccess": 24, "unsupport": 25, "unsur": [93, 96], "until": [13, 14, 17, 30, 47, 51, 71, 82], "untrust": 23, "unus": 84, "unusu": [29, 43, 78], "unwrap": 49, "up": [7, 11, 13, 14, 16, 17, 20, 22, 27, 29, 30, 34, 35, 36, 37, 43, 51, 52, 57, 59, 60, 68, 70, 72, 80, 85, 86, 87, 91, 93], "up_proj": [14, 22], "upcast": [18, 30], "upcom": [31, 34], "updat": [2, 3, 10, 12, 14, 17, 18, 22, 23, 28, 36, 51, 56, 74, 75, 79, 86, 99], "update_weight": 37, "update_weights_from_disk": [24, 37], "update_weights_from_distribut": 24, "update_weights_from_tensor": 24, "upgrad": [31, 56, 57, 59, 68, 69, 72, 91, 97], "upload": [23, 91], "upload_pypi": 55, "upon": [11, 14, 37, 41, 42, 86, 87, 94, 96], "upper": 11, "upsid": 34, "upstag": 93, "upstream": [12, 23, 91], "upstream_responses_tot": 23, "upward": 34, "urban": [29, 43, 78], "urgent": [52, 60], "url": [6, 14, 15, 22, 23, 25, 29, 33, 34, 37, 43, 46, 47, 48, 50, 51, 57, 61, 68, 71, 72, 86, 87, 91, 92, 96, 97], "us": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 45, 46, 47, 50, 52, 56, 58, 60, 69, 73, 76, 78, 80, 81, 82, 85, 86, 87, 88, 90, 92, 93, 94, 96, 97, 98, 99, 100], "us_president_exampl": 76, "usabl": [18, 70, 93], "usag": [3, 10, 22, 24, 25, 28, 29, 32, 37, 39, 42, 43, 47, 48, 49, 52, 60, 70, 71, 75, 76, 80, 81, 84, 97], "use_fast": 29, "use_fast_accum": 25, "use_mla_backend": 37, "user": [4, 7, 11, 13, 14, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 41, 43, 46, 47, 48, 51, 52, 54, 60, 68, 73, 76, 78, 81, 84, 85, 89, 91, 92, 94, 96, 97], "usernam": [57, 86], "userwarn": 25, "usp": 91, "uspattent": 91, "usr": [14, 21, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 57, 61, 62, 63, 68, 78], "usual": [17, 27, 41, 57, 68, 86, 97], "utf": [47, 48], "util": [5, 6, 7, 11, 13, 14, 17, 21, 22, 24, 25, 26, 27, 28, 29, 37, 38, 41, 42, 43, 47, 48, 59, 68, 71, 78, 80, 85, 91, 92], "uuid": 23, "uv": [16, 34, 68, 71], "uv_config_fil": 68, "uvicorn": [14, 22, 37, 80], "uvicorn_access_log_exclude_prefix": [14, 21, 26, 27, 28, 29, 37, 38], "v": [4, 7, 14, 18, 23, 24, 37, 49, 53, 56, 57, 59, 67, 68, 72, 89, 91, 93, 95, 96, 99], "v0": [28, 31, 35, 37, 56, 57, 59, 61, 67, 80, 91, 93, 98], "v01": [67, 93], "v1": [14, 18, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 46, 47, 48, 50, 67, 80, 81, 84, 87, 89, 91, 92, 93, 96, 97], "v1_5": 93, "v1alpha1": 84, "v2": [7, 22, 25, 37, 50, 67, 71, 93, 96, 97], "v3": [1, 7, 16, 18, 21, 22, 28, 44, 53, 54, 62, 67, 84, 93, 94, 96], "v32": [31, 84], "v6e": 71, "v7": 71, "v_cach": 49, "v_proj": [14, 22], "v_scale": 19, "vae": 91, "vae_config": 91, "vae_path": 91, "vae_precis": 91, "vae_sp": 91, "vae_til": 91, "valid": [0, 2, 4, 18, 22, 26, 27, 28, 31, 47, 49, 51, 52, 59, 60, 71, 74, 91, 92, 97], "valu": [3, 6, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 41, 46, 47, 49, 51, 52, 57, 60, 63, 68, 74, 75, 80, 81, 84, 90, 91, 96, 97], "valuabl": 99, "value1": [22, 28], "value2": [22, 28], "value_st": 100, "valueerror": [8, 37], "valuefrom": [81, 84], "vanilla": [38, 91], "var": [61, 84], "vari": [3, 4, 7, 19, 24, 27, 50], "variabl": [3, 10, 14, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 42, 43, 48, 49, 50, 51, 56, 57, 58, 68, 71, 78, 80, 86, 87, 94, 95, 99], "varianc": [7, 24, 52, 60], "variant": [3, 7, 21, 51, 57, 67, 93, 96, 98], "variat": 17, "varieti": [1, 38, 78], "variou": [1, 11, 16, 18, 27, 38, 41, 43, 67, 74], "varlen": 31, "vast": 93, "vc_task_index": 62, "ve": [27, 80], "vector": [25, 30, 52, 60, 92], "veget": 78, "vehicl": [29, 38, 78], "veil": 14, "vendetta": 14, "vendor": [23, 62], "venom": 78, "venv": [68, 71], "verb": 23, "verbos": [15, 22], "veri": [3, 5, 13, 14, 17, 27, 31, 33, 38, 43, 46, 47, 52, 60, 75, 99], "verif": [1, 22, 25, 30, 31, 32, 34, 49, 54, 74], "verifi": [1, 2, 4, 14, 19, 22, 23, 27, 31, 49, 50, 54, 59, 68, 70, 71, 72, 74, 86, 89], "verl": [24, 58, 85], "versatil": [93, 96], "version": [2, 22, 23, 24, 30, 37, 38, 45, 52, 53, 57, 60, 68, 71, 72, 74, 78, 80, 94, 96, 97], "versu": 24, "vertic": 23, "via": [6, 7, 8, 10, 12, 14, 15, 16, 18, 19, 20, 22, 23, 24, 31, 34, 37, 47, 50, 51, 52, 60, 68, 71, 72, 86, 87, 90, 93, 96], "vibrant": [25, 38, 58], "victor": 14, "vicuna": 96, "video": [3, 22, 54, 56, 59, 79, 97], "video_data": 96, "video_id": 91, "video_pruning_r": 96, "video_sparse_attn": 91, "video_url": [33, 46, 96, 97], "videomm": 54, "view": [0, 28, 29, 80, 86, 87], "vigor": 78, "vill": 38, "vim": 68, "vine": 14, "virtual": [14, 21, 24, 25, 26, 27, 28, 29, 31, 37, 38, 41, 42, 43, 48, 68, 78], "virtualenv": 23, "visibl": [51, 74], "vision": [3, 5, 6, 40, 41, 46, 47, 48, 50, 67, 93, 96, 99, 100], "vision_end": 29, "vision_flat": 29, "vision_model": 29, "vision_process": 43, "vision_start": 29, "visionattent": 99, "visit": [18, 71], "visitor": 38, "visual": [3, 5, 29, 47, 51, 53, 87, 91, 96], "visualstudio": 53, "vit": [3, 5, 6, 33, 67, 92, 96, 99], "vital": 7, "vitamin": 78, "vitcudagraphrunn": 3, "vl": [3, 5, 18, 28, 43, 44, 50, 51, 61, 67, 78, 92, 96], "vl2": [67, 96], "vllm": [18, 50, 51, 67, 89], "vlm": [5, 6, 18, 22, 24, 38, 50, 58, 85, 96, 99], "vlm1": 96, "vm": [59, 61, 62, 63, 71], "vmoba": 91, "vmoba_attn": 91, "vocab": 22, "vocabulari": [22, 25], "voic": 14, "void": 49, "volum": [53, 61, 80, 81, 84], "volumemount": [80, 81, 84], "vram": 3, "vsa": 91, "vscode_cli_alpine_x64_cli": 53, "vulner": 38, "vx": 57, "w": [25, 26, 27, 41, 47, 61, 62, 63, 78, 91], "w2a16": 18, "w3a16": 18, "w3c": 23, "w4a16": [18, 64], "w4a4": 64, "w4a8": [30, 62, 63, 64], "w4a8_awq": 22, "w4afp8": 22, "w8a16": [18, 64], "w8a8": [30, 62, 63, 64, 67, 68], "w8a8_fp8": [18, 22], "w8a8_int8": [18, 22, 68], "w8a8fp8config": 18, "wa": [14, 17, 27, 28, 34, 41, 51, 80, 89], "wai": [0, 2, 3, 14, 17, 27, 28, 29, 38, 49, 51, 61, 72, 78, 91, 99], "wait": [2, 10, 11, 12, 14, 17, 22, 23, 24, 25, 27, 37, 41, 42, 43, 51, 52, 60, 74, 78, 80, 81, 82, 86, 91], "wait_complet": [10, 11, 22], "wait_for_serv": [14, 21, 25, 26, 27, 28, 37, 41, 42, 43, 48, 78], "waiting_queu": [12, 24], "wake": 85, "walk": [14, 49, 52, 60, 91], "walkthrough": 99, "wall": [50, 90], "wallet": 23, "wan": [58, 91], "wan2": 91, "wan_pipelin": 91, "wand": 78, "wanpipelin": 91, "want": [8, 14, 15, 18, 22, 27, 28, 37, 38, 41, 47, 51, 52, 57, 60, 61, 68, 80, 87, 88, 91, 96, 99], "war": 14, "warmup": [14, 21, 22, 26, 27, 28, 29, 37, 38, 50, 51, 68, 71, 74, 91], "warmup_name1": 22, "warmup_name2": 22, "warn": [8, 13, 14, 19, 21, 22, 23, 25, 26, 27, 28, 29, 37, 41, 42, 43, 48, 50, 78], "warn_onc": 25, "warrior": 14, "washington": [14, 41, 48], "wasip2": 23, "wasm32": 23, "watch": [22, 23], "watchdog": [14, 17, 22, 31, 37, 62, 63, 65], "watchdog_timeout": [14, 21, 26, 27, 28, 29, 37, 38], "water": [14, 78], "waterfal": 14, "watermark": 22, "watsonx": 93, "wave": [1, 22], "wb": 91, "wcde": 91, "we": [0, 3, 6, 14, 16, 17, 18, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 48, 49, 51, 52, 53, 54, 57, 59, 60, 61, 62, 68, 71, 75, 78, 80, 81, 85, 87, 91, 95, 99, 100], "wear": 29, "weather": [26, 27, 28, 30, 41, 97], "weatherapi": 27, "web": [57, 86, 87, 97], "web_search_preview": 34, "webassembli": 23, "websit": [0, 27, 94], "week": [28, 52, 60, 78], "weekli": 79, "weight": [2, 7, 13, 14, 18, 20, 50, 51, 53, 56, 62, 63, 64, 65, 70, 74, 78, 93, 99], "weight_load_func": 22, "weight_loader_disable_mmap": [14, 21, 26, 27, 28, 29, 37, 38], "weight_update_group": 24, "weight_vers": [14, 21, 24, 25, 26, 27, 28, 29, 37, 38, 41, 43, 48], "weightlift": 78, "weilin": 25, "welcom": [10, 52, 60, 67, 71, 73], "well": [11, 17, 24, 27, 34, 38, 58, 91, 93, 99], "went": 14, "were": [14, 38, 41], "wget": [53, 61], "what": [8, 14, 18, 21, 24, 25, 26, 27, 28, 29, 30, 33, 34, 37, 38, 39, 41, 43, 46, 48, 76, 78, 85, 91, 92, 96, 97, 99, 100], "wheat": 78, "wheel": [52, 57, 60], "when": [0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 59, 60, 63, 64, 68, 73, 74, 75, 78, 86, 87, 89, 91, 96, 97, 99], "whenev": [23, 51, 52, 60], "where": [4, 7, 11, 14, 16, 17, 19, 22, 24, 26, 27, 28, 29, 30, 31, 33, 38, 41, 46, 47, 51, 76, 97, 99], "wherea": 11, "wherev": 14, "whether": [1, 11, 22, 24, 27, 37, 38, 47, 51, 52, 54, 60, 74, 87, 91, 97], "which": [0, 3, 4, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 38, 41, 43, 45, 47, 48, 49, 50, 51, 52, 57, 60, 61, 68, 71, 72, 73, 75, 78, 80, 87, 89, 91, 93, 99, 100], "while": [3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 33, 36, 37, 41, 42, 43, 48, 51, 56, 74, 75, 78, 82, 91, 93], "whisper": 14, "white": 38, "whitespac": 22, "whl": [23, 57, 61, 68, 72], "who": [14, 20, 36, 41, 71], "whole": [23, 31, 78], "whose": [14, 22, 47], "why": [14, 27], "wide": [11, 22, 30, 58, 78], "widespread": 58, "width": [18, 19, 91], "wield": 14, "wild": 92, "willing": 14, "window": [1, 3, 17, 22, 23, 52, 60, 71, 93], "wine": 38, "wise": [7, 91], "wish": 87, "with_devic": 49, "with_dtyp": 49, "with_stack": [51, 74], "with_strid": 49, "with_xxx": 49, "within": [6, 7, 11, 14, 16, 18, 19, 22, 23, 25, 27, 29, 31, 41, 52, 53, 57, 60, 72, 78, 80, 86, 87], "without": [1, 7, 11, 12, 19, 22, 23, 24, 25, 27, 31, 37, 38, 41, 51, 52, 60, 64, 71, 74, 91, 97, 99], "woman": [38, 91, 97], "won": [1, 14, 17, 36, 99], "wonder": [14, 27], "wood": 78, "word": [41, 47, 78], "work": [1, 10, 17, 18, 23, 24, 27, 28, 38, 47, 52, 56, 57, 60, 61, 73, 74, 80, 81, 84, 85, 89, 91, 97, 100], "workaround": [16, 51], "worker": [2, 16, 22, 24, 30, 31, 62, 63, 71, 74, 80, 81, 84], "worker1": 23, "worker2": 23, "worker_id": 23, "worker_typ": 23, "workers_discov": 23, "workertempl": [80, 81], "workflow": [23, 37, 50, 52, 60, 85, 93], "workload": [6, 11, 13, 14, 17, 19, 22, 23, 24, 25, 30, 33, 45, 46, 50, 51, 59, 71, 80, 84, 91, 93], "workspac": [53, 81, 84, 91], "world": [14, 22, 23, 24, 27, 36, 37, 38, 48, 58, 93], "world_siz": [24, 91], "worldwid": 58, "worst": 14, "would": [14, 26, 27, 28, 51, 68, 87], "wouldn": 14, "wrap": [25, 27, 50], "wrapper": [1, 22, 23, 25, 49], "write": [0, 1, 10, 14, 22, 27, 38, 41, 47, 90, 91, 99], "write_back": [11, 22], "write_through": [10, 11, 14, 21, 22, 26, 27, 28, 29, 37, 38], "write_through_select": [11, 22], "written": [11, 31, 81], "wrong": [37, 57], "www": 79, "x": [12, 14, 21, 22, 23, 26, 27, 28, 29, 37, 38, 49, 51, 57, 61, 64, 68, 79, 80, 81, 84, 90, 92, 93, 97, 99], "x1": [81, 84], "x64": 56, "x86_64": [23, 51, 57, 68], "x_": 82, "xai": [23, 93], "xdit": 91, "xeon": [30, 57, 58, 68], "xf": 53, "xformer": 91, "xgrammar": [14, 21, 22, 26, 27, 28, 29, 37, 38, 47, 72, 82], "xiaomi": [25, 93, 96], "xiaomimimo": [25, 67, 93, 96], "xlab": 91, "xml": 23, "xpu": [1, 22, 35, 57, 58], "xvers": [67, 93], "xx": 16, "xxx": [10, 16, 56, 62, 63], "xxxx": 16, "xxxxx": 51, "xxxxxx": 28, "y": [0, 23, 31, 41, 51, 56, 57, 72], "yaml": [11, 22, 23, 57, 71, 80, 81, 86, 87, 90, 91], "ye": [4, 37, 41, 74, 81, 84], "yeah": [25, 41], "year": [14, 27, 34, 38], "yearli": 27, "yellow": [29, 43, 78], "yep": 25, "yet": [14, 50, 80, 91, 96], "yield": [7, 11, 17], "yieldoper": 7, "yml": [52, 57, 60, 84], "yoga": 78, "york": [26, 27, 28, 29], "you": [0, 1, 3, 4, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 84, 85, 86, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100], "young": 14, "your": [0, 1, 4, 10, 12, 13, 14, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30, 31, 34, 35, 36, 38, 41, 42, 43, 48, 50, 51, 52, 53, 54, 57, 59, 60, 62, 63, 67, 68, 71, 72, 75, 78, 80, 81, 82, 84, 85, 86, 87, 91, 94, 96, 99], "your_aws_account": 57, "your_aws_region": 57, "your_exa_kei": 34, "your_image_tag": 57, "your_model_path": 86, "your_module_path": 10, "your_repository_nam": 57, "your_user_nam": [52, 60], "yourhicacheclassnam": 10, "yourkei": 50, "yourself": [38, 78], "yuanxiang": 93, "yum": 80, "z": [57, 82, 91], "zai": [28, 32, 33, 91, 96], "zealand": 41, "zero": [10, 11, 18, 20, 24, 28, 58, 74, 85], "zhao": 25, "zhipu": 93, "zhipuai": [67, 93], "zhousx": 25, "zip": [26, 27, 37, 38, 94, 99], "zmq": 87, "zmq_to_schedul": [6, 14, 21, 22, 26, 27, 28, 29, 37, 38], "zmq_to_token": [6, 22], "zsh": 53, "\u4e0d\u8fc7\u8981\u63a7\u5236\u8868\u60c5\u7b26\u53f7\u6570\u91cf": [81, 84], "\u4e5f\u53ef\u80fd\u662f\u60f3\u786e\u8ba4\u6211\u7684\u8eab\u4efd\u548c\u529f\u80fd\u8303\u56f4": [81, 84], "\u4f60\u53ef\u4ee5\u628a\u6211\u5f53\u6210\u4e00\u4e2a\u77e5\u8bc6\u4e30\u5bcc": [81, 84], "\u4f60\u662f\u8c01": [81, 84], "\u521a\u597d\u80fd\u4e2d\u548cai\u7684\u673a\u68b0\u611f": [81, 84], "\u529f\u80fd\u5b9a\u4f4d": [81, 84], "\u53c8\u80fd\u907f\u514d\u8ba9\u7528\u6237\u9762\u5bf9\u7a7a\u767d\u8f93\u5165\u6846\u65f6\u4e0d\u77e5\u6240\u63aa": [81, 84], "\u540c\u65f6\u7a81\u51fa\u5b9e\u7528\u4ef7\u503c\u6765\u964d\u4f4e\u964c\u751f\u611f": [81, 84], "\u540d\u5b57\u53eb": [81, 84], "\u5b66\u4e60": [81, 84], "\u5de5\u4f5c": [81, 84], "\u5e94\u8be5\u7528\u7b80\u4f53\u4e2d\u6587\u56de\u590d": [81, 84], "\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b": [81, 84], "\u5fb7\u56fd\u7684\u9996\u90fd\u662f\u67cf\u6797": 97, "\u6211\u662f\u4f60\u7684ai\u52a9\u624b": [81, 84], "\u65e2\u80fd\u4e86\u89e3\u9700\u6c42": [81, 84], "\u670d\u52a1\u8303\u56f4": [81, 84], "\u6cd5\u56fd\u7684\u9996\u90fd\u662f\u5df4\u9ece": 97, "\u6cd5\u56fd\u9996\u90fd\u662f\u54ea\u91cc": 97, "\u6df1\u5ea6\u6c42\u7d22": [81, 84], "\u751f\u6d3b": [81, 84], "\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u5f88\u57fa\u7840\u7684\u81ea\u6211\u4ecb\u7ecd\u95ee\u9898": [81, 84], "\u7531\u6df1\u5ea6\u6c42\u7d22\u516c\u53f8": [81, 84], "\u7ed3\u5c3e\u7528\u5f00\u653e\u6027\u95ee\u9898\u5f15\u5bfc\u5bf9\u8bdd\u5f88\u5173\u952e": [81, 84], "\u89e3\u6790": 37, "\u89e3\u7b54\u95ee\u9898": [81, 84], "\u8bed\u6c14\u7b80\u6d01\u4e2d\u6027": [81, 84], "\u8eab\u4efd\u5f52\u5c5e": [81, 84], "\u8fd9\u53ef\u80fd\u662f\u7b2c\u4e00\u6b21\u4e92\u52a8\u65f6\u7684\u5e38\u89c4\u5f00\u573a\u767d": [81, 84], "\u8fd9\u79cd\u573a\u666f\u4e0b\u65b0\u7528\u6237\u7684\u53ef\u80fd\u6027\u8f83\u9ad8": [81, 84], "\u907f\u514d\u663e\u5f97\u8f7b\u6d6e": [81, 84], "\u90a3\u4e2a\u7b11\u8138\u8868\u60c5": [81, 84], "\u91cd\u70b9\u8981\u8bf4\u660e\u4e09\u70b9": [81, 84], "\u968f\u53eb\u968f\u5230\u7684\u5c0f\u5e2e\u624b": [81, 84], "\u9700\u8981\u7ed9\u51fa\u6e05\u6670\u53cb\u597d\u7684\u81ea\u6211\u4ecb\u7ecd": [81, 84], "\u9999\u8549\u662f\u9ec4\u8272\u7684\u6c34\u679c": 97}, "titles": ["SGLang Documentation", "Attention Backend", "Checkpoint Engine Integration", "Cuda Graph for Multi-Modal Encoder in SGLang", "Deterministic Inference", "DP for Multi-Modal Encoder in SGLang", "EPD Disaggregation", "Expert Parallelism", "Model Hooks", "Hierarchical KV Caching (HiCache)", "SGLang HiCache Best Practices", "HiCache System Design and Optimization", "Runtime Attach/Detach HiCache Storage Backend (No Restart)", "Hyperparameter Tuning", "LoRA Serving", "Observability", "PD Disaggregation", "Pipeline Parallelism for Long Context", "Quantization", "Quantized KV Cache", "R-Fork", "Reasoning Parser", "Server Arguments", "SGLang Model Gateway", "SGLang for RL Systems", "Speculative Decoding", "Structured Outputs", "Structured Outputs For Reasoning Models", "Tool Parser", "Query VLM with Offline Engine", "DeepSeek V3/V3.1/R1 Usage", "DeepSeek V3.2 Usage", "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang", "GLM-4.6V / GLM-4.5V Usage", "GPT OSS Usage", "Llama4 Usage", "MiniMax M2.1/M2 Usage", "SGLang Native APIs", "Offline Engine API", "Ollama-Compatible API", "OpenAI-Compatible APIs", "OpenAI APIs - Completions", "OpenAI APIs - Embedding", "OpenAI APIs - Vision", "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)", "Qwen3-Next Usage", "Qwen3-VL Usage", "Sampling Parameters", "Sending Requests", "Development Guide for JIT Kernels", "Bench Serving Guide", "Benchmark and Profiling", "Contribution Guide", "Development Guide Using Docker", "Evaluating New Models with SGLang", "PyPI Package Release Process", "Set Up Self-Hosted Runners for GitHub Action", "Install SGLang", "SGLang Documentation", "AMD GPUs", "Contribution Guide", "SGLang installation with NPUs support", "Best Practice on Ascend NPU", "DeepSeek examples", "&lt;no title&gt;", "Qwen3 examples", "Ascend NPUs", "Support Models on Ascend NPU", "CPU Servers", "Moore Threads GPUs", "NVIDIA Jetson Orin", "TPU", "XPU", "Custom Chat Template", "Environment Variables", "Troubleshooting and Frequently Asked Questions", "Choices Methods in SGLang", "Frontend Language", "SGLang Frontend Language", "Learn More and Join the Community", "Deploy On Kubernetes", "LWS Based PD Deploy", "Multi-Node Deployment", "Multi-Node Deployment", "DeepSeekV32-Exp RBG Based PD Deploy", "Post-Training Integration", "Production Metrics", "Production Request Tracing", "Enabling cache for torch.compile", "Classification API", "Diffusion Language Models", "Diffusion Models", "Embedding Models", "Large Language Models", "MindSpore Models", "Use Models From ModelScope", "Multimodal Language Models", "Rerank Models", "Reward Models", "How to Support New Models", "Transformers fallback in SGLang"], "titleterms": {"": [4, 99], "0": [4, 75, 81, 84], "1": [12, 17, 29, 30, 36, 39, 49, 53, 56, 57, 59, 61, 62, 63, 65, 68, 71, 81, 82, 84, 91, 92], "100m": 62, "10m": 62, "11m": 62, "128k": 17, "12m": 62, "16": 2, "18m": 62, "2": [2, 12, 25, 28, 29, 31, 39, 49, 53, 56, 57, 61, 62, 63, 68, 71, 74, 81, 84, 91, 92], "2025": 31, "20m": 62, "235b": [17, 62, 65], "2507": 65, "2k": 62, "3": [12, 25, 28, 29, 39, 49, 56, 57, 62, 68, 71, 82, 91], "30b": [4, 65], "30m": 62, "32b": [62, 65], "3b": 68, "4": [12, 28, 29, 32, 33, 35, 57, 62, 63, 71], "40": 23, "405b": 82, "429": 23, "480b": 62, "5": [29, 32, 57, 62], "50m": 62, "5v": 33, "6": [32, 57], "6v": 33, "7": [32, 57], "7b": [71, 91], "8": 30, "800i": [62, 63, 65], "8b": [4, 65, 71], "8card": 62, "A": [37, 41, 42, 43, 48, 78], "For": [22, 27, 29, 61, 74], "In": [31, 51, 84], "No": 12, "On": 80, "One": 84, "The": [4, 75], "To": 24, "With": [57, 91], "a2": 62, "a22b": [17, 65], "a3": [62, 63, 65], "a3b": [4, 65], "about": 17, "abov": [33, 46], "acceler": 91, "access": 75, "accuraci": [19, 31, 35, 52, 54, 60], "achiev": 13, "action": 56, "adapt": [41, 91], "adaptor": [14, 61], "add": [1, 23, 49, 52, 56, 60, 87, 99], "address": 3, "adjust": [13, 17], "admin": [12, 23], "adopt": 85, "advanc": [16, 18, 38, 53, 58, 71, 74, 91], "aim": 31, "all": [7, 84], "amd": 59, "an": [91, 99], "api": [12, 14, 18, 21, 22, 23, 26, 27, 28, 29, 34, 37, 38, 39, 40, 41, 42, 43, 48, 51, 89, 91], "approach": 29, "ar": [75, 86], "architectur": [2, 11, 12, 23], "area": 71, "arg": 22, "argument": [3, 4, 14, 22, 91], "ascend": [16, 61, 62, 66, 67], "ask": 75, "async": [17, 23], "asynchron": 38, "asyncio": 38, "atla": [62, 63, 65], "attach": 12, "attent": [1, 3, 22, 30, 71, 91], "authent": [23, 50], "auto": [18, 59], "automat": [1, 53], "avail": [18, 23], "avoid": 13, "aw": 57, "awar": 23, "b": 13, "back": [11, 28], "backend": [1, 3, 4, 7, 10, 11, 12, 14, 16, 20, 22, 23, 28, 50, 71, 74, 91], "background": 12, "backward": 97, "balanc": [7, 23, 24, 59, 61], "base": [17, 81, 84, 91], "basic": [4, 29, 41, 58, 71, 78, 80, 91], "batch": [7, 13, 22, 23, 38, 78], "behavior": [4, 8, 12, 21], "being": 86, "bench": 50, "bench_offline_throughput": 51, "bench_serv": 51, "benchmark": [31, 35, 51, 52, 60, 62, 68, 71, 72, 74, 99], "benefit": [2, 18], "best": [10, 17, 19, 23, 62], "bf16": [33, 46], "bia": 41, "bin": 91, "binari": 23, "bind": 23, "block": 30, "breaker": 23, "bucket": 23, "budget": [30, 32, 33], "buffer": 3, "bug": 51, "build": [23, 31, 52], "built": 34, "c": 49, "cach": [9, 13, 19, 22, 23, 37, 45, 74, 88, 91], "call": [23, 28, 29, 30, 31, 74], "cann": 61, "capabl": 92, "capac": 13, "captur": 37, "case": [17, 80], "categori": 23, "caus": 4, "caveat": 12, "chang": 91, "chat": [28, 41, 73], "check": [23, 37, 49, 86], "checkpoint": [2, 22, 31], "choic": [28, 76], "choos": [14, 50], "chunk": [13, 17, 71], "ci": [52, 60, 74, 91], "circuit": 23, "class": 89, "classif": [23, 89], "classifi": 37, "cli": [39, 91], "client": [28, 42, 43, 48, 90, 92, 97], "clone": [52, 60], "cloud": [57, 71], "co": 23, "code": [49, 52, 55, 60, 90, 100], "collabor": 85, "collect": 86, "combin": 91, "command": [1, 3, 5, 22, 33, 46, 51, 68, 90, 93, 96, 97, 98, 100], "commit": [52, 60, 91], "common": [22, 57, 97], "commun": [7, 10, 17, 23, 79, 94], "comparison": [23, 71], "compat": [14, 21, 26, 27, 28, 39, 40, 61, 89, 91, 97], "compil": [25, 71, 88], "complet": 41, "complex": [78, 87], "compon": 61, "compos": 57, "comprehens": 71, "compressor": 18, "comput": [7, 74, 91], "concurr": 50, "config": [8, 56], "configur": [2, 4, 8, 10, 16, 22, 23, 31, 35, 41, 45, 56, 59, 62, 71, 74, 86, 90, 91], "connect": [23, 71], "connector": 23, "consider": [19, 51], "constrain": [47, 78], "constraint": 3, "contain": [53, 56, 70], "content": [23, 30, 91], "context": [17, 31], "continu": 24, "contribut": [52, 60, 71, 91], "control": [12, 13, 23, 78], "convent": 91, "convers": 23, "core": [10, 23, 47], "count": 91, "cp": 31, "cpu": [61, 68], "crash": 15, "creat": [49, 61, 81, 91], "cross": [37, 97], "cuda": [1, 3, 13, 75], "curl": [42, 43, 48, 89], "current": [12, 28], "custom": [10, 22, 29, 47, 71, 73, 91], "customop": 61, "data": [11, 12, 22, 23, 30], "dataset": 50, "dbcach": 91, "debug": [22, 23, 53, 74, 80, 94, 99], "debugg": 53, "decod": [1, 7, 16, 22, 23, 25, 32, 34, 35, 37, 45, 47, 51, 71, 78, 81, 97], "decrypt": 22, "deepep": [61, 74], "deepgemm": 74, "deepseek": [16, 17, 30, 31, 41, 44, 59, 62, 63, 68, 74, 82], "deepseekv32": 84, "default": [4, 31, 47, 53], "defin": 28, "demo": 34, "denois": 91, "depend": [0, 94], "deploi": [18, 23, 80, 81, 84], "deploy": [10, 11, 23, 36, 62, 81, 82, 83], "deprec": 22, "design": [3, 11], "detach": 12, "detail": 89, "determin": 4, "determinist": [4, 24, 75], "detoken": [23, 37], "dev": 53, "develop": [49, 53, 58], "devic": 94, "dialog": 78, "diamond": 31, "differ": [1, 92], "diffus": [22, 90, 91], "dimens": 92, "disabl": [12, 59, 61, 91], "disaggreg": [6, 10, 11, 16, 17, 22, 23, 31, 51, 63], "discoveri": 23, "disk": [24, 37], "distribut": [22, 24, 37, 51, 71, 74, 91], "dit": 91, "doc": 0, "docker": [23, 31, 53, 56, 57, 59, 61, 68, 71, 72, 91], "document": [0, 52, 58, 60, 71, 97, 99], "doe": 50, "doubl": 22, "download": [30, 91], "dp": [5, 12, 13], "dsa": 31, "dump": [15, 22, 91], "durat": 23, "dynam": [3, 10, 14, 17, 22], "eagl": [22, 25, 32, 35, 45], "eagle3": [65, 71], "easi": 24, "ebnf": [26, 27, 41, 47], "edit": 91, "embed": [29, 37, 42, 67, 92, 97], "enabl": [10, 12, 17, 19, 28, 51, 88], "encod": [3, 5, 22, 37, 97], "encount": 75, "end": 50, "end_profil": 51, "endpoint": [23, 39, 47, 50, 51, 89, 91], "engin": [2, 21, 24, 26, 27, 28, 29, 38, 68, 71, 72, 99], "environ": [49, 60, 61, 71, 74, 91, 94], "ep": 7, "epd": 6, "error": [13, 71, 75, 89], "evalu": [53, 54], "even": 75, "exampl": [2, 3, 4, 5, 7, 18, 23, 28, 30, 33, 37, 41, 46, 47, 50, 51, 59, 63, 65, 68, 71, 80, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100], "execut": 28, "exp": 84, "experiment": [1, 31], "expert": [7, 37, 41], "explain": 50, "explicitli": 94, "export": 18, "express": [26, 27], "extend": 87, "extens": 7, "extern": [71, 99], "extra": 91, "factor": [17, 19], "factori": 8, "failur": 23, "fallback": 100, "faq": [30, 81, 84, 91], "featur": [18, 23, 58, 71, 91, 100], "field": [8, 23, 89], "file": [22, 23, 51, 81, 84, 86, 90, 91], "fine": 24, "fit": 3, "flag": [24, 33, 46], "flap": 23, "flow": [23, 78], "flush": 37, "forc": 28, "fork": [20, 52, 60], "format": [19, 23, 28, 29, 50, 52, 60, 73, 89, 97], "forward": 22, "fp4": 19, "fp8": [17, 19, 30, 33, 46], "fraction": 13, "framework": [7, 61, 87], "frequenc": 25, "frequent": 75, "from": [11, 24, 31, 37, 52, 53, 57, 59, 60, 61, 68, 69, 71, 72, 91, 95, 99], "frontend": [77, 78], "full": [23, 33, 46, 91], "function": [23, 24, 28, 30, 31, 74], "futur": 14, "gatewai": 23, "gemm": 22, "gener": [4, 24, 37, 38, 47, 48, 74, 78, 91], "get": [37, 41, 58, 91], "github": [55, 56], "glm": [32, 33, 44], "go": 23, "gpqa": 31, "gpt": [34, 44], "gptqmodel": 18, "gpu": [14, 59, 69], "grain": 24, "grammar": 22, "graph": [3, 13], "greedi": [4, 76], "group": 24, "growth": 23, "grpc": 23, "grub": 59, "gsm8k": [31, 63], "guid": [1, 49, 50, 52, 53, 58, 60, 86, 87], "guidanc": [7, 17, 52, 60], "guidelin": [0, 10], "h20": 17, "h200": 30, "handl": [28, 89], "hang": 75, "hardwar": [33, 46, 58, 71], "head": 30, "health": [23, 37], "hf3f": 10, "hicach": [9, 10, 11, 12], "hierarch": [9, 22], "high": [13, 23, 62, 71], "highlight": 25, "hiradixtre": 11, "histori": 23, "hook": [8, 22], "hook_factori": 8, "host": [53, 56], "hot": 23, "how": [12, 28, 52, 60, 71, 87, 91, 99], "http": [12, 22, 23, 51], "hybrid": [1, 61], "hyperparamet": 13, "i": [6, 11, 16], "id": [23, 41, 42], "idl": 12, "illeg": 75, "imag": [29, 33, 43, 46, 61, 81, 84, 91, 97], "imbal": 23, "impact": 19, "implement": [7, 12, 17, 49, 89, 99], "import": [33, 46, 51], "increas": 13, "infer": [4, 13, 23, 24, 38, 70, 82, 91, 94], "info": 37, "inform": 91, "initi": 28, "input": [3, 17, 29, 33, 42, 43, 46, 96], "instal": [0, 2, 18, 23, 31, 52, 57, 59, 60, 61, 68, 69, 70, 71, 72, 91, 94], "instruct": [65, 97], "integ": 49, "integr": [2, 10, 11, 16, 23, 85], "interact": 99, "interest": 87, "interfac": [11, 49], "intern": 74, "introduct": 94, "issu": [16, 23, 71, 80, 94], "item": 22, "itl": 17, "jetson": 70, "jinja": 73, "jit": 49, "join": 79, "json": [26, 27, 41, 47, 73], "jsonl": 50, "k8": 81, "kei": [10, 23, 50, 80, 91], "kernel": [22, 49, 52, 60, 61], "known": [3, 5], "ktransform": 22, "kubernet": [23, 57, 80], "kv": [9, 13, 19], "l3": 11, "languag": [23, 61, 67, 77, 78, 90, 93, 96, 99], "larg": [61, 67, 93, 99], "latenc": [62, 71], "latent": 30, "launch": [1, 21, 22, 23, 28, 30, 31, 32, 33, 35, 37, 39, 41, 42, 43, 45, 46, 48, 49, 68, 71, 72, 78, 90, 92, 93, 96, 97, 98, 100], "layer": [22, 51], "layerwis": 51, "layout": 10, "lb": 81, "learn": 79, "length": [17, 76], "level": 8, "librari": [39, 61], "lifecycl": [8, 24], "likelihood": 76, "limit": [23, 52, 60, 91, 96], "line": 51, "list": [23, 68, 71, 72, 91], "llama": [4, 16, 28, 29, 35, 44, 68, 82, 99], "llama3": 59, "llama4": 35, "llm": [18, 22, 54], "lm_eval": 35, "lmcach": 22, "load": [10, 14, 23, 24], "loader": 22, "local": 11, "locat": 91, "log": [15, 22, 23], "logic": 1, "logit": [41, 47], "long": [17, 31, 71], "lora": [14, 22, 41, 91], "low": [62, 71, 91], "lw": 81, "m2": 36, "make": [55, 92], "mamba": [22, 45], "manag": [3, 23, 74, 91], "manifest": [81, 84], "manual": 53, "map": 61, "marker": 51, "mask": 91, "match": 11, "matrix": [1, 71, 91], "matryoshka": 92, "matter": [4, 10], "max": 13, "maximum": 29, "mcp": 23, "mem": 13, "memfabr": 61, "memori": [10, 13, 19, 22, 23, 24, 61, 71, 74, 75], "merg": [52, 60, 91], "merger": 51, "messag": [28, 91], "metadata": 11, "method": [18, 57, 61, 71, 76, 91], "metric": [15, 23, 50, 86], "mha": 1, "middlewar": 23, "mindspor": 94, "minilb": 81, "minimax": [36, 44], "mix": [61, 62, 63, 97], "mla": [1, 30], "modal": [3, 5, 22, 42, 78], "mode": [11, 16, 23, 28, 33, 46, 51, 63, 94], "model": [3, 4, 5, 8, 18, 21, 22, 23, 27, 28, 29, 30, 36, 37, 41, 42, 44, 50, 54, 58, 61, 62, 67, 68, 71, 72, 74, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], "modelopt": 18, "modelscop": 95, "modul": 23, "moe": [4, 7, 22, 37, 41, 65], "monitor": 23, "mooncak": [10, 16], "moor": 69, "more": [44, 79], "motiv": 3, "mp": 91, "mtl": 23, "multi": [2, 3, 5, 11, 16, 22, 23, 25, 30, 31, 42, 51, 71, 78, 82, 83, 89], "multimod": [47, 61, 67, 91, 92, 96, 97, 99], "multipl": [4, 14, 43], "multiplex": 22, "name": 8, "nativ": [21, 26, 27, 28, 37, 48], "nccl": 20, "nest": 38, "never": 23, "new": [1, 7, 21, 28, 49, 54, 91, 99], "newcom": [52, 60], "next": [45, 62], "ngram": 22, "nixl": 16, "node": [2, 16, 22, 30, 51, 71, 82, 83], "non": [4, 21, 28, 33, 38, 46], "normal": [47, 76], "note": [23, 33, 34, 46, 47, 50, 51, 57, 91, 96], "npu": [60, 61, 62, 66, 67], "nsa": 74, "nsight": [51, 91], "numa": [59, 61], "nvfp4": 31, "nvidia": [17, 18, 70], "nvlink": 16, "nvtx": 51, "observ": [15, 23], "obtain": 61, "offlin": [13, 18, 21, 26, 27, 28, 29, 38, 94, 99], "offload": 22, "ollama": 39, "one": 30, "onli": [37, 97], "onlin": 18, "oom": 71, "open": 24, "openai": [14, 21, 23, 26, 27, 28, 40, 41, 42, 43, 48, 91], "opentelemetri": 23, "optim": [10, 11, 22, 30, 31, 33, 46, 62, 68, 71, 72, 74, 91, 96], "option": [2, 8, 13, 22, 28, 47, 50, 53, 74, 91, 97], "oracl": 23, "organ": 11, "orin": 70, "oss": [34, 44], "other": [13, 47, 50, 51], "our": 99, "out": [13, 61, 71, 75], "output": [26, 27, 28, 29, 41, 47, 50, 51, 70, 91, 92], "overal": 11, "overflow": 23, "overlap": [7, 14], "overrid": 22, "overview": [2, 7, 8, 12, 23, 89, 91], "ovi": 91, "packag": [23, 55], "parallel": [2, 7, 12, 17, 22, 30, 31, 78], "paramet": [10, 11, 33, 41, 46, 47, 89, 91, 97], "pars": 23, "parser": [21, 23, 28, 31, 34], "path": [12, 91], "paus": 24, "pd": [10, 11, 16, 17, 22, 23, 31, 51, 61, 62, 63, 81, 84], "penal": 47, "perf": 91, "perform": [2, 19, 23, 25, 29, 54, 61, 62, 71, 74, 91, 96], "pin": 14, "pip": [57, 91], "pipelin": [17, 31, 91], "pitfal": 97, "plane": 23, "platform": [58, 91], "polici": [10, 23, 91], "pool": 13, "popular": 44, "port": 99, "possibl": 51, "post": 85, "postgresql": 23, "postpon": 24, "power": 61, "pp": 31, "practic": [10, 17, 19, 23, 62], "pre": [52, 60], "precis": [33, 46], "precomput": 29, "predict": [25, 30, 31], "prefetch": [10, 11], "prefil": [1, 13, 16, 17, 22, 23, 51, 71, 81], "prepar": [60, 61, 81, 84], "preprocess": 29, "prerequisit": [23, 39, 50, 61, 70, 80, 81, 84, 86, 91], "preset": 91, "prevent": 61, "prioriti": 91, "privaci": 23, "process": 55, "processor": [29, 47], "product": [15, 23, 86, 87], "profil": [16, 51, 53, 74, 91], "prometheu": 23, "prompt": 78, "promql": 23, "propag": 23, "protect": 91, "protobuf": 94, "proxi": 23, "pypi": [55, 71], "python": [18, 23, 28, 34, 36, 39, 42, 43, 48, 49, 61, 89], "pytorch": [51, 61, 91], "quantis": [33, 46], "quantiz": [18, 19, 22, 70, 74, 100], "quark_int4fp8_mo": 18, "queri": [12, 29, 97], "question": 75, "queu": 23, "queue": [13, 23], "quick": [23, 34, 39, 50, 92], "quickstart": 91, "qwen": [6, 44, 62, 71], "qwen2": 29, "qwen3": [4, 17, 41, 45, 46, 62, 65, 71, 97], "r": 20, "r1": [30, 62, 82], "radix": 45, "rang": 49, "rank": [11, 25], "rate": [23, 50, 52, 60], "raw": 29, "rbg": 84, "rdma": 80, "re": 87, "readi": 23, "reason": [21, 23, 27, 30, 31, 34, 41], "recommend": [23, 33, 46, 59, 71], "redi": 23, "refactor": 17, "refer": [2, 18, 23, 25, 58, 70, 71, 91], "refit": 24, "regex": [41, 47], "regist": 99, "regular": [23, 26, 27], "relat": [11, 22], "releas": [24, 55], "reliabl": 23, "remain": 80, "remot": [53, 100], "replai": 15, "report": [54, 91], "repositori": [52, 60], "reproduc": 4, "req": 13, "request": [13, 15, 21, 23, 28, 33, 42, 43, 46, 48, 52, 60, 68, 71, 72, 87, 89, 92, 97], "requestmetricsexport": 22, "requir": [8, 12, 16, 28, 36, 71, 91, 94], "rerank": [37, 67, 97], "resourc": 71, "respons": [4, 23, 34, 89, 97], "restart": 12, "restrict": 3, "result": [28, 31, 35, 54, 75], "resum": 24, "retri": 23, "return": 41, "return_docu": 97, "review": [52, 60], "reward": [37, 67, 89, 98], "rich": 11, "rl": 24, "robin": 31, "roce": 80, "rocm": 91, "root": 4, "rotari": 3, "round": [18, 31, 37], "rout": [23, 41], "router": [16, 23, 24, 39], "run": [13, 30, 52, 56, 57, 59, 60, 61, 63, 65, 68, 70, 91, 94], "runner": [56, 97], "runtim": [12, 22, 23, 26, 27, 28, 49], "rust": 23, "sagemak": 57, "sampl": [4, 22, 25, 47, 91], "save": 19, "sbo": 7, "scale": 19, "scenario": [80, 87], "scene": 61, "schedul": [16, 22], "schema": [8, 21], "scheme": 61, "scm": 91, "score": [22, 37, 89], "script": 71, "search": 34, "secur": 23, "select": [1, 7, 16, 37, 76, 91, 94], "self": 56, "semant": 12, "send": [28, 33, 46, 48], "separ": [23, 61], "sequenc": 31, "seri": 62, "serv": [14, 22, 50, 68, 71, 72, 91, 99], "server": [2, 4, 16, 21, 22, 23, 24, 28, 33, 37, 39, 41, 42, 43, 46, 48, 51, 68, 75, 78, 91, 92, 94], "servic": [23, 61, 81], "set": [23, 31, 56, 59, 61, 91], "setup": [2, 49, 53, 86, 87], "sgl": [52, 60, 91], "sglang": [0, 2, 3, 4, 5, 10, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 37, 39, 45, 46, 51, 52, 53, 54, 57, 58, 59, 60, 61, 69, 70, 76, 78, 91, 99, 100], "sh": 56, "share": 51, "simplest": 29, "singl": [2, 7, 14, 16, 89], "size": [13, 17], "skypilot": [57, 71], "sleep": 24, "slice": 87, "slide": 91, "slurm": 82, "smart": 39, "smooth": 17, "snippet": 90, "softwar": 71, "solut": 4, "some": 94, "sourc": [23, 31, 52, 57, 59, 60, 61, 68, 69, 71, 72, 91], "spars": 22, "sparsiti": 22, "spec": 8, "special": 91, "specif": [21, 28, 33, 46, 71, 74], "spectul": 7, "specul": [1, 22, 25, 32, 34, 35, 45, 71], "speed": [13, 52, 60], "split": 31, "srt": [26, 27, 28], "sta": 91, "stabl": 3, "stage": 91, "standard": 31, "start": [23, 39, 50, 53, 56, 58, 91, 92, 94], "start_profil": 51, "state": 12, "static": [3, 13], "statu": 12, "step": [1, 49, 56, 59, 91], "storag": [10, 11, 12, 23, 51, 74], "stream": [21, 28, 38, 47, 48, 50, 78], "strict": 12, "structur": [26, 27, 41, 47, 49, 70], "studi": 17, "style": [0, 52, 60], "submiss": 13, "success": 80, "suit": 99, "summari": [8, 39], "support": [1, 3, 4, 5, 7, 10, 19, 21, 22, 23, 27, 28, 36, 41, 50, 58, 61, 67, 71, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100], "swap": 61, "switch": 91, "synchron": [11, 38], "system": [11, 24, 36, 51, 59, 61, 71, 91], "tabl": 23, "tag": [26, 27], "target": 91, "target_modul": 8, "taylors": 91, "tbo": 7, "temperatur": [4, 75], "templat": [28, 73], "tensor": [2, 22, 24, 30, 49], "terminu": 68, "test": [23, 31, 35, 36, 52, 60, 63, 71, 74, 89, 99], "text": [37, 97], "think": [30, 32, 33, 41], "thread": 69, "three": 29, "throughput": [13, 30, 62, 71], "tile": 91, "time": [71, 91], "tip": [31, 35, 45, 51, 52, 60, 91], "tl": 23, "todo": 80, "token": [13, 17, 22, 23, 25, 30, 31, 37, 41, 50, 76], "tool": [23, 28, 34, 74], "top": 8, "top_n": 97, "torch": [25, 88], "torchao": [18, 70], "tp": [2, 13], "tpu": 71, "trace": [23, 51, 87, 91], "train": 85, "transfer": 11, "transferengin": 20, "transform": 100, "transport": [16, 23], "trigger": [52, 60], "trip": 37, "triton": 61, "troubleshoot": [2, 23, 50, 71, 75, 86, 91, 94], "try": 13, "tune": [13, 17, 23, 74], "turn": 78, "two": 7, "type": 22, "ultra": 17, "uncondit": 76, "understand": 29, "unifi": [11, 16], "unit": [52, 60], "unmerg": 91, "unsloth": 18, "up": [24, 53, 56], "updat": [0, 24, 37, 52, 55, 59, 60], "upload": 55, "us": [12, 18, 24, 39, 41, 42, 43, 48, 49, 51, 53, 57, 59, 61, 68, 71, 72, 74, 89, 91, 95], "usag": [2, 4, 6, 13, 14, 16, 18, 19, 20, 21, 23, 27, 30, 31, 33, 34, 35, 36, 38, 41, 44, 45, 46, 51, 58, 68, 78, 86, 89, 91, 96], "user": 1, "util": 49, "uv": [57, 91], "v": 1, "v1": 37, "v3": [17, 30, 31, 41, 59, 63, 68, 74, 82], "v32": 62, "variabl": [74, 91], "verif": [4, 71], "verifi": 91, "version": [55, 61], "via": [25, 91, 99], "video": [33, 46, 91, 96], "view": [51, 91], "vision": [29, 43], "vl": [6, 29, 46, 65, 97], "vllm": 99, "vlm": [29, 54], "vscode": 53, "wake": 24, "warmup": 59, "warn": 91, "wasm": 23, "web": 34, "weight": [22, 24, 30, 37, 91], "what": [6, 11, 16, 50], "why": [4, 6, 10, 11, 16, 17, 24], "wise": [30, 51], "without": 28, "work": 14, "worker": [23, 51], "workflow": [0, 11, 18, 51], "workload": 7, "wrapper": 99, "write": [8, 11, 49, 52, 60], "x": [30, 63, 65, 91], "xgrammar": 70, "xpu": 72, "ye": 97, "you": 87, "your": 49}})