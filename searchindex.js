Search.setIndex({"alltitles": {"/generate Endpoint": [[43, "generate-endpoint"]], "0. Prerequisites": [[70, "prerequisites"], [73, "prerequisites"]], "1. Image Preparation": [[70, "image-preparation"], [73, "image-preparation"]], "1. Launch SGLang Server": [[35, "launch-sglang-server"]], "1. Launch a Matryoshka\u2011capable model": [[80, "launch-a-matryoshkacapable-model"]], "1. Raw Images - Simplest approach": [[26, "1.-Raw-Images---Simplest-approach"]], "2. All In One manifest file": [[73, "all-in-one-manifest-file"]], "2. Deployment Manifest Files": [[70, "deployment-manifest-files"]], "2. Make requests with different output dimensions": [[80, "make-requests-with-different-output-dimensions"]], "2. Processor Output - For custom preprocessing": [[26, "2.-Processor-Output---For-custom-preprocessing"]], "2. Use Ollama CLI": [[35, "use-ollama-cli"]], "3. Precomputed Embeddings - For maximum performance": [[26, "3.-Precomputed-Embeddings---For-maximum-performance"]], "3. Use Ollama Python Library": [[35, "use-ollama-python-library"]], "AMD GPUs": [[53, null]], "API Endpoint": [[78, "api-endpoint"]], "API Surface": [[19, "api-surface"]], "API related": [[21, "api-related"]], "ASCEND": [[14, "ascend"]], "Accuracy Impact": [[17, "accuracy-impact"]], "Accuracy Test with aime 2025": [[28, "accuracy-test-with-aime-2025"]], "Accuracy Test with gpqa-diamond": [[28, "accuracy-test-with-gpqa-diamond"]], "Accuracy Test with gsm8k": [[28, "accuracy-test-with-gsm8k"]], "Accuracy Test with lm_eval": [[32, "accuracy-test-with-lm-eval"]], "Achieve a high token usage": [[11, "achieve-a-high-token-usage"]], "Achieving high throughput for offline batch inference": [[11, "achieving-high-throughput-for-offline-batch-inference"]], "Add a Runner": [[50, "add-a-runner"]], "Add the Model to the Test Suite": [[87, "add-the-model-to-the-test-suite"]], "Adjust the request submission speed to control #queue-req": [[11, "adjust-the-request-submission-speed-to-control-queue-req"]], "Adoption": [[74, "adoption"]], "Advanced Configuration": [[14, "advanced-configuration"]], "Advanced Features": [[16, "advanced-features"], [52, null], [60, "advanced-features"]], "Advanced Usage": [[34, "Advanced-Usage"]], "Advanced: Speculative Decoding (EAGLE3)": [[60, "advanced-speculative-decoding-eagle3"]], "Architecture": [[2, "architecture"], [19, "architecture"]], "Areas for Contribution": [[60, "areas-for-contribution"]], "Args for multi-item scoring": [[21, "args-for-multi-item-scoring"]], "Arguments for LoRA Serving": [[12, "Arguments-for-LoRA-Serving"]], "Ascend NPUs": [[57, null]], "Attention Backend": [[1, null]], "Attention Backend Comparison": [[60, "attention-backend-comparison"]], "Authentication": [[45, "authentication"]], "Available Quantization Methods": [[16, "available-quantization-methods"]], "Avoid out-of-memory errors by tuning --chunked-prefill-size, --mem-fraction-static, and --max-running-requests": [[11, "avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests"]], "Backend Compatibility": [[25, "Backend-Compatibility"]], "Backends for All-to-All Communication": [[6, "backends-for-all-to-all-communication"]], "Backends for MoE Computation": [[6, "backends-for-moe-computation"]], "Basic Example: Qwen-7B": [[60, "basic-example-qwen-7b"]], "Basic Offline Engine API Call": [[26, "Basic-Offline-Engine-API-Call"]], "Basic Usage": [[3, "basic-usage"], [37, "Basic-Usage"], [52, null], [67, "Basic-Usage"]], "Basic example": [[69, "basic-example"]], "Batching": [[67, "Batching"]], "Bench Serving Guide": [[45, null]], "Benchmark": [[46, "benchmark"], [87, "benchmark"]], "Benchmark and Profiling": [[46, null]], "Benchmark the speed": [[47, "benchmark-the-speed"]], "Benchmarking Results": [[28, "benchmarking-results"], [32, "benchmarking-results"]], "Benchmarking with Requests": [[58, "benchmarking-with-requests"], [60, "benchmarking-with-requests"], [61, "benchmarking-with-requests"]], "Benefits of ModelOpt": [[16, "benefits-of-modelopt"]], "Best Practice for Pipeline Parallelism with PD Disaggregation": [[15, "best-practice-for-pipeline-parallelism-with-pd-disaggregation"]], "Best Practices": [[17, "best-practices"]], "Block-wise FP8": [[27, "block-wise-fp8"]], "Build From Source": [[28, "build-from-source"]], "Build from source": [[47, "build-from-source"]], "Built-in Tools": [[31, "built-in-tools"]], "CANN": [[54, "cann"]], "CI rate limits": [[47, "ci-rate-limits"]], "CPU Servers": [[58, null]], "CPU performance power scheme": [[54, "cpu-performance-power-scheme"]], "CUDA Error: Illegal Memory Access Encountered": [[64, "cuda-error-illegal-memory-access-encountered"]], "CUDA Out of Memory": [[64, "cuda-out-of-memory"]], "Cache-Aware Tuning": [[19, "cache-aware-tuning"]], "Call with Precomputed Embeddings": [[26, "Call-with-Precomputed-Embeddings"], [26, "id2"]], "Call with Processor Output": [[26, "Call-with-Processor-Output"], [26, "id1"]], "Capture expert selection distribution in MoE models": [[33, "Capture-expert-selection-distribution-in-MoE-models"]], "Chat Completions": [[37, "Chat-Completions"]], "Check if the metrics are being collected": [[75, "check-if-the-metrics-are-being-collected"]], "Checkpoint Engine Integration": [[2, null]], "Checkpoint Engine Options": [[2, "checkpoint-engine-options"]], "Choices Methods in SGLang": [[65, null]], "Choosing LoRA Backend": [[12, "Choosing-LoRA-Backend"]], "Choosing model and tokenizer": [[45, "choosing-model-and-tokenizer"]], "Chunked Prefill": [[60, "chunked-prefill"]], "Chunked Prefill Size and Smoothing Factor": [[15, "chunked-prefill-size-and-smoothing-factor"]], "Circuit Breaker": [[19, "circuit-breaker"]], "Classification API": [[78, null]], "Classification Models (Multi-class)": [[78, "classification-models-multi-class"]], "Classify (reward model)": [[33, "Classify-(reward-model)"]], "Client Request": [[80, "client-request"]], "Co-launch Router + Workers": [[19, "co-launch-router-workers"]], "Code style guidance": [[47, "code-style-guidance"]], "Collaboration": [[74, "collaboration"]], "Command Example": [[4, "command-example"]], "Command Line Usage": [[46, "command-line-usage"]], "Common Notes": [[51, "common-notes"]], "Common launch commands": [[21, "common-launch-commands"]], "Community and Support": [[9, "community-and-support"]], "Compatibility": [[78, "compatibility"]], "Compilation Long-Time": [[60, "compilation-long-time"]], "Completions": [[37, "Completions"]], "Complex Prompts": [[67, "Complex-Prompts"]], "Comprehensive Benchmark Script": [[60, "comprehensive-benchmark-script"]], "Computation and Communication Overlap": [[6, "computation-and-communication-overlap"]], "Configuration Files": [[75, "configuration-files"]], "Configuration Guidelines": [[9, "configuration-guidelines"]], "Configuration Options": [[2, "configuration-options"]], "Configuration Reference": [[19, "configuration-reference"]], "Configuration Tips": [[28, "configuration-tips"], [29, "configuration-tips"], [32, "configuration-tips"], [41, "configuration-tips"]], "Configuration file support": [[21, "configuration-file-support"]], "Configuration overview": [[7, "configuration-overview"]], "Connection Issues": [[60, "connection-issues"]], "Constrained Decoding": [[67, "Constrained-Decoding"]], "Constrained decoding": [[43, "constrained-decoding"]], "Context-parallel Tips": [[28, "context-parallel-tips"]], "Contributing": [[60, "contributing"]], "Contribution Guide": [[47, null]], "Control Plane": [[19, "control-plane"]], "Control flow": [[67, "Control-flow"]], "Core HiCache Parameters": [[9, "core-hicache-parameters"]], "Core Settings": [[19, "core-settings"]], "Core parameters": [[43, "core-parameters"]], "Crash Dump and Replay": [[13, "crash-dump-and-replay"]], "Create decode k8s service": [[70, "create-decode-k8s-service"]], "Create prefill k8s service": [[70, "create-prefill-k8s-service"]], "Creating Service for Prefill and Decode": [[70, "creating-service-for-prefill-and-decode"]], "Currently supported parsers:": [[25, "Currently-supported-parsers:"]], "Custom Attention Backends": [[60, "custom-attention-backends"]], "Custom Chat Template": [[62, null]], "Custom Storage Backend Integration": [[9, "custom-storage-backend-integration"]], "Custom logit processor": [[43, "custom-logit-processor"]], "Custom weight loader": [[21, "custom-weight-loader"]], "CustomOps": [[54, "customops"]], "DP for Multi-Modal Encoder in SGLang": [[4, null]], "DSA long sequence context parallel optimization(experimental)": [[28, "dsa-long-sequence-context-parallel-optimization-experimental"]], "Data Parallelism Attention": [[27, "data-parallelism-attention"]], "Data Plane": [[19, "data-plane"]], "Data Transfer Optimization": [[10, "data-transfer-optimization"]], "Data Write-back": [[10, "data-write-back"]], "Data parallelism": [[21, "data-parallelism"]], "Datasets": [[45, "datasets"]], "Debug": [[69, "debug"]], "Debug Mode": [[82, "debug-mode"]], "Debug SGLang with VSCode Debugger": [[48, "debug-sglang-with-vscode-debugger"]], "Debug tensor dumps": [[21, "debug-tensor-dumps"]], "Decode": [[70, "decode"]], "Decode Server Configuration": [[14, "decode-server-configuration"]], "DeepEP Configuration": [[63, "deepep-configuration"]], "DeepEP-compatible Library": [[54, "deepep-compatible-library"]], "DeepGEMM Configuration (Advanced Optimization)": [[63, "deepgemm-configuration-advanced-optimization"]], "DeepSeek Multi-Node": [[14, "deepseek-multi-node"], [14, "id4"], [14, "id7"]], "DeepSeek V3.2 Usage": [[28, null]], "DeepSeek V3/R1": [[71, "deepseek-v3-r1"]], "DeepSeek V3/V3.1/R1 Usage": [[27, null]], "DeepSeek examples": [[55, null]], "DeepSeekV32-Exp RBG Based PD Deploy": [[73, null]], "Default Behavior": [[3, "default-behavior"]], "Define Messages": [[25, "Define-Messages"]], "Define Tools for Function Call": [[25, "Define-Tools-for-Function-Call"]], "Define a Tool Function": [[25, "Define-a-Tool-Function"]], "Deploy On Kubernetes": [[69, null]], "Deploy minilb and lb service": [[70, "deploy-minilb-and-lb-service"]], "Deploying Quantized Models": [[16, "deploying-quantized-models"]], "Deployment Modes": [[19, "deployment-modes"]], "Deployment with HF3FS": [[9, "deployment-with-hf3fs"]], "Deployment with Mooncake": [[9, "deployment-with-mooncake"]], "Deprecated arguments": [[21, "deprecated-arguments"]], "Deterministic Inference": [[3, null]], "Deterministic Inference with Non-Greedy Sampling (Temperature > 0)": [[3, "deterministic-inference-with-non-greedy-sampling-temperature-0"]], "Developer Guide": [[52, null]], "Development Guide Using Docker": [[48, null]], "Diffusion Language Models": [[79, null]], "Disable NUMA Auto-Balancing": [[53, "disable-numa-auto-balancing"]], "Disable NUMA balancing": [[54, "disable-numa-balancing"]], "Distributed Computing": [[63, "distributed-computing"]], "Docker": [[28, "docker"]], "Docs Workflow": [[0, "docs-workflow"]], "Documentation": [[60, "documentation"], [87, "documentation"]], "Documentation Style Guidelines": [[0, "documentation-style-guidelines"]], "Double Sparsity": [[21, "double-sparsity"]], "Download Weights": [[27, "download-weights"]], "Dynamic Backend Loading": [[9, "dynamic-backend-loading"]], "Dynamic LoRA loading": [[12, "Dynamic-LoRA-loading"]], "EAGLE Decoding": [[22, "EAGLE-Decoding"]], "EAGLE Speculative Decoding": [[29, "eagle-speculative-decoding"], [32, "eagle-speculative-decoding"], [41, "eagle-speculative-decoding"]], "EAGLE-2 Decoding via Frequency-Ranked Speculative Sampling": [[22, "EAGLE-2-Decoding-via-Frequency-Ranked-Speculative-Sampling"]], "EAGLE-2 Decoding with torch.compile": [[22, "EAGLE-2-Decoding-with-torch.compile"]], "EAGLE-2 decoding": [[22, "EAGLE-2-decoding"]], "EAGLE-3 Decoding": [[22, "EAGLE-3-Decoding"]], "EBNF": [[23, "EBNF"], [23, "id2"], [23, "id6"], [24, "EBNF"], [24, "id2"], [24, "id6"]], "EPD Disaggregation": [[5, null]], "Embedding Models": [[80, null]], "Enabling Quantized KV Cache": [[17, "enabling-quantized-kv-cache"]], "Enabling cache for torch.compile": [[77, null]], "Encode (embedding model)": [[33, "Encode-(embedding-model)"]], "End-to-end examples": [[45, "end-to-end-examples"]], "Endpoints": [[35, "endpoints"]], "Environment Variables": [[63, null]], "Environment Verification": [[60, "environment-verification"]], "Error Handling": [[78, "error-handling"]], "Evaluation": [[48, "evaluation"]], "Example Client Code Snippet": [[79, "example-client-code-snippet"]], "Example Client Request": [[85, "example-client-request"]], "Example Configuration File": [[79, "example-configuration-file"]], "Example Configurations": [[3, "example-configurations"]], "Example Launch Command": [[79, "example-launch-command"], [85, "example-launch-command"]], "Example Usage": [[78, "example-usage"]], "Example Usage Commands": [[58, "example-usage-commands"]], "Example launch Command": [[81, "example-launch-command"], [84, "example-launch-command"], [86, "example-launch-command"], [88, "example-launch-command"]], "Example usage with the above optimizations:": [[30, "example-usage-with-the-above-optimizations"], [42, "example-usage-with-the-above-optimizations"]], "Example workflow": [[46, "example-workflow"]], "Example: DeepSeek-V3 Models": [[37, "Example:-DeepSeek-V3-Models"]], "Example: Implementing and Serving a Llama Wrapper Model": [[87, "example-implementing-and-serving-a-llama-wrapper-model"]], "Example: Qwen3 Models": [[37, "Example:-Qwen3-Models"]], "Example: Required Tool Choice": [[25, "Example:-Required-Tool-Choice"]], "Example: Running DeepSeek-V3.1-Terminus": [[58, "example-running-deepseek-v3-1-terminus"]], "Example: Running Llama-3.2-3B": [[58, "example-running-llama-3-2-3b"]], "Example: Specific Function Choice": [[25, "Example:-Specific-Function-Choice"]], "Examples": [[6, "examples"], [6, "id1"], [43, "examples"], [45, "examples"], [53, "examples"]], "Examples of Offline Model Quantization": [[16, "examples-of-offline-model-quantization"]], "Execute the Tool": [[25, "Execute-the-Tool"]], "Expert Parallelism": [[6, null]], "Explicitly select devices": [[82, "explicitly-select-devices"]], "Extensible EP Framework": [[6, "extensible-ep-framework"]], "External Resources": [[60, "external-resources"]], "FAQ": [[27, "faq"], [70, "faq"], [73, "faq"]], "FP4 Accuracy": [[17, "fp4-accuracy"]], "FP4 Format": [[17, "fp4-format"]], "FP8 (quantised) mode": [[30, "fp8-quantised-mode"], [42, "fp8-quantised-mode"]], "FP8 Accuracy": [[17, "fp8-accuracy"]], "FP8 Format": [[17, "fp8-format"]], "Fault Tolerance": [[19, "fault-tolerance"]], "Feature Support Matrix": [[60, "feature-support-matrix"]], "Flush Cache": [[33, "Flush-Cache"]], "For PD-Multiplexing": [[21, "for-pd-multiplexing"]], "For deterministic inference": [[21, "for-deterministic-inference"]], "Forcing Pythonic Tool Call Output Without a Chat Template": [[25, "Forcing-Pythonic-Tool-Call-Output-Without-a-Chat-Template"]], "Fork and clone the repository": [[47, "fork-and-clone-the-repository"]], "Format code with pre-commit": [[47, "format-code-with-pre-commit"]], "Forward hooks": [[21, "forward-hooks"]], "Framework Overview": [[6, "framework-overview"]], "Frequently Asked Questions": [[64, "frequently-asked-questions"]], "Frontend Language": [[66, null], [66, null]], "Function Calling / Tool Use": [[63, "function-calling-tool-use"]], "Function Calling and Reasoning Parser": [[28, "function-calling-and-reasoning-parser"]], "Function calling for DeepSeek Models": [[27, "function-calling-for-deepseek-models"]], "Future Works": [[12, "Future-Works"]], "GLM-4.6V / GLM-4.5V Usage": [[30, null]], "GPT OSS Usage": [[31, null]], "General Configuration": [[63, "general-configuration"]], "Generate (text generation model)": [[33, "Generate-(text-generation-model)"]], "Generating Multiple Reproducible Responses": [[3, "generating-multiple-reproducible-responses"]], "Get Model Info": [[33, "Get-Model-Info"]], "Get Server Info": [[33, "Get-Server-Info"]], "Get Started": [[52, null]], "Getting Token IDs": [[37, "Getting-Token-IDs"]], "Greedy Token Selection": [[65, "greedy-token-selection"]], "Guidance about Dynamic Chunking": [[15, "guidance-about-dynamic-chunking"]], "HTTP API Usage": [[46, "http-api-usage"]], "HTTP server": [[21, "http-server"]], "Handle Tools": [[25, "Handle-Tools"], [25, "id1"]], "Hardware Platforms": [[52, null]], "Hardware-specific notes / recommendations": [[30, "hardware-specific-notes-recommendations"], [42, "hardware-specific-notes-recommendations"]], "Health Check": [[33, "Health-Check"]], "HiCache System Design and Optimization": [[10, null]], "HiRadixTree: Metadata Organization in HiCache": [[10, "hiradixtree-metadata-organization-in-hicache"]], "Hierarchical KV Caching (HiCache)": [[8, null]], "Hierarchical cache": [[21, "hierarchical-cache"]], "High-Performance Configuration: Qwen3-8B": [[60, "high-performance-configuration-qwen3-8b"]], "History & Data Connectors": [[19, "history-data-connectors"]], "Hook lifecycle and behavior": [[7, "hook-lifecycle-and-behavior"]], "Hook spec schema": [[7, "hook-spec-schema"]], "How to Contribute": [[60, "how-to-contribute"]], "How to Extend the Tracing Framework to Support Complex Tracing Scenarios": [[76, "how-to-extend-the-tracing-framework-to-support-complex-tracing-scenarios"]], "How to Support New Models": [[87, null]], "How to Support a New Language Model": [[87, "how-to-support-a-new-language-model"]], "How to Support a New Multimodal Large Language Model": [[87, "how-to-support-a-new-multimodal-large-language-model"]], "How to Trigger CI Tests": [[47, "how-to-trigger-ci-tests"]], "How to add Tracing for slices you\u2019re interested in?": [[76, "how-to-add-tracing-for-slices-you-re-interested-in"]], "How to enable": [[25, "How-to-enable"]], "How to support a new model?": [[25, "How-to-support-a-new-model?"]], "How to update sgl-kernel": [[47, "how-to-update-sgl-kernel"]], "Hybrid attention (different backends for prefill vs decode) (Experimental)": [[1, "hybrid-attention-different-backends-for-prefill-vs-decode-experimental"]], "Hyperparameter Tuning": [[11, null]], "Image input:": [[30, "image-input"], [42, "image-input"]], "Implementation Details": [[78, "implementation-details"]], "Implementation Refactoring based on Async Communication": [[15, "implementation-refactoring-based-on-async-communication"]], "Implementing New Backends": [[6, "implementing-new-backends"]], "Implementing Our Model": [[87, "implementing-our-model"]], "Important Notes": [[46, "important-notes"]], "Important Server Parameters and Flags": [[30, "important-server-parameters-and-flags"], [42, "important-server-parameters-and-flags"]], "Initialize the Client": [[25, "Initialize-the-Client"]], "Install Dependency": [[0, "install-dependency"]], "Install From Source": [[58, "install-from-source"], [61, "install-from-source"]], "Install SGLang": [[51, null], [53, "install-sglang"]], "Install SGLang from Source": [[47, "install-sglang-from-source"]], "Install Using Docker": [[58, "install-using-docker"], [61, "install-using-docker"]], "Install Using Docker (Recommended)": [[53, "install-using-docker-recommended"]], "Install from Source": [[53, "install-from-source"]], "Installation": [[2, "installation"], [16, "installation"], [28, "installation"], [58, "installation"], [60, "installation"], [61, "installation"], [82, "installation"]], "Installing SGLang": [[54, "installing-sglang"]], "Installing SGLang from source": [[54, "installing-sglang-from-source"]], "Installing and running SGLang with Jetson Containers": [[59, "installing-and-running-sglang-with-jetson-containers"]], "Integration with PD Disaggregation": [[9, "integration-with-pd-disaggregation"]], "Integration with PD-Disaggregation Deployment Mode": [[10, "integration-with-pd-disaggregation-deployment-mode"]], "Interactive Debugging": [[87, "interactive-debugging"]], "Introduction": [[82, "introduction"]], "Issues with Unified Scheduling": [[14, "issues-with-unified-scheduling"]], "JSON": [[23, "JSON"], [23, "id1"], [23, "id5"], [24, "JSON"], [24, "id1"], [24, "id5"]], "JSON Format": [[62, "json-format"]], "JSONL output format": [[45, "jsonl-output-format"]], "Jinja Format": [[62, "jinja-format"]], "Kernel Backends (Attention, Sampling, Grammar, GEMM)": [[21, "kernel-backends-attention-sampling-grammar-gemm"]], "Key Configurations with Storage Backends Enabled": [[9, "key-configurations-with-storage-backends-enabled"]], "Keys to success": [[69, "keys-to-success"]], "Known supported models": [[4, "known-supported-models"]], "Kubernetes Discovery": [[19, "kubernetes-discovery"]], "LMCache": [[21, "lmcache"]], "LWS Based PD Deploy": [[70, null]], "Large Language Models": [[81, null]], "Latency Optimization": [[60, "latency-optimization"]], "Latency Testing": [[60, "latency-testing"]], "Launch A Server": [[33, "Launch-A-Server"], [37, "Launch-A-Server"], [38, "Launch-A-Server"], [39, "Launch-A-Server"], [44, "Launch-A-Server"], [67, "Launch-A-Server"]], "Launch Command for Different Attention Backends": [[1, "launch-command-for-different-attention-backends"]], "Launch DeepSeek V3.1/V3/R1 with SGLang": [[27, "launch-deepseek-v3-1-v3-r1-with-sglang"]], "Launch DeepSeek V3.2 with SGLang": [[28, "launch-deepseek-v3-2-with-sglang"]], "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang": [[29, null]], "Launch Llama 4 with SGLang": [[32, "launch-llama-4-with-sglang"]], "Launch Qwen3-Next with SGLang": [[41, "launch-qwen3-next-with-sglang"]], "Launch Server": [[80, "launch-server"]], "Launch commands for SGLang": [[30, "launch-commands-for-sglang"], [42, "launch-commands-for-sglang"]], "Launch of the Serving Engine": [[58, "launch-of-the-serving-engine"], [60, "launch-of-the-serving-engine"], [61, "launch-of-the-serving-engine"]], "Launch with one node of 8 x H200": [[27, "launch-with-one-node-of-8-x-h200"]], "Launching the Server": [[20, "Launching-the-Server"], [25, "Launching-the-Server"]], "Layer-wise NVTX Profiling with Nsight Systems": [[46, "layer-wise-nvtx-profiling-with-nsight-systems"]], "Learn More and Join the Community": [[68, null]], "Llama 3.1 405B": [[71, "llama-3-1-405b"]], "Llama 4 Basic Call": [[26, "Llama-4-Basic-Call"]], "Llama Models": [[3, "llama-models"]], "Llama Single Node": [[14, "llama-single-node"], [14, "id3"], [14, "id6"]], "Llama4 Usage": [[32, null]], "LoRA": [[21, "lora"]], "LoRA GPU Pinning": [[12, "LoRA-GPU-Pinning"]], "LoRA Serving": [[12, null]], "Load Balancing Policies": [[19, "load-balancing-policies"]], "Local Match": [[10, "local-match"]], "Logging": [[13, "logging"], [21, "logging"]], "Logit Bias Support": [[37, "Logit-Bias-Support"], [37, "id1"]], "Low Throughput": [[60, "low-throughput"]], "MCP & Advanced Tooling": [[19, "mcp-advanced-tooling"]], "MHA Backends": [[1, "mha-backends"]], "MLA Backends": [[1, "mla-backends"]], "Make a release in GitHub": [[49, "make-a-release-in-github"]], "Mamba Cache": [[21, "mamba-cache"]], "Mamba Radix Cache": [[41, "mamba-radix-cache"]], "Matryoshka Embedding Example": [[80, "matryoshka-embedding-example"]], "MemFabric Adaptor": [[54, "memfabric-adaptor"]], "Memory Layout Optimization": [[9, "memory-layout-optimization"]], "Memory Management": [[63, "memory-management"]], "Memory Optimization": [[60, "memory-optimization"]], "Memory Savings": [[17, "memory-savings"]], "Memory and scheduling": [[21, "memory-and-scheduling"]], "Method 1: Installing from source with prerequisites": [[54, "method-1-installing-from-source-with-prerequisites"]], "Method 1: Using PyPI (Recommended)": [[60, "method-1-using-pypi-recommended"]], "Method 1: With pip or uv": [[51, "method-1-with-pip-or-uv"]], "Method 2: From Source": [[60, "method-2-from-source"]], "Method 2: From source": [[51, "method-2-from-source"]], "Method 2: Using docker": [[54, "method-2-using-docker"]], "Method 3: Using Docker": [[60, "method-3-using-docker"]], "Method 3: Using docker": [[51, "method-3-using-docker"]], "Method 4: Cloud TPU with SkyPilot": [[60, "method-4-cloud-tpu-with-skypilot"]], "Method 4: Using Kubernetes": [[51, "method-4-using-kubernetes"]], "Method 5: Using docker compose": [[51, "method-5-using-docker-compose"]], "Method 6: Run on Kubernetes or Clouds with SkyPilot": [[51, "method-6-run-on-kubernetes-or-clouds-with-skypilot"]], "Method 7: Run on AWS SageMaker": [[51, "method-7-run-on-aws-sagemaker"]], "Methods": [[65, "methods"]], "Metrics explained": [[45, "metrics-explained"]], "MindSpore Models": [[82, null]], "MoE": [[21, "moe"]], "Model Hooks": [[7, null]], "Model Thinking/Reasoning Support": [[37, "Model-Thinking/Reasoning-Support"]], "Model and tokenizer": [[21, "model-and-tokenizer"]], "Model override args": [[21, "model-override-args"]], "Model-Specific Behaviors": [[20, "Model-Specific-Behaviors"]], "Model-Specific Options": [[63, "model-specific-options"]], "Mooncake": [[14, "mooncake"]], "Multi Token Prediction": [[22, "Multi-Token-Prediction"]], "Multi-Modal Embedding Model": [[38, "Multi-Modal-Embedding-Model"]], "Multi-Node Deployment": [[71, null], [72, null], [72, null]], "Multi-Node Distributed Serving": [[60, "multi-node-distributed-serving"]], "Multi-Node Inference on SLURM": [[71, "multi-node-inference-on-slurm"]], "Multi-Node Profiling and Shared Storage Considerations": [[46, "multi-node-profiling-and-shared-storage-considerations"]], "Multi-Node Setup (2 Nodes)": [[2, "multi-node-setup-2-nodes"]], "Multi-Node Setup with Tensor Parallelism (TP=16)": [[2, "multi-node-setup-with-tensor-parallelism-tp-16"]], "Multi-Node Tensor Parallelism": [[27, "multi-node-tensor-parallelism"]], "Multi-Rank Synchronization": [[10, "multi-rank-synchronization"]], "Multi-head Latent Attention (MLA) Throughput Optimizations": [[27, "multi-head-latent-attention-mla-throughput-optimizations"]], "Multi-modal Generation": [[67, "Multi-modal-Generation"]], "Multi-node distributed serving": [[21, "multi-node-distributed-serving"]], "Multi-token Prediction": [[27, "multi-token-prediction"], [28, "multi-token-prediction"]], "Multi-turn Dialog": [[67, "Multi-turn-Dialog"]], "Multimodal": [[43, "multimodal"]], "Multimodal Embedding Example": [[80, "multimodal-embedding-example"]], "Multimodal Inputs Limitation": [[84, "multimodal-inputs-limitation"]], "Multimodal Language Models": [[84, null]], "Multiple-Image Inputs": [[39, "Multiple-Image-Inputs"]], "NCCL as backend": [[18, "nccl-as-backend"]], "NIXL": [[14, "nixl"]], "NVIDIA Jetson Orin": [[59, null]], "NVLink Transport Configuration": [[14, "nvlink-transport-configuration"]], "Native API and SGLang Runtime (SRT)": [[23, "Native-API-and-SGLang-Runtime-(SRT)"], [24, "Native-API-and-SGLang-Runtime-(SRT)"], [25, "Native-API-and-SGLang-Runtime-(SRT)"]], "Nest Asyncio": [[34, "Nest-Asyncio"]], "Ngram speculative decoding": [[21, "ngram-speculative-decoding"]], "Non-FP8 (BF16 / full precision) mode": [[30, "non-fp8-bf16-full-precision-mode"], [42, "non-fp8-bf16-full-precision-mode"]], "Non-Streaming Request": [[20, "Non-Streaming-Request"], [25, "Non-Streaming-Request"]], "Non-streaming Asynchronous Generation": [[34, "Non-streaming-Asynchronous-Generation"]], "Non-streaming Synchronous Generation": [[34, "Non-streaming-Synchronous-Generation"]], "Normal": [[43, "normal"]], "Note on defaults": [[43, "note-on-defaults"]], "Notes": [[31, "notes"], [45, "notes"]], "OOM (Out of Memory) Errors": [[60, "oom-out-of-memory-errors"]], "Observability": [[13, null], [19, "observability"]], "Offline Batch Inference": [[34, "Offline-Batch-Inference"]], "Offline Engine API": [[20, "Offline-Engine-API"], [23, "Offline-Engine-API"], [24, "Offline-Engine-API"], [25, "Offline-Engine-API"], [34, null]], "Offline Quantization": [[16, "offline-quantization"]], "Offline infer": [[82, "offline-infer"]], "Offloading": [[21, "offloading"]], "Ollama-Compatible API": [[35, null]], "Online Quantization": [[16, "online-quantization"]], "OpenAI APIs - Completions": [[37, null]], "OpenAI APIs - Embedding": [[38, null]], "OpenAI APIs - Vision": [[39, null]], "OpenAI Backend Proxy": [[19, "openai-backend-proxy"]], "OpenAI Compatible API": [[20, "OpenAI-Compatible-API"], [23, "OpenAI-Compatible-API"], [24, "OpenAI-Compatible-API"], [25, "OpenAI-Compatible-API"]], "OpenAI-Compatible APIs": [[36, null]], "OpenAI-compatible API usage": [[12, "OpenAI-compatible-API-usage"]], "Optimization/debug options": [[21, "optimization-debug-options"]], "Optimizations": [[27, "optimizations"]], "Optimized Model List": [[58, "optimized-model-list"], [60, "optimized-model-list"], [61, "optimized-model-list"]], "Option 1. Use the default dev container automatically from VSCode": [[48, "option-1-use-the-default-dev-container-automatically-from-vscode"]], "Option 2. Start up containers manually (advanced)": [[48, "option-2-start-up-containers-manually-advanced"]], "Other key options": [[45, "other-key-options"]], "Other options": [[43, "other-options"]], "Other tips": [[46, "other-tips"]], "Output Files": [[46, "output-files"]], "Overall Architecture": [[10, "overall-architecture"]], "Overall Workflow": [[10, "overall-workflow"]], "Overview": [[2, "overview"], [19, "overview"], [78, "overview"]], "PD Disaggregation": [[14, null], [28, "pd-disaggregation"]], "PD disaggregation": [[21, "pd-disaggregation"]], "Parallelism": [[67, "Parallelism"]], "Parameters": [[37, "Parameters"], [37, "id3"], [78, "parameters"]], "Penalizers": [[43, "penalizers"]], "Performance Benefits": [[2, "performance-benefits"]], "Performance Considerations": [[17, "performance-considerations"]], "Performance Highlights": [[22, "Performance-Highlights"]], "Performance Optimization": [[60, "performance-optimization"], [84, "performance-optimization"]], "Performance Tuning": [[63, "performance-tuning"]], "Pipeline Parallelism for Long Context": [[15, null]], "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, Qwen, and more)": [[40, null]], "Port a Model from vLLM to SGLang": [[87, "port-a-model-from-vllm-to-sglang"]], "Possible PyTorch bugs": [[46, "possible-pytorch-bugs"]], "Post-Training Integration": [[74, null]], "Prefetch Policies": [[9, "prefetch-policies"]], "Prefetch from L3": [[10, "prefetch-from-l3"]], "Prefill": [[70, "prefill"]], "Prefill Server Configuration": [[14, "prefill-server-configuration"]], "Prefill/Decode": [[19, "prefill-decode"]], "Prefill/Decode Disaggregation": [[19, "prefill-decode-disaggregation"]], "Prerequisites": [[35, "prerequisites"], [45, "prerequisites"], [59, "prerequisites"], [69, "prerequisites"], [75, "prerequisites"]], "Prevent swapping out system memory": [[54, "prevent-swapping-out-system-memory"]], "Production Metrics": [[13, "production-metrics"], [75, null]], "Production Request Tracing": [[76, null]], "Profile": [[48, "profile"]], "Profile Decode Workers": [[46, "profile-decode-workers"]], "Profile In PD Disaggregation Mode": [[46, "profile-in-pd-disaggregation-mode"]], "Profile Prefill Workers": [[46, "profile-prefill-workers"]], "Profile a server with HTTP API endpoints": [[46, "profile-a-server-with-http-api-endpoints"]], "Profile a server with sglang.bench_offline_throughput": [[46, "profile-a-server-with-sglang-bench-offline-throughput"]], "Profile a server with sglang.bench_serving": [[46, "profile-a-server-with-sglang-bench-serving"]], "Profile a server with sglang.profiler": [[46, "profile-a-server-with-sglang-profiler"]], "Profile with Nsight": [[46, "profile-with-nsight"]], "Profile with PyTorch Profiler": [[46, "profile-with-pytorch-profiler"]], "Profiler Trace Merger for Distributed Traces": [[46, "profiler-trace-merger-for-distributed-traces"]], "Profiling & Benchmarking": [[63, "profiling-benchmarking"]], "Profiling in PD Disaggregation Mode": [[14, "profiling-in-pd-disaggregation-mode"]], "PyPI Package Release Process": [[49, null]], "Python API Usage": [[16, "python-api-usage"]], "Python Tool": [[31, "python-tool"]], "Python Version": [[54, "python-version"]], "Pythonic Tool Call Format (Llama-3.2 / Llama-3.3 / Llama-4)": [[25, "Pythonic-Tool-Call-Format-(Llama-3.2-/-Llama-3.3-/-Llama-4)"]], "Pytorch and Pytorch Framework Adaptor on Ascend": [[54, "pytorch-and-pytorch-framework-adaptor-on-ascend"]], "Quantization": [[16, null], [88, "quantization"]], "Quantization and Export Workflow": [[16, "quantization-and-export-workflow"]], "Quantization and data type": [[21, "quantization-and-data-type"]], "Quantized KV Cache": [[17, null]], "Query VLM with Offline Engine": [[26, null]], "Querying Llama 4 Vision Model": [[26, "Querying-Llama-4-Vision-Model"]], "Querying Qwen2.5-VL Model": [[26, "Querying-Qwen2.5-VL-Model"]], "Quick Demo": [[31, "quick-demo"]], "Quick Start": [[35, "quick-start"], [80, "quick-start"]], "Quick start": [[45, "quick-start"]], "Qwen VL": [[5, "qwen-vl"]], "Qwen3 examples": [[56, null]], "Qwen3-30B-A3B (MoE Model)": [[3, "qwen3-30b-a3b-moe-model"]], "Qwen3-8B": [[3, "qwen3-8b"]], "Qwen3-Next Usage": [[41, null]], "Qwen3-VL Usage": [[42, null]], "R-Fork": [[18, null]], "RDMA RoCE case": [[69, "rdma-roce-case"]], "Rate Limiting & Queuing": [[19, "rate-limiting-queuing"]], "Rate, concurrency, and streaming": [[45, "rate-concurrency-and-streaming"]], "Reasoning Content for DeepSeek R1 & V3.1": [[27, "reasoning-content-for-deepseek-r1-v3-1"]], "Reasoning Parser": [[20, null]], "Reference": [[16, "reference"]], "References": [[2, "references"], [22, "References"], [52, null], [59, "references"], [60, "references"]], "Registering an External Model Implementation": [[87, "registering-an-external-model-implementation"]], "Regular expression": [[23, "Regular-expression"], [23, "id3"], [23, "id7"], [24, "Regular-expression"], [24, "id3"], [24, "id7"]], "Related Parameters": [[10, "related-parameters"]], "Reliability & Flow Control": [[19, "reliability-flow-control"]], "Remaining issues": [[69, "remaining-issues"]], "Remote code": [[88, "remote-code"]], "Request Dump and Replay": [[13, "request-dump-and-replay"]], "Request Format": [[78, "request-format"]], "Requesting a review for merge": [[47, "requesting-a-review-for-merge"]], "Requirements": [[14, "requirements"], [14, "id1"], [82, "requirements"]], "Rerank Models": [[85, null]], "Response Fields": [[78, "response-fields"]], "Response Format": [[78, "response-format"]], "Responses API": [[31, "responses-api"]], "Responses API & Built-in Tools": [[31, "responses-api-built-in-tools"]], "Retries": [[19, "retries"]], "Reward Models": [[86, null]], "Reward Models (Single score)": [[78, "reward-models-single-score"]], "RoCE scenario": [[69, "roce-scenario"]], "Router Integration": [[14, "router-integration"]], "Run Model": [[82, "run-model"]], "Run and add unit tests": [[47, "run-and-add-unit-tests"]], "Running DeepSeek on 1 x Atlas 800I A3.": [[55, "running-deepseek-on-1-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation on 2 x Atlas 800I A3.": [[55, "running-deepseek-with-pd-disaggregation-on-2-x-atlas-800i-a3"]], "Running DeepSeek with PD disaggregation on 4 x Atlas 800I A3.": [[55, "running-deepseek-with-pd-disaggregation-on-4-x-atlas-800i-a3"]], "Running DeepSeek-V3": [[53, "running-deepseek-v3"], [55, "running-deepseek-v3"]], "Running Inference": [[59, "running-inference"]], "Running Llama3.1": [[53, "running-llama3-1"]], "Running Qwen3": [[56, "running-qwen3"]], "Running Qwen3-235B-A22B-Instruct-2507 MOE on 1 x Atlas 800I A3.": [[56, "running-qwen3-235b-a22b-instruct-2507-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-30B-A3B MOE on 1 x Atlas 800I A3.": [[56, "running-qwen3-30b-a3b-moe-on-1-x-atlas-800i-a3"]], "Running Qwen3-32B on 1 x Atlas 800I A3 with Qwen3-32B-Eagle3.": [[56, "running-qwen3-32b-on-1-x-atlas-800i-a3-with-qwen3-32b-eagle3"]], "Running Qwen3-32B on 1 x Atlas 800I A3.": [[56, "running-qwen3-32b-on-1-x-atlas-800i-a3"]], "Running Qwen3-VL-8B-Instruct on 1 x Atlas 800I A3.": [[56, "running-qwen3-vl-8b-instruct-on-1-x-atlas-800i-a3"]], "Running examples on Multi-Node": [[27, "running-examples-on-multi-node"]], "Running quantization with TorchAO": [[59, "running-quantization-with-torchao"]], "Runtime options": [[21, "runtime-options"]], "SGLang Documentation": [[0, null], [52, null]], "SGLang Frontend Language": [[67, null]], "SGLang HiCache Best Practices": [[9, null]], "SGLang Kernels NPU": [[54, "sglang-kernels-npu"]], "SGLang Model Gateway (formerly SGLang Router)": [[19, null]], "SGLang Native API": [[20, "SGLang-Native-API"]], "SGLang Native APIs": [[33, null]], "SGLang Server Options": [[2, "sglang-server-options"]], "SGLang installation with NPUs support": [[54, null]], "SGLang\u2019s Solution": [[3, "sglang-s-solution"]], "Sampling Parameters": [[43, null]], "Sampling parameters": [[43, "id1"]], "Scaling Factors": [[17, "scaling-factors"]], "Security & Authentication": [[19, "security-authentication"]], "Send Results Back to Model": [[25, "Send-Results-Back-to-Model"]], "Sending Image/Video Requests": [[30, "sending-image-video-requests"], [42, "sending-image-video-requests"]], "Sending Requests": [[44, null]], "Separate Launch (HTTP)": [[19, "separate-launch-http"]], "Server Arguments": [[3, "server-arguments"], [21, null]], "Service Discovery (Kubernetes)": [[19, "service-discovery-kubernetes"]], "Serving Multiple Adaptors": [[12, "Serving-Multiple-Adaptors"]], "Serving Our Model Via SGLang\u2019s Offline Engine": [[87, "serving-our-model-via-sglang-s-offline-engine"]], "Serving Single Adaptor": [[12, "Serving-Single-Adaptor"]], "Set Up Self-Hosted Runners for GitHub Action": [[50, null]], "Setup Docker Container": [[48, "setup-docker-container"]], "Setup Guide": [[75, "setup-guide"], [76, "setup-guide"]], "Setup VSCode on a Remote Host": [[48, "setup-vscode-on-a-remote-host"]], "Single Node Setup": [[2, "single-node-setup"]], "Single-Batch Overlap (SBO)": [[6, "single-batch-overlap-sbo"]], "Smart Router": [[35, "smart-router"]], "Software Requirements": [[60, "software-requirements"]], "Some communication environment issues": [[82, "some-communication-environment-issues"]], "Some dependencies of protobuf": [[82, "some-dependencies-of-protobuf"]], "Speculative Decoding": [[22, null], [60, "speculative-decoding"]], "Speculative decoding": [[21, "speculative-decoding"]], "Speculative decoding with hybrid attention": [[1, "speculative-decoding-with-hybrid-attention"]], "Start server": [[82, "start-server"]], "Step 1: Start a docker container.": [[50, "step-1-start-a-docker-container"]], "Step 2: Configure the runner by config.sh": [[50, "step-2-configure-the-runner-by-config-sh"]], "Step 3: Run the runner by run.sh": [[50, "step-3-run-the-runner-by-run-sh"]], "Steps to add a new attention backend": [[1, "steps-to-add-a-new-attention-backend"]], "Storage & Caching": [[63, "storage-caching"]], "Storage & Privacy": [[19, "storage-privacy"]], "Streaming": [[43, "streaming"], [44, "Streaming"], [44, "id1"], [67, "Streaming"]], "Streaming Asynchronous Generation": [[34, "Streaming-Asynchronous-Generation"]], "Streaming Request": [[20, "Streaming-Request"], [25, "Streaming-Request"]], "Streaming Synchronous Generation": [[34, "Streaming-Synchronous-Generation"]], "Structural Tag": [[23, "Structural-Tag"], [23, "id4"], [23, "id8"], [24, "Structural-Tag"], [24, "id4"]], "Structured Outputs": [[23, null]], "Structured Outputs (JSON, Regex, EBNF)": [[37, "Structured-Outputs-(JSON,-Regex,-EBNF)"], [43, "structured-outputs-json-regex-ebnf"]], "Structured Outputs For Reasoning Models": [[24, null]], "Structured output with XGrammar": [[59, "structured-output-with-xgrammar"]], "Summary": [[7, "summary"], [35, "summary"]], "Support": [[82, "support"]], "Support Matrix": [[1, "support-matrix"]], "Supported Backends": [[3, "supported-backends"]], "Supported Backends and Selection Guidance": [[6, "supported-backends-and-selection-guidance"]], "Supported Formats": [[17, "supported-formats"]], "Supported Models": [[24, "Supported-Models"], [52, null], [78, "supported-models"], [79, "supported-models"], [80, "supported-models"], [82, "supported-models"]], "Supported Models & Parsers": [[20, "Supported-Models-&-Parsers"]], "Supported Models and Configuration": [[37, "Supported-Models-and-Configuration"]], "Supported TPU Hardware": [[60, "supported-tpu-hardware"]], "Supported Tool Choice Options": [[25, "Supported-Tool-Choice-Options"]], "Supported backends and endpoints": [[45, "supported-backends-and-endpoints"]], "Supported features": [[88, "supported-features"]], "Supported models": [[81, "supported-models"], [84, "supported-models"], [86, "supported-models"]], "Supported rerank models": [[85, "supported-rerank-models"]], "Supporting New Reasoning Model Schemas": [[20, "Supporting-New-Reasoning-Model-Schemas"]], "System Configuration": [[53, "system-configuration"]], "System Design": [[10, "system-design"]], "System Requirements": [[60, "system-requirements"]], "System Settings": [[54, "system-settings"]], "TODO": [[69, "todo"]], "TPU": [[60, null]], "TPU-Specific Optimizations": [[60, "tpu-specific-optimizations"]], "Table of Contents": [[19, "table-of-contents"]], "Test the accuracy": [[47, "test-the-accuracy"]], "Testing": [[78, "testing"]], "Testing & Debugging (Internal/CI)": [[63, "testing-debugging-internal-ci"]], "Testing and Debugging": [[87, "testing-and-debugging"]], "Testing on TPU": [[60, "testing-on-tpu"]], "The Root Cause of Non-Determinism": [[3, "the-root-cause-of-non-determinism"]], "The results are not deterministic, even with a temperature of 0": [[64, "the-results-are-not-deterministic-even-with-a-temperature-of-0"]], "The server hangs": [[64, "the-server-hangs"]], "Thinking Budget": [[29, "thinking-budget"]], "Thinking Budget for DeepSeek R1": [[27, "thinking-budget-for-deepseek-r1"]], "Thinking Budget for GLM-4.5V / GLM-4.6V": [[30, "thinking-budget-for-glm-4-5v-glm-4-6v"]], "Throughput Optimization": [[60, "throughput-optimization"]], "Throughput Testing": [[60, "throughput-testing"]], "Tips for newcomers": [[47, "tips-for-newcomers"]], "Token Length Normalized": [[65, "token-length-normalized"]], "Tokenize/Detokenize Example (Round Trip)": [[33, "Tokenize/Detokenize-Example-(Round-Trip)"]], "Tool & Reasoning Parser": [[31, "tool-reasoning-parser"]], "Tool Choice Mode": [[25, "Tool-Choice-Mode"]], "Tool Parser": [[25, null]], "Top-level fields": [[7, "top-level-fields"]], "TransferEngine as backend": [[18, "transferengine-as-backend"]], "Transformers fallback in SGLang": [[88, null]], "Triton on Ascend": [[54, "triton-on-ascend"]], "Troubleshooting": [[2, "troubleshooting"], [19, "troubleshooting"], [45, "troubleshooting"], [60, "troubleshooting"], [64, "troubleshooting"], [75, "troubleshooting"], [82, "troubleshooting"]], "Troubleshooting and Frequently Asked Questions": [[64, null]], "Try other options": [[11, "try-other-options"]], "Tune --cuda-graph-max-bs": [[11, "tune-cuda-graph-max-bs"]], "Tune --dp-size and --tp-size": [[11, "tune-dp-size-and-tp-size"]], "Tune --mem-fraction-static to increase KV cache pool capacity": [[11, "tune-mem-fraction-static-to-increase-kv-cache-pool-capacity"]], "Two-Batch Overlap (TBO)": [[6, "two-batch-overlap-tbo"]], "Unconditional Likelihood Normalized": [[65, "unconditional-likelihood-normalized"]], "Understanding the Three Input Formats": [[26, "Understanding-the-Three-Input-Formats"]], "Unified Interfaces and Rich L3 Storage Backends": [[10, "unified-interfaces-and-rich-l3-storage-backends"]], "Update Documentation": [[0, "update-documentation"]], "Update GRUB Settings": [[53, "update-grub-settings"]], "Update Weights From Disk": [[33, "Update-Weights-From-Disk"]], "Update the version in code": [[49, "update-the-version-in-code"]], "Upload the PyPI package": [[49, "upload-the-pypi-package"]], "Usage": [[3, "usage"], [5, "usage"], [12, "Usage"], [14, "usage"], [14, "id2"], [14, "id5"], [17, "usage"], [18, "usage"], [20, "Usage"], [24, "Usage"], [37, "Usage"], [37, "id2"], [75, "usage"]], "Usage Examples": [[2, "usage-examples"]], "Usage Notes": [[84, "usage-notes"]], "Use Models From ModelScope": [[83, null]], "User Guide": [[1, "user-guide"]], "Using --enable-layerwise-nvtx-marker with Nsight Systems and /start_profile": [[46, "using-enable-layerwise-nvtx-marker-with-nsight-systems-and-start-profile"]], "Using /end_profile endpoint": [[46, "using-end-profile-endpoint"]], "Using /start_profile endpoint": [[46, "using-start-profile-endpoint"]], "Using GPTQModel": [[16, "using-gptqmodel"]], "Using Input IDs": [[38, "Using-Input-IDs"]], "Using LLM Compressor": [[16, "using-llm-compressor"]], "Using LoRA Adapters": [[37, "Using-LoRA-Adapters"]], "Using NVIDIA ModelOpt": [[16, "using-nvidia-modelopt"]], "Using Native Generation APIs": [[44, "Using-Native-Generation-APIs"]], "Using OpenAI Python Client": [[38, "Using-OpenAI-Python-Client"], [39, "Using-OpenAI-Python-Client"], [44, "Using-OpenAI-Python-Client"]], "Using Python": [[78, "using-python"]], "Using Python Requests": [[38, "Using-Python-Requests"], [39, "Using-Python-Requests"], [44, "Using-Python-Requests"]], "Using Unsloth": [[16, "using-unsloth"]], "Using auto-round": [[16, "using-auto-round"]], "Using cURL": [[38, "Using-cURL"], [39, "Using-cURL"], [44, "Using-cURL"]], "Using curl": [[78, "using-curl"]], "Verification": [[3, "verification"]], "Video Input Support": [[84, "video-input-support"]], "Video Input:": [[30, "video-input"], [42, "video-input"]], "View traces": [[46, "view-traces"]], "Warmup Step": [[53, "warmup-step"]], "Web Search Tool": [[31, "web-search-tool"]], "What it does": [[45, "what-it-does"]], "Why Deterministic Inference Matters": [[3, "why-deterministic-inference-matters"]], "Why Dynamic Chunking": [[15, "why-dynamic-chunking"]], "Why HiCache Matters": [[9, "why-hicache-matters"]], "Why Pipeline Parallelism?": [[15, "why-pipeline-parallelism"]], "Why and What is EPD Disaggregation?": [[5, "why-and-what-is-epd-disaggregation"]], "Why and What is HiCache?": [[10, "why-and-what-is-hicache"]], "Why and What is PD Disaggregation?": [[14, "why-and-what-is-pd-disaggregation"]], "Worker Lifecycle & Dynamic Scaling": [[19, "worker-lifecycle-dynamic-scaling"]], "Workload Balancer": [[6, "workload-balancer"]], "Write documentations": [[47, "write-documentations"]], "Writing a hook factory": [[7, "writing-a-hook-factory"]], "XPU": [[61, null]], "config (optional)": [[7, "config-optional"]], "gRPC Launch": [[19, "grpc-launch"]], "hook_factory (required)": [[7, "hook-factory-required"]], "name (optional)": [[7, "name-optional"]], "target_modules (required)": [[7, "target-modules-required"]], "test gsm8k": [[55, "test-gsm8k"]], "v1/rerank (cross encoder rerank model)": [[33, "v1/rerank-(cross-encoder-rerank-model)"]]}, "docnames": ["README", "advanced_features/attention_backend", "advanced_features/checkpoint_engine", "advanced_features/deterministic_inference", "advanced_features/dp_for_multi_modal_encoder", "advanced_features/epd_disaggregation", "advanced_features/expert_parallelism", "advanced_features/forward_hooks", "advanced_features/hicache", "advanced_features/hicache_best_practices", "advanced_features/hicache_design", "advanced_features/hyperparameter_tuning", "advanced_features/lora", "advanced_features/observability", "advanced_features/pd_disaggregation", "advanced_features/pipeline_parallelism", "advanced_features/quantization", "advanced_features/quantized_kv_cache", "advanced_features/rfork", "advanced_features/router", "advanced_features/separate_reasoning", "advanced_features/server_arguments", "advanced_features/speculative_decoding", "advanced_features/structured_outputs", "advanced_features/structured_outputs_for_reasoning_models", "advanced_features/tool_parser", "advanced_features/vlm_query", "basic_usage/deepseek_v3", "basic_usage/deepseek_v32", "basic_usage/glm45", "basic_usage/glmv", "basic_usage/gpt_oss", "basic_usage/llama4", "basic_usage/native_api", "basic_usage/offline_engine_api", "basic_usage/ollama_api", "basic_usage/openai_api", "basic_usage/openai_api_completions", "basic_usage/openai_api_embeddings", "basic_usage/openai_api_vision", "basic_usage/popular_model_usage", "basic_usage/qwen3", "basic_usage/qwen3_vl", "basic_usage/sampling_params", "basic_usage/send_request", "developer_guide/bench_serving", "developer_guide/benchmark_and_profiling", "developer_guide/contribution_guide", "developer_guide/development_guide_using_docker", "developer_guide/release_process", "developer_guide/setup_github_runner", "get_started/install", "index", "platforms/amd_gpu", "platforms/ascend_npu", "platforms/ascend_npu_deepseek_example", "platforms/ascend_npu_qwen3_examples", "platforms/ascend_npu_support", "platforms/cpu_server", "platforms/nvidia_jetson", "platforms/tpu", "platforms/xpu", "references/custom_chat_template", "references/environment_variables", "references/faq", "references/frontend/choices_methods", "references/frontend/frontend_index", "references/frontend/frontend_tutorial", "references/learn_more", "references/multi_node_deployment/deploy_on_k8s", "references/multi_node_deployment/lws_pd/lws_pd_deploy", "references/multi_node_deployment/multi_node", "references/multi_node_deployment/multi_node_index", "references/multi_node_deployment/rbg_pd/deepseekv32_pd", "references/post_training_integration", "references/production_metrics", "references/production_request_trace", "references/torch_compile_cache", "supported_models/classify_models", "supported_models/diffusion_language_models", "supported_models/embedding_models", "supported_models/generative_models", "supported_models/mindspore_models", "supported_models/modelscope", "supported_models/multimodal_language_models", "supported_models/rerank_models", "supported_models/reward_models", "supported_models/support_new_models", "supported_models/transformers_fallback"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["README.md", "advanced_features/attention_backend.md", "advanced_features/checkpoint_engine.md", "advanced_features/deterministic_inference.md", "advanced_features/dp_for_multi_modal_encoder.md", "advanced_features/epd_disaggregation.md", "advanced_features/expert_parallelism.md", "advanced_features/forward_hooks.md", "advanced_features/hicache.rst", "advanced_features/hicache_best_practices.md", "advanced_features/hicache_design.md", "advanced_features/hyperparameter_tuning.md", "advanced_features/lora.ipynb", "advanced_features/observability.md", "advanced_features/pd_disaggregation.md", "advanced_features/pipeline_parallelism.md", "advanced_features/quantization.md", "advanced_features/quantized_kv_cache.md", "advanced_features/rfork.md", "advanced_features/router.md", "advanced_features/separate_reasoning.ipynb", "advanced_features/server_arguments.md", "advanced_features/speculative_decoding.ipynb", "advanced_features/structured_outputs.ipynb", "advanced_features/structured_outputs_for_reasoning_models.ipynb", "advanced_features/tool_parser.ipynb", "advanced_features/vlm_query.ipynb", "basic_usage/deepseek_v3.md", "basic_usage/deepseek_v32.md", "basic_usage/glm45.md", "basic_usage/glmv.md", "basic_usage/gpt_oss.md", "basic_usage/llama4.md", "basic_usage/native_api.ipynb", "basic_usage/offline_engine_api.ipynb", "basic_usage/ollama_api.md", "basic_usage/openai_api.rst", "basic_usage/openai_api_completions.ipynb", "basic_usage/openai_api_embeddings.ipynb", "basic_usage/openai_api_vision.ipynb", "basic_usage/popular_model_usage.rst", "basic_usage/qwen3.md", "basic_usage/qwen3_vl.md", "basic_usage/sampling_params.md", "basic_usage/send_request.ipynb", "developer_guide/bench_serving.md", "developer_guide/benchmark_and_profiling.md", "developer_guide/contribution_guide.md", "developer_guide/development_guide_using_docker.md", "developer_guide/release_process.md", "developer_guide/setup_github_runner.md", "get_started/install.md", "index.rst", "platforms/amd_gpu.md", "platforms/ascend_npu.md", "platforms/ascend_npu_deepseek_example.md", "platforms/ascend_npu_qwen3_examples.md", "platforms/ascend_npu_support.rst", "platforms/cpu_server.md", "platforms/nvidia_jetson.md", "platforms/tpu.md", "platforms/xpu.md", "references/custom_chat_template.md", "references/environment_variables.md", "references/faq.md", "references/frontend/choices_methods.md", "references/frontend/frontend_index.rst", "references/frontend/frontend_tutorial.ipynb", "references/learn_more.md", "references/multi_node_deployment/deploy_on_k8s.md", "references/multi_node_deployment/lws_pd/lws_pd_deploy.md", "references/multi_node_deployment/multi_node.md", "references/multi_node_deployment/multi_node_index.rst", "references/multi_node_deployment/rbg_pd/deepseekv32_pd.md", "references/post_training_integration.md", "references/production_metrics.md", "references/production_request_trace.md", "references/torch_compile_cache.md", "supported_models/classify_models.md", "supported_models/diffusion_language_models.md", "supported_models/embedding_models.md", "supported_models/generative_models.md", "supported_models/mindspore_models.md", "supported_models/modelscope.md", "supported_models/multimodal_language_models.md", "supported_models/rerank_models.md", "supported_models/reward_models.md", "supported_models/support_new_models.md", "supported_models/transformers_fallback.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [5, 6, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 47, 48, 51, 53, 54, 59, 63, 65, 67, 69, 74, 75, 76, 78, 79, 80, 81, 84, 85, 88], "0": [0, 2, 5, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 67, 69, 71, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "00": [12, 20, 22, 23, 24, 25, 26, 28, 33, 34, 37, 38, 39, 44, 67, 69, 71], "000": [24, 28, 47, 52], "0000": [11, 69], "00001": 16, "00002962350845336914": 38, "00004738569259643555": 38, "00005257129669189453": 38, "00006532669067382812": 38, "00008237361907958984": 38, "0000928044319152832": 38, "0000998377799987793": 38, "0001": 69, "00010514259338378906": 38, "0001322031021118164": 38, "00013875961303710938": 38, "00014603137969970703": 38, "0001493692398071289": 38, "0001697540283203125": 38, "00017774105072021484": 38, "00018644332885742188": 38, "0001951456069946289": 38, "0002": 22, "0002028942108154297": 38, "0002053976058959961": 38, "00021159648895263672": 38, "00021409988403320312": 38, "00023102760314941406": [33, 38], "0002351999282836914": 38, "00025582313537597656": 38, "0002701282501220703": 38, "00027441978454589844": 38, "00029540061950683594": 38, "0003": 22, "00031065940856933594": 38, "00032067298889160156": 38, "0003418922424316406": 38, "0003495216369628906": 38, "00035071372985839844": 38, "0003693103790283203": 38, "0003848075866699219": 38, "00039005279541015625": 38, "0003972053527832031": 38, "0004031658172607422": 38, "00040984153747558594": 38, "0004382133483886719": 38, "0004413127899169922": 38, "00044417381286621094": 38, "0004513263702392578": 38, "0004620552062988281": 38, "0005130767822265625": 38, "0005335807800292969": 38, "0005621910095214844": 38, "0005698204040527344": 38, "0005784034729003906": 38, "0006489753723144531": 38, "0006608963012695312": 38, "0006771087646484375": 38, "0006952285766601562": 38, "0007076263427734375": 38, "0007262229919433594": 38, "000728607177734375": 38, "0007519721984863281": 38, "0007572174072265625": 38, "0007658004760742188": 38, "0007991790771484375": 38, "0008139610290527344": 38, "0008296966552734375": 38, "0008397102355957031": 38, "0008406639099121094": 38, "0008764266967773438": 38, "0009050369262695312": 38, "0009250640869140625": 38, "0009288787841796875": 38, "0009407997131347656": 38, "0009546279907226562": 38, "0009584426879882812": 38, "0009703636169433594": 38, "000988006591796875": 38, "0009918212890625": 38, "001": [70, 73, 75], "0010013580322265625": 38, "0010061264038085938": 38, "0010251998901367188": 38, "0010318756103515625": 38, "0010385513305664062": 38, "0010423660278320312": 38, "001056671142578125": 38, "0010623931884765625": 38, "0010852813720703125": 38, "0010995864868164062": 38, "0011196136474609375": 38, "0011234283447265625": 38, "0011415481567382812": 38, "0011529922485351562": 38, "0011587142944335938": 38, "001186370849609375": 38, "0011911392211914062": 38, "0011949539184570312": 38, "00119781494140625": 38, "0012035369873046875": 38, "00121307373046875": 38, "0012311935424804688": 38, "0012607574462890625": 38, "0012693405151367188": 38, "0012760162353515625": 38, "0012845993041992188": 38, "0012979507446289062": 38, "0013246536254882812": 38, "001338958740234375": 38, "0013513565063476562": 38, "001354217529296875": 38, "0013570785522460938": 38, "0013742446899414062": 38, "001377105712890625": 38, "0013799667358398438": 38, "0013914108276367188": 38, "0014181137084960938": 38, "001422882080078125": 38, "0014295578002929688": 38, "0014467239379882812": 38, "0014743804931640625": 38, "0014867782592773438": 38, "0014982223510742188": 38, "0015039443969726562": 38, "0015106201171875": 38, "001552581787109375": 38, "0015573501586914062": 38, "0015630722045898438": 38, "0015840530395507812": 38, "00159454345703125": 38, "0016031265258789062": 38, "0016222000122070312": 38, "0016231536865234375": 38, "0016326904296875": 38, "0016994476318359375": 38, "0017156600952148438": 38, "0017194747924804688": 38, "001720428466796875": 38, "0017271041870117188": 38, "0017423629760742188": 38, "0017652511596679688": 38, "0017824172973632812": 38, "00179290771484375": 38, "001811981201171875": 38, "0018157958984375": 38, "0018186569213867188": 38, "0018243789672851562": 38, "0018367767333984375": 38, "0018520355224609375": 38, "0018749237060546875": 38, "0018901824951171875": 38, "0019025802612304688": 38, "0019130706787109375": 38, "0019359588623046875": 38, "0019464492797851562": 38, "001983642578125": 38, "0019989013671875": 38, "002": [20, 21, 23, 24, 25, 26, 33, 34], "00201416015625": 38, "002033233642578125": 38, "0020389556884765625": 38, "0020427703857421875": 38, "002044677734375": 38, "0020751953125": 38, "0020847320556640625": 38, "0021038055419921875": 38, "0021190643310546875": 38, "002124786376953125": 38, "00214385986328125": 38, "0021457672119140625": 38, "00217437744140625": 38, "002193450927734375": 38, "0021953582763671875": 38, "0022068023681640625": 38, "0022106170654296875": 38, "0022411346435546875": 38, "0022487640380859375": 38, "0022735595703125": 38, "002288818359375": 38, "0023021697998046875": 38, "0023040771484375": 38, "002338409423828125": 38, "002349853515625": 38, "0023708343505859375": 38, "0023746490478515625": 38, "00238800048828125": 38, "0024089813232421875": 38, "002460479736328125": 38, "0024623870849609375": 38, "0024738311767578125": 38, "002513885498046875": 38, "0025234222412109375": 38, "0025348663330078125": 38, "0025424957275390625": 38, "0025730133056640625": 38, "0025844573974609375": 38, "0025882720947265625": 38, "00261688232421875": 38, "0026378631591796875": 38, "0026416778564453125": 38, "00264739990234375": 38, "0026607513427734375": 38, "00270843505859375": 38, "002750396728515625": 38, "002765655517578125": 38, "00276947021484375": 38, "0027828216552734375": 38, "0027980804443359375": 38, "002826690673828125": 38, "002838134765625": 38, "0028438568115234375": 38, "002849578857421875": 38, "0028591156005859375": 38, "002864837646484375": 38, "00286865234375": 38, "002918243408203125": 38, "0029296875": 38, "0029582977294921875": 38, "0029697418212890625": 38, "00298309326171875": 38, "0029964447021484375": 38, "0030002593994140625": 38, "00301361083984375": 38, "0030498504638671875": 38, "0030574798583984375": 38, "0030612945556640625": 38, "003070831298828125": 38, "00307464599609375": 38, "0030803680419921875": 38, "003086090087890625": 38, "00308990478515625": 38, "0030918121337890625": 38, "003139495849609375": 38, "0031452178955078125": 38, "0031528472900390625": 38, "003154754638671875": 38, "0031948089599609375": 38, "003215789794921875": 38, "00322723388671875": 38, "0032444000244140625": 38, "0032711029052734375": [33, 38], "00328826904296875": 38, "003307342529296875": 38, "0033359527587890625": 38, "0033473968505859375": 38, "003353118896484375": 38, "00336456298828125": 38, "0033740997314453125": 38, "0033931732177734375": 38, "0034122467041015625": 38, "00342559814453125": 38, "0034503936767578125": 38, "0034637451171875": 38, "00347137451171875": 38, "003475189208984375": 38, "00350189208984375": 38, "0035037994384765625": 38, "003520965576171875": 38, "003574371337890625": 38, "003582000732421875": 38, "0036029815673828125": 38, "0036106109619140625": 38, "003631591796875": 38, "0036411285400390625": 38, "0036945343017578125": 38, "003711700439453125": 38, "0037212371826171875": 38, "0037288665771484375": 38, "0037326812744140625": 38, "003742218017578125": 38, "003753662109375": 38, "0037593841552734375": 38, "0037841796875": 38, "0037975311279296875": 38, "0038051605224609375": 38, "0038089752197265625": 38, "00382232666015625": 38, "003833770751953125": 38, "003917694091796875": 38, "00394439697265625": 38, "003948211669921875": 38, "003963470458984375": 38, "003971099853515625": 38, "003978729248046875": 38, "0039825439453125": 38, "003986358642578125": 38, "003993988037109375": 38, "00400543212890625": 38, "004016876220703125": 38, "004024505615234375": 38, "0040435791015625": 38, "00405120849609375": 38, "0040740966796875": 38, "004100799560546875": 38, "004123687744140625": 38, "004150390625": 38, "00415802001953125": 38, "004161834716796875": 38, "00417327880859375": 38, "004184722900390625": 38, "0041961669921875": 38, "004207611083984375": 38, "00424957275390625": 38, "004276275634765625": 38, "004283905029296875": 38, "0042877197265625": 38, "004390716552734375": 38, "00440216064453125": 38, "004413604736328125": 38, "004497528076171875": 38, "004512786865234375": 38, "0045318603515625": 38, "0045623779296875": 38, "00457000732421875": 38, "0045928955078125": 38, "00463104248046875": 38, "004642486572265625": 38, "00466156005859375": 38, "004665374755859375": 38, "004680633544921875": 38, "004688262939453125": 38, "00469207763671875": 38, "004695892333984375": 38, "00469970703125": 38, "0047149658203125": 38, "004726409912109375": 38, "0047607421875": 38, "004810333251953125": 38, "0048370361328125": 38, "00484466552734375": 38, "00487518310546875": 38, "004878997802734375": 38, "00493621826171875": 38, "0049591064453125": 38, "00496673583984375": 38, "004970550537109375": 38, "004974365234375": 38, "004985809326171875": 38, "005": 75, "0050048828125": 38, "005008697509765625": 38, "005023956298828125": 38, "005035400390625": 38, "005039215087890625": 38, "0050811767578125": 38, "005096435546875": 38, "005107879638671875": 38, "00513458251953125": 38, "005161285400390625": 38, "00521087646484375": 38, "005222320556640625": 38, "005237579345703125": 38, "00524139404296875": 38, "00525665283203125": 38, "005260467529296875": 38, "00527191162109375": 38, "00531005859375": 38, "005397796630859375": 38, "005405426025390625": 38, "00540924072265625": 38, "0054168701171875": 38, "00543975830078125": 38, "0054473876953125": 38, "00545501708984375": 38, "0054779052734375": 38, "00551605224609375": 38, "005519866943359375": 38, "005527496337890625": 38, "0055389404296875": 38, "005588531494140625": 38, "0055999755859375": 38, "00560760498046875": 38, "005626678466796875": 38, "005634307861328125": 38, "005657196044921875": 38, "00566864013671875": 38, "00569915771484375": 38, "0057220458984375": 38, "005725860595703125": 38, "005767822265625": 38, "0057830810546875": 38, "005794525146484375": 38, "00579833984375": 38, "00580596923828125": 38, "00583648681640625": 38, "005840301513671875": 38, "005847930908203125": 38, "005855560302734375": 38, "005859375": 38, "005878448486328125": 38, "005886077880859375": 38, "005893707275390625": 38, "0059051513671875": [33, 38], "00594329833984375": 38, "005962371826171875": 38, "005970001220703125": 38, "005992889404296875": 38, "00600433349609375": 38, "0060272216796875": 38, "00604248046875": 38, "00605010986328125": 38, "0060577392578125": 38, "006076812744140625": 38, "00611114501953125": 38, "006134033203125": 38, "006137847900390625": 38, "006145477294921875": 38, "0061492919921875": 38, "006160736083984375": 38, "00616455078125": 38, "006168365478515625": 38, "006175994873046875": 38, "00620269775390625": 38, "0062255859375": 38, "006229400634765625": 38, "0062408447265625": 38, "006256103515625": 38, "006259918212890625": 38, "006275177001953125": 38, "0063323974609375": 38, "00637054443359375": 38, "006374359130859375": 38, "00640106201171875": 38, "006420135498046875": 38, "006435394287109375": 38, "006450653076171875": 38, "0064544677734375": 38, "006465911865234375": 38, "006504058837890625": 38, "0065155029296875": 38, "006534576416015625": 38, "006542205810546875": 38, "0065765380859375": 38, "006580352783203125": 38, "00658416748046875": 38, "006587982177734375": 38, "006595611572265625": 38, "006618499755859375": 38, "006626129150390625": 38, "006633758544921875": 38, "006664276123046875": 38, "006687164306640625": 38, "00669097900390625": 38, "0066986083984375": 38, "006710052490234375": 38, "006717681884765625": 38, "00673675537109375": 38, "006755828857421875": 38, "00676727294921875": 38, "00679779052734375": 38, "006816864013671875": 38, "006908416748046875": 38, "006916046142578125": 38, "006923675537109375": 38, "006969451904296875": 38, "00698089599609375": 38, "006999969482421875": 38, "007": 24, "007007598876953125": 38, "007022857666015625": 38, "0070343017578125": 38, "00704193115234375": 38, "007106781005859375": 38, "007110595703125": 38, "007137298583984375": 38, "00717926025390625": 38, "007228851318359375": 38, "0072479248046875": 38, "00725555419921875": 38, "007289886474609375": 38, "007305145263671875": 38, "0073089599609375": 38, "00731658935546875": 38, "00733184814453125": 38, "00734710693359375": 38, "007373809814453125": 38, "00739288330078125": 38, "0074005126953125": 38, "00740814208984375": 38, "0074310302734375": 38, "007457733154296875": 38, "007465362548828125": 38, "00748443603515625": 38, "0074920654296875": 38, "00749969482421875": 38, "007507552643049313": 75, "007518768310546875": 38, "007534027099609375": 38, "0075531005859375": 38, "00759124755859375": 38, "00763702392578125": 38, "007678985595703125": 38, "007709503173828125": 38, "007720947265625": 38, "0077362060546875": 38, "00775146484375": 38, "007755279541015625": 38, "007778167724609375": 38, "007793426513671875": 38, "0077972412109375": 38, "00782012939453125": 38, "0078277587890625": 38, "00783538818359375": 38, "007843017578125": 38, "0078582763671875": 38, "007904052734375": 38, "0079193115234375": 38, "00794219970703125": 38, "007965087890625": 38, "00799560546875": 38, "00803375244140625": 38, "00807952880859375": 38, "00809478759765625": 38, "00811767578125": 38, "0081329345703125": 38, "0081634521484375": 38, "0081787109375": 38, "00820159912109375": 38, "00821685791015625": 38, "00824737548828125": 38, "0082550048828125": 38, "00826263427734375": 38, "0082855224609375": 38, "00829315185546875": 38, "00833892822265625": 38, "0083465576171875": 38, "00835418701171875": 38, "00836944580078125": 38, "0083770751953125": 38, "00838470458984375": 38, "0084228515625": 38, "00843048095703125": 38, "0084381103515625": 38, "00844573974609375": 38, "008453369140625": 38, "00847625732421875": 38, "008514404296875": 38, "0085296630859375": 38, "008544921875": 38, "00855255126953125": 38, "0085601806640625": 38, "00856781005859375": 38, "008575439453125": 38, "00860595703125": 38, "0086212158203125": 38, "0086669921875": 38, "0086822509765625": 38, "00868988037109375": 38, "008697509765625": 38, "00872039794921875": 38, "00872802734375": 38, "00873565673828125": 38, "0087432861328125": 38, "00878143310546875": 38, "00879669189453125": 38, "00881195068359375": 38, "008819580078125": 38, "00882720947265625": 38, "00884246826171875": 38, "00885772705078125": 38, "0088958740234375": 38, "0089111328125": 38, "0089263916015625": 38, "00893402099609375": 38, "00896453857421875": 38, "00897979736328125": 38, "009002685546875": 38, "0090179443359375": 38, "00902557373046875": 38, "00905609130859375": 38, "009063720703125": 38, "00907135009765625": 38, "0091094970703125": 38, "00911712646484375": 38, "00913238525390625": 38, "00914764404296875": 38, "00916290283203125": 38, "0091705322265625": 38, "00919342041015625": 38, "0092010498046875": 38, "00923919677734375": 38, "009246826171875": 38, "00925445556640625": 38, "00930023193359375": 38, "0093536376953125": 38, "00936126708984375": 38, "00939178466796875": 38, "0093994140625": 38, "00945281982421875": 38, "00946044921875": 38, "00948333740234375": 38, "009490966796875": 38, "00952911376953125": 38, "0095367431640625": 38, "00954437255859375": 38, "0095672607421875": 38, "00958251953125": 38, "00960540771484375": 38, "009613037109375": 38, "009674072265625": 38, "00968170166015625": 38, "0096893310546875": 38, "00970458984375": 38, "00975799560546875": 38, "00978851318359375": 38, "00980377197265625": 38, "00981903076171875": 38, "00982666015625": 38, "00983428955078125": 38, "009857177734375": 38, "00986480712890625": 38, "00988006591796875": 38, "00994110107421875": 38, "00995635986328125": 38, "00it": 26, "01": [11, 12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67, 69, 75], "0100250244140625": 38, "010040283203125": 38, "010101318359375": 38, "01010894775390625": 38, "0101165771484375": 38, "0101318359375": 38, "01013946533203125": 38, "01015472412109375": 38, "010162353515625": 38, "01018524169921875": 38, "01019287109375": 38, "0102081298828125": 38, "010223388671875": 38, "0102386474609375": 38, "01024": 16, "01025390625": 38, "01026153564453125": 38, "0102691650390625": 38, "01031494140625": 38, "0103302001953125": 38, "010345458984375": 38, "01035308837890625": 38, "01038360595703125": 38, "0104522705078125": 38, "010467529296875": 38, "01052093505859375": 38, "01053619384765625": 38, "0105438232421875": 38, "0105743408203125": 38, "01058197021484375": 38, "01064300537109375": 38, "01065826416015625": 38, "0106658935546875": 38, "01068115234375": 38, "01068878173828125": 38, "010711669921875": 38, "0107269287109375": 38, "0107421875": 38, "01074981689453125": 38, "010772705078125": 38, "01078033447265625": 38, "01079559326171875": 38, "01080322265625": 38, "0108184814453125": 38, "01084136962890625": 38, "0108489990234375": 38, "0108795166015625": 38, "010894775390625": 38, "01097869873046875": 38, "01099395751953125": 38, "01100921630859375": 38, "011016845703125": 38, "0110321044921875": 38, "0110626220703125": 38, "011077880859375": [33, 38], "01110076904296875": 38, "0111083984375": 38, "01113128662109375": 38, "01114654541015625": 38, "0111846923828125": 38, "01119232177734375": 38, "01123046875": 38, "01123809814453125": 38, "0112457275390625": 38, "0112762451171875": 38, "01129913330078125": 38, "01131439208984375": 38, "01132965087890625": 38, "0113372802734375": 38, "0113525390625": 38, "01136016845703125": 38, "0113677978515625": 38, "01137542724609375": 38, "011383056640625": 38, "0113983154296875": 38, "01141357421875": 38, "01143646240234375": 38, "011444091796875": 38, "01145172119140625": 38, "011474609375": 38, "0114898681640625": 38, "011505126953125": 38, "01151275634765625": 38, "0115203857421875": 38, "01152801513671875": 38, "01153564453125": 38, "0115814208984375": 38, "01158905029296875": 38, "0115966796875": 38, "0116119384765625": 38, "011627197265625": 38, "01171875": 38, "01175689697265625": 38, "01177978515625": 38, "01178741455078125": 38, "01180267333984375": 38, "01184844970703125": 38, "0118560791015625": 38, "01189422607421875": 38, "01190948486328125": 38, "0119476318359375": 38, "01195526123046875": 38, "011962890625": 38, "01198577880859375": 38, "01200103759765625": 38, "0120391845703125": 38, "01207733154296875": 38, "0120849609375": 38, "01210784912109375": 38, "01212310791015625": 38, "01213836669921875": 38, "01214599609375": 38, "0121612548828125": 38, "01218414306640625": 38, "0121917724609375": 38, "01219940185546875": 38, "01220703125": 38, "01224517822265625": 38, "01226806640625": 38, "012298583984375": 38, "0123291015625": 38, "012359619140625": 38, "0123748779296875": 38, "01241302490234375": 38, "012420654296875": 38, "012451171875": 38, "01247406005859375": 38, "01248931884765625": 38, "0125274658203125": 38, "01253509521484375": 38, "012542724609375": 38, "0125579833984375": 38, "01256561279296875": 38, "01259613037109375": 38, "012603759765625": 38, "01262664794921875": 38, "01263427734375": 38, "01264190673828125": 38, "01276397705078125": 38, "012786865234375": 38, "01280975341796875": 38, "0128326416015625": 38, "01285552978515625": 38, "01287078857421875": 38, "01287841796875": 38, "0128936767578125": 38, "012908935546875": 38, "01300811767578125": 38, "0130157470703125": 38, "01302337646484375": 38, "01303863525390625": 38, "0130462646484375": 38, "01305389404296875": 38, "01308441162109375": 38, "01312255859375": 38, "01317596435546875": 38, "01320648193359375": 38, "01325225830078125": 38, "01326751708984375": 38, "01328277587890625": 38, "0132904052734375": 38, "0133056640625": 38, "01332855224609375": 38, "0133514404296875": 38, "01335906982421875": 38, "01336669921875": 38, "01340484619140625": 38, "01346588134765625": 38, "01348114013671875": 38, "01349639892578125": 38, "0135040283203125": 38, "01355743408203125": 38, "01360321044921875": 38, "01361083984375": 38, "0136260986328125": 38, "01364898681640625": 38, "01367950439453125": 38, "01371002197265625": 38, "0137176513671875": 38, "01372528076171875": 38, "01373291015625": 38, "01374053955078125": 38, "013763427734375": 38, "0137786865234375": 38, "0138092041015625": 38, "01381683349609375": 38, "01384735107421875": 38, "01386260986328125": 38, "01389312744140625": 38, "01392364501953125": 38, "0139312744140625": 38, "013946533203125": 38, "01397705078125": 38, "0140228271484375": 38, "0140533447265625": [33, 38], "0140838623046875": 38, "01409912109375": 38, "01412200927734375": 38, "014129638671875": 38, "0141448974609375": 38, "01415252685546875": 38, "01418304443359375": 38, "0142059326171875": 38, "0142364501953125": 38, "01427459716796875": 38, "014312744140625": 38, "0143280029296875": 38, "0143585205078125": 38, "014373779296875": 38, "01441192626953125": [33, 38], "01442718505859375": 38, "01445770263671875": 38, "0144805908203125": 38, "014495849609375": 38, "0145111083984375": 38, "0145263671875": 38, "01454925537109375": 38, "01456451416015625": 38, "01457977294921875": 38, "014617919921875": 38, "0146484375": 38, "0146636962890625": 38, "014678955078125": 38, "0146942138671875": 38, "01470184326171875": 38, "01471710205078125": 38, "01473236083984375": 38, "0147857666015625": 38, "0148162841796875": 38, "01483154296875": 38, "0148468017578125": 38, "01488494873046875": 38, "01490020751953125": 38, "01491546630859375": 38, "01495361328125": 38, "0149993896484375": 38, "015": 75, "0150146484375": 38, "01505279541015625": 38, "01506805419921875": 38, "01509857177734375": 38, "01513671875": 38, "0151519775390625": 38, "01519012451171875": 38, "01520538330078125": 38, "01522064208984375": 38, "01523590087890625": 38, "01525115966796875": 38, "0152740478515625": 38, "01531982421875": 38, "01535797119140625": 38, "01540374755859375": 38, "01541900634765625": 38, "0154266357421875": 38, "01544189453125": 38, "015472412109375": 38, "0154876708984375": 38, "01551055908203125": 38, "01557159423828125": 38, "01558685302734375": 38, "0156097412109375": 38, "0156707763671875": 38, "01568603515625": 38, "015716552734375": 38, "0157318115234375": 38, "0157470703125": 38, "015777587890625": 38, "0157928466796875": 38, "015838623046875": 38, "0158538818359375": 38, "015869140625": 38, "0158843994140625": 38, "015899658203125": 38, "0159149169921875": 38, "015960693359375": 38, "0159759521484375": 38, "0159912109375": [33, 38], "0160064697265625": 38, "016021728515625": 38, "0160675048828125": 38, "0160980224609375": 38, "016143798828125": 38, "01617431640625": 38, "0161895751953125": 38, "016265869140625": 38, "016326904296875": 38, "016357421875": 38, "016448974609375": 38, "016510009765625": 38, "0165252685546875": 38, "0166015625": 38, "0166168212890625": 38, "016632080078125": 38, "0166778564453125": 38, "016693115234375": 38, "0167236328125": 38, "0167388916015625": 38, "0167694091796875": 38, "01678466796875": 38, "016815185546875": 38, "0168304443359375": 38, "016845703125": 38, "0168609619140625": 38, "016876220703125": 38, "016937255859375": 38, "0169677734375": 38, "016998291015625": 38, "0170745849609375": 38, "01708984375": 38, "0171966552734375": 38, "0172119140625": 38, "0172271728515625": 38, "017242431640625": 38, "0172882080078125": 38, "017333984375": 38, "017364501953125": 38, "0173797607421875": 38, "0174102783203125": 38, "0174560546875": 38, "017486572265625": 38, "0175018310546875": 38, "01751708984375": 38, "0175323486328125": 38, "0175628662109375": 38, "017578125": 38, "0176239013671875": 38, "01763916015625": 38, "0176849365234375": 38, "0177001953125": 38, "017730712890625": 38, "0177764892578125": 38, "0178070068359375": 38, "0178375244140625": 38, "017852783203125": 38, "01788330078125": 38, "0178985595703125": 38, "017913818359375": 38, "0179290771484375": 38, "0180816650390625": 38, "01812744140625": 38, "018157958984375": 38, "0181732177734375": 38, "018218994140625": 38, "0182342529296875": 38, "01824951171875": 38, "018280029296875": 38, "0183258056640625": 38, "01837158203125": 38, "018402099609375": 38, "0184173583984375": 38, "0184326171875": 38, "018463134765625": 38, "0185394287109375": 38, "0185546875": 38, "018585205078125": 38, "0186004638671875": 38, "018707275390625": 38, "01873779296875": 38, "0187530517578125": 38, "018768310546875": 38, "0188446044921875": 38, "018890380859375": 38, "0189208984375": 38, "0189361572265625": 38, "018951416015625": 38, "0189666748046875": 38, "01898193359375": 38, "019012451171875": 38, "01904296875": 38, "019073486328125": 38, "01910400390625": 38, "019134521484375": 38, "0192413330078125": 38, "01934814453125": 38, "0193634033203125": 38, "0193939208984375": 38, "0194854736328125": 38, "01953125": 38, "0196075439453125": 38, "019622802734375": 38, "0196533203125": 38, "019683837890625": 38, "0196990966796875": 38, "01971435546875": 38, "019775390625": 38, "0198211669921875": 38, "0198516845703125": 38, "019927978515625": 38, "019989013671875": 38, "02": [12, 20, 22, 23, 24, 25, 26, 33, 38, 39, 44, 67, 69, 75], "0200": 69, "0200042724609375": 38, "020050048828125": 38, "0200653076171875": 38, "020111083984375": 38, "020172119140625": 38, "0202178955078125": 38, "020233154296875": 38, "02032470703125": 38, "0203399658203125": 38, "0204315185546875": 38, "02044677734375": 38, "020477294921875": 38, "0205535888671875": 38, "02056884765625": 38, "0206298828125": 38, "0207061767578125": 38, "020721435546875": 38, "0207977294921875": 38, "02081298828125": 38, "0208282470703125": 38, "020843505859375": 38, "0208587646484375": 38, "0208740234375": 38, "0208892822265625": 38, "0209503173828125": 38, "0210418701171875": 38, "02117919921875": 38, "0211944580078125": 38, "021209716796875": 38, "0212249755859375": 38, "0212860107421875": 38, "0213470458984375": 38, "021392822265625": 38, "02142333984375": 38, "0214385986328125": 38, "021453857421875": 38, "021484375": 38, "021514892578125": 38, "0215301513671875": 38, "0215911865234375": 38, "0216522216796875": 38, "02166748046875": 38, "0216827392578125": 38, "0217132568359375": 38, "02175999991595745": 22, "0217742919921875": 38, "0218": 22, "0218353271484375": 38, "0218658447265625": 38, "021881103515625": 38, "0219573974609375": 38, "0219879150390625": 38, "0220": 22, "022016000002622604": 22, "02203369140625": 38, "0222": 22, "0222015380859375": 38, "022207999601960182": 22, "022216796875": 38, "0222625732421875": 38, "0222930908203125": 38, "0223236083984375": 38, "0224456787109375": 38, "0224761962890625": 38, "022491455078125": 38, "0225": 69, "02264404296875": 38, "022735595703125": 38, "0228424072265625": [33, 38], "022857666015625": 38, "022918701171875": 38, "0229949951171875": 38, "023": 80, "023040771484375": 38, "0230712890625": 38, "0231170654296875": 38, "02313232421875": 38, "0231475830078125": 38, "023162841796875": 38, "0232391357421875": 38, "023264000192284584": 22, "0232696533203125": 38, "0233": 22, "0233306884765625": 38, "0233612060546875": 38, "0234": 22, "0235137939453125": 38, "0235748291015625": 38, "02362060546875": 38, "0238494873046875": 38, "02386474609375": 38, "0238800048828125": 38, "023956298828125": 38, "02398681640625": 38, "024017333984375": 38, "02410888671875": 38, "0241546630859375": 38, "02423095703125": 38, "0242462158203125": 38, "024322509765625": 38, "0243988037109375": 38, "024505615234375": 38, "02471923828125": 38, "024749755859375": 38, "0247650146484375": 38, "0247802734375": 38, "0247955322265625": 38, "0248565673828125": 38, "0248870849609375": 38, "0249176025390625": 38, "025": 75, "0251617431640625": 38, "02520751953125": 38, "025238037109375": 38, "0252838134765625": 38, "025299072265625": 38, "0254058837890625": 38, "0255279541015625": 38, "025543212890625": 38, "0255584716796875": 38, "0255889892578125": 38, "0256500244140625": 38, "0256805419921875": 38, "025848388671875": 38, "025970458984375": 38, "0260009765625": 38, "026031494140625": 38, "026092529296875": 38, "0261688232421875": 38, "02618408203125": 38, "026214599609375": 38, "0262451171875": 38, "0262603759765625": 38, "0262908935546875": 38, "02642822265625": 38, "02646470069885254": 23, "0264739990234375": 38, "0265": 22, "0266265869140625": 38, "0266876220703125": 38, "0267181396484375": 38, "0268402099609375": 38, "0269775390625": 38, "0269927978515625": 38, "02716064453125": 38, "0272064208984375": 38, "0272369384765625": 38, "02728271484375": 38, "0272979736328125": [33, 38], "0273284912109375": 38, "0274200439453125": 38, "0275421142578125": 38, "027618408203125": 38, "027923583984375": 38, "0279693603515625": 38, "027a9f4a96df4481abb3307cb9e5fc7c": 23, "028045654296875": 38, "028076171875": 38, "0280914306640625": 38, "0281524658203125": 38, "0282135009765625": 38, "028228759765625": 38, "0282745361328125": 38, "028289794921875": 38, "0283050537109375": 38, "0284271240234375": 38, "0284423828125": 38, "028472900390625": 38, "0285491943359375": 38, "028656005859375": 38, "0286865234375": 38, "02874755859375": 38, "0288848876953125": 38, "0289154052734375": 38, "0289306640625": 38, "029052734375": 38, "0291595458984375": 38, "0291900634765625": 38, "029296875": 38, "02935791015625": 38, "0294036865234375": 38, "0294342041015625": 38, "0294952392578125": 38, "0295562744140625": 38, "029571533203125": 38, "029632568359375": 38, "0298004150390625": 38, "0298309326171875": 38, "029937744140625": 38, "02it": [12, 23], "03": [11, 12, 22, 23, 24, 25, 33, 44, 67, 75], "030029296875": 38, "0300445556640625": 38, "0301055908203125": 38, "0301361083984375": 38, "0301666259765625": 38, "0302": 22, "030242919921875": 38, "030364990234375": 38, "0305023193359375": 38, "030670166015625": 38, "0307769775390625": 38, "030975341796875": 38, "0310211181640625": 38, "0311431884765625": 38, "0311737060546875": 38, "03143310546875": 38, "03155517578125": 38, "0316": 22, "031646728515625": 38, "032012939453125": 38, "032135009765625": 38, "032318115234375": 38, "0324": [14, 25, 27], "032440185546875": 38, "032470703125": 38, "032501220703125": 38, "03266": 23, "03271484375": 38, "032806396484375": 38, "03289794921875": 38, "03314208984375": 38, "03326416015625": 38, "0333251953125": 38, "033447265625": 38, "03375244140625": 38, "0338134765625": 38, "033935546875": 38, "0340576171875": 38, "03411865234375": 38, "03424072265625": 38, "0343017578125": 38, "034454345703125": 38, "03448486328125": 38, "0345458984375": 38, "034637451171875": 38, "03466796875": 38, "034759521484375": 38, "03509521484375": 38, "035247802734375": 38, "035308837890625": 38, "03570556640625": 38, "035888671875": 38, "03607177734375": 38, "03619384765625": 38, "0362548828125": 38, "036346435546875": 38, "036376953125": 38, "036468505859375": 38, "036529541015625": 38, "03668212890625": 38, "03692626953125": 38, "0369873046875": 38, "037078857421875": 38, "0372314453125": 38, "037506103515625": 38, "037841796875": 38, "0380859375": 38, "038116455078125": 38, "03826904296875": 38, "038604736328125": 38, "038787841796875": 38, "038818359375": 38, "038848876953125": 38, "0389": 22, "0392": 22, "03924560546875": 38, "039276123046875": 38, "039435e": 75, "039459228515625": 38, "0395": 22, "039703369140625": 38, "04": [12, 20, 22, 24, 25, 37, 50, 69, 75], "040252685546875": 38, "0404052734375": 38, "0406": 22, "040618896484375": 38, "0406494140625": 38, "040802001953125": 38, "0410": 22, "041412353515625": 38, "041717529296875": 38, "041961669921875": 38, "0420": 22, "0424": 22, "04248046875": 38, "0426": 22, "042938232421875": 38, "04381108283996582": 23, "044219970703125": 38, "045166015625": 38, "045257568359375": 38, "04534912109375": 38, "0458984375": 38, "045951999723911285": 22, "0460": 22, "0467529296875": 38, "0471": 22, "04710400104522705": 22, "04729599878191948": 22, "0473": 22, "047698974609375": 38, "0479": 22, "04793599992990494": 22, "0481": 22, "048128001391887665": 22, "048248291015625": 38, "0483": 22, "048370361328125": 38, "04840087890625": 38, "048492431640625": 38, "0489": 22, "048928000032901764": 22, "0490880012512207": 22, "0491": 22, "0492": 22, "049652099609375": 38, "04986572265625": [33, 38], "049957275390625": 38, "04it": 12, "05": [20, 22, 23, 33, 39, 69, 75], "0503": 22, "05078125": 38, "0524": 22, "0528": [17, 20, 37, 70], "052978515625": 38, "053497314453125": 38, "05401611328125": 38, "0543": 22, "0548": 22, "0551": 22, "0556": 22, "0558": 22, "05634570121765137": 44, "0564": 22, "056488037109375": 38, "057037353515625": 38, "057373046875": 38, "0578": 22, "05792236328125": 38, "059112548828125": 38, "0593": 22, "05987548828125": 38, "05it": 25, "06": [12, 20, 22, 23, 24, 25, 33, 75], "06072998046875": 38, "0609": 22, "0611572265625": 38, "0625": 38, "062744140625": 38, "0631103515625": 38, "0633544921875": 38, "0641": 22, "0643310546875": 38, "0646": 22, "0656": 22, "06707763671875": 38, "0676": 22, "068603515625": 38, "0688": 22, "06927490234375": 38, "07": [12, 22, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67, 69], "0709": 22, "07232666015625": 38, "073486328125": 38, "07436800003051758": 22, "0744": 22, "0745": 22, "075": 75, "07500000000000001": 75, "0751": 22, "07513599842786789": 22, "0757": 22, "0760": 22, "0765": 22, "0775146484375": 38, "0781": 22, "0792": 22, "0795": 22, "07958984375": 38, "07977294921875": 38, "07it": [12, 24, 25, 33], "08": [11, 12, 22, 33, 38, 69, 75], "08087158203125": 38, "0830": 22, "0832": 22, "085993": 23, "0881": 22, "0884": 22, "089599609375": 38, "08it": 22, "09": [12, 22, 64], "0903": 22, "0913": 22, "09197998046875": 38, "0922": 22, "0924": [22, 81], "0928": 22, "0934": 22, "0936": 22, "0938": 22, "0943603515625": 38, "0946044921875": 38, "09521484375": 38, "0958": 22, "0959": 22, "09625244140625": 38, "0967": 22, "0972": 22, "0994": 22, "099656343460083": 24, "09967999905347824": 22, "0997": 22, "0999": 22, "09it": [12, 25, 26], "0dd7": 69, "0e6e2979ead54b80bc5da0337ed5117": 39, "0eed276416a94a6da80da81b82646599": 25, "0rc1": 50, "0rc4": 54, "0x0": 69, "1": [0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 59, 61, 63, 67, 69, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87], "10": [0, 11, 12, 14, 20, 21, 22, 23, 24, 25, 26, 27, 31, 33, 34, 37, 38, 39, 44, 46, 54, 55, 67, 69, 73, 74, 75, 78, 81], "100": [9, 11, 12, 13, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 37, 38, 39, 44, 45, 46, 60, 67, 74, 75], "1000": [6, 20, 21, 23, 24, 25, 26, 33, 34, 45, 46, 63], "10000": 9, "1000000": 32, "10000000": [20, 21, 23, 24, 25, 26, 33, 34], "100000000": 73, "1000000000": 73, "10001": 19, "10011": 60, "1002": 21, "1002946": 23, "1004": 21, "10040": 24, "1005": 22, "10061": 24, "1007": 24, "10078": [17, 24], "1008": [21, 33, 38], "100b": [79, 81], "100mb": 46, "1011": 22, "1012": 22, "1013": 22, "10146": 33, "1016": 21, "10161": 24, "1018": 22, "1021": 22, "10239999741315842": 22, "1024": [10, 16, 20, 22, 23, 24, 25, 26, 27, 29, 33, 34, 45, 46, 58, 60, 61, 70, 73, 75, 79, 80], "1031": 22, "1034067294": 24, "1035": 75, "104": [20, 23, 24, 25, 26, 34], "1040": 22, "1042": 24, "1048576": 84, "1049": 22, "1052": 24, "10542": 24, "10696": 24, "106b": 84, "1070858581": 23, "1075": 24, "1080p": 45, "1080x1920": 45, "1082": 22, "1083": 24, "1084": [24, 44], "10865": 24, "109": 28, "10912": 73, "10997": 24, "109b": 32, "10b": 58, "10it": [23, 25], "10m": 32, "11": [11, 12, 21, 22, 23, 24, 25, 26, 31, 33, 34, 39, 44, 46, 54, 67, 69, 75], "11008": [22, 75], "11008x4096": 22, "1101": 24, "11050": 33, "11066889762878418": 23, "1111": 22, "11111": 37, "11136": 24, "11141": 24, "11177754402160645": 33, "1119": 24, "112": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "11228": 75, "1124": [24, 81], "1125": 75, "1128": 24, "11465": 33, "1152": [20, 23, 24, 25, 26, 33, 34], "11584": 23, "116": [12, 27, 31], "116093850019932e": 75, "1161": 22, "1162": 22, "11649": 24, "11668944358825684": 23, "11685": 75, "118": 12, "1181": 24, "1184": [24, 33], "11852": 15, "11853480339050293": 23, "11906": 24, "1191": 24, "1195": 22, "1196": 24, "11b": 84, "11it": [12, 23, 25, 26, 39], "12": [12, 14, 20, 21, 22, 23, 24, 25, 26, 31, 33, 34, 37, 38, 39, 44, 46, 50, 51, 55, 58, 60, 61, 67, 71], "120": [19, 20, 23, 24, 25, 26, 34, 47, 63], "1200": 73, "120000": 28, "12065": 28, "12095": [24, 33, 44], "120b": [17, 25, 31, 81], "12159": 24, "1221": 22, "123": [37, 76], "1231": 24, "12345": 37, "123456": 31, "123859": 75, "1246": 33, "1249": 33, "125": [33, 58], "1251": 24, "1255": 22, "12612": 17, "1265": 24, "127": [5, 9, 12, 14, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 37, 38, 43, 44, 45, 46, 55, 60, 69, 78, 79, 80, 82, 85], "1273": 24, "12730": 24, "128": [1, 3, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 37, 43, 45, 48, 53, 55, 58, 59, 60, 61, 63, 72, 75, 79, 80, 84], "1280": [20, 23, 24, 25, 26, 33, 34], "128009": [22, 23], "1281": 24, "12824": 33, "1284": 22, "128902e": 75, "128a1a6915ef47fb8255acf086af0305": 37, "128e": 32, "128g": 50, "128k": [81, 84], "128x11008": 22, "128x128": 27, "128x4096": 22, "1290": 24, "12943": 24, "12b": 84, "12it": [25, 33], "12t": 81, "13": [11, 12, 22, 23, 24, 25, 26, 31, 33, 44, 58, 67], "130859375": 38, "130b": 81, "131072": [22, 33, 73], "13126": 4, "1319": 28, "13230": 24, "13289": 24, "132b": 81, "1330": 75, "13327": 6, "1335": 24, "1345": 22, "1349": 24, "13530": 24, "13550": 28, "135m": 81, "136": [20, 23, 24, 25, 26, 34, 70, 73], "1364": 22, "1372": 24, "13724": 4, "1376": 24, "138": [27, 31], "13837": 24, "13862": 24, "13874": 24, "139": 25, "13925": 4, "13959": 44, "13b": [81, 84], "14": [12, 22, 23, 24, 25, 31, 33, 38, 55, 67, 70, 73, 75], "140": 75, "14006": 75, "14007": 75, "1401": 24, "1403818130493164": 23, "14038968086242676": 23, "1403942108154297": 23, "1408": [20, 23, 24, 25, 26, 33, 34], "14097": 4, "1414": 24, "1416": 33, "14190": 24, "1427": [33, 38], "1429": 24, "14319": 33, "1438": 24, "144": [20, 23, 24, 25, 26, 33, 34], "1444": 22, "1447": [24, 33], "1449": 24, "1469": 22, "147": 24, "1477": 24, "148": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "1482": 33, "1495": 24, "14b": [1, 81], "14it": 44, "15": [12, 22, 23, 24, 25, 26, 31, 33, 67, 69, 75], "150": [37, 67], "15040": 28, "151": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "1513": 75, "1513671875": 38, "151643": [24, 33], "151645": [22, 37, 39, 44], "151649": 24, "152": [20, 23, 24, 25, 26, 34], "1522": 19, "1524": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "1533": 22, "1536": [20, 23, 24, 25, 26, 33, 34, 55, 56, 80], "15423": 24, "15457510948181152": 24, "15458369255065918": 24, "1545882225036621": 24, "1550": 24, "1552705f68c047f6ac49884df5cc6fdf": 24, "158": 22, "15934": 24, "15b": [81, 84], "15b3": 69, "15it": [12, 23, 67], "16": [1, 12, 14, 17, 20, 21, 22, 23, 24, 25, 26, 27, 31, 33, 34, 37, 38, 39, 44, 45, 55, 56, 58, 60, 67, 69, 70, 71, 73, 81], "160": [11, 20, 23, 24, 25, 26, 33, 34], "1600": 55, "1602": 24, "16045": 24, "1616": 24, "162": 75, "1632": 28, "1633": 24, "16375": 24, "16384": [11, 20, 21, 23, 24, 25, 26, 33, 34, 60, 69], "163840": 69, "163d45a88ea84d2a93d16b05a3044e83": 25, "164": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "1650390625": 38, "1664": [20, 23, 24, 25, 26, 33, 34], "16686": 76, "16688": 33, "167": 58, "1673": 28, "168": [20, 21, 23, 24, 25, 26, 34], "1681": 24, "16875": 75, "169": [70, 73], "1692": 22, "16e": [25, 26, 32, 81], "16g": [53, 54], "16it": 67, "16k": 81, "16x": 21, "17": [11, 12, 22, 23, 24, 25, 33, 67, 69], "17045": 33, "171": 58, "171662e": 75, "171875": 33, "172": [70, 71, 73], "1741943359375": 38, "1744": 24, "1745383213": 78, "1745993638": 27, "175": 31, "1750252498": [70, 73], "176": [20, 23, 24, 25, 26, 33, 34], "1761685269133": 33, "1766386561": 22, "1766386643": 23, "1766386644": 23, "1766386652": 22, "1766386718": 22, "1766386728": 25, "1766386731": 24, "1766386732": 25, "1766386735": 24, "1766386747": 24, "1766386750": 24, "1766386770": 22, "1766386815": 22, "1766386825": 25, "1766386894": 37, "1766386895": 37, "1766386938": 44, "1766386948": 39, "1766386949": 39, "1766386950": 39, "1766387525": 33, "1766387663": 33, "17724609375": 38, "17767": 24, "1792": [20, 23, 24, 25, 26, 33, 34], "17b": [25, 26, 32, 81], "17it": [12, 37, 67], "18": [12, 20, 21, 22, 23, 24, 25, 26, 31, 33, 34, 55, 69, 71], "1815": 75, "184": [20, 23, 24, 25, 26, 34], "1855": 24, "1868896484375": 38, "187": 31, "1879": 44, "18it": [12, 67], "19": [12, 20, 22, 23, 24, 25, 33], "1906806": 33, "1907a4fe3b874249980fb2705202dc5a": 39, "19083": 24, "19091": 24, "192": [20, 21, 23, 24, 25, 26, 33, 34], "1920": [20, 23, 24, 25, 26, 33, 34], "19324": 24, "19482": 24, "19539": 33, "1963704": 24, "1970": [22, 75], "19730": 2, "198": [24, 28], "1986": 24, "1990": 24, "1995": [24, 33], "19it": 12, "1b": [16, 25, 48, 81, 84, 88], "1cb848b79c614ff8bf0240b05852442b": 23, "1e9": 10, "1gb": 10, "1m": [1, 32, 81], "1p1d": 70, "1t": 81, "1v": 84, "1x": 22, "2": [0, 1, 4, 7, 9, 10, 12, 14, 16, 17, 19, 20, 21, 23, 24, 27, 30, 31, 32, 33, 34, 37, 38, 39, 40, 43, 44, 45, 46, 47, 56, 61, 62, 63, 67, 69, 71, 74, 75, 78, 81, 82, 84, 86, 87, 88], "20": [2, 11, 12, 20, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 39, 55, 60, 63, 67, 69, 73, 75], "200": [12, 20, 23, 24, 25, 26, 31, 33, 34, 45, 47, 55, 69], "2000": [11, 45, 48], "20000": [19, 69, 71], "200b": 17, "200k": 81, "20102": [70, 73], "2022": 33, "2023": 24, "2023todai": 23, "2024userpari": 23, "2025": [11, 12, 20, 22, 23, 24, 25, 26, 31, 33, 34, 37, 38, 39, 44, 64, 67, 69], "20474": 33, "2048": [11, 20, 22, 23, 24, 25, 26, 28, 32, 33, 34, 45, 60, 64, 70, 73], "20480": [20, 23, 24, 25, 33, 34], "2055": 24, "206": 31, "20699": 24, "208": [20, 23, 24, 25, 26, 33, 34, 67], "2086": 44, "20b": [25, 58, 81], "21": [20, 22, 23, 25, 33, 54, 67, 75], "210": [31, 58], "214": 58, "2141000": 23, "2147000": [23, 24], "2147483648": 73, "21500000": 23, "2154000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 24, "216": [20, 23, 24, 25, 26, 34], "2163": 24, "2176": [20, 23, 24, 25, 26, 33, 34], "21b": 81, "21fa61cf853e4c53bcb5db3596defb8c": 23, "21it": [23, 25], "22": [12, 20, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 44, 55, 64, 67, 73], "220": [20, 23, 24, 25, 26, 34], "220b4bb686f042318b0ab72ece3f1296": 23, "221": [70, 73], "2217": 33, "222": 67, "2236": 24, "224": [20, 23, 24, 25, 26, 33, 34], "224gb": 71, "2297": 24, "22it": 33, "22m": [70, 73], "23": [24, 25, 33, 38, 54, 69], "2304": [20, 23, 24, 25, 26, 33, 34], "2308": 24, "23126": 24, "232": [20, 23, 24, 25, 26, 34], "2326": 75, "233": 11, "2344396": 23, "235": [28, 70, 73], "235b": [9, 17, 20, 42, 58, 84], "23933": 33, "23it": 33, "24": [20, 22, 23, 24, 25, 26, 33, 34, 38, 55, 58, 69, 70], "240": [17, 20, 23, 24, 25, 26, 33, 34], "2407": 25, "240gb": 10, "24155": 28, "2417": 75, "242": [70, 73], "2432": [20, 23, 24, 25, 26, 33, 34], "244": 22, "247": 75, "2474": 24, "248": [20, 23, 24, 25, 26, 34], "2486572265625": 38, "2494": 24, "24b": 84, "24it": [12, 25, 67], "25": [10, 12, 22, 23, 24, 25, 28, 33, 37, 67, 69, 75], "25000": 21, "2503": 84, "2506": 24, "2507": [9, 20], "2513": 75, "253": 58, "2530": 24, "253125": 75, "253b": 81, "255b": 81, "256": [10, 11, 12, 16, 19, 20, 21, 23, 24, 25, 26, 33, 34, 45, 46, 48, 60, 67, 80, 84], "2560": [20, 23, 24, 25, 26, 33, 34], "2567": 24, "256mb": 19, "2578": 24, "25it": [12, 22], "26": [12, 22, 23, 33, 55, 70, 73], "262144": [70, 73], "26297": 33, "26306266784668": 75, "264": [24, 33], "264404296875": 38, "2651572227478027": 24, "2652": 22, "26553": 24, "266055e": 75, "2661": 33, "2666": 33, "2670": 24, "26826": 24, "2688": [20, 23, 24, 25, 26, 33, 34], "2697": 24, "2699": 24, "27": [25, 31, 67, 69, 75], "2704": 24, "271": 24, "2750": 24, "2755": 22, "277": 31, "27748": 24, "2776": 24, "279": [23, 24, 33, 44], "2797": 24, "27b": [81, 84, 86], "27it": [22, 67], "28": [20, 22, 23, 24, 25, 26, 33, 34, 55, 75, 81], "281": 25, "2814453125": 75, "2816": [20, 23, 24, 25, 26, 33, 34], "2824": 22, "2826": 75, "2866": 22, "28680": 55, "288": [20, 23, 24, 25, 26, 33, 34], "28it": [12, 23, 25], "29": [12, 22, 28, 31, 33, 73], "29000": 19, "2908": 24, "290b": 81, "2911202907562256": 33, "29138749187": 31, "29208": 33, "2924": 24, "292995206": 25, "2938": 24, "2944": [20, 23, 24, 25, 26, 33, 34], "29500": [2, 82], "2959": 22, "296": 24, "296752e": 75, "297039": 24, "2989": 24, "29985": 33, "29it": 25, "2_6": 84, "2a": [0, 21], "2b": [16, 21, 80, 81, 84], "2c52f79ed9874a1d835ff53b63102bbf": 22, "2f": [33, 85], "2t": 81, "2x": [6, 9, 21, 69, 74], "3": [0, 1, 3, 11, 12, 14, 16, 17, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 56, 59, 61, 62, 67, 69, 70, 73, 75, 77, 81, 82, 84, 86, 87, 88], "30": [10, 12, 19, 20, 22, 26, 28, 47, 70, 73, 75], "300": [14, 20, 21, 23, 24, 25, 26, 30, 33, 34, 39, 42, 73, 84], "3000": [45, 73, 75], "30000": [3, 5, 13, 14, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 42, 43, 45, 46, 48, 51, 53, 54, 58, 60, 62, 70, 71, 73, 75, 79, 80, 81, 83, 84, 85, 86, 88], "30001": [5, 14, 19, 35, 46, 70], "30002": [5, 46], "30003": [5, 46], "30011": 19, "3003": 24, "30080": 73, "30111": 56, "3019": 33, "30339": 24, "304": [24, 44], "3042": 24, "3053": 22, "307": 39, "3072": [20, 23, 24, 25, 26, 33, 34], "308": 24, "30800": [70, 73], "3090": 75, "30b": [25, 42, 81, 84], "30gb": 10, "30it": [22, 67], "31": [12, 20, 23, 33, 51, 63], "31000": 19, "311": 24, "3118": 24, "312226e": 75, "314": 75, "3146": [24, 33], "314b": 81, "315": [23, 24, 33, 44], "316000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 24, "317": 11, "31it": [12, 67], "32": [1, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 38, 43, 44, 46, 55, 56, 60, 61, 63, 69, 70, 73, 75, 79], "320": [20, 23, 24, 25, 26, 33, 34], "3200": [20, 23, 24, 25, 26, 33, 34], "3202": 17, "3204": 24, "3207": 24, "3213": 24, "323": [24, 44], "32313": 24, "3248779296875": 75, "3259": 24, "326": 24, "32768": [33, 70, 73], "3278": [24, 33], "3283": [24, 44], "3295": 22, "32b": [58, 60], "32b_eagle3": 60, "32exp": 73, "32g": [48, 51], "32it": [12, 67], "33": [22, 67], "330": [23, 24, 33], "3315": 22, "3328": [20, 23, 24, 25, 26, 33, 34], "3337": 22, "336": 80, "33849": 37, "339675e": 75, "33it": [22, 33, 67], "34": [12, 20, 22, 23, 24, 25, 26, 31, 33, 34, 37, 38, 39, 44, 67], "3410": 33, "3430": 24, "3456": [20, 23, 24, 25, 26, 33, 34], "3460": 24, "35": [22, 25, 67], "3500000": 24, "350x": 27, "3518979474117756e": 75, "352": [20, 23, 24, 25, 26, 33, 34, 55], "3526": 24, "352789b1fb824df88c823d1ca1bfe167": 23, "3533": 17, "3545": 33, "3561": 24, "3565": 24, "357747e": 75, "358": [24, 33], "3583": 28, "3584": [20, 23, 24, 25, 26, 33, 34], "3598": 24, "35it": 22, "36": [12, 22, 23, 26, 31, 33, 44], "3600": 27, "3600000": 24, "360p": 45, "3614807": 24, "3614857": 24, "3614883": 24, "36342": 33, "369": 24, "369873046875": 38, "36b": 81, "36it": [12, 67], "37": [22, 33, 34, 37, 44], "37007": 67, "370959": 11, "3712": [20, 23, 24, 25, 26, 33, 34], "37129": 33, "373": [22, 39], "374": [23, 24, 31, 33, 44], "37511": 33, "376641": 33, "37795": 67, "3786": 24, "379": 24, "3796875": 75, "38": [22, 24, 33], "380": 26, "382": [24, 33, 75], "3825": 33, "384": [20, 23, 24, 25, 26, 33, 34], "3840": [20, 23, 24, 25, 26, 33, 34], "3847094": 23, "384714": 23, "3847172": 23, "387": 24, "3880": 24, "389": [24, 44], "389414e": 75, "38it": 33, "39": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 44, 58, 67], "3946": 33, "3950": 33, "3953": 24, "3968": [20, 22, 23, 24, 25, 26, 33, 34], "3988": 33, "39it": [25, 33, 44], "3_1": 81, "3_3": 81, "3b": [25, 26, 45, 61, 81], "3e": 2, "3f": 10, "3moe": 81, "3next": 81, "3rd": 37, "3x": 10, "4": [0, 1, 4, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 56, 58, 63, 67, 69, 70, 71, 73, 74, 75, 81, 82, 84, 86], "40": [20, 21, 22, 23, 24, 25, 26, 33, 34, 39, 51, 58, 60, 67, 75, 81], "400": [52, 78], "4000": [17, 53], "40000": 69, "400757e": 75, "400b": [32, 81], "401": 45, "403": 45, "405": 24, "407": 25, "408": 19, "4096": [11, 20, 21, 22, 23, 24, 25, 26, 33, 34, 60, 63, 64, 73], "4096x12288": 22, "4096x22016": 22, "4096x32000": 22, "4096x4096": 22, "40it": 33, "41": [12, 22, 23, 24, 33, 67], "4135": 24, "4152": 24, "416": [20, 23, 24, 25, 26, 33, 34], "419": [24, 33], "41988": 23, "41it": [22, 25, 26], "42": [3, 22, 33, 37, 58, 67], "420": 25, "421": 24, "4226": 33, "424b": 81, "4257": 24, "4261789321899414": 24, "4264": 22, "427": 25, "4270556": 33, "429": [19, 24], "42it": 23, "43": [3, 22, 33, 58], "4317": [19, 20, 21, 23, 24, 25, 26, 33, 34, 76], "4318": 76, "432": 24, "433413": 75, "4340292513370514": 78, "4350": 22, "4378": 24, "438": [24, 33], "4396": 24, "43it": [22, 33, 34], "44": [3, 12, 22, 23, 25, 33, 39, 44], "4411": 24, "441716594": 26, "4418": 28, "44270": 24, "44292": 24, "44441": 24, "448": [20, 23, 24, 25, 26, 33, 34], "44868": 24, "44daf1b4f5804b8db7b8e159692fea55": 37, "44it": [22, 67], "45": [3, 22, 23, 25, 33, 37], "4505": 44, "4526": 22, "45541": 23, "458": 24, "4594": 11, "46": [3, 12, 20, 22, 23, 33], "4623": 33, "4658": 24, "466": 25, "4677": 22, "4695": 24, "47": [12, 20, 22, 23, 33], "4710": [24, 33], "4718": 24, "4734": 24, "4755": 33, "476": [24, 33], "4795": 33, "47b": 81, "47it": 12, "48": [20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34], "480": [20, 23, 24, 25, 26, 33, 34], "486": 75, "487316894531251": 75, "48771047592163": 24, "48908": 69, "48924": 69, "49": [22, 23, 44, 75], "49000": 24, "4934": 17, "4938": 24, "4963326": 33, "497": 24, "498": [23, 31, 33], "49b": 81, "4a": 45, "4ab43393742b4394bd194420530de9ef": 44, "4b": [37, 45, 80, 81, 84], "4bit": 16, "4f487b1af86943259de8624f7bf9773d": 24, "4k": 45, "4so": 67, "4th": [37, 58], "4v": [81, 84], "4xh100": 41, "5": [0, 1, 4, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 47, 50, 53, 54, 55, 58, 60, 61, 67, 69, 70, 73, 75, 78, 80, 81, 82, 83, 84, 86, 87], "50": [3, 11, 12, 19, 20, 21, 22, 23, 24, 25, 26, 28, 33, 37, 38, 39, 67, 69, 75], "500": [21, 24, 45, 47, 63, 76, 78], "5000": [14, 55], "50000": 21, "500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000": 24, "50051": 9, "5008": 24, "50100": 23, "5011084": 44, "5018": 23, "5020": 24, "50311": 33, "504": 24, "5067": 17, "5081": 17, "50814177726902": 75, "51": [22, 33], "512": [10, 11, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 45, 46, 55, 60, 67, 80, 84], "512x768": 45, "514771912145079": 75, "515": [22, 24], "5179": 22, "518": 33, "5185": 24, "51it": 67, "52": [22, 33, 39, 71, 81], "5226": 28, "524": 33, "524288": 70, "525": 24, "527617": 23, "52b": 81, "52it": 12, "53": 22, "5310": 24, "532": 24, "53371": 24, "5340": 22, "537": 24, "5382": 24, "54": [20, 22], "541": 22, "54231": 24, "5434": 17, "545": 28, "545445dec44243d8a1597508fb5d608a": 33, "54815": 33, "55": [12, 20, 22, 23, 34, 44], "5512": 24, "553": [24, 33], "557572e": 75, "55it": [12, 33], "56": [12, 17, 20, 22, 23, 24, 25, 26, 34, 39], "5648": 24, "565": 25, "565970778465271": 78, "56953125": 75, "56it": 22, "57": [12, 22, 23, 24, 44], "570": 26, "5707": [24, 33], "5711": 24, "5724": 15, "5730c80e6ddd4478bd636ca7dff73766": 25, "57344": 17, "57508": 33, "57512": 33, "57514": 33, "57522": 33, "57528": 33, "576": [24, 33], "5791549598": 75, "57it": 12, "58": [12, 22, 24, 25, 31, 33, 39, 67], "5847": 24, "58it": 22, "59": [22, 23, 24, 25, 37], "593": 75, "594": [24, 33], "5944": 24, "595": 24, "59604": [24, 33], "596463012695313": 75, "5975": 24, "5978": 24, "59it": 22, "5b": [0, 12, 33, 34, 35, 37, 38, 44, 61, 78, 81, 86, 87], "5m": 32, "5moe": 81, "5t": 81, "5v": [4, 40, 84], "5x": 27, "6": [12, 20, 21, 22, 23, 24, 25, 26, 30, 33, 34, 37, 38, 39, 40, 44, 45, 46, 53, 54, 55, 58, 59, 67, 69, 74, 75, 82, 84], "60": [19, 22, 33, 39, 44, 46, 67, 69, 73, 75, 84], "600": [14, 19, 24, 55], "6000": [17, 19, 55], "6017": 70, "602112": 84, "60444": 33, "606": 24, "60704": 23, "609": 23, "6099": 24, "61": [25, 31], "614": [24, 33], "616481668": 33, "6169": 24, "617": 28, "62": [22, 24, 33, 39, 67], "62166": 24, "62301": 33, "624": 24, "6286": 24, "63": [22, 33], "6364": 24, "64": [1, 9, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 30, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 60, 61, 63, 67, 70, 73, 76], "640": [20, 23, 24, 25, 26, 33, 34], "64000": 28, "64547": 33, "646": 24, "64x11008": 22, "64x4096": 22, "65": [1, 22, 30, 33, 42], "6501ef8e2d874006bf555bc80cddc7c5": 27, "65063": 24, "65232": 24, "6540": 24, "65536": [11, 26, 32], "65it": 37, "66": [12, 22, 33, 39, 44], "6617": 24, "665690": 11, "6688": 55, "66it": 12, "67": [12, 20, 22, 28, 67], "67108864": 19, "671b": 81, "672": 33, "6722": [24, 33], "6771": 24, "6778": 17, "678": 24, "678175413": 34, "67890": 37, "67it": 25, "68": [22, 37, 55], "6864": 23, "6894": 24, "6896": 24, "6899": 17, "68it": [20, 25, 33], "69": 22, "69520": 24, "6980p": [27, 58], "6b": [51, 80, 81], "6lcbd": 70, "6th": 58, "6v": [4, 40], "7": [11, 12, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 37, 40, 44, 46, 54, 64, 67, 69, 70, 75, 78, 81, 82], "70": [22, 46], "700": 24, "7007": 23, "7010": 17, "702": 24, "7039": 24, "7042": 24, "7071": 24, "70b": [25, 58], "71": [28, 37, 39], "7108": 24, "712400": 69, "714": 24, "7196": 24, "71it": 67, "72": [20, 22, 23, 24, 25, 26, 34, 37, 67], "720": 55, "720p": 45, "7273": 17, "728": 24, "72b": [84, 86], "72it": 33, "73": [22, 75], "730975341796876": 75, "7333": 17, "73594": 24, "737": 25, "73it": [22, 33], "74": [22, 32, 33, 34], "7407": 44, "742": 24, "7482": 24, "7486296874999999": 26, "749": 31, "74m": [70, 73], "75": [12, 14, 15, 22, 23, 25, 32, 33, 37, 67, 75], "752": 24, "7533": 17, "756": 24, "75b": 81, "76": [33, 37, 44], "7653": 33, "76602": 24, "7667": 17, "768": [11, 20, 23, 24, 25, 26, 33, 34], "7697": 17, "76it": 20, "77": [22, 24, 33], "7707": 17, "773": 24, "7733": 17, "7772": [24, 44], "77it": 12, "77x": 74, "78": [17, 22, 33, 55], "783": 28, "784d9087f48d4af1ad6390f1e016095f": 37, "788": [24, 28], "79": [22, 28], "793": 28, "794": 23, "797": 28, "7979": 15, "798": 28, "79it": [12, 34], "7ae557604adf67be50417f59c2c2f167def9a775": 33, "7b": [4, 16, 20, 22, 24, 25, 33, 39, 43, 47, 62, 67, 80, 81, 83, 84, 86], "7f": 69, "7fa2af80": 46, "7x": 27, "8": [1, 2, 3, 6, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 42, 43, 44, 45, 46, 48, 53, 54, 55, 56, 59, 60, 64, 67, 69, 70, 71, 73, 75, 82], "80": [12, 19, 20, 22, 23, 24, 25, 26, 32, 33, 34, 39, 60, 67], "800": 27, "8000": [5, 14, 19, 28, 45, 46, 55, 70, 71, 73, 78], "8001": [19, 55], "800i": [27, 54], "803": [24, 28], "808": 28, "8080": [0, 9, 19, 51, 73], "80b": [25, 41, 81], "80it": 34, "81": [22, 24, 55], "816043786240": 9, "8188": 55, "8192": [11, 20, 22, 23, 24, 25, 26, 30, 33, 34, 42, 55, 59, 60, 63, 69], "81cdbe29fd8a4470bd8155b3e391b9ff": 24, "82": [11, 22, 58], "821": 24, "829": 33, "8290393052ae44dc95d827d1e7382463": 22, "829680056": 20, "82989172e6964011b508448987f54024": 22, "83": [22, 28], "8318": 24, "832": 55, "835": [20, 23, 24, 25, 34], "84": [22, 39, 67, 69], "841": 33, "8420": 24, "84204177856446": 75, "845": 75, "847": 24, "8482": 24, "849": [70, 73], "85": [9, 22, 24, 25, 38], "8542968750000001": 75, "854d24c2cfd64ea2bf410644a83465b7": 23, "855": 75, "856728": 24, "85it": 12, "86": [22, 24, 58, 75], "862": 24, "8658": 24, "866964": 75, "87": [22, 28], "879": 33, "87it": 12, "88": [12, 20, 22, 23, 24, 25, 26, 33, 34, 55], "8826": 24, "8832519531250003": 75, "8833": 31, "8846": 15, "88646": 24, "8884": 47, "89": [12, 22, 69], "89156": 24, "892": [24, 33], "8926": 24, "894": [24, 33], "89469451904297": 75, "896": [20, 23, 24, 25, 26, 33, 34], "8965": 76, "897": 24, "8996": 55, "8997": 55, "8998": [20, 21, 23, 24, 25, 26, 28, 33, 34], "89it": 12, "8b": [1, 2, 5, 12, 14, 16, 19, 21, 22, 23, 25, 33, 43, 45, 46, 51, 53, 54, 58, 59, 61, 75, 77, 81, 82, 84, 86, 87], "8bdbe814e81b4490ae06c771f7d05fb1": 24, "8caf7ce12ae04d7bb976b5ad054b8e4": 23, "8t": 81, "8th": 37, "8x": 27, "8xh100": [29, 32], "8xh200": 28, "9": [11, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 37, 41, 45, 46, 50, 54, 58, 60, 61, 67, 69, 75, 82], "90": [12, 22, 25, 28], "9000": [55, 56], "9001": 19, "9090": 75, "90it": [12, 24], "91": [12, 22, 39], "910b": 54, "911": 24, "9120": 2, "9124": 17, "9152": 17, "9154": 17, "9157": 17, "916": 24, "9161": 17, "9163": 17, "9168": 17, "9181": 17, "9181063": 24, "9186": 17, "92": [23, 24, 28], "9220": 47, "9221679687500002": 75, "93": [12, 22, 69], "94": [22, 28], "941": 75, "944": 24, "949": 24, "95": [16, 20, 22, 23, 24, 25, 28, 33, 34, 37, 64, 79], "950195e": 75, "956": 28, "96": [20, 22, 23, 24, 25, 26, 27, 28, 33, 34, 60, 72], "9625": [24, 33, 44], "9658": 24, "97": [12, 22], "9733": 24, "97904": 24, "97it": 22, "97m": [70, 73], "98": 22, "9806": 44, "9822": 23, "983": 46, "984": 21, "99": [22, 25], "990": 24, "992": 21, "996": 21, "9974": 24, "998": 21, "9998": 11, "999999": 32, "99it": 22, "9b": [81, 84], "9b9d62a1be704868a22ab26b5569d382": 33, "9bf17f2847b046c7b2d5495f4b4f9682": 78, "9c5dbfc57": [70, 73], "9dff": 69, "9ff11813843349b78a4acb20629583ca": 44, "9th": 37, "9x": 27, "A": [4, 7, 10, 11, 12, 14, 15, 19, 20, 21, 24, 27, 28, 34, 43, 46, 47, 51, 58, 59, 61, 69, 76, 80, 81, 84, 85, 86, 88], "And": [15, 31, 34, 74], "As": [10, 11, 34, 39, 46], "At": [10, 54, 69, 70, 73], "But": [22, 24, 34, 37], "By": [3, 6, 9, 10, 11, 12, 13, 21, 22, 27, 31, 43, 51, 62, 75, 87, 88], "For": [0, 1, 6, 7, 9, 10, 12, 14, 15, 16, 20, 22, 23, 25, 27, 28, 29, 30, 31, 32, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 51, 52, 54, 58, 60, 65, 69, 73, 75, 76, 80, 81, 82, 84, 87], "If": [0, 1, 7, 10, 11, 12, 14, 16, 17, 21, 23, 24, 25, 27, 28, 30, 33, 34, 35, 37, 42, 43, 45, 46, 47, 48, 51, 53, 54, 58, 60, 62, 64, 69, 74, 75, 76, 77, 78, 80, 81, 84, 87], "In": [4, 5, 7, 10, 12, 14, 15, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 37, 38, 39, 44, 47, 48, 53, 58, 60, 63, 64, 67, 69, 70, 76, 82, 87], "It": [1, 4, 6, 10, 11, 15, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 37, 41, 42, 43, 44, 45, 46, 47, 51, 52, 58, 62, 65, 67, 80, 81, 84, 87], "Its": [27, 52], "NOT": [25, 62], "No": [3, 7, 17, 19, 20, 22, 24, 31, 33, 37, 63, 75], "Not": [1, 17, 21, 45, 63], "OFED": 69, "On": [4, 10, 11, 17, 28, 30, 42, 58, 72, 76], "One": [26, 37, 43], "Or": [14, 16, 22, 25, 45, 59, 83], "THE": 37, "That": [24, 87, 88], "The": [1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 58, 59, 60, 61, 63, 65, 67, 68, 69, 70, 73, 75, 76, 77, 78, 81, 82, 84, 85, 87, 88], "Their": 76, "Then": [16, 24, 28, 35, 47, 50, 69, 71, 75, 87], "There": [41, 48, 62], "These": [6, 16, 21, 22, 31, 34, 37, 47, 63, 74, 76, 81, 84, 86, 87], "To": [1, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 51, 53, 58, 60, 64, 67, 70, 74, 75, 76, 83, 84, 87], "Will": 1, "With": [0, 1, 15, 27, 28, 45, 46, 53, 60, 84], "_": [7, 28, 67], "__call__": [43, 87], "__init__": [49, 87], "__main__": [55, 79, 87], "__name__": [7, 55, 79, 87], "_attn_implement": 88, "_dynamo": 22, "_forward_attn": 6, "_forward_combin": 6, "_forward_dispatch": 6, "_forward_mlp": 6, "_output_": 28, "_supports_attention_backend": 88, "_work": 33, "a10": 51, "a100": [1, 27, 30, 42, 51, 52], "a2": [28, 33, 54, 69], "a22b": [9, 17, 20, 42, 58, 84], "a2a": [6, 14, 21, 55, 70, 73], "a2dc": 69, "a3": [27, 28, 54], "a36b": 81, "a3b": [25, 41, 42, 81, 84], "a40": 1, "a800": 27, "a800m": 81, "aarch64": 54, "ab": 19, "abbrevi": [23, 24, 25], "abc": 10, "abil": [34, 81], "abl": [34, 75, 87], "abnorm": 16, "abort_on_priority_when_dis": [20, 23, 24, 25, 26, 33, 34], "about": [7, 10, 11, 18, 21, 22, 23, 24, 31, 34, 37, 48, 61, 62, 64, 67, 68, 84, 87, 88], "abov": [9, 21, 22, 25, 26, 27, 34, 35, 37, 43, 45, 46, 47, 51, 58, 61, 64, 65, 67, 69, 76, 87], "absolut": [0, 19], "absorpt": 27, "abstract": 6, "abus": 47, "acc": 21, "acc_typ": 22, "acceler": [2, 6, 11, 21, 22, 27, 51, 55, 60], "accelerator_arg": 60, "accept": [14, 17, 19, 21, 22, 24, 37, 43, 45, 71, 79, 81, 84, 87], "accept_length": 45, "access": [5, 10, 19, 21, 23, 24, 27, 37, 46, 51, 58, 60, 63, 69, 70, 73, 75, 76, 87], "accid": 34, "accommod": 76, "accord": [1, 14, 16, 25, 29, 31, 41, 46, 58, 69, 70, 73], "accordingli": [0, 19, 20, 25, 33], "account": [17, 47, 64], "accumul": [17, 63, 64], "accur": [24, 41, 80], "accuraci": [16, 21, 22, 55, 81, 84, 85, 87], "achiev": [3, 6, 10, 12, 15, 22, 27, 28, 34, 37, 60, 64, 69, 74, 81, 84], "across": [2, 3, 4, 6, 9, 10, 12, 17, 19, 21, 27, 46, 52, 60, 63, 64, 65, 71, 74, 76], "act": [25, 26, 31, 35], "action": 16, "activ": [6, 7, 11, 16, 21, 27, 34, 46, 52, 54, 58, 60, 61, 63, 67, 69, 71, 81], "actual": [7, 10, 12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67, 70, 73, 75, 76, 78], "ad": [0, 3, 12, 13, 15, 19, 20, 21, 24, 25, 31, 37, 47, 51, 75, 76], "adapt": [6, 12, 21, 28, 34, 54, 60, 69, 87], "adapter_a": [12, 37], "adapter_b": 37, "adb": 19, "add": [0, 2, 6, 9, 16, 19, 20, 21, 22, 23, 24, 25, 27, 29, 32, 34, 38, 41, 43, 45, 46, 48, 51, 53, 58, 64, 70, 73, 75, 84], "add_generation_prompt": [20, 23, 24, 25], "add_link": 76, "add_special_token": 33, "add_work": 19, "addit": [2, 3, 12, 17, 20, 24, 25, 34, 37, 47, 51, 54, 60, 65, 76, 78, 87], "addition": [5, 22, 27, 28, 34, 46, 58, 61, 67, 69], "addr": [2, 14, 21, 28, 55, 60, 69, 70, 71, 73, 82], "address": [2, 5, 6, 9, 10, 14, 15, 18, 19, 21, 58, 61, 63, 64, 67, 69, 71], "adept": 81, "adequ": 67, "adjust": [15, 22, 27, 29, 32, 33, 41, 45, 58, 60, 64, 70, 73, 75, 84], "admin": [19, 75], "administr": 24, "adopt": [12, 19, 21, 52], "adv": 46, "advanc": [6, 12, 28, 31, 43, 46, 76, 81, 84], "advis": 23, "aerob": 67, "affect": [10, 12, 14, 16, 21, 54, 60], "affin": 63, "aflah02": 71, "afm": 81, "aforement": [15, 28], "after": [0, 4, 6, 10, 12, 14, 16, 20, 21, 22, 27, 30, 34, 42, 44, 45, 46, 59, 64, 70, 76, 84, 87], "afterward": [22, 53], "ag": 69, "again": [10, 12, 16, 22, 25, 37, 47, 53, 87], "against": [0, 10, 16, 21, 45, 65], "agent": [19, 45, 81], "aggreg": [10, 45, 76], "aggress": [15, 19, 79], "agnost": 6, "agx": 59, "ahrenheit": 25, "ai": [1, 6, 14, 17, 19, 20, 23, 24, 25, 27, 28, 31, 34, 37, 48, 53, 54, 58, 59, 69, 70, 73, 81, 82, 84, 87], "aibrix": [10, 21], "aig": 70, "ailuropoda": [33, 85], "aim": [22, 27, 63, 67, 69], "aime25": [17, 28], "aiohttp": 45, "aiter": [1, 21, 28, 32, 63], "aiter_attn": 21, "aiv": 56, "ai\u52a9\u624b": [70, 73], "alex": 37, "algo": 41, "algoprog": 12, "algorithm": [10, 15, 16, 21, 22, 27, 28, 29, 32, 34, 41, 55, 56, 60, 70, 73, 79], "alia": [19, 53, 54], "alibaba": [33, 38, 42, 80, 81, 84], "align": [16, 19, 74, 81, 84, 86], "aliv": 67, "all": [0, 1, 2, 3, 4, 7, 9, 10, 12, 13, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 34, 37, 39, 43, 45, 46, 47, 48, 50, 51, 60, 63, 65, 70, 76, 78, 83, 87], "all_attention_funct": 88, "all_hip": 53, "all_other_model": 87, "all_reduc": 10, "allen": 81, "allenai": [16, 81], "allevi": 10, "allgath": 21, "alloc": [10, 11, 21, 33, 46, 60, 75], "allocator_ascend": 47, "allow": [2, 6, 9, 10, 13, 17, 21, 22, 24, 27, 30, 35, 37, 42, 46, 48, 51, 60, 63, 70, 76, 78, 80, 84, 87], "allow_auto_trunc": [20, 23, 24, 25, 26, 33, 34], "allow_tf32": 22, "allreduc": 21, "almost": 87, "along": [12, 67, 81, 84], "alongsid": [19, 46, 51, 84], "alpha": [60, 81], "alreadi": [10, 12, 14, 16, 27, 31, 34, 35, 58, 75, 76, 80], "alright": [22, 24], "also": [1, 10, 11, 12, 15, 16, 21, 22, 24, 25, 27, 28, 31, 33, 34, 37, 38, 39, 41, 43, 44, 45, 46, 47, 51, 53, 59, 62, 64, 67, 69, 70, 71, 74, 76, 84, 87, 88], "altern": [0, 9, 10, 16, 21, 39, 65, 86], "alwai": [0, 1, 3, 11, 17, 20, 21, 23, 24, 25, 34, 37, 43, 47, 60, 78], "am": [34, 37], "amaz": 34, "amazon": 10, "amazonaw": 51, "amd": [28, 32, 50, 51, 52, 63], "america": [23, 24], "among": [9, 10, 22, 27, 74, 76], "amount": [12, 37, 58, 67], "amper": 6, "amx": [1, 58], "amxint4": 33, "an": [1, 2, 4, 5, 6, 7, 9, 10, 12, 16, 21, 22, 23, 24, 25, 26, 27, 31, 33, 34, 35, 37, 39, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 58, 64, 65, 67, 69, 74, 75, 76, 81, 82, 83, 84, 86], "analysi": [20, 21, 25, 48, 60], "analyst": 31, "analyz": [6, 33, 34, 46, 84], "ancient": 37, "angelslim": 60, "ani": [1, 7, 10, 13, 16, 19, 21, 22, 24, 25, 27, 33, 34, 37, 43, 46, 47, 51, 54, 67, 69, 78, 80, 87, 88], "annot": [19, 21, 22, 25, 37, 44, 46], "anonym": 76, "anoth": [1, 11, 12, 14, 21, 24, 26, 39, 46, 53, 58, 61, 64, 67, 76], "answer": [20, 22, 23, 24, 25, 33, 34, 37, 65, 67, 84], "antidisestablishmentarian": 65, "anver": 22, "anyth": 67, "apach": 81, "apart": 33, "apeach": [78, 86], "api": [7, 10, 43, 51, 52, 58, 60, 61, 62, 65, 67, 69, 70, 76, 79, 84], "api_kei": [19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 37, 38, 39, 43, 44], "apivers": [69, 70, 73], "app": [19, 70, 73], "appear": [21, 26, 37, 39, 43, 46, 47, 67], "append": [3, 7, 19, 25, 27, 45, 53], "append_messag": 26, "appli": [0, 5, 6, 12, 16, 19, 21, 26, 27, 34, 37, 45, 47, 48, 51, 54, 58, 63, 69, 70], "applic": [12, 19, 24, 26, 27, 33, 34, 38, 39, 44, 46, 52, 58, 69, 70, 73, 78, 79], "apply_chat_templ": [20, 23, 24, 25, 32, 33], "appreci": 47, "approach": [3, 10, 11, 15, 27, 46, 51, 70], "appropri": [0, 10, 16, 22, 24, 37, 45, 78], "approv": 47, "approxim": [17, 24, 58], "apt": [0, 46, 50], "ar": [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 73, 74, 79, 80, 81, 82, 84, 85, 86, 87, 88], "arbitrari": 7, "arc": 61, "arce": 81, "arch": 50, "architectur": [1, 4, 5, 6, 16, 17, 27, 31, 33, 37, 46, 60, 79, 80, 81, 84, 87], "area": [24, 26, 34], "areal": 74, "arg": [14, 18, 28, 33, 46, 48, 55, 65, 80], "argument": [16, 17, 18, 19, 23, 24, 25, 27, 28, 29, 30, 32, 33, 37, 41, 42, 43, 45, 46, 47, 51, 52, 59, 76, 82, 87], "arguments_non_stream": 25, "aris": 64, "around": [24, 25, 27, 87], "arrai": [45, 78], "arrang": 6, "arriv": [21, 33, 45], "art": [22, 24, 26, 34, 47, 74, 81], "articl": 31, "artifici": [34, 87], "artist": 34, "ascend": [1, 21, 51, 52, 55, 56, 82], "ascend_attn": [21, 56], "ascend_fuseep": 21, "ascend_instal": 54, "ascend_mf_store_url": [14, 55], "ascend_npu_phy_id": 14, "ascend_rt_visible_devic": [56, 82], "ask": [20, 22, 24, 25, 37, 47, 52, 67], "aspect": [2, 21], "aspect_ratio_id": 26, "aspect_ratio_mask": 26, "assert": [33, 43, 46], "asset": [26, 30, 39, 42, 43, 67], "assign": [12, 43], "assist": [10, 22, 23, 24, 25, 26, 27, 31, 33, 37, 39, 43, 44, 62, 65, 67, 70, 73, 79], "assistant_begin": 67, "assistant_end": 67, "associ": [3, 19, 27, 34], "assum": [20, 22, 24, 25], "astral": 58, "async": [9, 21, 34, 87], "async_gener": [34, 87], "async_stream_and_merg": 34, "asynchron": [15, 30, 42, 74, 87], "asyncio": 87, "at_least_on": 23, "atla": [27, 54], "atmospher": 34, "atp": 19, "atp_dsn": 19, "atp_password": 19, "atp_pool_max": 19, "atp_pool_min": 19, "atp_tns_alia": 19, "atp_us": 19, "atp_wallet_path": 19, "attach": [7, 84], "attachment_ep_statist": 70, "attact": 25, "attain": 11, "attempt": [10, 45], "atten_tp_s": 28, "attent": [3, 6, 10, 11, 12, 14, 17, 20, 22, 23, 24, 25, 26, 28, 30, 32, 33, 34, 37, 38, 39, 42, 44, 51, 52, 54, 55, 56, 59, 61, 63, 67, 69, 70, 73, 80, 81, 82, 85, 87, 88], "attention_backend": [20, 23, 24, 25, 26, 33, 34, 82], "attention_interfac": 88, "attn": 21, "attn_output": 88, "attn_weight": 88, "attract": [22, 25, 65], "attribut": [7, 76], "attributeerror": 7, "audio": [21, 22, 25, 33, 37, 43, 44, 84], "audio_data": 43, "audiodataitem": 43, "aug": 31, "augment": [81, 84], "august": 31, "auror": 67, "australia": [12, 22, 37, 44, 67], "auth": [19, 45], "author": [19, 45, 47, 67, 70, 73], "auto": [0, 6, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 45, 55, 63, 75, 77, 79], "auto_awq": 16, "auto_gptq": 16, "auto_map": 88, "auto_next_anon": 76, "auto_round": 16, "autograd": 46, "autom": 53, "automat": [0, 1, 6, 9, 10, 12, 16, 17, 19, 21, 25, 26, 28, 30, 32, 33, 37, 41, 42, 43, 45, 46, 47, 51, 58, 63, 75, 76, 78], "autonom": [19, 34], "autonomi": 34, "autoprocessor": 26, "autoregress": [5, 17, 22, 79], "autoround": 16, "autoroundmllm": 16, "autosc": 51, "autotag": 59, "autotoken": [16, 20, 23, 24, 25, 33, 38], "autotun": [21, 22, 77], "auxiliari": 14, "avail": [10, 12, 18, 19, 21, 23, 24, 27, 31, 33, 34, 35, 37, 38, 39, 44, 45, 51, 53, 58, 60, 63, 64, 69, 75, 78, 81, 88], "avail_mem": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 39, 44, 67], "available_gpu_mem": [11, 33], "available_tool": 25, "averag": [21, 65], "avg": 28, "avg_token": 28, "avoid": [9, 10, 12, 16, 17, 21, 24, 26, 28, 30, 32, 37, 42, 46, 47, 48, 58, 60, 61, 64, 67, 69, 82, 83, 84], "await": [34, 87], "awar": [14, 34, 74], "award": 34, "awq": [16, 21, 27, 52], "awq_marlin": [16, 21], "aws_account": 51, "aws_region": 51, "b": [3, 12, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 44, 51, 53, 54, 55, 58, 61, 64, 67, 69, 70, 73, 76], "b19aad150e9847b78a39ae0bc21c3494": 22, "b200": [1, 27, 28, 30, 32, 42], "b300": 52, "b580": 61, "baai": [33, 80, 81, 85], "back": [19, 21, 26, 28, 39, 78, 88], "backbon": [74, 84], "backend": [5, 14, 17, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 65, 67, 70, 71, 73, 74, 75, 80, 82, 85, 87, 88], "backend_nam": [9, 10, 21], "backendfactori": 9, "background": [19, 26, 34, 39, 75, 88], "backoff": 19, "backtrac": 46, "backu": 25, "backup": 21, "backward": [12, 21, 37], "bad": [7, 65, 78], "baichuan": 81, "baichuan2": 81, "baichuanai": 81, "baidu": 81, "bail": 60, "balanc": [5, 9, 10, 14, 21, 26, 27, 31, 37, 39, 55, 60, 67, 70, 73, 74], "balanced": [6, 21], "bandwidth": [2, 4, 5, 10, 14], "bank": 44, "bar": [48, 81, 84], "bare": 58, "base": [1, 4, 5, 6, 9, 10, 12, 14, 16, 17, 21, 22, 24, 27, 28, 30, 31, 32, 34, 37, 42, 43, 45, 46, 54, 58, 60, 63, 65, 69, 71, 72, 76, 77, 80, 81, 84, 85, 86], "base64": [26, 43], "base_config": 87, "base_gpu_id": [20, 23, 24, 25, 26, 33, 34], "base_url": [20, 22, 23, 24, 25, 27, 29, 31, 32, 33, 37, 38, 39, 43, 44, 46], "basedispatch": 6, "baseformatdetector": 25, "baselin": [10, 87], "basemodel": [23, 24], "basemultimodalprocessor": 87, "basereasoningformatdetector": 20, "bash": [0, 28, 46, 49, 50, 51, 58, 59, 60, 71], "bashrc": [46, 58], "basi": 28, "basic": [12, 45, 46, 81, 82], "basic_qa": 67, "batch": [3, 4, 10, 12, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 37, 39, 43, 44, 45, 46, 47, 48, 52, 58, 60, 63, 64, 69, 70, 84], "batch_get_v1": 9, "batch_set_v1": 9, "batch_siz": [16, 32], "batchspanprocessor": 63, "bce": 37, "be47de5b848e4b27b61b7b92d19a88bf": 44, "bear": [33, 85], "bearer": [19, 45, 70, 73], "beauti": 34, "becaus": [4, 10, 22, 24, 25, 45, 55, 67, 87], "becom": [2, 4, 15, 17, 21, 34, 74], "been": [10, 15, 16, 22, 28, 34, 37, 46, 58, 60, 61, 69], "befor": [0, 1, 2, 6, 10, 11, 12, 13, 14, 17, 19, 21, 24, 25, 27, 34, 45, 46, 47, 59, 60, 76, 84, 87], "beforehand": [27, 58], "begin": [23, 24, 33, 46, 67, 76], "behav": 1, "behavior": [14, 21, 25, 30, 42, 43, 45, 63, 84, 86], "behind": [6, 15, 35], "beij": [23, 24, 27], "being": [1, 4, 11, 14, 21, 24, 37, 67, 76], "believ": 24, "belong": 10, "below": [1, 12, 21, 22, 25, 26, 30, 33, 42, 43, 48, 50, 51, 53, 54, 58, 67, 76, 79, 80, 81, 84, 87], "bench": [22, 46, 52, 80], "bench_one_batch": [46, 48, 87], "bench_one_batch_serv": [46, 60], "bench_serv": [45, 53, 58, 60, 61, 75], "bench_sglang": [28, 48], "bench_specul": [22, 27, 28], "benchmark": [10, 12, 13, 14, 16, 22, 33, 45, 48, 52, 53, 75, 84], "benchmark_and_profil": 87, "benefici": 11, "benefit": [10, 17, 46, 67], "berlin": [22, 23, 24, 37, 65, 67], "berlin3": 67, "bertforsequenceclassif": 78, "besid": 67, "bespok": 65, "best": [1, 5, 8, 10, 22, 26, 27, 28, 30, 37, 42, 60], "best_effort": [9, 10, 20, 21, 23, 24, 25, 26, 33, 34], "best_kernel": 22, "best_kernel_desc": 22, "best_tim": 22, "best_triton_kernel": 22, "best_triton_kernel_desc": 22, "best_triton_po": 22, "best_triton_tim": 22, "better": [10, 11, 12, 15, 16, 17, 21, 22, 23, 24, 27, 28, 33, 37, 43, 51, 60, 79, 80, 84], "between": [1, 2, 9, 10, 11, 14, 15, 17, 18, 21, 28, 33, 35, 43, 45, 46, 60, 67, 70, 74, 80, 81], "bewar": 58, "beyond": [10, 19, 27, 28], "bf": [20, 21, 23, 24, 25, 26, 33, 34], "bf16": [17, 21, 25, 27, 28, 58, 61, 63, 84], "bfloat16": [21, 22, 33, 41, 55, 59, 60, 63], "bge": [33, 80, 85], "bgererankmodel": 85, "bia": [34, 87], "bias": 87, "big": [22, 24, 34], "bigcod": 81, "bilingu": 81, "billion": [58, 81], "bin": [21, 28, 48, 50, 51, 58, 60, 71], "binari": 82, "birth": 24, "bisheng": 54, "bisheng_nam": 54, "bisheng_url": 54, "bit": [16, 17, 22, 24], "bitsandbyt": [16, 21], "black": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "blackwel": [1, 6, 16, 21, 25, 27, 28, 32, 63], "blank": 45, "blinker": 28, "blob": [26, 30, 39, 42, 43, 67], "block": [1, 6, 10, 17, 24, 47, 63, 67], "block_k": 22, "block_m": 22, "block_n": 22, "block_siz": 79, "blockwis": [21, 63], "blog": [6, 10, 18, 27, 64, 68, 71], "blogpost": 65, "blood": 67, "blue": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "bluefield": 69, "bmm": [27, 63], "bnf": [23, 43], "board": [26, 39, 67], "bodi": [12, 19, 45, 67], "bogart": 67, "bond0": 73, "book": [34, 39], "bool": [12, 21, 43, 63, 87], "boolean": 47, "boost": [4, 6, 30, 67], "boot": 18, "bootstrap": [14, 19, 21, 28, 55, 76], "bootstrap_room": 76, "bootstrap_room_list": 76, "bootstrap_room_span": 76, "born": 67, "boston": 25, "bot": [23, 24], "both": [1, 2, 10, 11, 12, 19, 20, 21, 24, 25, 26, 27, 28, 31, 32, 37, 43, 45, 46, 47, 48, 63, 64, 75, 80, 84, 87], "bottleneck": [6, 9, 46], "bottom": [31, 48], "bound": [21, 33], "boundari": [10, 15, 19, 25], "box": [20, 30, 34, 42], "bracket": 24, "branch": [0, 1, 21, 22, 41, 47, 51, 53, 54], "brasilia": 12, "bras\u00edlia": [12, 22], "brave_search": [23, 24], "brazil": [12, 22], "breadth": 21, "break": [24, 37, 43, 44, 54], "breakdown": [33, 37, 45], "breakpoint": 48, "brief": [34, 79], "bring": 34, "brisk": 67, "broad": 81, "broadcast": 2, "broken": 24, "brought": 15, "brows": 75, "browser": [0, 31, 46, 75, 76], "browser_serv": 31, "bubbl": 15, "bucket": [19, 21], "bucket_e2e_request_lat": [20, 23, 24, 25, 26, 33, 34], "bucket_inter_token_lat": [20, 23, 24, 25, 26, 33, 34], "bucket_time_to_first_token": [20, 23, 24, 25, 26, 33, 34], "budget": [10, 17], "buffer": [1, 11, 20, 21, 41], "bug": [9, 16, 47, 60, 64], "build": [0, 3, 10, 14, 16, 18, 26, 34, 39, 48, 49, 51, 53, 54, 58, 59, 61, 63, 76, 84], "built": [10, 12, 21, 24, 46, 47, 51, 53, 82, 84], "buliltin": 21, "bump": 47, "burst": 45, "busi": [34, 39, 67, 81], "bustl": [24, 34], "bypass": 6, "byte": 10, "bytesio": 26, "c": [3, 12, 25, 33, 34, 37, 44, 51, 53, 60, 69, 73, 76], "c3ec": 69, "c4": 16, "c4ai": 81, "c7": 69, "c79a": 69, "ca": [23, 24, 25], "cab": 26, "cach": [1, 3, 5, 9, 10, 12, 14, 22, 26, 27, 28, 29, 30, 32, 42, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 60, 64, 69, 70, 73, 74, 75, 83, 84, 85], "cache_awar": [19, 55], "cache_hit_r": 75, "cached_token": [23, 24, 33, 44], "cadenc": 19, "caf\u00e9": 78, "calcul": [14, 16, 17, 20, 21, 26, 31, 34, 43, 67], "calibr": 16, "calibration_dataset": 16, "california": [23, 24, 25], "call": [1, 7, 19, 21, 22, 23, 24, 29, 30, 31, 33, 34, 37, 42, 45, 46, 52, 65, 67, 70, 76, 84, 85, 87], "call_037b4babf1a049a6b71b139b": 25, "call_461f2732d83c4c78a7033436": 25, "call_4c00abefba2c46468e22fae9": 25, "call_62421622aa284eb382735f1f": 25, "call_6ac620ba27e74df9a460c705": 25, "call_9585dc72572e46049bbfcc6b": 25, "call_a64004f5c0cf4b509865f51a": 25, "call_ad2cb1f5103c4e2ea49fe377": 25, "call_cb21d7d2bfda45f0b87a199b": 25, "call_d7143cbda23d403a931f8b4b": 25, "call_e01baa6d272d4cf381d410ff": 25, "callabl": 7, "caller": 47, "came": 34, "can": [0, 1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 84, 87, 88], "canada": [37, 44], "canberra": [12, 22, 37, 44, 67], "cancer": 67, "candid": 22, "cann": 82, "cannot": [1, 7, 46, 58, 60, 69, 74], "cano": 59, "cap": [45, 53], "capabl": [19, 29, 32, 33, 34, 41, 42, 53, 70, 73, 74, 79, 84], "capac": [9, 10, 17, 19, 21, 22, 27, 28], "capit": [12, 16, 22, 23, 24, 25, 27, 29, 33, 34, 37, 43, 44, 65, 67, 80, 82, 87], "capital_info": 23, "capitalinfo": [23, 24], "capitol": 22, "caption": 84, "captur": [1, 2, 7, 12, 16, 20, 21, 22, 23, 24, 25, 26, 27, 34, 37, 39, 44, 46, 63, 67, 69], "capture_out": 7, "car": 34, "carbohydr": 67, "care": 31, "career": 34, "carefulli": [39, 67], "carri": 67, "cascad": 22, "case": [0, 1, 6, 10, 11, 12, 15, 16, 21, 24, 27, 28, 34, 45, 46, 60, 64, 81, 82, 84], "cast": [21, 22, 27], "cat": [21, 54], "cathedr": [22, 34], "caus": [7, 13, 14, 15, 17, 21, 25, 46, 64], "causallm": 21, "caveat": 46, "cb": 19, "cbm": [70, 73], "ccccdd": [70, 73], "cd": [14, 28, 49, 51, 53, 54, 58, 60, 61, 75, 82], "celsiu": [23, 24, 25], "censu": 24, "center": [6, 24, 34, 37], "central": 19, "centuri": 37, "certain": [22, 24, 53, 67, 76], "certainli": [34, 67], "cf": 70, "chain": 52, "challeng": [5, 14, 17, 47, 64], "champ": 22, "chanc": [22, 24, 25], "chang": [0, 6, 15, 22, 24, 28, 31, 33, 34, 43, 46, 47, 48, 50, 53, 54, 58, 64, 69, 73, 75, 80, 87], "channel": [9, 16, 20, 21, 25, 27, 47, 58, 61], "charact": [34, 67, 84, 87], "character": 34, "character_gen": 67, "character_regex": 67, "characterist": 10, "chart": 70, "chat": [12, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 35, 39, 42, 43, 44, 45, 52, 59, 60, 70, 73, 80, 81, 84, 85, 87], "chat_exampl": 67, "chat_templ": [20, 23, 24, 25, 26, 27, 28, 33, 34, 62], "chat_template_kwarg": [28, 37], "chatcomplet": [22, 25, 37, 44], "chatcompletionmessag": [22, 25, 37, 44], "chatcompletionmessagefunctiontoolcal": 25, "chatglm": 81, "chatglm2": 81, "chatml": [62, 84], "cheaper": 84, "check": [0, 2, 9, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 35, 37, 38, 39, 43, 44, 45, 47, 51, 54, 58, 60, 63, 67, 69, 88], "check_env": 60, "check_output": [38, 39, 44], "checker": 19, "checkout": [22, 58, 61], "checkpoint": [12, 16, 17, 20, 21, 22, 23, 24, 25, 26, 30, 33, 34, 37, 38, 39, 42, 44, 46, 52, 63, 67, 87], "checkpoint_engin": 2, "checkpoint_engine_wait_weights_before_readi": [20, 23, 24, 25, 26, 33, 34], "child": 10, "children": [7, 63], "china": [12, 23, 24, 33, 74, 85], "chines": 81, "chmod": 54, "choic": [20, 21, 22, 23, 24, 27, 28, 34, 37, 39, 41, 44, 66, 67, 70, 73, 74], "choicedeltatoolcal": 25, "choicedeltatoolcallfunct": 25, "choices_method": 65, "choos": [1, 3, 9, 10, 17, 19, 21, 22, 23, 24, 48], "chosen": [1, 17, 21, 34], "chrome": 46, "chronic": 67, "chunk": [1, 3, 12, 20, 21, 25, 27, 28, 30, 33, 35, 37, 42, 43, 44, 52, 55, 63, 64, 70, 73, 85], "chunked_prefill_s": [11, 20, 23, 24, 25, 26, 33, 34, 69], "chunkedsgmv": [12, 21], "ci": [0, 12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "ci_permiss": 47, "circular": 21, "cite": 24, "citi": [22, 23, 24, 25, 26, 27, 34, 37, 39, 44, 87], "civil": 37, "ckpt": 21, "clariti": [12, 20, 22, 23, 24, 25, 27, 33, 37, 38, 39, 44, 67], "class": [1, 7, 9, 10, 21, 23, 24, 25, 34, 43, 87, 88], "class_0": 78, "class_1": 78, "class_nam": [9, 10, 21], "classic": [1, 10], "classif": [52, 86], "classifi": [44, 78, 86], "clean": [0, 14], "cleaned_chunk": 34, "clear": [7, 24, 34], "clearli": 24, "cli": [19, 21, 33, 46, 51], "client": [11, 12, 18, 19, 20, 22, 23, 24, 27, 29, 31, 35, 37, 43, 46, 60, 63, 69], "client_tool_choic": 25, "climb": 31, "clip": [63, 80, 84], "clone": [14, 28, 51, 53, 54, 58, 59, 60, 61, 82], "close": [16, 17, 19, 28, 31, 41], "cloth": [26, 39], "clotheslin": 26, "clothespin": 67, "cloudi": 25, "cloudli": 25, "cluster": [10, 21, 51, 52, 54, 58, 60, 69, 70, 71], "clusterfirstwithhostnet": [69, 70, 73], "clusterip": [70, 73], "cm1": 69, "cn": 54, "cnbc": 31, "co": 80, "code": [0, 1, 9, 11, 12, 14, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 46, 48, 53, 55, 56, 58, 60, 61, 64, 67, 69, 70, 73, 76, 78, 80, 81, 84, 85, 86, 87], "code_interpret": 31, "codebas": [0, 47], "codeown": 47, "coder": 25, "cofeai": 81, "coffe": 78, "coher": [22, 81], "cohereforai": 81, "collabor": 81, "collect": [4, 16, 21, 63], "collect_tokens_histogram": [20, 23, 24, 25, 26, 33, 34], "collector": [21, 76], "coloc": [5, 74], "color": [4, 12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 46, 67], "colosseum": 37, "column": 1, "com": [14, 19, 26, 28, 30, 33, 39, 42, 43, 46, 47, 48, 49, 50, 51, 53, 54, 58, 59, 60, 61, 67, 68, 69, 70, 73, 76, 82, 84], "combin": [1, 2, 6, 12, 14, 19, 20, 21, 22, 23, 24, 25, 27, 33, 37, 38, 39, 44, 46, 60, 63, 67, 74, 84], "combineinput": 6, "come": [21, 82, 84, 88], "comma": [21, 24], "command": [6, 13, 14, 16, 25, 27, 28, 32, 38, 44, 47, 48, 50, 51, 53, 54, 59, 60, 61, 69, 70, 73, 75, 87], "comment": [24, 47], "commerci": [26, 81], "commit": [0, 21], "common": [0, 1, 10, 17, 37, 45, 47, 58, 64, 69], "commonli": [24, 25], "commun": [2, 4, 18, 21, 34, 46, 52, 55, 60, 69, 70], "compact": [21, 81, 84], "compani": [34, 68, 70, 74], "compar": [4, 10, 15, 17, 27, 33, 81, 87], "comparison": [65, 87], "compat": [3, 6, 9, 10, 15, 16, 17, 19, 21, 27, 31, 33, 37, 38, 39, 41, 43, 45, 52, 60, 62, 69, 70, 73, 76, 84], "compet": 81, "compil": [0, 6, 11, 21, 24, 27, 53, 58, 63, 69], "compile_deep_gemm": 27, "complet": [1, 9, 10, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 51, 58, 59, 61, 67, 69, 70, 73, 78, 81, 84], "completion_templ": [20, 23, 24, 25, 26, 33, 34], "completion_token": [22, 23, 24, 25, 27, 33, 37, 38, 39, 44, 70, 73, 78], "completion_tokens_detail": [22, 25, 37, 44], "completionchoic": 37, "completionusag": [22, 25, 37, 44], "complex": [0, 17, 24, 34, 35, 47, 81, 84], "complianc": 19, "compon": [2, 4, 6, 10, 11, 16, 35, 47, 70, 87], "compos": [75, 76], "comprehens": [10, 19, 25, 27, 63, 85], "compressedtensorsconfig": 16, "compris": 14, "comput": [5, 10, 14, 15, 16, 17, 21, 22, 26, 27, 28, 33, 34, 39, 41, 46, 59, 60, 64], "con": 1, "concaten": 27, "concern": 34, "concis": [24, 34, 37, 47, 74, 87], "conclus": 33, "concurr": [1, 10, 11, 12, 17, 19, 21, 30, 42, 60, 64, 76], "conda": [51, 54, 61], "condit": [6, 10, 14, 15], "confid": [22, 24, 34, 65, 79], "config": [6, 9, 10, 12, 14, 16, 19, 21, 22, 33, 46, 48, 58, 59, 63, 70, 75, 78, 79, 80, 84, 87, 88], "configur": [0, 6, 10, 12, 16, 26, 27, 33, 45, 47, 48, 58, 69, 70, 73, 76, 84, 87], "configure_log": 13, "confirm": [33, 53, 75], "conflict": [61, 75], "confus": 22, "connect": [2, 12, 14, 19, 20, 22, 23, 24, 25, 26, 31, 33, 34, 35, 37, 38, 39, 44, 45, 48, 67, 71, 75], "connect_data": 19, "connectx": 69, "consecut": [10, 14, 17, 21, 63], "consensu": 10, "conserv": [11, 15, 21, 60, 79], "consid": [0, 10, 16, 19, 22, 24, 34, 43, 60], "consist": [2, 3, 4, 10, 19, 24, 27, 30, 47, 67, 74, 76, 81], "consol": [45, 48], "consolid": 63, "constant": 43, "constitut": 22, "constrain": [21, 23], "constrained_json_disable_any_whitespac": [20, 23, 24, 25, 26, 33, 34], "constrained_json_whitespace_pattern": [20, 23, 24, 25, 26, 33, 34], "constraint": [1, 23, 24, 43, 63, 67, 76, 84], "construct": 45, "constructor": 87, "consult": [21, 67], "consum": [10, 11, 17, 67, 84], "consumpt": 22, "contact": 70, "contain": [2, 10, 14, 19, 21, 24, 27, 33, 37, 43, 46, 51, 54, 58, 65, 69, 70, 73, 75, 76], "container": 69, "container_id": 75, "container_nam": 75, "containerd": 69, "containerport": [69, 70, 73], "content": [13, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 35, 37, 38, 39, 42, 43, 44, 45, 46, 58, 70, 73, 78, 79, 84, 86], "context": [9, 10, 17, 19, 21, 22, 24, 26, 30, 32, 34, 42, 45, 52, 55, 59, 61, 63, 70, 73, 76, 81, 84], "context_len": [11, 33, 69], "context_length": [20, 21, 22, 23, 24, 25, 26, 33, 34], "contigu": [6, 10], "continu": [7, 9, 10, 19, 21, 22, 28, 33, 34, 46, 52, 60, 63, 74], "contract": 20, "contrast": 10, "contribut": [9, 19, 22, 34, 52, 62, 67, 70], "contributor": [0, 47, 60, 81], "control": [1, 6, 9, 10, 12, 13, 14, 15, 21, 22, 25, 30, 37, 42, 43, 45, 46, 52, 63, 69, 74], "conv": [26, 33], "conveni": [16, 46, 53, 67], "convent": [9, 14], "convers": [6, 9, 19, 26, 32, 45, 62, 81, 84, 87], "convert": [10, 16, 23, 24, 37, 51, 76, 84, 87], "convert_dict_to_tool": 25, "cool": 47, "cooldown": [19, 47], "coordin": 60, "copi": [9, 10, 18, 21, 24, 26, 30, 42, 51, 77, 84], "core": [6, 10, 12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 52, 58, 60, 67, 76], "corpu": 81, "correct": [0, 12, 21, 24, 25, 34, 37, 46, 87], "correctli": [24, 28, 37, 46, 69, 87, 88], "correl": 6, "correspond": [1, 10, 12, 16, 21, 24, 25, 38, 43, 47, 76, 87], "cost": [21, 46, 60, 80, 81, 84], "cot": 20, "could": [15, 21, 31, 34, 53, 54, 55, 56, 69], "count": [10, 19, 33, 37, 45, 58, 60, 63], "counter": [19, 63, 75], "countri": [12, 22, 23, 24, 33, 34, 37, 43, 44, 67], "coupl": [5, 6, 67], "cours": 34, "cover": [10, 19, 24, 37, 38, 39, 69, 87], "coverag": 47, "cp": [28, 58, 61], "cp311": [14, 54], "cp_size": 28, "cpp": 46, "cpu": [1, 2, 9, 10, 12, 16, 20, 21, 23, 24, 25, 26, 27, 33, 34, 46, 47, 51, 52, 63, 70, 71, 73, 84], "cpu0": 54, "cpu_count": 14, "cpu_offload_gb": [20, 23, 24, 25, 26, 33, 34], "cpufreq": 54, "crash": [21, 73], "crash_dump": 13, "crash_dump_fold": [20, 23, 24, 25, 26, 33, 34], "creat": [0, 1, 6, 7, 10, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31, 33, 34, 37, 38, 39, 43, 44, 47, 48, 51, 53, 54, 58, 60, 61, 73, 76, 78, 87], "creativ": [34, 37], "credenti": 19, "credibl": 24, "crimin": 34, "critic": [1, 3, 10, 46, 47], "cross": [9, 10, 15, 24, 28, 80, 84, 85], "crucial": [1, 24, 67, 69], "csgmv": [12, 20, 21, 23, 24, 25, 26, 33, 34], "csrc": 46, "csv": [21, 33], "ctrl": [33, 69], "cubla": 64, "cuda": [1, 2, 3, 6, 10, 12, 16, 20, 21, 22, 23, 24, 25, 26, 27, 30, 33, 34, 42, 46, 48, 50, 51, 55, 59, 61, 63, 69, 70, 73], "cuda_graph_b": [20, 23, 24, 25, 26, 33, 34], "cuda_graph_max_b": [20, 23, 24, 25, 26, 33, 34], "cuda_hom": 51, "cuda_launch_block": [70, 73], "cuda_profil": 46, "cuda_visible_devic": 50, "cudagraph": [21, 77], "cudamemcpyasync": 10, "cudaprofilerapi": 46, "cudaprofilerstart": 46, "cudaprofilerstop": 46, "cudnn": 59, "cuisin": 34, "cultur": [22, 24, 34], "cumul": 43, "curl": [13, 19, 27, 33, 43, 46, 50, 58, 60, 61, 70, 73, 75, 79], "curl_command": [39, 44], "curl_id": 38, "curl_text": 38, "current": [6, 7, 10, 12, 14, 16, 17, 19, 21, 22, 23, 24, 27, 28, 31, 33, 34, 43, 45, 47, 54, 58, 60, 61, 63, 64, 70, 73, 76, 82, 84, 85], "custom": [0, 6, 10, 19, 20, 23, 24, 25, 27, 28, 29, 30, 33, 34, 37, 45, 52, 54, 63, 74, 75], "custom_backend_nam": 9, "custom_logit_processor": [27, 29, 43], "custom_op": 54, "custom_param": [27, 29, 43], "custom_param_list": 43, "custom_serv": 34, "custom_sigquit_handl": [20, 23, 24, 25, 26, 33, 34], "custom_weight_load": [20, 23, 24, 25, 26, 33, 34], "customlogitprocessor": [27, 29, 30, 43], "cut": [16, 27], "cutedsl": 21, "cutlass": [1, 6, 12, 16, 21, 63], "cutlass_mla": [1, 21], "cutlassmla": 27, "cycl": [6, 19, 67], "d": [12, 19, 21, 27, 28, 34, 37, 38, 39, 44, 46, 51, 67, 70, 71, 73, 75, 76, 78, 79], "d158fe70a72e4a6db13cb09f5346861b": 24, "d2h": [21, 30, 42], "d5421ea9407e4124b6a3b79799afca75": 22, "d9411e8577de410e9c321ed7af452185": 24, "d_": 28, "d_host_ip": 55, "dai": [25, 27, 31, 37, 67], "daili": 34, "dame": [22, 34], "dan": 34, "dao": 27, "dashboard": 75, "data": [4, 6, 9, 11, 14, 17, 18, 20, 22, 24, 25, 26, 30, 31, 33, 34, 38, 39, 42, 43, 44, 46, 52, 53, 60, 73, 75, 76, 78, 80, 82, 84, 87], "data1": [69, 70, 73], "data_fil": 16, "data_path": 55, "databas": 19, "databrick": 81, "dataload": 21, "dataset": [16, 17, 28, 32, 46, 53, 58, 60, 61, 75, 80], "datasourc": 75, "date": [23, 24, 28, 31], "davinci": 54, "davinci0": 54, "davinci1": 54, "davinci10": 54, "davinci11": 54, "davinci12": 54, "davinci13": 54, "davinci14": 54, "davinci15": 54, "davinci2": 54, "davinci3": 54, "davinci4": 54, "davinci5": 54, "davinci6": 54, "davinci7": 54, "davinci8": 54, "davinci9": 54, "davinci_manag": 54, "dbazur": 48, "dbrx": 81, "dd094b0de2134973aa38f334672d9c65": 44, "dd6dbdf7ab094808926ba3e13b708b1b": 23, "de": 74, "deactiv": 51, "deadlock": 21, "death": [24, 67], "deb": 46, "debug": [2, 3, 6, 7, 13, 19, 22, 46], "debug_tensor_dump_inject": [20, 23, 24, 25, 26, 33, 34], "debug_tensor_dump_input_fil": [20, 23, 24, 25, 26, 33, 34], "debug_tensor_dump_lay": [20, 23, 24, 25, 26, 33, 34], "debug_tensor_dump_output_fold": [20, 23, 24, 25, 26, 33, 34], "debugg": 3, "debugpi": 48, "dec": 21, "deceas": 67, "decemb": 23, "decentr": 6, "decid": [21, 24, 37], "decis": 34, "declar": 87, "decod": [4, 5, 6, 9, 10, 11, 27, 28, 39, 44, 45, 52, 55, 58, 63, 64, 73, 76, 79, 81, 84, 88], "decode1": 19, "decode_addr": 28, "decode_attention_backend": [20, 23, 24, 25, 26, 33, 34], "decode_host": 5, "decode_host_ip": 55, "decode_log_interv": [20, 23, 24, 25, 26, 33, 34], "decode_master_ip": 14, "decode_unicod": [43, 44], "decompos": 5, "decor": 26, "decord": 84, "decoupl": [5, 6, 84], "decreas": [11, 29, 37, 41, 60, 64], "decrypted_config_fil": [20, 23, 24, 25, 26, 33, 34], "decrypted_draft_config_fil": [20, 23, 24, 25, 26, 33, 34], "dedic": [10, 14, 34, 43, 46, 51, 58, 60, 61, 74, 84, 87], "dee": [70, 73], "deep": 31, "deep_gemm": [6, 21, 63], "deep_normal_mode_use_int8_qu": 55, "deepep": [6, 14, 21, 28, 55, 70, 73], "deepep_config": [20, 23, 24, 25, 26, 33, 34], "deepep_mod": [20, 23, 24, 25, 26, 33, 34], "deeper": [22, 47], "deepgemm": [6, 21, 27], "deepli": [19, 33], "deepseek": [1, 2, 6, 9, 10, 11, 16, 17, 19, 20, 21, 22, 24, 25, 48, 51, 52, 54, 57, 59, 63, 69, 70, 72, 73, 81, 82, 84], "deepseek_r1_0528": 70, "deepseek_v3": 48, "deepseek_v3_mo": 69, "deepseekr10528": 70, "deepseekr1thinkingbudgetlogitprocessor": 27, "deepseekv3": [21, 25, 27], "deepseekv31": [21, 25, 28], "deepseekv32": [25, 28, 72], "deepseekv32_pd": 28, "def": [7, 23, 24, 25, 34, 43, 55, 65, 67, 79, 87, 88], "default": [1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 41, 44, 45, 46, 47, 51, 53, 54, 58, 60, 62, 63, 65, 67, 69, 73, 75, 76, 78, 79, 84, 87, 88], "defer": 60, "defin": [1, 6, 7, 20, 21, 23, 24, 30, 42, 43, 47, 62, 67, 71, 75, 87], "definit": [22, 24, 75], "degrad": [12, 15, 17, 22, 55, 69], "degre": 25, "delai": [2, 14, 16, 31, 46], "delet": [19, 21, 51], "delete_ckpt_after_load": [20, 23, 24, 25, 26, 33, 34], "delimit": [20, 21, 25], "deliv": [52, 60, 81], "deliveri": 34, "delta": [20, 21, 25, 27, 37, 44], "demand": 12, "dementor": 67, "demo": 21, "demograph": 24, "demonstr": [6, 10, 12, 16, 25, 26, 33, 34, 37, 81, 87], "denot": [21, 24], "dens": [21, 58, 70, 73, 81, 82], "densiti": 24, "deocod": 4, "dep": [45, 51, 61], "depend": [1, 10, 16, 17, 21, 24, 34, 45, 47, 51, 58, 61, 73, 76], "deploi": [9, 14, 27, 51, 60, 72, 74, 77], "deploy": [2, 5, 6, 14, 16, 21, 27, 28, 30, 42, 51, 52, 58, 60, 69, 73, 80, 81, 84, 85], "deploy_and_serve_endpoint": 51, "deprec": [19, 25, 33, 63, 67], "depth": [22, 81], "dequant": 17, "deriv": [17, 22, 86], "describ": [7, 37, 39, 43, 47, 51, 53, 65, 75, 76, 78], "descript": [3, 6, 7, 14, 19, 21, 23, 24, 25, 27, 29, 32, 34, 35, 41, 43, 46, 47, 58, 60, 63, 79, 80, 81, 84, 85, 86, 87], "descriptor": [19, 45], "design": [1, 5, 6, 8, 9, 14, 20, 27, 28, 34, 37, 39, 52, 60, 74, 76, 78, 81, 84, 85], "desir": [23, 58, 61], "desktop": 75, "destin": [14, 34], "detach": 26, "detail": [1, 6, 9, 10, 12, 13, 14, 18, 19, 21, 22, 23, 24, 27, 28, 31, 32, 33, 34, 37, 41, 43, 45, 46, 47, 58, 59, 60, 61, 64, 69, 74, 79, 84, 87], "detailed_tip": 67, "detect": [12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 63, 67], "detector": 25, "determin": [10, 11, 15, 20, 21, 25, 34, 58, 65, 76], "determinist": [47, 52, 74], "deterministiclogitprocessor": 43, "detoken": [43, 63], "detokenization_result": 33, "detokenize_payload": 33, "detokenize_respons": 33, "detokenize_url": 33, "dev": [21, 46, 50, 51, 53, 54, 58, 69, 70, 73], "dev20251120": 54, "devcontain": 48, "devel": 50, "develop": [3, 6, 10, 12, 21, 25, 34, 35, 46, 47, 51, 60, 61, 68, 74, 76, 81], "developer_guid": 87, "devic": [6, 9, 10, 14, 16, 20, 21, 23, 24, 25, 26, 27, 30, 33, 34, 42, 47, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 69, 70, 73, 81, 84], "device_config": 16, "device_list": 9, "device_map": 16, "device_nam": [14, 33], "device_typ": 54, "deviceconfig": 16, "devkit": 59, "devtool": 46, "df": 21, "dgx": 51, "diabet": 67, "diagnos": 69, "diagram": 48, "dialogu": [9, 81], "dict": [7, 21, 23, 24, 25, 26, 43], "dictionari": [21, 24, 25, 37], "did": 33, "didn": [24, 25], "diet": 67, "dietitian": 67, "differ": [3, 4, 6, 10, 12, 15, 16, 21, 22, 26, 27, 28, 30, 33, 34, 37, 39, 42, 45, 48, 53, 58, 60, 63, 64, 69, 70, 73, 75, 76, 77, 79, 83, 87], "diffus": [52, 80], "dimens": [21, 46], "dir": [16, 19, 21, 46, 60, 69], "direct": [2, 9, 10, 21, 34, 58], "directli": [0, 2, 7, 10, 16, 19, 20, 21, 22, 23, 24, 26, 37, 46, 47, 70, 87], "directori": [2, 19, 21, 28, 46, 48, 58, 63, 75, 76, 83, 87], "directoryorcr": [70, 73], "disabl": [3, 6, 9, 16, 19, 20, 21, 22, 24, 27, 33, 38, 45, 46, 47, 48, 55, 58, 60, 61, 63, 64, 70, 73, 85], "disable_chunked_prefix_cach": [20, 23, 24, 25, 26, 33, 34], "disable_cuda_graph": [20, 23, 24, 25, 26, 33, 34], "disable_cuda_graph_pad": [20, 23, 24, 25, 26, 33, 34], "disable_custom_all_reduc": [20, 23, 24, 25, 26, 33, 34], "disable_fast_image_processor": [20, 23, 24, 25, 26, 33, 34], "disable_flashinfer_autotun": [20, 23, 24, 25, 26, 33, 34], "disable_flashinfer_cutlass_moe_fp4_allgath": [20, 23, 24, 25, 26, 33, 34], "disable_hybrid_swa_memori": [20, 23, 24, 25, 26, 33, 34], "disable_outlines_disk_cach": [20, 23, 24, 25, 26, 33, 34], "disable_overlap_schedul": [20, 23, 24, 25, 26, 33, 34], "disable_radix_cach": [20, 23, 24, 25, 26, 33, 34], "disable_shared_experts_fus": [20, 23, 24, 25, 26, 33, 34], "disable_tokenizer_batch_decod": [20, 23, 24, 25, 26, 33, 34], "disaggreg": [27, 52, 54, 70, 72, 73, 74, 76], "disaggregation_bootstrap_port": [20, 23, 24, 25, 26, 33, 34], "disaggregation_decode_dp": [20, 23, 24, 25, 26, 33, 34], "disaggregation_decode_enable_offload_kvcach": [20, 23, 24, 25, 26, 33, 34], "disaggregation_decode_polling_interv": [20, 23, 24, 25, 26, 33, 34], "disaggregation_decode_tp": [20, 23, 24, 25, 26, 33, 34], "disaggregation_ib_devic": [20, 23, 24, 25, 26, 33, 34], "disaggregation_mod": [20, 23, 24, 25, 26, 33, 34], "disaggregation_prefill_pp": [20, 23, 24, 25, 26, 33, 34], "disaggregation_transfer_backend": [20, 23, 24, 25, 26, 33, 34], "discard": 1, "discourag": [37, 43], "discov": 19, "discoveri": 73, "discuss": [9, 27, 34, 37, 47, 60], "diseas": 67, "disjoint": 21, "disk": [2, 21, 63, 83, 87], "dispatch": [1, 6, 21, 63, 64, 70, 73], "dispatchoutput": 6, "displai": [0, 12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 48, 53, 67], "dist": [2, 14, 21, 22, 27, 28, 55, 60, 69, 70, 71, 73, 82], "dist_init_addr": [20, 23, 24, 25, 26, 33, 34], "dist_port": 28, "dist_timeout": [20, 23, 24, 25, 26, 33, 34], "distil": [20, 24, 37, 58, 59], "distinct": [5, 14], "distinguish": 76, "distrib_releas": 46, "distribut": [0, 2, 6, 10, 14, 19, 43, 51, 52, 69, 82], "distro": 53, "diverg": 74, "divers": [3, 6, 10, 22, 34, 37, 43, 74], "divid": [17, 45], "divis": [21, 28], "dkr": 51, "dlami": 48, "dllm": 79, "dllm_algorithm": [20, 23, 24, 25, 26, 33, 34, 79], "dllm_algorithm_config": [20, 23, 24, 25, 26, 33, 34], "dn": 67, "dnspolici": [69, 70, 73], "do": [0, 1, 16, 21, 24, 25, 27, 34, 37, 46, 47, 50, 55, 58, 60, 64, 71, 87], "doc": [10, 22, 23, 43, 46, 47, 48, 51, 53, 59, 65, 82, 87], "doc_patch": [12, 20, 22, 23, 24, 25, 33, 34, 37, 38, 39, 44, 67], "docker": [21, 27, 31, 46, 52, 59, 63, 69, 75, 76, 83], "dockerfil": [51, 53, 54, 58], "dockerx": 53, "document": [1, 9, 10, 12, 14, 19, 21, 22, 25, 27, 28, 31, 33, 34, 35, 37, 48, 51, 53, 58, 59, 61, 62, 63, 69, 71, 78, 82, 84, 85], "doe": [7, 10, 12, 13, 21, 46, 47, 48, 87], "doesn": [28, 63, 69], "domain": 2, "domin": 5, "don": [1, 7, 22, 24, 25, 26, 32, 34, 35, 37, 43, 46, 47, 48, 53, 54, 84, 87], "donald": 65, "done": [27, 39, 43, 44, 46, 50, 55, 60, 71], "dot": [7, 84], "dotsvlm": 84, "doubl": [24, 37], "down": [11, 24, 31, 37, 47, 64, 65], "down_mo": 33, "down_proj": [12, 21], "downcast": [33, 38], "download": [14, 16, 21, 22, 26, 33, 43, 45, 46, 48, 54, 58, 60, 61, 82, 87], "download_dir": [20, 23, 24, 25, 26, 33, 34], "downstream": 19, "downward": 69, "dp": [14, 19, 21, 27, 28, 30, 46, 52, 55, 70, 73, 82], "dp_attent": 21, "dp_rank": 76, "dp_size": [11, 20, 23, 24, 25, 26, 28, 33, 34, 55, 82], "dpkg": 46, "dpo": 74, "draft": [1, 21, 22, 27, 28, 29, 32, 41, 55, 56, 60], "dragonst": 67, "dramat": 9, "drape": 39, "drastic": 47, "dream": 37, "dress": 67, "dri": [50, 53], "drink": 67, "drive": 34, "driven": [34, 45], "driver": [54, 69], "drop": [12, 17, 54, 60, 63], "drun": [53, 54], "ds_channel_config_path": [20, 23, 24, 25, 26, 33, 34], "ds_heavy_channel_num": [20, 23, 24, 25, 26, 33, 34], "ds_heavy_channel_typ": [20, 23, 24, 25, 26, 33, 34], "ds_heavy_token_num": [20, 23, 24, 25, 26, 33, 34], "ds_sparse_decode_threshold": [20, 23, 24, 25, 26, 33, 34], "dsa": 1, "dshm": [69, 70, 73], "dsl": 6, "dsn": 19, "dsv32": [28, 73], "dtype": [1, 17, 20, 21, 22, 23, 24, 25, 26, 28, 33, 34, 41, 55, 59, 60], "dual": [1, 58], "dual_chunk_flash_attn": [1, 21], "dublin": 23, "duck": 65, "ducx_path": 14, "due": [3, 11, 14, 16, 21, 24, 34, 46, 47, 48, 59, 60, 63, 65, 74, 76], "dummi": [2, 21, 43, 46], "dummy_hook_factori": 7, "dump": [23, 24, 38, 43, 73, 78], "dump_expert_distribution_record": 33, "duplic": [27, 47], "durat": [19, 27, 30, 42, 45, 46], "dure": [1, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 21, 26, 28, 30, 33, 42, 43, 46, 58, 63, 64, 74, 76, 85], "dusti": 59, "dustin": 59, "dv": 48, "dynam": [3, 6, 10, 14, 16, 17, 21, 22, 46, 60, 64, 70, 73, 84], "dynamic_batch_tokenizer_batch_s": [20, 23, 24, 25, 26, 33, 34], "dynamic_batch_tokenizer_batch_timeout": [20, 23, 24, 25, 26, 33, 34], "dynamo": [14, 21, 22], "e": [0, 1, 3, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 33, 37, 42, 45, 46, 47, 48, 50, 51, 53, 54, 58, 60, 61, 71, 75, 76, 81, 82, 84, 87], "e2": [21, 30, 42], "e2e_lat": [23, 24, 33, 44], "e2e_request_latency_second": 75, "e2e_request_latency_seconds_bucket": 75, "e2e_request_latency_seconds_count": 75, "e2e_request_latency_seconds_sum": 75, "e2m1": 17, "e4a5be04da904b5a9a3dd2f67f528c42": 24, "e4m3": [17, 27], "e5": [52, 80], "e5m2": 17, "each": [0, 1, 2, 3, 7, 10, 12, 14, 15, 17, 21, 24, 26, 27, 30, 33, 34, 37, 41, 42, 43, 45, 46, 47, 58, 63, 67, 69, 71, 76, 78, 84, 87], "eager": [20, 23, 24, 25, 26, 33, 34], "eagl": [1, 21, 27, 28, 55, 56, 60], "eagle2": 21, "eagle3": [21, 22, 32], "earli": [11, 81], "earlier": 65, "earn": 31, "easi": [6, 16, 24, 47, 52, 67, 74], "easier": [48, 87], "easili": [34, 87], "east": 54, "eater": 67, "ebnf": 25, "ebnf_grammar": [23, 24], "ec": [70, 73], "ec2cd49b0c40420c8009a7d2b9d5c8b9": 39, "echo": [28, 46, 50, 51, 53, 54, 60, 71], "econom": [24, 34], "ecosystem": 61, "ecr": 51, "ecr_registri": 51, "edg": [16, 81, 84], "edit": [47, 48, 50], "effect": [1, 2, 10, 17, 22, 34, 37, 60, 69], "effici": [2, 6, 9, 10, 12, 14, 15, 18, 21, 22, 26, 27, 28, 30, 33, 34, 42, 43, 47, 52, 58, 59, 60, 74, 80, 81, 84, 85], "effort": [1, 9], "eg": [21, 30, 42], "eic": 21, "eiffel": [22, 24, 34], "eight": [69, 84], "eighth": 37, "either": [7, 16, 21, 24, 28, 31, 43, 51], "elabor": 16, "elaps": [33, 69], "elast": [6, 21], "elastic_ep_backend": [20, 23, 24, 25, 26, 33, 34], "element": [7, 17, 21, 26, 37], "eleutherai": 65, "elif": 67, "els": [7, 12, 23, 24, 33, 47], "elsiu": 25, "embark": 37, "embed": [12, 19, 21, 36, 37, 43, 44, 52, 85, 86, 87], "embed_token": 12, "embedding_process": [33, 38], "emit": 46, "emmanuel": 33, "emot": 34, "emploi": [6, 10, 22, 43, 84], "empti": [25, 33, 37, 46], "emptydir": [69, 70, 73], "emul": 1, "en": [16, 80], "enabl": [1, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31, 32, 37, 38, 39, 41, 42, 43, 45, 48, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 70, 73, 74, 75, 76, 80, 81, 82, 84, 85], "enable_ascend_moe_nz": 56, "enable_ascend_transfer_with_mooncak": 14, "enable_attn_tp_input_scatt": [20, 23, 24, 25, 26, 33, 34], "enable_broadcast_mm_inputs_process": [20, 23, 24, 25, 26, 33, 34], "enable_cache_report": [20, 23, 24, 25, 26, 33, 34], "enable_cudagraph_gc": [20, 23, 24, 25, 26, 33, 34], "enable_custom_logit_processor": [20, 23, 24, 25, 26, 33, 34], "enable_deterministic_infer": [20, 23, 24, 25, 26, 33, 34], "enable_double_spars": [20, 23, 24, 25, 26, 33, 34], "enable_dp_attent": [20, 23, 24, 25, 26, 33, 34], "enable_dp_lm_head": [20, 23, 24, 25, 26, 33, 34], "enable_draft_weights_cpu_backup": [20, 23, 24, 25, 26, 33, 34], "enable_dynamic_batch_token": [20, 23, 24, 25, 26, 33, 34], "enable_dynamic_chunk": [20, 23, 24, 25, 26, 33, 34], "enable_eplb": [20, 23, 24, 25, 26, 33, 34], "enable_expert_distribution_metr": [20, 23, 24, 25, 26, 33, 34], "enable_flashinfer_allreduce_fus": [20, 23, 24, 25, 26, 33, 34], "enable_fp32_lm_head": [20, 23, 24, 25, 26, 33, 34], "enable_fused_qk_norm_rop": [20, 23, 24, 25, 26, 33, 34], "enable_hierarchical_cach": [20, 23, 24, 25, 26, 33, 34], "enable_layerwise_nvtx_mark": [20, 23, 24, 25, 26, 33, 34], "enable_lmcach": [20, 23, 24, 25, 26, 33, 34], "enable_lora": [12, 20, 23, 24, 25, 26, 33, 34], "enable_memory_sav": [20, 23, 24, 25, 26, 33, 34], "enable_metr": [20, 23, 24, 25, 26, 33, 34, 73], "enable_metrics_for_all_schedul": [20, 23, 24, 25, 26, 33, 34], "enable_mixed_chunk": [20, 23, 24, 25, 26, 33, 34], "enable_moe_nz": 55, "enable_mscclpp": [20, 23, 24, 25, 26, 33, 34], "enable_mtp": [20, 23, 24, 25, 26, 33, 34], "enable_multimod": [20, 23, 24, 25, 26, 33, 34], "enable_nan_detect": [20, 23, 24, 25, 26, 33, 34], "enable_nccl_nvl": [20, 23, 24, 25, 26, 33, 34], "enable_nsa_prefill_context_parallel": [20, 23, 24, 25, 26, 33, 34], "enable_p2p_check": [20, 23, 24, 25, 26, 33, 34], "enable_pdmux": [20, 23, 24, 25, 26, 33, 34], "enable_piecewise_cuda_graph": [20, 23, 24, 25, 26, 33, 34], "enable_prefix_mm_cach": [20, 23, 24, 25, 26, 33, 34], "enable_priority_schedul": [20, 23, 24, 25, 26, 33, 34], "enable_profile_cuda_graph": [20, 23, 24, 25, 26, 33, 34], "enable_request_time_stats_log": [20, 23, 24, 25, 26, 33, 34], "enable_return_hidden_st": [20, 23, 24, 25, 26, 33, 34], "enable_return_routed_expert": [20, 23, 24, 25, 26, 33, 34], "enable_single_batch_overlap": [20, 23, 24, 25, 26, 33, 34], "enable_symm_mem": [20, 23, 24, 25, 26, 33, 34], "enable_think": [20, 37], "enable_tokenizer_batch_encod": [20, 23, 24, 25, 26, 33, 34], "enable_torch_compil": [20, 23, 24, 25, 26, 33, 34], "enable_torch_compile_debug_mod": [20, 23, 24, 25, 26, 33, 34], "enable_torch_symm_mem": [20, 23, 24, 25, 26, 33, 34], "enable_trac": [20, 23, 24, 25, 26, 33, 34], "enable_two_batch_overlap": [20, 23, 24, 25, 26, 33, 34], "enable_weights_cpu_backup": [20, 23, 24, 25, 26, 33, 34], "encapsul": 10, "encod": [5, 21, 26, 30, 37, 38, 43, 44, 52, 84, 85], "encoder_onli": [20, 23, 24, 25, 26, 33, 34], "encoder_transfer_backend": [20, 23, 24, 25, 26, 33, 34], "encoder_url": [20, 23, 24, 25, 26, 33, 34], "encoding_for_model": 37, "encoding_format": 80, "encount": [11, 16, 27, 46, 51, 53, 54, 58, 60, 69, 75], "encourag": [11, 37, 43, 47], "end": [4, 6, 15, 20, 21, 23, 24, 30, 33, 34, 35, 37, 43, 44, 46, 67, 69, 75, 76, 84, 87], "end_tag": [23, 24], "endem": [33, 85], "endpoint": [2, 5, 19, 21, 23, 24, 33, 44, 51, 67, 75, 76, 87], "energi": 67, "enforc": [12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 63, 67], "engag": [22, 67], "engin": [5, 10, 14, 16, 18, 21, 22, 27, 35, 39, 46, 47, 52, 53, 54, 59, 64, 67, 70, 74, 79, 82], "england": [23, 24, 43], "english": [24, 34, 81], "enhanc": [6, 22, 34, 67, 81, 84], "enjoi": [34, 67], "enough": [7, 11, 21], "ensembl": 45, "ensur": [0, 2, 3, 6, 9, 10, 12, 14, 19, 22, 24, 25, 27, 28, 31, 34, 45, 46, 47, 48, 53, 54, 58, 59, 60, 67, 71, 73, 74, 75, 85, 87], "enter": [48, 58, 76], "enterpris": [10, 16, 19, 51, 74, 81], "entir": [4, 7, 14, 23, 24, 46, 53], "entri": [6, 7, 11, 19], "entryclass": 87, "entrypoint": [2, 78, 87], "enum": [23, 24, 25], "enumer": [16, 43, 67], "env": [14, 22, 51, 53, 54, 58, 69, 70, 73, 76, 83], "env_fold": 71, "envelop": 21, "environ": [9, 10, 12, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 44, 45, 46, 47, 50, 51, 52, 58, 61, 67, 69, 70, 71, 73, 75, 76, 83], "eo": [11, 43, 45, 60], "eof": 21, "eom": 25, "ep": [5, 21, 27, 28, 30, 42, 46, 70, 73], "ep_dispatch_algorithm": [20, 23, 24, 25, 26, 33, 34], "ep_num_redundant_expert": [20, 23, 24, 25, 26, 33, 34], "ep_siz": [6, 20, 23, 24, 25, 26, 33, 34], "epd": 52, "eplb": [6, 21, 70, 73], "eplb_algorithm": [20, 23, 24, 25, 26, 33, 34], "eplb_min_rebalancing_utilization_threshold": [20, 23, 24, 25, 26, 33, 34], "eplb_rebalance_layers_per_chunk": [20, 23, 24, 25, 26, 33, 34], "eplb_rebalance_num_iter": [20, 23, 24, 25, 26, 33, 34], "equal": [12, 20, 21, 28, 45, 67], "equip": [28, 58], "equival": [19, 44, 53, 64], "erni": 81, "err": 71, "error": [0, 2, 7, 16, 17, 20, 21, 22, 23, 24, 25, 27, 33, 34, 45, 46, 47, 58, 69, 71, 75], "error_messag": 12, "error_typ": 78, "esc": 58, "especi": [2, 10, 11, 12, 15, 17, 21, 24, 25, 34, 47, 48], "essenti": [9, 67, 69, 74, 75, 87], "establish": [20, 74], "estim": [15, 24, 34, 63], "et": 31, "etc": [4, 7, 9, 16, 19, 21, 25, 45, 46, 52, 53, 54, 78, 81, 87], "eth": 69, "ethernet": 69, "ethic": 34, "europ": [22, 34, 44], "eval": [26, 28, 47, 87], "evalu": [3, 17, 22, 28, 33, 45, 47, 60, 86], "evaluation_mod": 28, "even": [3, 15, 48, 63, 65, 81, 84], "even_k": 22, "event": [21, 25, 46], "eventu": [19, 87], "everi": [0, 4, 6, 7, 10, 13, 21, 24, 46, 47, 48, 58, 76], "everyth": 24, "evict": [10, 12, 19, 21], "evidenc": 26, "evolv": [6, 19], "exa": 31, "exa_api_kei": 31, "exact": [10, 22, 24, 31], "exactli": [7, 19, 24, 35, 46, 87], "exampl": [0, 1, 7, 9, 10, 12, 19, 21, 22, 23, 24, 26, 28, 29, 31, 32, 34, 38, 39, 41, 47, 48, 50, 51, 57, 61, 65, 67, 71, 75, 76, 82, 83], "example_function_nam": [23, 24], "example_imag": [26, 30, 39, 42, 43, 67], "example_nam": [23, 24], "example_valu": [23, 24], "exampleoutput": 37, "exaon": 81, "exce": [10, 21, 30, 42, 43, 47, 58, 63, 87], "exceed": 55, "excel": [1, 47, 81], "except": [1, 7, 25, 28, 33, 60, 88], "excess": 67, "excit": 34, "exclud": 51, "exclus": 46, "exec": [0, 46, 48], "execut": [0, 5, 6, 10, 16, 19, 23, 24, 31, 46, 51, 58, 69, 70, 76, 80, 85, 86], "exercis": 67, "exhibit": 81, "exist": [0, 1, 5, 9, 10, 16, 21, 22, 26, 47, 48, 70, 73, 76, 87], "exit": [58, 71], "exp": [25, 28, 72], "expand": [1, 10, 67, 87], "expandable_seg": [55, 56], "expans": [6, 22], "expect": [3, 7, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 44, 46, 58, 60, 67], "expens": 47, "experi": [3, 16, 17, 34, 70], "experienc": 27, "experiment": [17, 21, 22, 63], "expert": [11, 21, 27, 52, 55, 58, 63, 70, 72, 73, 79, 81], "expert_distribution_recorder_buffer_s": [20, 23, 24, 25, 26, 33, 34], "expert_distribution_recorder_mod": [20, 23, 24, 25, 26, 33, 34], "expert_record_server_process": 33, "expir": 19, "explain": [24, 31, 34, 60, 76, 80, 87], "explan": [1, 25, 37, 59, 61], "explicit": [7, 19, 25], "explicitli": [12, 19, 23, 32, 33, 58, 75, 76], "exploit": 10, "explor": [1, 37, 84], "expon": 17, "exponenti": [17, 21], "export": [7, 9, 14, 19, 28, 31, 45, 46, 48, 50, 51, 53, 55, 56, 58, 60, 76, 82, 83, 87], "export_metrics_to_fil": [20, 23, 24, 25, 26, 33, 34], "export_metrics_to_file_dir": [20, 23, 24, 25, 26, 33, 34], "exported_model": 16, "expos": [10, 13, 19, 31, 37, 45, 46, 70, 75], "express": [43, 67, 81, 84], "extend": [9, 10, 19, 21, 22, 25, 27, 28, 37, 45, 65, 81, 87], "extens": [48, 52, 84], "extern": [7, 9, 17, 19, 24, 31, 33, 52], "extra": [9, 10, 21, 28, 41, 45], "extra_bodi": [20, 23, 24, 27, 29, 37, 43], "extra_buff": [21, 41], "extract": [4, 34, 47, 84, 87], "extrem": [10, 12, 17, 25, 47], "f": [7, 12, 16, 20, 22, 23, 24, 25, 26, 30, 33, 34, 37, 38, 39, 42, 43, 44, 51, 53, 54, 55, 58, 67, 69, 70, 76, 82, 85, 87], "f1": 48, "f5": 48, "f7ff": 69, "f_": 22, "f_1": 22, "f_k": 22, "fa": 60, "fa3": [1, 3, 9, 12, 20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 37, 38, 42, 44, 67], "fa4": [1, 21], "fabdb6a30b49f79a7aba0f2ad9df9b399473380f": 48, "face": [16, 21, 37, 52, 62, 81, 87], "facilit": [27, 58, 74, 80], "fact": [12, 22, 24], "facto": 74, "factor": [16, 19, 21, 22, 34, 45, 64], "factori": [19, 21, 74], "factory_nam": 7, "factual": [34, 87], "fahrenheit": [23, 24, 25], "fail": [0, 7, 12, 16, 25, 33, 45, 46, 47, 65, 71], "failur": [7, 14, 16, 19, 47, 51], "failurethreshold": 73, "fair": 47, "faith": 37, "fake": [16, 21], "fall": [19, 21, 28, 78, 88], "fallback": [21, 23, 24, 32, 43, 52], "fals": [19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 43, 44, 46, 48, 63, 70, 73, 87], "famili": [1, 19, 20, 28, 37, 42, 60, 79, 80, 81, 84, 85, 86], "familiar": 35, "famou": [22, 34], "far": 43, "fascin": 37, "fashion": [24, 34], "fast": [1, 7, 10, 21, 31, 35, 47, 52, 81], "fastapi_root_path": [20, 23, 24, 25, 26, 33, 34], "faster": [10, 12, 22, 47, 51, 60, 74, 79, 80, 81, 84], "fastest": 22, "fat": 67, "fatal": 7, "fault": 14, "favor": [11, 37], "favorit": 34, "fcf": [14, 20, 21, 23, 24, 25, 26, 33, 34], "fe36": 69, "fe64": 69, "fe6e": 69, "fe73": 69, "fe80": 69, "feasibl": 21, "featur": [0, 1, 2, 3, 4, 6, 7, 9, 12, 15, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 39, 41, 42, 43, 46, 47, 68, 69, 74, 76, 79, 84, 87], "feed": [19, 87], "feedback": [9, 34], "feel": [24, 33, 34, 37, 47, 54, 58], "fetch": [10, 23, 24, 25, 45, 46], "few": [47, 53], "few_shot_gsm8k": [47, 55], "fewer": [15, 58], "ffn": 21, "fi": 71, "fibrou": 67, "fiction": [34, 87], "field": [12, 21, 23, 24, 33, 34, 45, 87], "fieldpath": [70, 73], "fieldref": [70, 73], "fifo": [12, 19, 21], "figur": [24, 48], "file": [0, 2, 10, 13, 17, 19, 26, 30, 33, 42, 43, 45, 47, 58, 60, 61, 62, 64, 69, 78, 84, 87], "file_storage_path": [20, 23, 24, 25, 26, 33, 34], "filenam": 21, "fill": [1, 67], "fillmor": 65, "filter": 25, "final": [20, 22, 24, 25, 64, 87], "final_hidden_st": 6, "final_respons": 25, "financi": 34, "find": [0, 20, 21, 22, 23, 24, 25, 28, 37, 43, 47, 51, 60, 64, 67, 69, 75, 76, 87], "fine": [6, 10, 14, 25, 28, 30, 42, 46, 74, 81, 84], "finer": 76, "finetun": 25, "finish": [27, 46], "finish_reason": [22, 23, 24, 25, 27, 33, 37, 39, 44, 70, 73], "fire": [33, 53, 58, 69], "firewal": [35, 60], "firm": 31, "firmwar": 54, "first": [0, 1, 2, 7, 9, 10, 11, 12, 15, 16, 19, 20, 21, 22, 24, 26, 27, 33, 34, 37, 38, 39, 45, 46, 47, 48, 51, 58, 60, 63, 71, 75, 76, 82, 87], "first_answ": 67, "firstli": 46, "fit": [10, 15, 28, 51, 67, 84], "five": [34, 47], "fix": [0, 1, 15, 47, 51, 60], "fla": 21, "flag": [2, 3, 6, 9, 19, 21, 24, 27, 28, 29, 43, 45, 46, 48, 58, 63, 76, 80, 84], "flagship": 58, "flaki": 47, "flap": 19, "flash": [21, 30, 42, 63, 79], "flash_attn": 28, "flash_attn_with_kvcach": 28, "flash_mla": 28, "flash_mla_sparse_fwd": 28, "flash_mla_with_kvcach": 28, "flashattent": [1, 3, 28, 60], "flashattention3": 27, "flashattention_backend": 1, "flashinf": [1, 3, 6, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 39, 51, 59, 63, 67], "flashinfer_cutedsl": [6, 21, 63], "flashinfer_cutlass": [6, 21, 63], "flashinfer_mla_disable_rag": [20, 23, 24, 25, 26, 33, 34], "flashinfer_mxfp4": [6, 21], "flashinfer_mxfp4_moe_precis": [20, 23, 24, 25, 26, 33, 34], "flashinfer_trtllm": [1, 6, 21, 63], "flashmla": [1, 21, 27], "flashmla_auto": 28, "flashmla_decod": 21, "flashmla_kv": [21, 28], "flashmla_prefil": 21, "flashmla_spars": [20, 21, 23, 24, 25, 26, 28, 33, 34], "flatten": 26, "fleet": 19, "flex_attent": [1, 21], "flexattent": 1, "flexibl": [6, 12, 44, 52, 60, 80, 85], "flexibli": 27, "flight": [19, 45], "flm": 81, "float": [3, 17, 19, 21, 37, 43, 80], "float16": [21, 22, 33, 38], "float32": [20, 21, 22, 23, 24, 25, 26, 33, 34, 38, 41], "float8_e4m3fn": 17, "flourish": 37, "flow": [6, 52, 76], "fluctuat": 24, "fluenci": 37, "fluent": 34, "flush": [19, 34, 35, 43, 44, 45, 67], "flush_cach": [19, 33, 45], "fly": [16, 17], "fn_name": 7, "fnmatch": 7, "focal": 31, "focu": 67, "focus": [6, 34, 37], "folder": [0, 13, 21, 46, 48, 50, 58, 73, 75, 77], "follow": [0, 1, 3, 7, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 27, 28, 30, 33, 34, 37, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 58, 59, 60, 64, 67, 68, 69, 70, 71, 75, 76, 78, 81, 82, 84, 87, 88], "foo": [23, 24], "food": 67, "fool": 31, "footprint": [1, 17], "forc": [14, 43, 51, 58, 63], "forev": 50, "forget": [22, 34], "fork": [46, 67], "form": [5, 7, 24, 25, 43, 46, 61], "format": [2, 4, 6, 7, 12, 16, 18, 21, 23, 24, 27, 33, 43, 46, 58, 60, 70, 75, 76, 84], "formerli": [52, 68], "forum": 37, "forward": [1, 6, 7, 19, 47, 63, 87, 88], "forward_batch": 87, "forward_batch_info": 87, "forward_decod": [1, 87], "forward_extend": [1, 87], "forward_hook": [7, 20, 23, 24, 25, 26, 33, 34], "forwardbatch": 87, "found": [3, 10, 12, 14, 17, 21, 33, 34, 55, 56, 59, 69], "foundat": 81, "four": [27, 34, 76], "fp": 84, "fp16": [21, 71], "fp32": 21, "fp4": [1, 6, 16, 21, 52], "fp4_e2m1": 17, "fp8": [1, 6, 11, 16, 21, 28, 29, 52, 58, 63, 71], "fp8_dynam": 16, "fp8_e4m3": [1, 17, 21, 28], "fp8_e5m2": [17, 21], "fp8_gemm_runner_backend": [20, 23, 24, 25, 26, 33, 34], "fp8_kernel": 16, "fp8dq": [16, 21], "fp8wo": [16, 21], "fr": 22, "frac": 46, "fraction": [9, 14, 21, 22, 27, 28, 29, 30, 32, 42, 55, 56, 59, 60, 64, 69, 70, 73], "fragment": [25, 27], "frame": 84, "framework": [10, 47, 52, 73, 74, 82, 85], "franc": [12, 16, 22, 23, 24, 25, 27, 29, 33, 34, 37, 43, 44, 65, 67, 80, 82, 87], "francisco": [23, 24, 25], "franklin": 59, "fran\u00e7ais": 22, "fraud": 34, "free": [24, 37, 47, 54, 58], "freeli": 76, "french": 34, "freq_32768": 22, "frequenc": [10, 30, 42, 43, 63], "frequency_penalti": [37, 43], "frequent": [10, 11, 12, 14, 21, 52], "fridai": 31, "friendli": [22, 34, 74], "from": [0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 34, 37, 38, 39, 43, 44, 45, 46, 52, 55, 59, 62, 63, 64, 67, 73, 74, 75, 76, 78, 79, 81, 82, 84, 85, 86, 88], "from_pretrain": [16, 20, 23, 24, 25, 26, 33, 38], "front": 4, "frontend": [52, 62], "frontier": 74, "frozen": 21, "fruit": 67, "full": [5, 6, 9, 11, 12, 19, 21, 27, 33, 41, 46, 69, 74, 80, 81, 84], "full_argu": 25, "full_siz": 21, "fulli": [0, 3, 5, 10, 16, 19, 25, 26, 27, 28, 34, 37, 47, 53, 70, 73, 74, 81], "func_latency_second": 75, "func_latency_seconds_bucket": 75, "func_latency_seconds_count": 75, "func_latency_seconds_sum": 75, "func_name1": 25, "func_name2": 25, "function": [0, 1, 6, 7, 10, 15, 21, 22, 23, 24, 37, 47, 60, 65, 67, 74, 75, 87], "function_cal": [22, 25, 37, 44], "function_call_input": 25, "function_call_pars": 25, "function_call_respons": 25, "function_call_response_json": 25, "function_dict": 25, "function_nam": [23, 24], "functioncallpars": 25, "functool": [22, 87], "fundament": 9, "further": [5, 10, 22, 24, 33, 34, 51, 67, 76], "furthermor": 22, "fuse": [6, 16, 17, 63], "fused_moe_triton": [33, 70], "fusedmo": 6, "fusion": [16, 21, 55, 63], "futur": [10, 16, 20, 21, 33, 34, 47, 54, 63, 67, 70, 82, 87], "g": [0, 1, 3, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 23, 24, 25, 27, 30, 31, 33, 42, 45, 46, 47, 48, 50, 51, 58, 61, 75, 81, 84, 87], "gain": [4, 6, 10, 26, 81], "galaxi": 37, "garbag": 21, "gate": [16, 47], "gate_proj": [12, 21], "gate_up_proj": 21, "gatewai": [52, 78], "gather": [6, 21, 84], "gaudi": 16, "gaug": [19, 75], "gb": [9, 11, 12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 39, 44, 60, 67, 69], "gb200": [27, 32, 52], "gc": [21, 60], "gc_warning_threshold_sec": [20, 23, 24, 25, 26, 33, 34], "gcc": 58, "gcp": 60, "gd": 10, "gemm": [6, 12, 63], "gemma": [52, 60, 81, 84, 86], "gemma2forsequenceclassif": [78, 86], "gemma3": 39, "gen": [11, 58, 65, 67, 81], "gen_data": [20, 25], "gen_respons": [20, 25], "gen_second": 28, "gen_throughput": 75, "gen_url": [20, 25], "gener": [4, 5, 6, 10, 12, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 31, 32, 35, 37, 45, 46, 52, 58, 60, 69, 74, 75, 76, 77, 78, 79, 81, 82, 84, 87], "generate_request": 75, "generate_stream": 45, "generated_text": [20, 25, 45], "generatereqinput": 43, "generation_config": [21, 43], "generation_tokens_bucket": [20, 23, 24, 25, 26, 33, 34], "generation_tokens_tot": 75, "generative_model": 87, "geographi": [23, 24], "germani": [22, 23, 24, 37, 67], "get": [0, 7, 9, 19, 21, 22, 23, 24, 25, 26, 27, 34, 35, 38, 41, 45, 46, 47, 51, 58, 61, 67, 69, 70, 73, 80, 87], "get_current_d": [23, 24], "get_current_weath": [23, 24, 25], "get_embed": 87, "get_image_featur": 87, "get_load": 19, "get_max_total_num_token": 33, "get_memory_pool_s": 33, "get_messag": [23, 24, 25], "get_model_info": [19, 21, 33, 67, 69], "get_model_load": 16, "get_prompt": 26, "get_server_arg": 33, "get_server_info": [19, 33, 45], "get_start": 0, "get_tourist_attract": 25, "get_weath": 25, "getattr": 7, "gf_auth_anonymous_en": 75, "gf_server_http_port": 75, "ggml": [23, 43], "gguf": [16, 21, 88], "giant": [33, 85], "gibberish": 45, "gid": 69, "gigabyt": [10, 21], "git": [14, 28, 47, 50, 51, 53, 54, 58, 59, 60, 61, 82], "github": [9, 14, 26, 28, 30, 33, 39, 42, 43, 47, 51, 53, 54, 58, 59, 60, 61, 64, 67, 73, 76, 81, 82, 84], "githubusercont": 39, "give": [12, 20, 23, 24, 25, 50, 67, 87], "given": [7, 10, 22, 23, 24, 25, 27, 28, 33, 43], "glass": 26, "glm": [4, 21, 25, 52, 74, 81, 84], "glm4": 19, "glm45": [21, 29, 30], "glm47": [21, 29], "glm4moethinkingbudgetlogitprocessor": [29, 30], "glob": [7, 21], "global": [10, 22, 23, 24, 34, 76], "glog_v": 82, "gloo": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "gloo_socket_ifnam": [69, 73], "gme": 80, "gnu": 58, "gnupg": 46, "go": [24, 31, 37, 53, 54, 75], "goal": [34, 67, 87], "good": [11, 24, 27, 34, 47, 53, 67], "googl": [52, 60, 67, 74, 81, 84], "got": [22, 24], "govern": [24, 34, 37], "gpqa_diamond": 17, "gpt": [17, 19, 20, 21, 25, 37, 52, 81], "gptq": [16, 21, 52], "gptq_marlin": [16, 21], "gpu": [3, 4, 6, 9, 10, 11, 14, 16, 17, 18, 21, 22, 26, 27, 28, 29, 30, 32, 33, 35, 41, 42, 46, 47, 48, 50, 51, 52, 61, 63, 69, 70, 71, 72, 73, 74, 83, 84], "gpu_id_step": [20, 23, 24, 25, 26, 33, 34], "grade": [16, 51, 74], "gradual": [34, 60], "grafana": 75, "grain": [6, 10, 14, 28, 46, 67, 74, 76, 84], "grammar": [23, 24, 25, 43, 71], "grammar_backend": [20, 23, 24, 25, 26, 33, 34], "grand": 37, "granit": 81, "grant": 19, "granular": [10, 46], "graph": [1, 2, 3, 6, 12, 16, 21, 22, 27, 33, 46, 48, 55, 64, 69, 70, 73], "graphic": 61, "gre": 71, "great": [34, 78, 79], "greater": [2, 10, 12, 14, 15, 21, 22, 34], "greedi": 43, "greedy_token_select": 65, "greenctx": 21, "greet": 43, "grep": [69, 70, 73], "grok": [60, 81], "group": [1, 3, 6, 10, 18, 21, 27, 34, 45, 50, 53, 59, 63], "group_m": 22, "group_siz": [16, 21], "grouped_gemm": 6, "grow": [34, 43], "growth": 19, "grpc": 76, "grpc_mode": [20, 23, 24, 25, 26, 33, 34], "grpo": [3, 74], "grub_cmdline_linux": 53, "gryffindor": 67, "gserver": 45, "gsm8k": [17, 47, 48, 87], "gsp": 45, "gt": [24, 26, 67], "gte": [33, 38, 52, 80], "guarante": [10, 23, 43], "guard": 16, "gui": 46, "guid": [9, 14, 16, 21, 23, 25, 27, 43, 44, 46, 51, 53, 54, 60, 69, 82, 86], "guidanc": [22, 58, 60, 64, 74, 87], "guidelin": [47, 87], "gz": [16, 46, 48], "h": [19, 27, 28, 38, 39, 44, 46, 58, 61, 70, 73, 78, 79], "h100": [1, 22, 27, 30, 32, 42, 51, 52, 72], "h20": [1, 2, 27, 69], "h200": [1, 28, 29, 30, 32, 41, 42, 72], "ha": [1, 7, 10, 11, 12, 15, 16, 17, 21, 24, 25, 27, 28, 29, 31, 32, 33, 34, 41, 46, 47, 58, 69, 73, 74, 76, 81, 88], "had": [15, 37], "hadn": 46, "half": [21, 59, 67], "halt": 12, "hammurabi": 37, "hand": [4, 11], "handl": [6, 7, 9, 14, 17, 20, 21, 26, 27, 33, 43, 44, 46, 60, 69, 70, 80, 84, 87], "handler": 47, "hang": [21, 26], "happen": [11, 16, 21, 30, 42, 84, 88], "happi": [47, 74], "hard": [9, 69], "hardwar": [1, 6, 12, 16, 21, 28, 32, 47, 53, 54], "harm": 48, "harri": 67, "has_audio_understand": 33, "has_image_understand": 33, "hash": [63, 87], "hasn": 69, "hat": 81, "have": [12, 14, 16, 20, 21, 22, 23, 24, 27, 31, 33, 34, 37, 39, 46, 47, 53, 54, 58, 60, 61, 63, 65, 69, 70, 74, 76, 79, 81, 84, 87], "hbm": 60, "hccl_buffsiz": [55, 56], "hccl_op_expansion_mod": 56, "he": 37, "head": [1, 10, 21, 28, 30, 35, 42, 46, 55, 70, 71, 73, 84, 87], "head_nod": 71, "header": [19, 21, 76, 78], "headlin": 31, "health": [14, 19, 35, 60, 63, 67, 73], "health_gener": 33, "healthcar": 34, "healthi": [11, 19, 67], "heard": 24, "heart": 67, "heartbeat": 14, "heavi": [5, 21], "heavili": 25, "hei": 43, "heightxwidth": 45, "helfpul": 31, "hello": [16, 25, 34, 35, 43, 82, 87], "helm": 70, "help": [0, 10, 11, 21, 23, 24, 25, 26, 31, 34, 37, 43, 45, 46, 47, 51, 53, 60, 64, 67, 70, 73, 74, 75, 84], "here": [9, 10, 11, 12, 16, 22, 23, 24, 25, 26, 27, 33, 34, 37, 43, 44, 47, 51, 53, 54, 55, 56, 67, 69, 70, 74, 75, 88], "heritag": 34, "heterogen": 19, "heurist": [11, 28], "hf": [16, 19, 22, 33, 45, 62, 79, 81, 84, 86, 87], "hf3f": [10, 21], "hf_home": [33, 50], "hf_token": [50, 51, 53, 54, 58, 87], "hf_xxx": 50, "hi": [33, 37, 43, 71, 85], "hicach": [21, 52], "hicache_io_backend": [20, 23, 24, 25, 26, 33, 34], "hicache_mem_layout": [20, 23, 24, 25, 26, 33, 34], "hicache_ratio": [10, 20, 21, 23, 24, 25, 26, 33, 34], "hicache_s": [10, 20, 23, 24, 25, 26, 33, 34], "hicache_storage_backend": [20, 23, 24, 25, 26, 33, 34], "hicache_storage_backend_extra_config": [10, 20, 23, 24, 25, 26, 33, 34], "hicache_storage_prefetch_polici": [20, 23, 24, 25, 26, 33, 34], "hicache_write_polici": [20, 23, 24, 25, 26, 33, 34], "hicachefil": 10, "hicachestorag": 10, "hidden": [7, 21, 22, 34, 43], "hidden_st": [87, 88], "hide": [6, 10], "hierarch": [9, 10, 52], "hierarchi": [10, 46, 76], "high": [6, 10, 12, 16, 19, 21, 22, 24, 25, 26, 27, 30, 31, 35, 42, 43, 52, 59, 65, 67, 74, 80, 81, 82, 84, 85], "higher": [1, 6, 9, 10, 11, 17, 21, 22, 31, 37, 43, 54, 60, 79, 84], "highest": [19, 43, 65], "highest_token_prob": 43, "highli": [5, 6, 43], "highlight": [12, 20, 23, 24, 25, 33, 37, 38, 39, 44, 67], "hiit": 67, "hilab": 84, "him": 37, "hint": 6, "hisi_hdc": 54, "histogram": [19, 21, 75], "histor": [22, 34, 63], "histori": [22, 24, 25, 34], "historian": 37, "hit": [9, 10, 11, 19, 43, 69, 75], "hmm": [24, 37], "hobbi": 34, "hold": 10, "holist": 84, "home": [34, 48, 53, 58, 70], "hood": 64, "hook": 6, "hook_cal": 7, "hook_factori": 21, "hook_factory_path": 7, "hook_spec": 7, "hope": 24, "hopper": [1, 6, 16, 21, 27, 28, 32, 63], "horizont": 5, "host": [2, 9, 10, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 51, 53, 54, 55, 58, 59, 60, 61, 63, 67, 69, 70, 73, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "hostipc": [69, 70, 73], "hostnam": [21, 71], "hostnetwork": [69, 70, 73], "hostpath": [69, 70, 73], "hot": [10, 19], "hottest": 10, "hour": 27, "hous": [34, 67], "how": [0, 1, 10, 11, 15, 16, 21, 22, 24, 26, 27, 33, 34, 37, 45, 46, 52, 53, 58, 61, 65, 71, 75, 84], "howev": [4, 5, 10, 11, 12, 22, 25, 34, 41, 64, 69, 74, 76, 87, 88], "hpu": [21, 28], "html": [0, 23, 46, 77, 87], "http": [0, 2, 3, 5, 9, 12, 13, 14, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 64, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79, 80, 82, 84, 85, 87], "http_server": [33, 78, 87], "http_worker_ipc": 12, "httpget": 73, "hub": [21, 22, 33, 51, 53, 88], "hufflepuff": 67, "hug": [16, 21, 37, 52, 62, 81, 87], "huge": 22, "huggingfac": [16, 19, 21, 26, 33, 43, 48, 50, 51, 53, 58, 80, 81, 83, 84, 85, 86, 87], "huggingface_hub": 87, "huggingfacetb": 81, "human": [7, 34, 79, 86], "humil": 34, "humor": [26, 67], "hundr": 58, "hybrid": [4, 6, 20, 21, 32, 37, 41, 81, 84], "hybrid_attn_backend": 1, "hybrid_kvcache_ratio": [20, 23, 24, 25, 26, 33, 34], "hydrat": 67, "hyperparamet": [21, 52], "i": [0, 1, 2, 3, 4, 6, 7, 9, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88], "ib": [9, 14, 21, 69, 70, 73], "ibdev2netdev": 69, "ibm": 81, "ibstatu": 69, "ibv_devic": 69, "ibv_devinfo": 69, "icon": [22, 26, 34, 39], "id": [14, 19, 20, 21, 22, 23, 24, 25, 27, 33, 39, 43, 44, 45, 46, 70, 73, 78], "id2label": 78, "idea": [10, 34, 47], "ideal": [9, 19, 85], "ident": [3, 10, 15, 53], "identif": 46, "identifi": [2, 9, 20, 21, 24, 33, 34, 46, 58, 61, 78, 81, 84, 85, 86], "idl": [6, 10, 21, 27], "ignor": [16, 21, 22, 28, 45, 60], "ignore_eo": 43, "igw": 19, "ii": 27, "illustr": 58, "im_end": [26, 43, 62, 67], "im_start": [26, 43, 62, 67], "imag": [5, 21, 33, 43, 45, 48, 51, 52, 53, 54, 58, 59, 67, 69, 75, 80, 81, 84, 87], "image_byt": 67, "image_data": [26, 43], "image_featur": 26, "image_fil": 67, "image_grid_thw": 26, "image_id": 51, "image_nam": [54, 59], "image_output": 26, "image_pad": 26, "image_path": 80, "image_qa": 67, "image_tag": 51, "image_token": 26, "image_uri": 51, "image_url": [30, 39, 42, 67], "imagedataitem": 43, "imbal": [6, 14, 19, 63], "imit": 87, "immedi": [10, 24, 45, 46, 47], "immun": 67, "impact": [10, 34, 46, 84], "impl": [21, 82, 88], "implement": [1, 7, 9, 10, 17, 19, 20, 21, 22, 25, 27, 28, 29, 30, 37, 45, 54, 60, 63, 64, 65, 70, 76, 81, 82, 84, 88], "impli": 31, "import": [0, 3, 7, 11, 12, 16, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 37, 38, 39, 43, 44, 55, 60, 67, 78, 79, 80, 82, 84, 85, 87, 88], "import_model_class": 87, "import_modul": 7, "import_new_model_class": 87, "importlib": 7, "impos": 76, "impress": 37, "improv": [3, 5, 6, 9, 10, 12, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 37, 38, 39, 41, 42, 44, 60, 67, 81, 84, 85], "inaccur": 46, "inc": 81, "includ": [5, 6, 10, 12, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 33, 34, 37, 45, 46, 52, 58, 60, 64, 67, 75, 78, 80, 81, 87], "inclus": 46, "inclusionai": [79, 81], "incom": [10, 14, 21], "incompat": 1, "inconsist": [10, 25, 45], "incorpor": [12, 22, 39, 67, 73, 81, 85], "incorrect": [22, 65], "increas": [2, 6, 10, 14, 19, 21, 22, 25, 27, 28, 29, 34, 37, 41, 60, 67, 81, 84], "increasingli": 34, "increment": [10, 11, 63], "incur": [4, 65], "inde": 33, "indent": 78, "independ": [5, 19, 27, 82], "indetermin": 64, "index": [0, 22, 25, 27, 28, 33, 37, 38, 39, 44, 46, 54, 58, 61, 70, 73, 78], "indic": [1, 11, 14, 17, 63, 69], "individu": [46, 87], "indoor": 39, "inductor_root_cach": 77, "industri": [19, 32, 34, 52, 74], "ineffici": [5, 14, 46], "inf": [43, 45, 58, 61, 75], "infer": [2, 5, 6, 10, 12, 14, 16, 19, 26, 27, 28, 30, 35, 41, 42, 45, 47, 51, 52, 53, 58, 60, 61, 64, 69, 73, 74, 81, 84, 87], "inference_mod": 63, "infiniband": [21, 69, 70, 73], "infinit": [21, 45], "info": [7, 9, 12, 20, 21, 22, 23, 24, 25, 26, 30, 34, 37, 38, 39, 42, 44, 54, 67, 69, 71, 82], "inform": [14, 23, 24, 25, 28, 31, 33, 34, 35, 37, 43, 46, 51, 58, 60, 67, 78, 88], "infra": [51, 60], "infrastructur": [47, 74], "ing": 27, "inher": 10, "inherit": [1, 19, 25, 87], "init": [2, 14, 19, 21, 28, 33, 55, 60, 69, 70, 71, 73, 82], "init_cuda_graph_st": 1, "init_expert_loc": [20, 23, 24, 25, 26, 33, 34], "init_forward_metadata": 1, "init_forward_metadata_capture_cuda_graph": 1, "init_forward_metadata_replay_cuda_graph": 1, "initi": [1, 2, 5, 7, 10, 12, 14, 15, 19, 20, 21, 22, 33, 37, 38, 39, 43, 58, 64, 65, 67, 71, 76, 82], "initialdelaysecond": [69, 73], "inject": 21, "inner": [7, 17], "innov": 27, "input": [3, 5, 6, 7, 10, 12, 14, 15, 20, 21, 22, 25, 28, 31, 33, 43, 45, 46, 47, 48, 51, 52, 53, 58, 60, 61, 64, 75, 78, 80, 81, 87], "input_emb": [21, 43, 87], "input_hidden_st": 6, "input_id": [21, 25, 26, 38, 43, 87], "input_ids_embed": 38, "input_len": 45, "input_seq_len": 60, "input_text": 33, "insert": [34, 58, 76], "insid": [19, 46, 48, 50], "inspect": [11, 19, 46], "inspir": 10, "inst": 84, "instal": [14, 19, 21, 31, 35, 44, 45, 46, 48, 49, 50, 52, 57, 63, 69, 70, 73, 75, 76], "installationguid": 46, "instanc": [9, 10, 14, 16, 18, 19, 21, 37, 43, 46, 58, 60, 65, 75], "instant": 19, "instanti": 19, "instantli": 46, "instead": [7, 10, 12, 17, 21, 22, 25, 26, 31, 33, 43, 45, 47, 63, 64, 67, 75, 78, 87], "instinct": 53, "institut": 34, "instruct": [0, 1, 3, 4, 5, 9, 12, 14, 16, 19, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 53, 54, 58, 59, 61, 67, 69, 71, 75, 77, 80, 81, 83, 84, 87, 88], "instruct_lora_4_alpha_16": 12, "instrument": 76, "int": [14, 19, 21, 23, 24, 43], "int4": [16, 52, 59, 63], "int4_awq": 21, "int4wo": [16, 21, 59], "int8": [16, 21, 27, 58], "int8_kernel": 16, "int8dq": [16, 21], "int8wo": [16, 21], "intak": 67, "integ": [21, 23, 24, 43, 45, 78], "integr": [5, 6, 16, 19, 26, 31, 34, 47, 52, 63, 69, 80, 81, 84, 87], "integratedtermin": 48, "intel": [1, 16, 32, 51, 52, 58, 61], "intel_amx": 21, "intel_xpu": [1, 32, 61], "intellig": [9, 34, 35, 84, 87], "intens": [5, 14, 67], "intention": 12, "inter": [18, 21, 45, 60], "interact": [0, 21, 34, 35, 46, 52], "interchang": 24, "interconnect": 4, "interest": [34, 47, 70, 74], "interfac": [6, 52, 75, 78, 80, 85, 87], "interface_v1": 9, "interleav": [6, 39], "intermedi": [7, 21], "intern": [7, 37, 46, 48, 69, 75, 78, 87], "internal_st": 33, "internlm": [81, 86], "internlm2": [81, 86], "internlm2forrewardmod": 86, "internlm2forrewardmodel": 78, "internvl": 4, "interpret": [20, 25, 31], "interrupt": 14, "interv": [14, 19, 21, 47, 63, 67], "intervent": 6, "intervitensinc": 58, "intfloat": 80, "introduc": [5, 6, 10, 11, 12, 14, 15, 17, 21, 27, 33, 47, 61, 64, 69], "introduct": [34, 47, 79, 87], "introductori": 87, "intuit": [34, 52], "invalid": [7, 24, 28, 78], "invari": [3, 21], "investig": 64, "invoc": 28, "invok": [7, 16, 25], "involv": [4, 10, 27, 34, 67, 76, 87], "io": [0, 9, 10, 21, 26, 68, 69, 70, 73, 87], "io_struct": [25, 43], "iommu": 53, "ip": [2, 18, 21, 31, 63, 67, 71, 75], "ipc": [30, 42, 48, 51, 53, 54, 58, 83], "ipc_lock": [70, 73], "ipynb": [0, 12], "ipython": 34, "ireland": [23, 24], "iron": [26, 39, 67], "is_embed": [20, 23, 24, 25, 26, 33, 34], "is_gener": 33, "is_matryoshka": 80, "is_multimodal_model": 87, "isl": 60, "isn": 69, "isol": [16, 69], "issu": [3, 9, 10, 12, 15, 16, 17, 21, 24, 27, 28, 32, 47, 51, 53, 54, 58, 61, 64, 67, 75, 76], "itali": [23, 24, 37, 67], "itd": 48, "item": [7, 19, 26, 33, 47, 85], "item1": 21, "item2": 21, "item_id": 19, "iter": [2, 21, 33, 46], "iter_lin": [43, 44], "itl": 45, "its": [6, 10, 15, 21, 23, 24, 31, 33, 34, 37, 43, 46, 47, 63, 65, 76, 80, 81, 87], "j": 71, "j_master": 71, "j_node": 71, "jaeger": 76, "jamesliu1": 22, "janu": 84, "japan": [12, 22, 37, 67], "japanes": 81, "jason9693": [78, 86], "jax": [21, 60, 74], "jax_compilation_cache_dir": 60, "jean": 67, "jet": [81, 84], "jetpack": 59, "jetson": [51, 52], "jetvlm": 84, "jinja": [25, 27, 28], "jit": [6, 21, 60, 63], "jit_cach": 60, "jitter": 19, "job": [19, 34, 47, 71], "jobs_presenting_ipod": [30, 42, 84], "johnni": 59, "join": [7, 9, 25, 52, 60], "jointli": 81, "joke": 3, "journei": 37, "jpeg": 45, "jpg": 80, "jq": 19, "json": [3, 7, 9, 10, 12, 16, 17, 19, 20, 21, 22, 25, 27, 30, 33, 38, 39, 42, 44, 45, 46, 47, 48, 67, 70, 73, 75, 76, 78, 79, 80, 84, 85, 87], "json_data": 12, "json_model_override_arg": [20, 23, 24, 25, 26, 33, 34], "json_output": 67, "json_schema": [23, 24, 43], "judg": 35, "judgment": 10, "jul": 23, "jump": [20, 31], "jupyt": 0, "just": [10, 11, 12, 21, 22, 24, 50, 60, 62, 63, 79, 87, 88], "justmycod": 48, "k": [22, 24, 33, 43, 58], "k2": [19, 25, 72], "k8": [51, 69, 73], "k_cach": 28, "k_proj": [12, 21], "k_scale": 17, "keep": [0, 4, 19, 21, 22, 24, 30, 31, 37, 42, 47, 48, 71, 84, 87], "keep_mm_feature_on_devic": [20, 23, 24, 25, 26, 33, 34], "kei": [1, 5, 6, 7, 10, 14, 17, 19, 21, 22, 23, 24, 26, 27, 31, 33, 34, 37, 43, 46, 53, 60, 67, 70, 73, 84, 87], "kept": 31, "kernel": [1, 3, 6, 9, 10, 12, 16, 17, 20, 23, 24, 25, 26, 27, 28, 33, 34, 46, 51, 53, 58, 60, 63, 64, 74], "kernel_ascend": 21, "key_stat": 88, "keyword": 87, "kfd": [50, 53], "kill": 46, "kimi": [19, 20, 21, 25, 37, 52, 72, 84], "kimi_k2": [21, 25], "kind": [34, 69, 70, 73], "kingdom": [37, 67], "kit": 59, "kl": 74, "know": [24, 35, 37, 87], "knowledg": [22, 23, 24, 37], "known": [16, 22, 24, 34, 37, 81], "korean": 81, "kt_cpuinfer": [20, 23, 24, 25, 26, 33, 34], "kt_max_deferred_experts_per_token": [20, 23, 24, 25, 26, 33, 34], "kt_method": [20, 23, 24, 25, 26, 33, 34], "kt_num_gpu_expert": [20, 23, 24, 25, 26, 33, 34], "kt_threadpool_count": [20, 23, 24, 25, 26, 33, 34], "kt_weight_path": [20, 23, 24, 25, 26, 33, 34], "kubectl": [51, 69, 70, 73], "kubernet": [10, 21, 72], "kv": [1, 5, 9, 10, 14, 21, 27, 28, 29, 32, 33, 41, 46, 52, 54, 60, 63, 64], "kv16": 17, "kv4": [1, 17], "kv8": 17, "kv_cach": 17, "kv_cache_dtyp": [20, 23, 24, 25, 26, 28, 33, 34], "kv_events_config": [20, 23, 24, 25, 26, 33, 34], "kvcach": [9, 10, 14, 21, 32, 33, 45], "kwarg": 88, "l": [24, 35, 43, 71], "l1": 10, "l12": 31, "l15": 31, "l2": 10, "l27": 31, "l2a": 33, "l31": 31, "l34": 31, "l38": 31, "l4": 51, "l40": [27, 51], "l53": 31, "l57": 31, "lab": [3, 43, 74, 82, 84], "label": [19, 20, 21, 23, 24, 25, 26, 33, 34, 46, 47, 50, 69, 70, 73, 75, 76, 78], "label1": 21, "label2": 21, "label_0": 78, "label_1": 78, "lack": [16, 45], "landmark": [22, 24, 34], "lang": 67, "languag": [4, 5, 10, 14, 21, 34, 37, 39, 42, 44, 51, 52, 58, 60, 62, 74, 88], "language_onli": [20, 23, 24, 25, 26, 33, 34], "larg": [1, 2, 6, 10, 11, 14, 15, 17, 19, 21, 24, 27, 30, 42, 45, 46, 51, 52, 58, 60, 72, 74, 80, 84, 85], "larger": [10, 11, 12, 14, 15, 17, 21, 26, 27, 28, 43, 58, 60, 61, 81, 84], "largest": [24, 34, 44, 81], "last": [7, 20, 21, 22, 50, 51, 53, 54, 76, 78], "last_gen_throughput": 33, "last_hidden_st": 26, "lastli": 87, "late": 31, "latenc": [6, 10, 12, 14, 19, 21, 27, 28, 30, 42, 45, 46, 47, 52, 75, 80, 84, 85], "latent": [1, 21], "later": [7, 11, 13, 25, 50, 59, 65], "latest": [15, 23, 24, 28, 31, 32, 42, 51, 54, 58, 60, 68, 69, 73, 74, 75, 80, 81, 83], "latter": 10, "launch": [0, 2, 5, 6, 9, 13, 16, 17, 23, 24, 31, 34, 40, 43, 46, 47, 48, 51, 53, 59, 62, 63, 71, 75, 76, 77, 82, 83, 87], "launch_rout": [5, 14, 19, 28, 46, 55, 70, 73, 76], "launch_serv": [1, 2, 3, 4, 5, 6, 9, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 67, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "launch_server_cmd": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "launder": 34, "laundri": 26, "law": [27, 37], "layer": [1, 4, 6, 7, 9, 10, 12, 16, 17, 19, 21, 22, 27, 33, 47, 63, 64, 70, 73, 87], "layer_first": [9, 10, 20, 21, 23, 24, 25, 26, 33, 34], "layer_id": 87, "layerwis": 21, "layerwise_profil": 46, "layout": [4, 6, 10, 21, 60], "lb": 76, "lccl": 82, "ld_library_path": [19, 58], "ld_preload": 58, "le": 75, "lead": [3, 5, 10, 12, 14, 15, 16, 22, 32, 34, 43, 45, 64, 74], "leader": [33, 69, 70, 73], "leadercr": 70, "leadertempl": [69, 70], "leaderworkerset": [69, 70, 73], "leaderworkertempl": [69, 70], "leaf": 10, "leak": 19, "lean": 67, "leap": 37, "learn": [0, 1, 3, 18, 21, 24, 34, 37, 52, 53, 74, 80, 81, 84, 86, 87], "least": [1, 12, 21, 25, 43, 67, 69], "leav": [43, 54], "left": 48, "legaci": 19, "legal": 37, "len": [7, 43, 44, 45, 46, 58, 60, 61], "length": [3, 10, 12, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 30, 32, 33, 37, 38, 39, 42, 43, 44, 45, 46, 55, 59, 63, 67, 70, 73], "less": [11, 14, 45, 46, 74], "let": [7, 20, 21, 22, 24, 25, 34, 37, 67, 87], "letter": [23, 24, 25, 37, 39], "level": [1, 4, 9, 10, 12, 13, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 37, 38, 39, 42, 43, 44, 46, 53, 63, 67, 76, 81, 82], "leverag": [6, 10, 18, 33, 53, 74, 81, 88], "lfu": 21, "lg": 81, "lgai": 81, "li": 76, "lib": [22, 58, 61], "lib64": 58, "libiomp5": 58, "librari": [6, 21, 27, 28, 58, 74, 87], "libtbbmalloc": 58, "libtcmalloc": 58, "licens": 81, "lid": 69, "life": 1, "lift": 31, "light": [22, 24, 34], "lighter": 19, "lightn": 28, "lightweight": 4, "like": [1, 2, 3, 6, 7, 10, 11, 16, 20, 22, 24, 25, 26, 27, 30, 33, 34, 37, 41, 46, 47, 58, 63, 67, 69, 75, 79, 80], "likelihood": 37, "lill": 34, "limit": [5, 9, 10, 11, 12, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 37, 38, 39, 42, 44, 45, 46, 59, 63, 64, 65, 67, 69, 70, 73], "limit_mm_data_per_request": [20, 23, 24, 25, 26, 33, 34], "line": [6, 12, 14, 16, 21, 23, 24, 30, 31, 33, 34, 42, 47, 58, 61, 67, 75], "linear": [10, 16, 41], "linearli": 43, "ling": 81, "linguist": 84, "link": [0, 14, 69, 87], "link_lay": 69, "link_up": 69, "linkedin": 68, "linkup": 69, "lint": [0, 47], "linux": [48, 50, 54, 58], "linux64cli": 48, "linux_aarch64": [14, 54], "list": [3, 7, 12, 18, 19, 20, 21, 22, 25, 27, 31, 33, 35, 37, 38, 43, 44, 46, 47, 63, 64, 67, 74, 76, 78, 87], "list_work": 19, "listen": [18, 21], "lite": [81, 84], "liter": 25, "littl": 4, "liuhaotian": [80, 84], "live": [19, 24, 34, 46], "livenessprob": 73, "ll": [20, 24, 25, 33, 37, 46, 69], "llada2": 79, "llada2moemodellm": 79, "llama": [1, 12, 16, 19, 21, 22, 23, 33, 39, 43, 45, 46, 48, 51, 52, 53, 54, 59, 60, 61, 62, 74, 75, 77, 80, 81, 84, 86, 88], "llama2": [22, 84], "llama3": [21, 22, 25, 84], "llama4": [25, 40], "llama4forconditionalgener": 26, "llama_ckpt": 87, "llama_dir": 87, "llama_wrapp": 87, "llamaattent": 87, "llamaconfig": 87, "llamaforcausallm": 87, "llamaforsequenceclassif": [78, 86], "llamaforsequenceclassificationwithnormal_weight": 78, "llamamlp": 87, "llamawrapp": 87, "llava": [39, 43, 80, 84], "llavavid": 84, "llguidanc": [21, 23], "llm": [3, 4, 6, 10, 14, 17, 19, 20, 22, 23, 24, 25, 26, 28, 30, 32, 34, 35, 45, 51, 52, 53, 58, 60, 61, 65, 74, 79, 81, 82, 84, 87], "llmcompressor": 16, "lm": [21, 55, 70, 73], "lm_head": [12, 16, 22, 87], "lmcach": 10, "lmdeploi": 45, "lmhead": 22, "lmm": [43, 84], "lmsy": [22, 25, 64, 68, 71, 74], "lmsysorg": [28, 48, 50, 51, 53, 68, 70, 73, 83], "load": [2, 5, 6, 7, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 43, 44, 45, 46, 58, 62, 67, 70, 74, 75, 88], "load_balance_method": [20, 23, 24, 25, 26, 33, 34], "load_config": 16, "load_dataset": 16, "load_format": [20, 21, 23, 24, 25, 26, 33, 34], "load_imag": [43, 67], "load_lora_adapt": 12, "load_model": 16, "load_watch_interv": [20, 23, 24, 25, 26, 33, 34], "loadconfig": 16, "loaded_adapt": 12, "loader": [16, 18, 87], "local": [0, 19, 21, 22, 31, 32, 33, 35, 37, 38, 39, 45, 47, 48, 51, 54, 58, 60, 67, 79, 81, 82, 84, 86, 87], "local_attention_s": 21, "local_dir": 87, "local_ip": [14, 28], "localhost": [2, 3, 12, 13, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 60, 67, 75, 84], "locat": [0, 10, 19, 21, 23, 24, 25, 34, 43, 44, 46, 48, 58, 70, 73], "lof": 21, "log": [2, 7, 9, 11, 12, 19, 20, 22, 23, 24, 25, 30, 33, 37, 38, 39, 42, 43, 44, 51, 58, 63, 67, 69, 73, 75, 82], "log_level": [20, 23, 24, 25, 26, 33, 34], "log_level_http": [20, 23, 24, 25, 26, 33, 34], "log_request": [20, 23, 24, 25, 26, 33, 34], "log_requests_level": [20, 23, 24, 25, 26, 33, 34], "logger": [7, 21], "logic": [6, 7, 25, 78], "login": [51, 75], "logit": [21, 27, 29, 30, 87], "logit_bia": 37, "logits_processor": 87, "logitsprocessor": 87, "logitsprocessoroutput": 87, "logo": 39, "logprob": [3, 21, 22, 25, 27, 37, 39, 43, 44, 64, 65, 70, 73], "logprob_start_len": [43, 64], "london": [23, 24, 37, 65, 67], "long": [0, 9, 10, 11, 17, 21, 27, 45, 46, 52, 64, 81, 84], "longer": [10, 14, 15, 17, 21, 37, 47, 48, 63, 65], "longest": 11, "look": [7, 11, 22, 23, 24, 28, 34, 45, 47, 61, 62, 87], "lookup": 33, "loop": [19, 34, 67], "lora": [43, 45, 52, 60, 74, 84], "lora0": 12, "lora0_new": 12, "lora1": 12, "lora2": 12, "lora3": 12, "lora_backend": [12, 20, 23, 24, 25, 26, 33, 34], "lora_eviction_polici": [12, 20, 23, 24, 25, 26, 33, 34], "lora_nam": [12, 21], "lora_path": [12, 20, 21, 23, 24, 25, 26, 33, 34, 37, 43, 45], "lora_target_modul": [12, 20, 23, 24, 25, 26, 33, 34], "lose": 14, "loss": 16, "lot": [34, 47], "louvr": [22, 34], "love": [34, 78], "low": [6, 10, 11, 21, 22, 27, 31, 37, 43, 45, 46, 52, 64, 85], "low_lat": [6, 21, 55, 73], "lowconfid": 79, "lower": [1, 4, 10, 11, 16, 17, 19, 21, 27, 30, 37, 47, 60, 63, 64, 79, 87], "lpm": [11, 21], "lru": [12, 20, 21, 23, 24, 25, 26, 33, 34], "lru_cach": [22, 87], "lsb": 46, "lsof": 75, "lspci": 69, "lssf": 58, "lt": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "lustr": 46, "lw": [28, 69, 72, 73], "lws_group_siz": [69, 70, 73], "lws_leader_address": [69, 70, 73], "lws_worker_index": [69, 70, 73], "lyon": 22, "m": [1, 2, 3, 4, 5, 6, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 67, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "m2": 81, "m3": [33, 85], "ma": 25, "maas_hosted_model": 70, "machin": [1, 3, 21, 28, 34, 47, 48, 51, 53, 54, 75, 77, 87], "macron": 33, "made": [15, 24, 34], "madison": 67, "madrid": [22, 37], "madrid2": 67, "magic": 67, "mai": [10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 24, 25, 28, 31, 34, 45, 46, 47, 48, 53, 58, 64, 67, 69, 70, 73, 76, 80, 83, 84, 85, 86], "main": [2, 3, 4, 15, 24, 26, 30, 33, 34, 39, 42, 43, 45, 47, 58, 61, 67, 70, 73, 76, 79, 80, 84, 87], "main_doc": [70, 73], "mainli": [10, 21, 33], "maintain": [3, 10, 17, 24, 47, 60, 67, 76, 87], "major": [10, 22, 23, 24, 28, 34, 37, 47, 69, 74, 87], "make": [0, 1, 3, 11, 12, 21, 22, 23, 24, 25, 27, 34, 37, 46, 47, 54, 67, 69, 74, 78, 79, 85, 87], "make_hook": 21, "makeshift": 26, "malform": 7, "mamba": [29, 81, 84], "mamba_full_memory_ratio": [20, 23, 24, 25, 26, 33, 34], "mamba_scheduler_strategi": [20, 23, 24, 25, 26, 33, 34], "mamba_ssm_dtyp": [20, 23, 24, 25, 26, 33, 34], "mamba_track_interv": [20, 23, 24, 25, 26, 33, 34], "mambaradixcach": 41, "man": [26, 39], "manag": [2, 6, 9, 13, 14, 16, 19, 21, 25, 51, 58, 60, 67], "mani": [1, 10, 11, 12, 15, 21, 27, 34, 37, 45, 46, 47, 58, 64, 65, 77, 87], "manifest": 21, "manner": [22, 43], "mantissa": 17, "manual": [0, 12, 27, 32, 46, 47, 59, 76, 83], "manylinux_2_28_": 54, "map": [19, 21, 22, 48, 54, 75, 78], "margin": 10, "maritim": 34, "mark": [14, 21, 24, 76], "markdown": 0, "marker": 21, "market": 31, "marlin": [16, 21, 63], "marseil": 22, "mask": [6, 43, 63], "massachusett": 25, "master": 2, "match": [1, 7, 11, 19, 21, 23, 24, 25, 28, 32, 33, 35, 43, 60, 63, 75, 87], "matched_stop": [22, 25, 27, 37, 39, 44, 70, 73], "matchlabel": 70, "materi": 68, "math": [45, 67, 81, 86], "mathemat": 64, "matrix": [6, 27, 63], "matryoshka_dimens": 80, "matter": 17, "maverick": 32, "max": [6, 12, 14, 19, 21, 22, 27, 28, 29, 30, 33, 41, 42, 45, 54, 55, 58, 60, 63, 64, 69, 70, 73, 77, 84], "max_concurr": [45, 60], "max_export_batch_s": 63, "max_fram": 84, "max_gen_tok": 32, "max_loaded_lora": [12, 20, 23, 24, 25, 26, 33, 34], "max_lora_chunk_s": [20, 23, 24, 25, 26, 33, 34], "max_lora_rank": [12, 20, 23, 24, 25, 26, 33, 34], "max_loras_per_batch": [12, 20, 23, 24, 25, 26, 33, 34], "max_mamba_cache_s": [20, 23, 24, 25, 26, 33, 34], "max_model_len": 33, "max_new_token": [3, 11, 12, 16, 20, 23, 24, 25, 43, 44, 55, 79], "max_pixel": 84, "max_position_embed": 22, "max_prefill_token": [11, 20, 23, 24, 25, 26, 33, 34, 69], "max_queued_request": [20, 23, 24, 25, 26, 33, 34], "max_req_input_len": 33, "max_running_request": [11, 20, 23, 24, 25, 26, 33, 34, 69, 79], "max_token": [22, 23, 24, 25, 27, 29, 30, 37, 39, 42, 43, 44, 67, 70, 73, 84], "max_total_num_token": [11, 33, 69], "max_total_token": [20, 23, 24, 25, 26, 33, 34], "maxim": [1, 6, 10, 11, 12, 22, 60], "maximum": [1, 11, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 30, 33, 34, 37, 38, 39, 42, 43, 44, 58, 60, 63, 64, 67], "maxium": 74, "maxsurg": 70, "maxunavail": 70, "mayb": [22, 24], "mc_force_mnnvl": 14, "mc_te_metr": [70, 73], "mcdse": 52, "mcp": 31, "md": [0, 28, 30, 47, 87], "me": [3, 22, 23, 24, 34, 35, 37, 67], "meal": 67, "mean": [6, 10, 11, 14, 15, 21, 23, 24, 25, 28, 45, 53, 58, 63, 84, 88], "meaning": 78, "measur": [43, 45, 60], "mechan": [10, 15, 16, 27, 28, 80, 86], "medatada": 1, "median": 45, "medicin": 34, "mediev": 22, "mediterranean": 37, "medium": [31, 69, 70, 73], "meet": [10, 21, 34, 67, 68, 87], "megatron": [74, 81], "meituan": 58, "melanoleuca": [33, 85], "mellanox": 69, "mem": [9, 10, 14, 21, 22, 27, 28, 29, 30, 32, 33, 42, 46, 55, 56, 59, 60, 64, 69, 70, 71, 73], "mem_fraction_stat": [11, 20, 23, 24, 25, 26, 33, 34], "member": [70, 87], "memori": [1, 5, 6, 10, 12, 14, 19, 22, 24, 27, 30, 32, 33, 41, 42, 46, 58, 59, 69, 70, 73, 84], "memory_usag": 33, "mental": 67, "mention": 24, "mere": 18, "merg": [27, 33, 45, 46, 54, 84], "merge_profil": 46, "merged_output": 34, "messag": [7, 20, 21, 22, 23, 24, 27, 29, 30, 33, 35, 37, 39, 42, 43, 44, 45, 70, 73, 78, 84], "messages_requir": 25, "messages_specif": 25, "met": 24, "meta": [1, 2, 3, 12, 14, 16, 19, 21, 22, 23, 25, 26, 32, 43, 45, 46, 48, 51, 53, 54, 58, 59, 61, 62, 71, 75, 77, 81, 84, 87, 88], "meta_info": [23, 24, 33, 44], "metadata": [1, 2, 7, 9, 19, 21, 22, 25, 37, 39, 44, 46, 69, 70, 73, 84], "metal": 58, "method": [2, 6, 9, 15, 19, 21, 22, 27, 28, 35, 37, 43, 46, 53, 66, 74, 87], "methodologi": [18, 81], "metric": [9, 19, 21, 30, 42, 52, 55, 63], "metropolitan": 24, "mf": 54, "mf_adapt": 14, "mha": [10, 17, 28], "mha_one_shot": 28, "mi300": 52, "mi300x": [27, 53], "mi350": 28, "mi355": [28, 52], "mi355x": 27, "micro": [6, 21], "microsc": 17, "microsoft": [48, 81, 84], "mid": [22, 31], "might": [12, 13, 16, 22, 24, 33, 43, 48, 61, 63, 64, 75], "migrat": [24, 78], "mild": 37, "mile": 74, "millard": 65, "million": [24, 34], "mimo": [22, 81, 84], "min": [0, 10, 21, 31, 43, 47], "min_new_token": 43, "min_p": 43, "mind": [0, 47], "mindspor": 52, "miner": 67, "mini": [76, 79, 81, 84], "minicpm": [81, 84], "minicpm3": 81, "minim": [6, 7, 10, 15, 17, 22, 47, 60, 84], "minimax": 81, "minimum": [16, 19, 21, 27, 28, 47], "minimum_token": 21, "ministri": 67, "minor": [12, 21, 47], "minut": [11, 13, 14, 18, 27, 33, 47, 67], "misalign": 15, "misconfigur": 7, "mislead": 65, "mismatch": [33, 82], "miss": [7, 19, 45, 62, 78], "misses_tot": 19, "mistak": 24, "mistral": [19, 21, 25, 52, 80, 81, 84], "mistralai": [25, 81, 84], "mitig": [10, 32], "mix": [1, 6, 16, 21, 22, 24, 26, 60], "mixtral": 81, "mixtur": [6, 27, 58, 79, 81], "ml": [51, 69], "mla": [10, 17, 21, 60], "mlc": 23, "mllm": 87, "mlp": [7, 16, 21, 84], "mlx5_0": [9, 21, 70, 73], "mlx5_1": [21, 73], "mlx5_2": 73, "mlx5_3": 73, "mlx5_4": 73, "mlx5_5": [70, 73], "mlx5_6": [70, 73], "mlx5_7": 73, "mlx5_bond_0": [69, 70], "mlx5_bond_1": [69, 70], "mlx5_bond_2": [69, 70], "mlx5_bond_3": [69, 70], "mlx5_roce0": 14, "mm": [1, 4, 21, 22, 30, 42, 56, 84], "mm_attention_backend": [20, 23, 24, 25, 26, 33, 34], "mm_enable_dp_encod": [20, 23, 24, 25, 26, 33, 34], "mm_fp4": 63, "mm_item": 26, "mm_max_concurrent_cal": [20, 23, 24, 25, 26, 33, 34], "mm_per_request_timeout": [20, 23, 24, 25, 26, 33, 34], "mm_process_config": [20, 23, 24, 25, 26, 33, 34], "mmap": 21, "mmlu": [32, 87], "mmlu_pro": 32, "mmmu": [45, 87], "mobil": [81, 84], "mod_part": 7, "modal": [30, 32, 42, 45, 52, 80, 84], "mode": [1, 2, 3, 5, 6, 7, 9, 15, 20, 21, 28, 32, 33, 34, 37, 45, 48, 54, 55, 58, 59, 63, 64, 69, 70, 73, 77], "model": [0, 1, 2, 5, 6, 9, 10, 11, 12, 14, 15, 17, 18, 22, 23, 28, 29, 30, 31, 32, 34, 35, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 55, 56, 59, 62, 65, 67, 69, 70, 71, 73, 74, 75, 77, 88], "model_arch_name_to_cl": 87, "model_arg": 32, "model_class": 87, "model_config": [16, 22, 33, 38, 87], "model_dump_json": 23, "model_executor": 87, "model_id": 16, "model_id_or_path": [58, 61], "model_impl": [20, 23, 24, 25, 26, 33, 34, 82], "model_info": [33, 67], "model_json_schema": [23, 24], "model_load": [16, 87], "model_loader_extra_config": [20, 23, 24, 25, 26, 33, 34], "model_nam": [16, 20, 25, 28, 33, 75, 78, 87], "model_name_tool_choic": 25, "model_path": [9, 16, 20, 23, 24, 25, 26, 33, 34, 55, 60, 71, 79, 82, 87], "model_typ": 33, "model_valid": 23, "model_validate_json": 23, "modelconfig": 16, "modelopt": [6, 17, 21], "modelopt_checkpoint_restore_path": [16, 20, 23, 24, 25, 26, 33, 34], "modelopt_checkpoint_save_path": [16, 20, 23, 24, 25, 26, 33, 34], "modelopt_export_path": [16, 20, 23, 24, 25, 26, 33, 34], "modelopt_fp4": [1, 16, 21], "modelopt_fp8": 16, "modelopt_qu": [20, 23, 24, 25, 26, 33, 34], "modelopt_quantize_and_export": 16, "modelregistri": 87, "modelrunn": [7, 87], "modelscop": [45, 52, 63], "modelslim": 55, "moder": [37, 67, 86], "modern": [5, 10, 74], "modif": [47, 69], "modifi": [6, 7, 16, 37, 46, 47, 48, 51, 69, 70, 75, 87], "modul": [6, 7, 9, 10, 12, 21, 46, 48, 87, 88], "modular": [6, 74], "module_nam": 7, "module_path": [9, 10, 21], "module_typ": 7, "moe": [1, 14, 16, 27, 55, 58, 60, 63, 70, 73, 74, 79, 81, 82, 84], "moe_a2a_backend": [20, 23, 24, 25, 26, 28, 33, 34], "moe_dense_tp_s": [20, 23, 24, 25, 26, 28, 33, 34], "moe_runn": 6, "moe_runner_backend": [20, 23, 24, 25, 26, 33, 34], "moe_wna16": 21, "moerunn": 6, "moerunnercor": 6, "moment": 54, "monei": 34, "monitor": [2, 19, 73, 75, 76], "mont": 48, "mooncak": [5, 6, 10, 20, 21, 23, 24, 25, 26, 33, 34, 45, 54], "mooncake_devic": 9, "mooncake_global_segment_s": 9, "mooncake_ib_devic": [20, 23, 24, 25, 26, 33, 34], "mooncake_mast": 9, "mooncake_protocol": 9, "mooncake_te_meta_data_serv": 9, "moonshotai": [25, 84], "more": [2, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 39, 41, 43, 44, 45, 46, 47, 48, 51, 52, 58, 61, 64, 67, 69, 76, 79, 80, 82, 84, 87, 88], "morgan": 31, "most": [0, 1, 4, 10, 11, 12, 22, 24, 25, 27, 31, 34, 46, 47, 52, 58, 62, 67, 69, 87, 88], "mostli": 64, "motlei": 31, "mount": [48, 50], "mountpath": [69, 70, 73], "move": [9, 10, 84], "movement": 10, "movi": 34, "mp4": [30, 42, 84], "mrl": 80, "ms_enable_lccl": 82, "mscclpp": 21, "msg": 22, "mt": 22, "mt43244": 69, "mtp": [22, 27, 28], "much": [0, 10, 11, 15, 47, 87], "muggl": 67, "mul": 63, "multi": [1, 9, 12, 19, 26, 30, 32, 42, 51, 52, 61, 63, 69, 82, 84, 87], "multi_item_scoring_delimit": [20, 23, 24, 25, 26, 33, 34], "multi_modal_item": 26, "multi_modal_projector": 26, "multi_node_deploy": 28, "multi_turn_qa": 67, "multiformatpars": 25, "multilingu": [80, 81, 86], "multimod": [1, 5, 21, 26, 30, 32, 42, 52, 56, 81], "multimodal_language_model": 87, "multimodal_processor": 87, "multimodaldataitem": 63, "multipl": [1, 2, 4, 5, 6, 10, 14, 15, 19, 21, 22, 25, 27, 31, 37, 43, 45, 46, 47, 60, 63, 71, 76, 81, 82, 84, 87], "multipli": 19, "museum": [22, 34], "music": 34, "must": [1, 5, 7, 10, 12, 14, 16, 17, 19, 21, 22, 23, 24, 25, 26, 28, 34, 35, 43, 46, 47, 69, 76, 87], "mus\u00e9": 34, "mutual": 46, "mv": [53, 54], "mxfp4": [6, 16, 17, 21, 27], "my": [2, 22, 24, 34, 47, 82, 87], "my_checkpoint": 16, "my_model": 62, "my_model_templ": 62, "my_packag": 21, "my_project": 7, "myattent": 88, "myhuaweicloud": 54, "mymodel": 88, "n": [1, 3, 10, 12, 20, 21, 22, 23, 24, 25, 28, 33, 34, 35, 37, 43, 44, 45, 58, 61, 67, 70, 71, 73, 80, 85], "n1": [22, 33, 37, 44], "n10": 37, "n2": [22, 33, 37, 44], "n3": [22, 33, 37, 44], "n4": 37, "n5": 37, "n6": 37, "n7": 37, "n8": 37, "n9": 37, "nalso": 22, "naltern": 22, "name": [0, 2, 9, 10, 12, 16, 21, 22, 23, 24, 25, 27, 28, 29, 33, 34, 35, 37, 41, 43, 45, 46, 47, 48, 50, 53, 54, 58, 60, 61, 62, 65, 67, 69, 70, 73, 75, 76, 78, 82, 87], "name1": 45, "name2": 45, "name_non_stream": 25, "name_to_modul": 7, "named_modul": [7, 21], "namespac": [19, 73], "nan": [21, 33], "nano": [81, 84], "nativ": [1, 10, 12, 19, 31, 43, 45, 52, 60, 69, 74, 84], "natur": [5, 10, 34, 37, 47], "naur": 25, "navig": 75, "navit": 84, "nbstripout": 0, "nc": 71, "ncapit": 22, "nccl": [20, 21, 23, 24, 25, 26, 27, 33, 34, 64, 69, 70, 71, 73], "nccl_debug": 69, "nccl_ib_gid_index": [48, 53, 69, 73], "nccl_ib_hca": [70, 73], "nccl_ib_qps_per_connect": [70, 73], "nccl_ib_sl": [70, 73], "nccl_ib_split_data_on_qp": [70, 73], "nccl_ib_tc": [70, 73], "nccl_ib_timeout": 73, "nccl_init_addr": 71, "nccl_min_nchannel": [70, 73], "nccl_net_plugin": [70, 73], "nccl_port": [20, 23, 24, 25, 26, 33, 34], "nccl_socket_ifnam": [69, 73], "ncontent": 24, "ndescrib": 43, "ndetoken": 33, "ndr": 69, "ndv5": 53, "nearli": 53, "neatli": 24, "necessari": [10, 24, 51, 64, 69, 87], "need": [1, 2, 3, 6, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 27, 28, 32, 33, 34, 35, 37, 45, 46, 47, 48, 50, 53, 54, 58, 60, 62, 64, 67, 69, 70, 73, 74, 75, 76, 80, 82, 83, 84, 87, 88], "neg": [37, 43, 63], "negat": 17, "nemo": [25, 28, 81], "nemo_skills_aime25_": 28, "nemo_skills_disable_uncommitted_changes_check": 28, "nemotron": [81, 84], "nest": 76, "nest_asyncio": [26, 34], "netdev": 69, "network": [2, 33, 48, 53, 54, 58, 59, 64, 69, 70, 73, 75], "networkconfig": 70, "neural": 33, "neuralmag": 16, "neutral": [34, 87], "never": 19, "new": [0, 9, 10, 11, 12, 18, 19, 21, 23, 24, 26, 31, 33, 34, 37, 43, 47, 49, 50, 52, 58, 60, 63, 69, 70, 76, 78, 81], "new_token_ratio": 11, "new_york": [23, 24], "newer": [51, 58], "newli": [10, 28, 87], "newmodeldetector": 25, "next": [10, 15, 20, 22, 24, 25, 34, 40, 43, 76, 81, 84, 87], "next_token_logit": 87, "nextn": [21, 41, 55], "nf": 46, "ngener": [23, 24, 34], "nhere": 24, "nhttp": 33, "ni": [24, 33], "nic": [10, 69], "nice": 34, "nicknam": 22, "nightli": [51, 54], "nimag": 26, "ninth": 37, "nixl": [10, 21], "njust": 22, "nlet": 24, "nlp": [33, 38, 80, 81], "nn": [7, 69, 88], "nnal": 54, "nnext": 24, "nnode": [2, 14, 20, 21, 23, 24, 25, 26, 33, 34, 55, 60, 69, 70, 71, 73, 82], "nnow": 24, "no_answ": 28, "no_buff": [20, 21, 23, 24, 25, 26, 33, 34, 41], "no_grad": 87, "no_stop_trim": [25, 43], "node": [9, 10, 15, 18, 19, 22, 33, 51, 52, 55, 63, 69, 70, 73, 76, 82], "node0_ip": 60, "node1": 69, "node_rank": [20, 23, 24, 25, 26, 33, 34], "nodeport": [70, 73], "nodeselector": [70, 73], "nois": 3, "nokai": 22, "non": [1, 7, 15, 19, 21, 35, 37, 45, 47, 63, 67, 78, 79, 87], "nondeterminist": 64, "none": [6, 7, 12, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 43, 44, 55, 63, 70, 73, 87], "normal": [1, 6, 20, 21, 25, 55, 60, 73, 76], "normal_text": 25, "northern": 24, "notabl": [24, 58], "note": [10, 11, 12, 14, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 37, 38, 39, 44, 47, 48, 50, 53, 58, 60, 61, 62, 63, 67, 69, 70, 71, 73, 76, 78, 82, 83, 87], "notebook": [0, 12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "noth": [19, 21], "notic": [54, 64, 69, 70], "notr": [22, 34], "nousresearch": 53, "novel": [18, 37], "now": [1, 15, 22, 24, 31, 33, 37, 46, 48, 53, 67, 78, 87], "nowadai": 47, "npcach": 21, "nproc": 2, "nprompt": [34, 87], "npu": [1, 21, 28, 51, 52, 55, 56, 82], "npugraph": 54, "nput": 24, "nround": 33, "nsa": [1, 21, 28], "nsa_decode_backend": [20, 23, 24, 25, 26, 33, 34], "nsa_prefill_backend": [20, 23, 24, 25, 26, 33, 34], "nsight": 21, "nsy": [46, 48], "ntask": 71, "nthe": 22, "ntherefor": 33, "nthi": 24, "nto": 33, "ntoken": 33, "null": [20, 21, 23, 24, 25, 26, 27, 33, 34, 38, 39, 51, 70, 73, 78], "num": [21, 22, 27, 28, 29, 32, 41, 45, 46, 47, 48, 53, 55, 56, 58, 60, 61, 70, 73, 75], "num_choic": 22, "num_class": 78, "num_concurr": 32, "num_continuous_decode_step": [20, 23, 24, 25, 26, 33, 34], "num_entri": 28, "num_fewshot": 32, "num_fram": 84, "num_hidden_lay": 46, "num_key_value_head": 46, "num_paused_request": 33, "num_prompt": 60, "num_prompts_per_concurr": 60, "num_quest": 55, "num_queue_req": 75, "num_reserved_decode_token": [20, 23, 24, 25, 26, 33, 34], "num_running_req": 75, "num_shot": 55, "num_stag": 22, "num_step": 46, "num_token_to_fetch": 10, "num_triton_choic": 22, "num_used_token": 75, "num_warp": 22, "numa": [21, 58], "numa_balanc": [53, 54], "numa_nod": [20, 23, 24, 25, 26, 33, 34], "number": [1, 2, 10, 11, 12, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 47, 58, 60, 63, 67, 75, 76, 78, 79], "numer": [27, 33, 34, 64], "numexpr": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "numexpr_max_thread": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "numpi": [21, 45], "nurgaliyev": 59, "nutanix": 12, "nutrient": 67, "nutritionist": 67, "nv": 59, "nvda": 31, "nvfp4": [6, 16, 17, 21, 27, 63], "nvfp4_awq": 21, "nvidia": [1, 6, 17, 21, 27, 28, 31, 32, 46, 47, 50, 51, 52, 63, 69, 70, 73, 81, 84], "nvidia_h100_80gb_hbm3": 33, "nvidia_h100_80gb_hbm3_down": 33, "nvila": 84, "nvl": 21, "nvl72": [14, 27], "nvme": 48, "nvpmodel": 59, "nvrtc": 63, "nvshmem_bootstrap_uid_sock_ifnam": 73, "nvshmem_disable_p2p": 73, "nvshmem_enable_nic_pe_map": 70, "nvshmem_hca_list": 70, "nvshmem_hca_pe_map": 70, "nvshmem_ib_gid_index": [70, 73], "nvshmem_ib_sl": 73, "nvshmem_ib_traffic_class": [70, 73], "nvtx": 21, "nwait": [22, 24], "ny": [23, 24, 25], "nyou": 43, "n\u00fa\u00f1ez": 59, "n\u4f60\u597d\u5440": [70, 73], "n\u55ef": [70, 73], "n\u6211\u7684\u4efb\u52a1\u5c31\u662f\u966a\u4f60\u804a\u5929": [70, 73], "n\u7528\u6237\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u80cc\u666f\u4fe1\u606f": [70, 73], "n\u7528\u6ce2\u6d6a\u7ebf\u7ed3\u5c3e\u53ef\u4ee5\u8f6f\u5316\u8bed\u6c14": [70, 73], "n\u8003\u8651\u5230\u4e2d\u6587\u7528\u6237": [70, 73], "o": [9, 10, 14, 22, 23, 24, 38, 43, 46, 48, 50, 54, 71, 84], "o_proj": [12, 21], "oai": 45, "ob": 54, "obes": 67, "object": [4, 7, 10, 21, 22, 23, 24, 25, 27, 34, 37, 38, 39, 43, 44, 45, 70, 73, 78], "obscur": 26, "observ": [17, 22, 52, 76], "obtain": [10, 22, 25, 33, 65, 69, 76], "occasion": 11, "occup": [46, 67], "occur": [11, 33, 43, 64], "ocp": 17, "ocr": 84, "odd": 45, "odel": 20, "ofassistantgener": 23, "ofed_info": 69, "off": [6, 24, 27, 29, 41, 53, 63, 79, 80, 82], "offer": [6, 24, 43, 52, 81, 84, 85, 86], "offici": [21, 22, 27, 28, 32, 33, 47, 48, 53, 58, 62, 70, 82], "offlin": [14, 17, 39, 46, 52], "offload": [9, 10], "offload_group_s": [20, 23, 24, 25, 26, 33, 34], "offload_mod": [20, 23, 24, 25, 26, 33, 34], "offload_num_in_group": [20, 23, 24, 25, 26, 33, 34], "offload_prefetch_step": [20, 23, 24, 25, 26, 33, 34], "often": [6, 10, 22, 27, 33, 34, 63, 86], "ok": [33, 69], "okai": [11, 24, 37], "old": 37, "older": 69, "ollama": 52, "ollama_host": 35, "olmo": 81, "oltp": 21, "om": 51, "omit": [24, 37, 65, 80], "omni": 84, "onboard": 19, "onc": [1, 7, 10, 24, 25, 33, 37, 38, 39, 47, 48, 54, 58, 65, 69, 77], "oncal": 47, "ondemand": 54, "one": [1, 7, 10, 12, 14, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 37, 39, 43, 45, 46, 47, 51, 53, 58, 63, 64, 65, 75, 80, 88], "oneshot": 16, "onevis": [39, 43, 84], "ongo": [14, 32, 46], "onli": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 35, 43, 45, 46, 47, 48, 51, 53, 54, 59, 61, 63, 64, 65, 67, 69, 81, 82, 84, 85, 87], "onlin": [27, 34, 45, 46, 71], "only_run": 87, "onto": 51, "oom": [11, 32, 64, 84], "op": [4, 10, 21, 54], "open": [0, 17, 19, 22, 26, 32, 34, 46, 47, 48, 51, 52, 53, 58, 74, 75, 81, 84], "openai": [21, 22, 27, 29, 31, 33, 43, 45, 52, 58, 60, 61, 62, 65, 67, 78, 80, 81, 84], "openai_api_complet": 12, "openai_api_kei": [45, 50], "openbmb": [81, 84], "opentelemetri": [21, 76], "opentelmetri": 19, "oper": [1, 3, 6, 9, 10, 14, 17, 19, 21, 22, 27, 33, 46, 47, 51, 54, 55, 58, 60, 63, 70, 73, 80], "opera": 34, "opp": 54, "opportun": [34, 60], "opt": [16, 48, 51, 53, 58], "optic": 84, "optim": [1, 2, 3, 6, 8, 11, 12, 14, 16, 17, 18, 19, 22, 26, 32, 33, 41, 47, 51, 53, 54, 70, 74, 81, 82, 85], "option": [9, 12, 14, 16, 19, 20, 22, 24, 27, 31, 37, 46, 51, 60, 65, 75, 76, 78, 79, 87], "oracl": 19, "oraclecloud": 19, "orchestr": [6, 19], "order": [3, 12, 19, 34, 67, 84, 85], "org": [25, 29, 30, 54, 58, 61, 64, 71, 74, 77, 81, 84], "organ": [9, 34], "orient": 10, "orig_logit": 87, "origin": [1, 12, 15, 16, 20, 22, 23, 24, 25, 27, 28, 33, 37, 38, 39, 44, 67, 78], "orin": 52, "orion": 81, "orionstarai": 81, "oscar": 67, "oserror": 51, "osl": 60, "oss": [17, 19, 20, 21, 25, 37, 52, 81], "otel_exporter_otlp_traces_protocol": 76, "otel_trac": 76, "other": [0, 1, 2, 4, 12, 13, 21, 22, 24, 25, 26, 27, 28, 32, 34, 37, 39, 41, 47, 51, 53, 54, 60, 63, 64, 65, 67, 71, 75, 76, 77, 79, 81, 84, 87], "otherwis": [21, 28, 45, 46, 76, 80, 88], "otlp": [19, 76], "otlp_traces_endpoint": [20, 23, 24, 25, 26, 33, 34, 76], "ottawa": [37, 44], "our": [0, 12, 16, 22, 28, 31, 34, 43, 47, 54, 64, 70, 74, 78], "out": [12, 20, 21, 22, 24, 25, 26, 30, 32, 33, 37, 39, 42, 46, 47, 51, 58, 67, 71, 74, 83], "outdat": 58, "outer": [7, 17], "outer_linear_hook": 7, "outlin": [21, 23, 25, 27, 43, 63], "output": [0, 3, 4, 6, 7, 10, 12, 16, 20, 21, 22, 27, 28, 31, 33, 34, 38, 39, 44, 47, 48, 52, 53, 58, 60, 61, 63, 64, 67, 69, 70, 71, 75, 79, 81, 82, 84, 86, 87], "output_dir": [16, 28, 46], "output_hidden_st": 26, "output_id": [23, 24, 33, 44], "output_len": 45, "output_seq_len": 60, "output_text": 31, "outweigh": 21, "ov": [43, 84], "over": [0, 6, 7, 10, 12, 14, 16, 19, 21, 24, 28, 34, 39, 46, 52, 63], "overal": [6, 27, 60, 67], "overflow": 19, "overhead": [4, 10, 11, 12, 17, 21, 22, 26, 28, 34, 46, 47, 52, 63, 84], "overlap": [2, 10, 15, 21, 22, 28, 33, 34, 38, 41, 46, 55, 58, 60, 61, 63, 65, 70], "overrid": [9, 10, 19, 22, 32, 43, 45, 46, 47, 62, 80], "overview": [10, 23, 27, 38, 47], "overweight": 31, "overwrit": 63, "own": [19, 21, 22, 24, 28, 34, 47, 51, 54, 58, 61, 71], "p": [21, 28, 31, 43, 51, 53, 58, 70, 75, 83], "p2p": [2, 21, 63], "p95": 45, "p99": 45, "p_": 22, "p_host_ip": 55, "packag": [2, 7, 22, 31, 47, 51, 53, 54, 58, 60, 61, 63, 70, 76, 82], "pad": [1, 21, 63, 87], "pad_input_id": 87, "page": [1, 9, 10, 12, 21, 31, 38, 41, 51, 52, 60, 61, 64, 70, 73, 88], "page_first": [9, 10, 21], "page_first_direct": [9, 10, 21], "page_first_kv_split": 21, "page_s": [1, 10, 20, 21, 23, 24, 25, 26, 33, 34], "pai": 69, "pair": [9, 17, 24, 39, 45, 67], "pairwis": 33, "panda": [33, 85], "pandoc": 0, "pant": 39, "pantheon": 37, "paper": [1, 12, 22], "paragraph": 67, "parallel": [0, 4, 10, 11, 12, 14, 17, 22, 25, 26, 30, 42, 46, 48, 52, 55, 58, 60, 63, 69, 70, 72, 73, 79, 82, 86], "param": [12, 17, 21, 25, 33, 45, 81], "param1": 25, "param2": 25, "param_dict": 43, "paramet": [2, 11, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 33, 44, 46, 47, 48, 51, 52, 58, 60, 61, 63, 64, 70, 71, 73, 81, 84, 87], "parameter": 7, "pari": [12, 22, 23, 24, 25, 27, 29, 33, 34, 37, 43, 44, 65, 67], "paris2": 67, "pariti": 19, "park": [26, 39, 67], "pars": [16, 20, 24, 25, 31, 37, 51, 63, 78], "parse_function_cal": 25, "parse_non_stream": [20, 25], "parse_url": [20, 25], "parser": [19, 21, 24, 26, 27, 29, 37, 51, 52, 81], "part": [1, 7, 10, 24, 26, 27, 34, 64, 67, 70], "partern": 74, "partial": [21, 25, 26, 74], "particip": 2, "particular": [24, 25, 34], "particularli": [3, 6, 17, 24, 46], "partit": [15, 21, 27, 63, 71], "partli": 25, "partnership": 74, "pass": [0, 6, 7, 10, 12, 21, 22, 26, 28, 35, 37, 45, 47, 63, 84, 87], "passion": 34, "password": [51, 75], "past": 58, "patch": 76, "patch14": 80, "patchleadertempl": 73, "patchworkertempl": 73, "path": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 67, 69, 70, 71, 73, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "patronu": 67, "pattern": [7, 10, 14, 21, 23, 24, 43, 46, 47, 69], "pattern1": 7, "pattern2": 7, "paus": [6, 48, 60], "payload": [19, 23, 24, 45, 73, 80, 85], "pci": 53, "pd": [5, 19, 27, 52, 54, 72, 76], "pd_role": 73, "pdmux": 21, "pdmux_config_path": [20, 23, 24, 25, 26, 33, 34], "peak": [6, 11, 21, 27, 64], "pedestrian": 26, "peer": [2, 12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 63, 67], "penalti": 37, "peopl": [22, 24, 34, 47], "per": [1, 2, 10, 11, 12, 14, 16, 17, 19, 21, 22, 24, 27, 30, 42, 43, 45, 46, 47, 60, 63, 71, 73, 75, 84], "per_row": [16, 21], "per_tensor": [16, 21], "perfect": [15, 34], "perfectli": 3, "perfetto": [46, 76], "perform": [1, 4, 5, 6, 9, 10, 12, 15, 16, 19, 20, 21, 23, 24, 25, 27, 28, 30, 32, 33, 35, 37, 38, 39, 42, 44, 46, 47, 52, 53, 55, 58, 59, 61, 65, 67, 69, 74, 76, 80, 81, 82, 85, 87], "perhap": [22, 24], "period": [6, 19, 47, 63], "periodsecond": [69, 70, 73], "perman": [12, 75], "permiss": 47, "permut": [6, 34], "permutemethodpool": 6, "persimmon": 81, "persist": 19, "person": [34, 67], "petit_nvfp4": 21, "phase": [1, 10, 12, 14, 15, 21, 22, 27, 60, 63, 76], "phenomenon": 15, "phi": [81, 84], "philschmid": 12, "phoenix": 67, "phrase": 37, "phy": 69, "physic": [63, 67], "physical_st": 69, "pick": [19, 45, 47], "pickl": 13, "piecewis": 21, "piecewise_cuda_graph_compil": [20, 23, 24, 25, 26, 33, 34], "piecewise_cuda_graph_max_token": [20, 23, 24, 25, 26, 33, 34], "piecewise_cuda_graph_token": [20, 23, 24, 25, 26, 33, 34], "pil": [26, 43], "pillow": 45, "pin": 21, "ping": 41, "pip": [0, 2, 14, 16, 21, 28, 35, 46, 49, 50, 53, 54, 58, 60, 61, 76, 82], "pip3": [28, 47, 51, 61], "pipelin": [0, 19, 21, 22, 26, 52, 63, 86], "pixel": 26, "pixel_valu": 26, "place": [4, 6, 10, 24, 25, 30, 47], "plai": [34, 67], "plan": [1, 12, 25, 33, 34, 48, 51, 60, 63, 67], "platform": [1, 32, 51, 54, 58, 82], "playground": [13, 87], "pleas": [1, 12, 14, 16, 18, 21, 22, 23, 24, 25, 27, 28, 31, 33, 34, 38, 39, 43, 46, 47, 48, 51, 53, 54, 58, 59, 60, 61, 63, 64, 67, 69, 71, 73, 76, 82, 84, 87], "plenti": 67, "plu": [19, 20, 30, 42, 81], "plugin": [10, 25, 60, 69], "png": [26, 30, 39, 42, 43, 45, 67], "po": [70, 73], "pod": 19, "point": [3, 6, 7, 17, 19, 21, 31, 70, 73, 75, 76, 87], "poisson": 45, "polici": [3, 10, 11, 12, 14, 21, 22, 55, 73], "polit": [24, 34], "poll": [19, 21, 63], "pong": 41, "pool": [10, 12, 19, 21, 30, 33, 42, 63, 64], "poorli": 65, "popul": [23, 24, 34, 43, 87], "popular": [16, 37, 52, 58], "port": [0, 2, 5, 9, 12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 60, 62, 63, 67, 69, 70, 71, 73, 75, 76, 79, 80, 81, 83, 84, 85, 86, 88], "port_tool_choic": 25, "portion": [2, 17, 25, 64], "posit": [34, 37, 41, 43, 84, 87], "possibl": [0, 10, 11, 21, 24, 34, 47, 87], "possibli": 76, "post": [3, 6, 12, 16, 19, 20, 22, 23, 24, 25, 30, 33, 35, 38, 39, 42, 43, 44, 45, 46, 52, 64, 69, 70, 71, 73, 76, 78, 79, 80, 84, 85], "post2": [33, 51, 53, 54], "post3": 54, "postgr": 19, "postgresql": 19, "postpon": 74, "potenti": [15, 17, 21, 22, 34, 61, 76, 79], "potter": 67, "power": [19, 28, 35, 46, 52, 53, 74, 84], "power_of_two": 19, "pp": [15, 21, 46], "pp_async_batch_depth": [20, 23, 24, 25, 26, 33, 34], "pp_max_micro_batch_s": [20, 23, 24, 25, 26, 33, 34], "pp_proxy_tensor": 87, "pp_size": [20, 23, 24, 25, 26, 33, 34], "ppo": 74, "ppproxytensor": 87, "pprint": [27, 29], "pr": [0, 6, 17, 28, 32, 41, 47, 73, 87], "practic": [8, 27, 46, 47], "pre": [0, 1, 6, 16, 17, 21, 26, 43, 53, 54, 75], "preced": [37, 47], "precis": [6, 10, 16, 17, 21, 24, 27, 58, 60], "precompil": [22, 27, 63], "precomput": [43, 63], "precomputed_embed": [26, 43], "predefin": [21, 87], "predict": [15, 45, 65, 78, 79, 81], "preempt": 21, "preemption": 21, "prefer": [0, 17, 21, 25, 33, 45, 47, 48, 58, 86], "preferred_sampling_param": [20, 23, 24, 25, 26, 33, 34], "prefetch": 21, "prefetch_threshold": 10, "prefetch_timeout_bas": 10, "prefetch_timeout_per_ki_token": 10, "prefil": [3, 5, 6, 9, 10, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 42, 52, 55, 63, 64, 69, 73, 75, 76, 85, 87], "prefill1": 19, "prefill_addr": 28, "prefill_attention_backend": [20, 23, 24, 25, 26, 33, 34], "prefill_host": 5, "prefill_host_ip": 55, "prefill_in1024": 70, "prefill_master_ip": 14, "prefill_max_request": [20, 23, 24, 25, 26, 33, 34], "prefill_round_robin_bal": [20, 23, 24, 25, 26, 33, 34], "prefix": [1, 3, 10, 11, 15, 19, 21, 27, 28, 41, 45, 46, 51, 52, 60, 63, 64, 87], "preliminari": [2, 17], "prepar": [3, 28, 69], "prepare_data": 28, "preprocess": [5, 21], "prereleas": 51, "prerequisit": 46, "presence_penalti": [37, 43], "present": [10, 24, 28, 34, 58, 84], "preserv": 25, "preset": [45, 70], "presid": [33, 34, 65], "press": [33, 39, 48, 58, 69], "pressur": 10, "pretend": 26, "pretrain": 81, "pretrainedmodel": 88, "pretti": [24, 27, 29], "prev": [43, 44], "prevent": [10, 11, 12, 14, 21, 34, 37, 47, 48, 61, 64, 69], "preview": [0, 12], "previou": [24, 27, 31, 75, 76, 81], "previous": [17, 21, 43], "price": 31, "primari": 61, "primarili": [17, 47, 51, 63, 81], "primit": [19, 65], "principl": 76, "print": [3, 12, 16, 24, 25, 26, 30, 31, 33, 34, 35, 37, 38, 42, 43, 44, 45, 46, 55, 67, 78, 79, 80, 82, 84, 85, 87], "print_highlight": [20, 22, 23, 24, 25, 33, 37, 38, 39, 43, 44, 67], "prior": [6, 54, 58], "priorit": 47, "prioriti": [21, 78], "priority_scheduling_preemption_threshold": [20, 23, 24, 25, 26, 33, 34], "privaci": [37, 74], "privat": 10, "privileg": [48, 53, 54, 58, 69, 70, 73], "pro": [1, 32, 61, 84, 87], "proactiv": 10, "prob": [21, 78], "probabl": [21, 22, 24, 43, 78], "probe": 19, "problem": [14, 16, 20, 34, 51, 54, 69], "proc": [53, 54], "proceed": 10, "process": [2, 4, 5, 10, 14, 15, 19, 21, 22, 26, 27, 28, 30, 33, 34, 37, 42, 45, 46, 47, 51, 58, 60, 63, 67, 69, 75, 76, 78, 81, 84, 85], "process_tracing_init": 76, "processor": [21, 27, 29, 30, 37, 58, 84, 87], "processor_output": [26, 43], "produc": [3, 25, 45, 75, 81], "product": [3, 10, 16, 19, 28, 31, 34, 51, 52, 60, 74, 88], "profess": 34, "profession": 34, "profil": [21, 45, 47, 52, 60], "profile_id": 46, "profile_log": 46, "profiler_python": 46, "program": [37, 48, 52, 80, 84, 85], "programmat": [16, 46], "progress": 19, "progress_bar": 67, "project": [4, 17, 24, 26, 28, 30, 31, 33, 34, 39, 42, 43, 49, 50, 51, 53, 54, 58, 60, 61, 62, 67, 68, 73, 76, 81, 84], "projector": [26, 84], "prometheu": [13, 19, 21, 75], "promis": [15, 21, 34, 79], "prompt": [1, 3, 11, 16, 20, 21, 23, 24, 25, 26, 27, 31, 33, 34, 37, 43, 45, 46, 52, 53, 58, 60, 61, 64, 75, 79, 82, 84, 87], "prompt_token": [22, 23, 24, 25, 27, 33, 37, 38, 39, 44, 70, 73, 78], "prompt_tokens_bucket": [20, 23, 24, 25, 26, 33, 34], "prompt_tokens_detail": [21, 22, 25, 27, 37, 38, 39, 44, 70, 73, 78], "prompt_tokens_tot": 75, "pronounc": 17, "propag": [15, 19, 76], "proper": [24, 45, 47, 58, 69, 84], "properli": [17, 53, 60, 69, 76], "properti": [23, 24, 25, 27, 43], "proport": 67, "propos": [10, 15, 25], "protein": 67, "proto": 76, "protobuf": 76, "protocol": [19, 69, 70, 73, 78], "protocol_buffers_python_implement": 82, "prototyp": [19, 26], "provid": [2, 3, 6, 10, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 31, 33, 34, 35, 37, 38, 39, 43, 44, 45, 46, 47, 51, 52, 53, 54, 58, 60, 63, 71, 75, 76, 78, 80, 81, 82, 84, 86, 87], "prss": 48, "prune": 19, "pt": [21, 22, 26, 53, 81], "pth": 16, "ptq": 16, "pub": 46, "public": 68, "public_sglang_ci": 33, "publish": 21, "pull": [0, 28, 31, 47, 48, 50], "punica": 12, "pure": [21, 28, 47, 67], "purpos": [6, 10, 13, 21, 35], "pursu": 34, "push": [0, 47, 51], "put": [19, 23, 24], "pwd": 16, "py": [1, 2, 6, 12, 13, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 43, 44, 46, 47, 48, 49, 51, 53, 62, 67, 78, 87], "pybase64": 45, "pydant": [23, 24], "pypi": 47, "pyproject": [47, 49, 53, 54, 58, 61], "pyproject_cpu": 58, "pyproject_oth": [53, 54], "pyproject_xpu": 61, "python": [1, 2, 5, 6, 7, 9, 10, 14, 18, 19, 20, 21, 23, 24, 28, 30, 32, 33, 34, 37, 42, 43, 45, 46, 47, 48, 49, 51, 53, 55, 56, 58, 59, 60, 61, 62, 67, 70, 71, 75, 76, 79, 81, 82, 83, 84, 87, 88], "python3": [1, 3, 4, 9, 12, 13, 16, 17, 19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 60, 69, 70, 71, 73, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "python_execution_backend": 31, "python_serv": 31, "python_tag": 25, "pytorch": [1, 7, 16, 21, 51, 58, 61, 63, 64, 77], "pytorch_npu_alloc_conf": [55, 56], "pytorch_vers": 54, "q": [27, 28, 84], "q2": 31, "q4_k_m": 16, "q_b_proj": 63, "q_proj": [12, 21], "qa": 10, "qdrep": 46, "qingdao": 27, "qk": [20, 21, 23, 24, 25, 26, 33, 34], "qkv": [16, 21], "qkv_proj": [21, 46], "qlora": 74, "qoq": 21, "qperf": 69, "quad": 20, "quadrat": 15, "qualiti": [16, 22, 23, 33, 60, 79, 80, 81], "quant": [16, 21], "quant_config": [16, 87], "quant_method": 6, "quant_path": 16, "quantiz": [1, 6, 11, 20, 23, 24, 25, 26, 27, 33, 34, 52, 55, 58, 60, 63, 87], "quantization_param_path": [20, 23, 24, 25, 26, 33, 34], "quantizationconfig": 87, "quantizationmodifi": 16, "quantize_and_sav": 16, "quantize_and_serv": [20, 23, 24, 25, 26, 33, 34], "quantizeconfig": 16, "quantized_model": 16, "quantized_tinyllama_fp4": 16, "quantized_tinyllama_fp8": 16, "queri": [0, 10, 13, 21, 23, 24, 33, 45, 52, 84, 85], "query_st": 88, "query_weath": 27, "question": [20, 22, 24, 27, 28, 29, 33, 37, 45, 47, 48, 52, 53, 67, 84], "queu": 21, "queue": [14, 19, 33, 69, 75], "queue_schedul": 54, "quick": [19, 24, 26, 44, 46, 47, 51, 60], "quickli": [0, 46, 47], "quiet": 54, "quirki": 67, "quit": [24, 33, 69], "quot": 31, "quotat": 24, "qwen": [0, 1, 2, 3, 4, 12, 16, 20, 21, 24, 25, 26, 33, 34, 35, 37, 39, 41, 42, 44, 45, 46, 47, 51, 52, 56, 58, 61, 67, 80, 81, 83, 84, 86, 87], "qwen1": 33, "qwen2": [0, 1, 4, 12, 16, 25, 33, 34, 35, 37, 38, 39, 43, 44, 45, 47, 61, 67, 70, 73, 78, 80, 83, 84, 86, 87], "qwen25": [21, 25], "qwen2_5_vlforconditionalgener": [26, 84], "qwen2forcausallm": 33, "qwen2forrewardmodel": [78, 86], "qwen2forsequenceclassif": [78, 86], "qwen2vl": 87, "qwen3": [2, 4, 5, 9, 17, 19, 20, 21, 25, 40, 51, 57, 58, 74, 80, 81, 82, 84], "qwen3_cod": [21, 25], "qwen3forcausallm": 81, "qwen3forsequenceclassif": 78, "qwen_vl": 84, "qwq": [24, 58], "r": [0, 19, 23, 24, 37, 67, 78, 81], "r1": [1, 2, 9, 16, 17, 19, 20, 21, 24, 37, 40, 51, 53, 58, 59, 69, 70, 81, 82], "race": 14, "radix": [3, 21, 33, 45, 46, 55, 60, 64, 70, 73, 85], "radix_cach": 3, "radix_eviction_polici": [20, 23, 24, 25, 26, 33, 34], "radixattent": [9, 10, 21, 52, 87], "radixtre": 10, "rag": [21, 28], "rai": 74, "rais": [7, 21, 31, 33, 45, 76], "raise_for_statu": 33, "ralli": 31, "ram": 21, "ran": 87, "random": [19, 21, 22, 45, 46, 53, 58, 60, 61, 73, 75], "random_se": [20, 23, 24, 25, 26, 33, 34], "randomli": [43, 45], "rang": [10, 11, 16, 17, 21, 22, 33, 37, 43, 45, 46, 52, 58, 60, 61, 75, 79], "rank": [2, 12, 14, 15, 17, 19, 20, 21, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 44, 46, 55, 58, 60, 63, 67, 69, 70, 71, 73, 82, 86], "rapid": [10, 34], "rate": [7, 9, 10, 22, 31, 58, 61, 69, 75], "rather": [11, 16], "ratio": [6, 9, 10, 17, 19, 21, 32, 41, 45, 58, 60, 61, 75], "ravenclaw": 67, "raw": [17, 30, 39, 42, 43, 67, 84, 87], "raw_tool": 25, "rbac": 19, "rbg": [28, 72], "rbg_pd": 28, "rc": 46, "rc2": [54, 82], "rc_rdma_write_bw": 69, "rdma": [6, 9, 10, 48, 53, 54, 70, 73], "re": [0, 21, 24, 27, 34, 47, 48, 60, 69, 74, 87], "reach": [10, 31, 63, 74], "reachabl": 45, "react": 47, "reaction": 47, "read": [10, 21, 24, 43, 48, 53, 60, 84], "readabl": [7, 33], "readi": [2, 10, 11, 16, 19, 28, 33, 46, 53, 58, 69, 71, 81, 87], "readinessprob": [69, 70, 73], "readm": [47, 87], "real": [10, 16, 21, 23, 24, 25, 34, 46, 81], "realloc": 53, "reasoing_cont": 24, "reason": [13, 15, 17, 19, 21, 25, 29, 41, 42, 51, 52, 63, 81, 84], "reasoning_cont": [20, 22, 24, 25, 27, 37, 39, 44, 70, 73], "reasoning_effort": 31, "reasoning_pars": [19, 20, 23, 24, 25, 26, 33, 34], "reasoning_text": 20, "reasoning_token": [22, 25, 37, 38, 39, 44], "reasoningpars": 20, "rebal": [21, 73], "rebalanc": [6, 21], "reboot": 53, "rebuild": 0, "recal": [22, 24], "receiv": [10, 14, 27, 76, 87], "recent": [12, 21, 22, 24, 31, 47, 64], "recip": [16, 77], "recogn": [20, 32, 81, 87], "recognit": 84, "recommend": [0, 1, 2, 6, 9, 10, 12, 14, 16, 17, 21, 25, 27, 28, 31, 32, 37, 46, 47, 51, 54, 58, 67, 82], "reconstruct": [27, 33], "reconstructed_text": 33, "record": [10, 21, 33, 63, 76], "record_shap": 63, "recoveri": 51, "recreategrouponpodrestart": [69, 70], "recv": [21, 63], "red": 81, "redesign": 15, "redhatai": 58, "rednot": 84, "reduc": [0, 1, 2, 3, 4, 6, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 43, 44, 46, 47, 60, 64, 67, 76, 80, 84], "reduct": [3, 17, 27, 51], "redund": [10, 16, 17, 21, 26, 70, 73], "redundantli": 10, "ref": [30, 42, 84], "refactor": 6, "refer": [6, 9, 10, 11, 14, 17, 21, 24, 25, 27, 28, 31, 34, 37, 38, 39, 43, 44, 46, 47, 51, 53, 58, 61, 64, 69, 71, 73, 82, 84, 87], "reference_hf": 87, "refin": [85, 86], "refit": 74, "refus": [22, 25, 37, 44], "regard": [24, 76], "regardless": [21, 45], "regex": [21, 23, 24, 67], "regimen": 67, "region": [19, 22, 24, 34, 37, 46, 51], "regist": [6, 7, 9, 19, 46], "register_forward_hook": 7, "register_fused_func": 6, "register_post_permut": 6, "register_pre_permut": 6, "registr": [7, 19], "registri": [19, 87], "regress": [16, 47, 79], "regul": 19, "regular": [7, 12, 19, 22, 43, 67], "regular_expression_gen": 67, "regularli": 67, "reinforc": [3, 74, 81, 84, 86], "reiniti": 12, "reinstal": [14, 51, 58], "reject": 22, "rel": [0, 3, 4, 17, 19], "relat": [12, 39, 47, 51, 58, 62, 69, 70, 73], "relationship": [10, 76], "relax": 14, "releas": [12, 20, 31, 46, 47, 51, 53, 54, 70], "release_memory_occup": 21, "release_weights_occup": 21, "relev": [0, 12, 22, 23, 24, 34, 85], "reli": [47, 87], "reliabl": [3, 24, 25, 81], "reload": 12, "remain": [1, 12, 19, 64, 76, 84], "remax": 74, "rememb": [0, 22, 24, 38], "remind": [23, 24], "remot": [1, 14, 18, 19, 21, 22, 27, 28, 30, 32, 33, 35, 42, 53, 55, 56, 58, 60, 61, 69, 70, 73, 80, 84, 85, 86], "remote_inst": [18, 21], "remote_instance_weight_loader_backend": [20, 23, 24, 25, 26, 33, 34], "remote_instance_weight_loader_seed_instance_ip": [20, 23, 24, 25, 26, 33, 34], "remote_instance_weight_loader_seed_instance_service_port": [20, 23, 24, 25, 26, 33, 34], "remote_instance_weight_loader_send_weights_group_port": [20, 23, 24, 25, 26, 33, 34], "remote_instance_weight_loader_start_seed_via_transfer_engin": [20, 23, 24, 25, 26, 33, 34], "remov": [0, 7, 19, 22, 33, 34, 43, 48, 53, 54, 67, 87], "remove_work": 19, "renderd176": 50, "renderd184": 50, "renown": [24, 34], "reorder": [11, 27], "rep": 46, "repeat": [12, 26, 28, 30, 34, 42, 43, 48], "repetit": [37, 43], "repetition_penalti": [33, 43], "replac": [12, 21, 34, 51, 53, 54, 58, 60, 71, 75, 76, 87], "replai": [1, 46], "replay_request_dump": 13, "repli": [23, 24], "replic": [4, 6], "replica": [69, 70, 73], "repo": [19, 21, 22, 46, 47, 48, 81, 84], "repo_id": 87, "report": [9, 21, 28, 30, 42, 45, 46, 60, 64, 87], "repositori": [2, 6, 9, 33, 48, 54, 58, 59, 60], "repository_nam": 51, "repres": [10, 12, 20, 22, 23, 24, 25, 33, 34, 37, 38, 39, 44, 67, 76, 80], "represent": [21, 80], "reproduc": 37, "req": [21, 33, 45, 69, 76], "req_id": 76, "req_root_span": 76, "request": [0, 3, 4, 5, 6, 9, 10, 12, 14, 15, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 33, 37, 41, 43, 45, 46, 48, 52, 53, 55, 63, 64, 69, 70, 71, 73, 75, 79, 84, 87], "request_r": 45, "requestexcept": 33, "requir": [0, 1, 5, 6, 10, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 28, 31, 34, 41, 43, 45, 48, 51, 53, 54, 58, 64, 69, 76, 78, 79, 80, 85, 86, 87, 88], "require_reason": 24, "rerank": [19, 22, 52], "reranker_process": 33, "rerun": 47, "research": 81, "reserv": [4, 11, 12, 21], "resid": [10, 12, 19], "residu": 21, "resleas": 54, "resolut": [45, 84], "resolv": [0, 7, 14, 16, 27, 47, 64, 69, 80], "resolve_cal": 7, "resort": 78, "resourc": [5, 10, 14, 26, 47, 51, 59, 69, 70, 73, 74, 80, 87], "respect": [27, 37, 44, 76], "respond": [19, 25, 37], "respons": [4, 10, 12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 65, 80, 84, 85, 86], "response1": 33, "response2": 33, "response_cont": 23, "response_data": 23, "response_format": [23, 24], "response_json": [33, 85], "response_non_stream": [20, 25], "response_requir": 25, "response_sent_to_client_t": [23, 24, 33, 44], "response_specif": 25, "response_stream": [20, 25], "rest": [19, 24, 79], "restart": [27, 33, 48, 50, 69], "restartpolici": [69, 70, 73], "restor": [16, 21], "restrict": [24, 45], "result": [3, 10, 12, 14, 17, 20, 21, 23, 24, 27, 31, 33, 37, 38, 41, 45, 46, 47, 58, 60, 65, 78, 81, 84, 85, 86, 87], "resume_memory_occup": 21, "resume_weights_occup": 21, "retain": [30, 42], "reth0": 69, "reth2": 69, "reth4": 69, "reth6": 69, "retoken": 45, "retract": [11, 21, 63], "retracted_req": 11, "retri": 0, "retriev": [9, 10, 19, 80, 81, 85], "return": [7, 10, 19, 21, 23, 24, 25, 33, 43, 67, 78, 80, 87], "return_dict": [20, 23, 24, 25, 33], "return_hidden_st": 43, "return_logprob": [23, 24, 43], "return_tensor": 26, "return_text_in_logprob": 43, "reus": [0, 1, 9, 10, 16, 19, 21, 28, 41, 47, 87], "reusabl": 10, "reuter": 31, "rev": 69, "revis": [20, 21, 23, 24, 25, 26, 33, 34], "revolution": 34, "reward": [44, 52], "reward_process": 33, "rf": [51, 53], "rich": [24, 27, 29, 34], "rid": [12, 43, 70, 73, 76, 78], "right": [17, 22, 24, 37, 64, 67], "rigor": 47, "risen": 31, "risk": [11, 22, 34, 67], "rl": [3, 22, 74, 81, 84], "rl2": 74, "rl_on_policy_target": [20, 23, 24, 25, 26, 33, 34], "rl_quant_profil": [20, 23, 24, 25, 26, 33, 34], "rl_team": 74, "rlhf": [74, 86], "rlimit_nofil": 45, "rm": [50, 51, 53, 54, 59, 86], "rmsnorm": [21, 87], "roadmap": [3, 6, 12, 19, 27, 28, 32, 60, 68], "roar": 54, "robin": [21, 55, 73], "robust": [45, 80], "roce": [48, 53], "rocm": [1, 21, 28, 53], "rocm630": 50, "rodin": 34, "role": [19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 37, 39, 42, 43, 44, 67, 69, 70, 73, 79, 84], "role_end": 79, "rolebasedgroup": 73, "roll": [33, 53, 58, 69, 74], "rollingupd": 70, "rollingupdateconfigur": 70, "rollout": 74, "rolloutstrategi": 70, "roman": 37, "romant": 34, "rome": [23, 24, 37, 67], "roof": 67, "room": [15, 76], "root": [10, 23, 24, 28, 43, 46, 48, 51, 53, 54, 58, 69, 70, 73, 76, 77, 83, 87], "rope": 63, "rotari": 84, "roughli": [31, 64], "round": [21, 25, 45, 55, 73], "round_robin": [19, 20, 21, 23, 24, 25, 26, 33, 34], "rout": [6, 14, 19, 35, 45, 78, 81, 84], "router": [5, 6, 11, 21, 28, 46, 52, 55, 73, 74, 76], "router_log": 19, "routin": 67, "rst": 0, "rule": [11, 21, 26, 60], "run": [0, 1, 2, 3, 7, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 44, 45, 46, 48, 52, 54, 60, 61, 63, 64, 67, 69, 70, 71, 73, 75, 77, 83, 84, 87], "run_batch": 67, "run_ev": [28, 55], "run_llm": 87, "runnabl": 0, "runner": [1, 6, 21, 33, 63], "runner_allow_runasroot": 50, "runnerinput": 6, "runneroutput": 6, "runtim": [6, 12, 15, 16, 19, 33, 43, 46, 47, 51, 52, 59, 60, 61, 63, 84, 87], "runtime_vers": 60, "runtimeendpoint": [65, 67], "runtimeerror": 46, "rust": [19, 70, 78], "r\u00e9publiqu": 22, "s3": 10, "safe": [12, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "safetensor": [12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "sai": [22, 37, 67], "salt": 67, "same": [3, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 33, 37, 43, 46, 47, 60, 64, 67, 76, 78, 87], "sampl": [1, 7, 19, 27, 29, 33, 44, 45, 51, 52, 64, 84, 87], "sampler": 84, "sampling_backend": [20, 23, 24, 25, 26, 33, 34], "sampling_default": [20, 23, 24, 25, 26, 33, 34], "sampling_param": [3, 12, 16, 20, 23, 24, 25, 34, 43, 44, 79, 82, 87], "sampling_se": 3, "samplingparam": 43, "san": [23, 24, 25], "sandbox": 31, "saniti": 47, "satellit": 24, "satisfi": 24, "save": [2, 11, 16, 21, 33, 41, 46, 48, 58, 60, 64, 84], "save_dir": 16, "save_pretrain": 16, "saver": 21, "sbatch": 71, "sbin": 54, "scalabl": [5, 6, 58, 84], "scalar": [17, 86], "scale": [5, 6, 10, 14, 15, 16, 21, 27, 43, 45, 51, 72, 74, 81, 85], "scaling_factor": 17, "scaling_governor": 54, "scarc": [4, 12], "scatter": [21, 76], "scenario": [1, 3, 6, 9, 10, 12, 17, 21, 26, 27, 28, 70, 73, 84], "scene": [24, 26, 34, 84], "schedul": [5, 9, 10, 11, 22, 28, 33, 34, 38, 41, 45, 47, 52, 58, 60, 61, 63, 73, 76], "schedule_conserv": [20, 23, 24, 25, 26, 33, 34], "schedule_delay_milli": 63, "schedule_low_priority_values_first": [20, 23, 24, 25, 26, 33, 34], "schedule_polici": [20, 23, 24, 25, 26, 33, 34], "scheduler_output_processor_mixin": 47, "scheduler_recv_interv": [20, 23, 24, 25, 26, 33, 34], "schema": [12, 19, 21, 23, 24, 43, 67], "schema_get_current_d": [23, 24], "schema_get_current_weath": [23, 24], "scheme": [6, 10, 16], "scienc": [34, 81], "scontrol": 71, "scope": 19, "score": [28, 33, 85, 86, 87], "scout": [25, 26, 32, 81], "scrape": 75, "scratch": 84, "screenshot": 76, "script": [13, 16, 27, 28, 31, 34, 45, 46, 47, 48, 51, 53, 58, 59, 61, 63, 71, 78, 82, 87], "sdk": [51, 76], "sdpa": [1, 21], "seamless": [5, 6, 16, 78], "seamlessli": [9, 74], "search": [10, 21, 23, 24, 27, 28, 67, 80, 81, 84, 85], "seat": 34, "sec": [19, 21, 69, 73], "seccomp": 53, "second": [2, 12, 14, 18, 19, 20, 21, 22, 30, 39, 42, 44, 45, 47, 60, 63, 75, 81], "second_answ": 67, "secret": [19, 51, 53, 54, 58], "section": [6, 12, 14, 24, 26, 37, 43, 54, 64, 69, 70, 73, 75, 76, 84, 87], "secur": [21, 46, 53, 69], "securitycontext": [69, 70, 73], "see": [1, 6, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 27, 34, 35, 37, 38, 43, 44, 46, 51, 58, 60, 61, 64, 67, 69, 75, 84, 87, 88], "seed": [3, 18, 21, 37, 60], "seed_instance_ip": 18, "seed_instance_service_port": 18, "seem": [24, 25, 26, 37, 45], "seen": [32, 41], "segment": [21, 76], "sein": 34, "select": [1, 5, 7, 10, 16, 19, 21, 22, 28, 32, 34, 37, 43, 45, 51, 63, 70, 73], "select_expert": 6, "selector": [19, 69, 70, 73], "self": [6, 7, 34, 37, 38, 39, 43, 87, 88], "self_attn": 46, "semant": [80, 85], "send": [0, 11, 13, 15, 18, 19, 21, 23, 24, 39, 43, 45, 46, 52, 53, 64, 71, 76, 84], "send_on": 46, "send_weights_nccl_group_ports_list": 18, "sender": 76, "sens": [24, 34], "sensetim": 81, "sensit": [10, 12, 19], "sent": [24, 45, 58, 61], "sentenc": [24, 31, 37, 39, 43], "sep": 62, "sep_styl": 62, "separ": [2, 5, 12, 14, 20, 21, 22, 23, 24, 25, 33, 37, 38, 39, 44, 46, 47, 60, 67, 70, 76, 84], "separate_reason": [20, 37], "separate_reasoning_data": 20, "separate_reasoning_response_json": 20, "seq": [28, 33, 69], "sequenc": [5, 10, 12, 14, 15, 17, 21, 22, 27, 37, 43, 46, 60, 86], "sequenti": 70, "seri": [20, 24, 25, 27, 58, 61, 81, 86], "serial": [19, 43], "serv": [0, 6, 10, 19, 24, 26, 27, 28, 29, 32, 33, 34, 37, 41, 46, 51, 52, 69, 71, 74, 80, 85], "served_model_nam": [20, 23, 24, 25, 26, 33, 34], "server": [0, 5, 9, 10, 11, 12, 13, 16, 17, 18, 22, 23, 24, 27, 28, 29, 31, 34, 41, 43, 45, 47, 48, 51, 52, 53, 54, 59, 60, 62, 63, 69, 71, 75, 76, 77, 78, 79, 83, 87], "server_address": 28, "server_arg": [7, 12, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67, 87], "server_info": 33, "server_ip": 69, "server_nam": 76, "server_process": [12, 20, 22, 23, 24, 25, 33, 37, 44, 67], "server_process_tool_choic": 25, "server_typ": 28, "serverarg": [7, 20, 23, 24, 25, 26, 33, 34], "servic": [5, 18, 21, 26, 31, 34, 37, 38, 39, 46, 51, 58, 69, 73, 75, 78], "service_nam": 19, "service_ti": [22, 25, 37, 44], "servicenow": 81, "serving_classifi": 78, "session": [19, 25, 46, 76], "set": [1, 4, 6, 9, 10, 11, 12, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 51, 55, 58, 59, 60, 61, 62, 63, 64, 67, 69, 71, 75, 76, 77, 79, 80, 82, 83, 84, 86, 87, 88], "set_default_backend": 67, "setup": [6, 14, 21, 37, 46, 51, 52, 58, 60, 67, 69, 85], "setup_rocm": 53, "setuptool": [58, 61], "sever": [10, 16, 18, 33, 43, 46, 58, 87], "sft": 74, "sgl": [4, 9, 16, 20, 21, 23, 24, 25, 26, 28, 30, 31, 33, 34, 39, 42, 43, 48, 49, 50, 51, 53, 54, 58, 60, 61, 65, 67, 68, 70, 71, 73, 76, 78, 79, 81, 82, 84, 87], "sgl_": 63, "sgl_cach": 70, "sgl_cache1": 70, "sgl_cache4": 73, "sgl_dg_use_nvrtc": 63, "sgl_disable_tp_memory_inbalance_check": 63, "sgl_enable_jit_deepgemm": 73, "sgl_jax": 60, "sgl_router_active_work": 19, "sgl_router_cache_hits_tot": 19, "sgl_router_generate_duration_second": 19, "sgl_router_processed_requests_tot": 19, "sgl_router_requests_tot": 19, "sgl_router_running_request": 19, "sgl_use_deepgemm_bmm": 63, "sglang": [1, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 26, 31, 34, 37, 38, 39, 40, 43, 44, 45, 49, 50, 55, 56, 57, 58, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "sglang_": 63, "sglang_allow_overwrite_longer_context_len": 63, "sglang_block_nonzero_rank_children": 63, "sglang_chunked_prefix_cache_threshold": [63, 70], "sglang_ci_small_kv_s": 63, "sglang_clip_max_new_tokens_estim": 63, "sglang_cpu_omp_threads_bind": 58, "sglang_cutlass_mo": 63, "sglang_debug_memory_pool": 63, "sglang_deepep_bf16_dispatch": [56, 63], "sglang_deepep_ll_combine_send_num_sm": 63, "sglang_deepep_num_max_dispatch_tokens_per_rank": [55, 56, 63], "sglang_detokenizer_max_st": 63, "sglang_dev": 48, "sglang_dg_cache_dir": 63, "sglang_disable_consecutive_prefill_overlap": 63, "sglang_disable_fa4_warmup": 63, "sglang_disable_outlines_disk_cach": 63, "sglang_disable_request_log": 63, "sglang_disaggregation_bootstrap_timeout": [14, 73], "sglang_disaggregation_heartbeat_interv": 14, "sglang_disaggregation_heartbeat_max_failur": 14, "sglang_disaggregation_queue_s": 14, "sglang_disaggregation_thread_pool_s": 14, "sglang_disaggregation_waiting_timeout": [14, 73], "sglang_dynamic_chunking_smooth_factor": 15, "sglang_enable_flashinfer_fp8_gemm": [21, 63], "sglang_enable_jit_deepgemm": [27, 63, 70], "sglang_enable_overlap_plan_stream": [55, 56], "sglang_enable_spec_v2": [22, 28, 55, 56], "sglang_enable_torch_compil": 63, "sglang_enable_torch_inference_mod": 63, "sglang_eplb_heatmap_collection_interv": 63, "sglang_flashinfer_fp4_gemm_backend": 63, "sglang_force_fp8_marlin": 63, "sglang_forward_unknown_tool": 63, "sglang_fused_mla_enable_rope_fus": 63, "sglang_hack_deepep_new_mod": 70, "sglang_hack_deepep_num_sm": 70, "sglang_health_check_timeout": 63, "sglang_host_ip": 63, "sglang_imag": 53, "sglang_in_deepgemm_precompile_stag": 63, "sglang_int4_weight": 63, "sglang_is_first_rank_on_nod": 63, "sglang_is_flashinfer_avail": 63, "sglang_is_in_ci": [50, 63], "sglang_is_in_ci_amd": 63, "sglang_jit_deepgemm_compile_work": 63, "sglang_jit_deepgemm_precompil": 63, "sglang_logging_config_path": 63, "sglang_mm_precompute_hash": 63, "sglang_moe_nvfp4_dispatch": 63, "sglang_moe_pad": 63, "sglang_mooncake_custom_mem_pool": 14, "sglang_mooncake_trans_thread": 70, "sglang_npu": 54, "sglang_npu_use_mlapo": 55, "sglang_nvfp4_ckpt_fp8_gemm_in_attn": 63, "sglang_one_visible_device_per_process": 63, "sglang_otlp_exporter_max_export_batch_s": [63, 76], "sglang_otlp_exporter_schedule_delay_milli": [63, 76], "sglang_per_token_group_quant_8bit_v2": 63, "sglang_port": 63, "sglang_pp_layer_partit": 63, "sglang_profile_record_shap": 63, "sglang_profile_with_stack": [46, 63], "sglang_random": 45, "sglang_record_step_tim": 63, "sglang_request_dump": 13, "sglang_rout": [5, 14, 19, 21, 28, 46, 55, 70, 73, 76], "sglang_scheduler_max_recv_per_pol": 63, "sglang_scheduler_recv_skipper_weight_decod": 63, "sglang_scheduler_recv_skipper_weight_default": 63, "sglang_scheduler_recv_skipper_weight_non": 63, "sglang_scheduler_recv_skipper_weight_verifi": 63, "sglang_server_host": 75, "sglang_set_cpu_affin": [56, 63, 70, 73], "sglang_skip_p2p_check": 63, "sglang_skip_sgl_kernel_version_check": 73, "sglang_storag": [20, 21, 23, 24, 25, 26, 33, 34], "sglang_support_cutlass_block_fp8": [21, 63], "sglang_test_request_time_stat": 63, "sglang_test_retract": 63, "sglang_test_retract_no_prefill_b": 63, "sglang_tool_strict_level": 63, "sglang_torch_profiler_dir": [45, 46, 63], "sglang_use_ait": 63, "sglang_use_cpu_engin": 58, "sglang_use_cuda_ipc_transport": [30, 42], "sglang_use_custom_triton_kernel_cach": 63, "sglang_use_fia_nz": 55, "sglang_use_modelscop": [45, 63, 83], "sglang_vlm_cache_size_mb": [30, 42], "sglang_wait_weights_ready_timeout": 63, "sglang_zhync": 48, "sglangtracepropagatecontext": 76, "sglangtracereqcontext": 76, "sglangtracethreadcontext": 76, "sglroutertestatp_high": 19, "sgmv": 12, "sh": [0, 49, 51, 53, 58, 59, 73], "shakhizat": 59, "shape": [7, 12, 16, 26, 34, 43, 46, 63], "shard": [12, 14, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67], "sharded_st": 21, "share": [1, 6, 9, 10, 11, 12, 14, 17, 19, 21, 23, 24, 30, 31, 34, 42, 45, 47, 50, 55, 60, 68, 69, 70, 74, 76], "sharegpt": [45, 46], "sharpli": 31, "shell": [38, 39, 44, 46, 48], "shift": 34, "ship": [19, 77], "shirt": 67, "shm": [21, 48, 50, 51, 53, 54, 58, 69, 70, 73], "shop": 67, "short": [21, 28, 31, 34, 37, 43, 45, 87], "shorter": 65, "shortest": 19, "shortest_queu": 21, "shorthand": 21, "shot": [25, 28, 47, 48], "should": [3, 10, 11, 12, 15, 17, 21, 22, 24, 25, 27, 28, 29, 31, 34, 37, 46, 48, 58, 62, 69, 70, 75, 76, 87], "show": [2, 3, 12, 17, 21, 24, 25, 26, 28, 31, 34, 35, 37, 39, 53, 54, 67, 69, 71, 84], "show_time_cost": [20, 23, 24, 25, 26, 33, 34], "showcas": 71, "shown": [1, 12, 25, 26, 34, 46, 53, 79], "shuffl": 6, "shutdown": [20, 23, 24, 25, 26, 34, 87], "side": [12, 21, 46, 67, 78, 84], "sidewalk": 26, "sig": [69, 70, 73], "sigmoid": 33, "sign": [17, 26], "signal": 31, "signatur": [7, 87], "signific": [2, 4, 6, 14, 15, 17, 24, 27, 34, 47, 64, 67, 81], "significantli": [2, 10, 15, 18, 28, 30, 42, 51, 55, 60], "silent": 22, "silu": 63, "siluandmul": 87, "similar": [1, 33, 37, 43, 87], "similarli": [10, 58, 64, 81, 87], "simpl": [10, 11, 16, 17, 20, 22, 26, 28, 34, 35, 67, 69, 87], "simplenamespac": 55, "simpler": [17, 46], "simpli": [16, 23, 33, 51, 65, 80, 85], "simplifi": [6, 27, 46, 60], "simul": 6, "simultan": [14, 15, 60], "sinc": [4, 10, 12, 24, 25, 31, 32, 41, 47], "singl": [3, 10, 17, 19, 21, 25, 26, 27, 28, 37, 43, 46, 47, 51, 52, 53, 58, 60, 63, 71, 87], "singleprocess": 22, "site": 34, "situat": 67, "size": [1, 2, 3, 4, 6, 9, 10, 12, 14, 16, 17, 19, 21, 26, 27, 28, 29, 30, 33, 41, 42, 45, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 69, 70, 71, 73, 80, 81, 82, 84, 85, 86], "sk": [31, 45, 50], "skew": 43, "skill": 28, "skip": [0, 7, 16, 21, 33, 45, 46, 48, 53, 60, 63, 77], "skip_server_warmup": [20, 23, 24, 25, 26, 33, 34], "skip_special_token": [20, 25, 33, 43], "skip_tokenizer_init": [20, 23, 24, 25, 26, 33, 34], "skipper": 63, "sky": [51, 60], "skyserv": 51, "skywork": [33, 52, 86], "slack": [9, 47, 60, 68], "slash": 47, "sleep": [2, 21, 50, 71, 74], "sleep_on_idl": [20, 23, 24, 25, 26, 33, 34], "slice_span": 76, "slide": [1, 27, 60, 68, 74], "slight": 64, "slightli": [24, 37, 64], "slime": 74, "slo": 10, "slot": 12, "slow": [11, 17, 21, 64, 77], "slowdown": 45, "slower": [10, 79], "slowli": 11, "slurm_log": 71, "slurm_nodeid": 71, "slurm_nodelist": 71, "slurm_procid": 71, "slytherin": 67, "sm": [21, 63, 69], "sm10": 21, "sm100": [21, 28, 63], "sm75": 51, "sm90": [21, 28, 63], "sm_group_num": [20, 23, 24, 25, 26, 33, 34], "sm_sglang_": 51, "sm_sglang_input_argu": 51, "sm_sglang_model_path": 51, "sm_sglang_reasoning_pars": 51, "small": [0, 4, 10, 11, 15, 21, 22, 26, 27, 28, 46, 47, 63, 64, 81, 84], "small3": 81, "smaller": [10, 11, 12, 15, 17, 21, 47, 51, 60, 64, 86], "smallest": 43, "smart": 34, "smollm": 81, "smooth": [37, 38, 39, 47], "smoother": 21, "smoothli": 46, "snapshot": [19, 30, 33, 42, 87], "snapshot_download": 87, "snc": 58, "snippet": [25, 31, 46, 47], "snowplow": 26, "so": [0, 1, 7, 11, 12, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 39, 43, 44, 46, 47, 58, 67, 87], "societi": [34, 37], "socket": [2, 58, 69], "soft": 45, "soft_watchdog_timeout": [20, 23, 24, 25, 26, 33, 34], "softwar": 82, "solar": 81, "solut": [10, 20, 21, 51], "solv": [20, 34, 67], "some": [0, 1, 11, 15, 16, 24, 25, 26, 27, 28, 34, 37, 45, 46, 47, 48, 50, 69, 70, 75, 76, 80, 81, 85, 86, 87], "someon": [24, 67], "someth": [22, 24], "sometim": [13, 22, 33, 64, 69, 85], "soon": [16, 82, 84, 88], "sophist": 34, "sort": 43, "sota": 81, "sourc": [3, 14, 22, 23, 24, 31, 32, 43, 46, 52, 71, 75, 81, 84, 87], "south": 44, "space": [10, 29, 37, 41, 43, 45, 80, 83], "spaces_between_special_token": 43, "spain": [22, 37, 67], "spam": 47, "span": [10, 37, 46, 76, 81], "spark": [51, 52], "spars": [21, 28, 81], "sparseautomodelforcausallm": 16, "speak": 64, "spec": [1, 21, 22, 55, 60, 69, 70, 73, 78], "spec_nam": 7, "speci": [33, 85], "special": [6, 20, 24, 25, 28, 43, 78, 81, 82, 84, 86], "specif": [1, 7, 9, 10, 16, 17, 21, 24, 27, 34, 37, 43, 46, 47, 51, 61, 81, 82, 84], "specifi": [1, 3, 5, 6, 10, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 37, 38, 39, 42, 43, 44, 46, 50, 51, 53, 58, 60, 62, 65, 67, 75, 76, 80], "specific_funct": 25, "specul": [27, 28, 45, 52, 55, 56, 74], "speculative_accept_threshold_acc": [20, 23, 24, 25, 26, 33, 34], "speculative_accept_threshold_singl": [20, 23, 24, 25, 26, 33, 34], "speculative_algorithm": [20, 23, 24, 25, 26, 33, 34], "speculative_attention_mod": [20, 23, 24, 25, 26, 33, 34], "speculative_draft_attention_backend": [20, 23, 24, 25, 26, 33, 34], "speculative_draft_load_format": [20, 23, 24, 25, 26, 33, 34], "speculative_draft_model_path": [20, 22, 23, 24, 25, 26, 33, 34], "speculative_draft_model_quant": [20, 23, 24, 25, 26, 33, 34], "speculative_draft_model_revis": [20, 23, 24, 25, 26, 33, 34], "speculative_eagle_topk": [20, 22, 23, 24, 25, 26, 33, 34], "speculative_moe_a2a_backend": [20, 22, 23, 24, 25, 26, 33, 34], "speculative_moe_runner_backend": [20, 22, 23, 24, 25, 26, 33, 34], "speculative_ngram_branch_length": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_capac": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_match_typ": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_max_bfs_breadth": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_max_match_window_s": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_min_bfs_breadth": [20, 23, 24, 25, 26, 33, 34], "speculative_ngram_min_match_window_s": [20, 23, 24, 25, 26, 33, 34], "speculative_num_draft_token": [20, 21, 22, 23, 24, 25, 26, 33, 34], "speculative_num_step": [20, 22, 23, 24, 25, 26, 33, 34], "speculative_token_map": [20, 23, 24, 25, 26, 33, 34], "speech": 81, "speed": [10, 21, 22, 27, 28, 41, 45, 64, 69, 84], "speedup": [26, 27, 28, 74], "spell": 37, "spike": 6, "split": [1, 3, 6, 7, 10, 16, 19, 21, 24, 45, 47], "split_kv": 1, "spoken": 34, "spot": 60, "sql": [12, 37], "sqrt": 87, "squar": 87, "src": [19, 48, 73, 78], "srt": [1, 2, 13, 16, 19, 20, 26, 27, 29, 33, 43, 67, 70, 78, 81, 84, 87, 88], "srt_npu": 54, "srun": 71, "sse": [19, 31], "ssh": [35, 48], "ssm": [21, 41], "st": 51, "stabil": [6, 27, 28, 74], "stabilityai": 81, "stabl": [3, 37, 48, 53], "stablelm": 81, "stack": [19, 22, 46, 63, 73, 74, 75, 84], "stag": 67, "stage": [5, 6, 14, 15, 19, 21, 28, 47], "stai": [0, 15, 19, 61, 63, 67], "stand": [11, 21, 26, 39, 67], "standalon": [21, 22], "standard": [1, 3, 6, 7, 10, 20, 28, 37, 60, 69, 78, 87], "stanlei": 31, "star": 37, "starcod": 81, "starcoder2": 81, "start": [0, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 31, 33, 34, 37, 43, 44, 46, 47, 51, 53, 54, 58, 59, 60, 61, 67, 69, 75, 76, 83, 87], "start_expert_distribution_record": 33, "start_profil": 45, "start_step": 46, "start_tag": [23, 24], "startswith": [43, 44], "startup": [7, 12, 19, 21, 22, 28, 33, 48, 53, 60, 69, 70, 73, 82], "startuppolici": 70, "starvat": 12, "stat": [19, 21, 22, 33], "state": [7, 10, 11, 12, 19, 21, 22, 23, 24, 25, 27, 34, 37, 41, 43, 44, 47, 63, 67, 69, 74, 81], "statefulset": 51, "statement": [34, 87], "static": [6, 9, 14, 21, 22, 27, 28, 29, 30, 32, 42, 46, 55, 56, 59, 60, 64, 69, 70, 73], "static_config": 75, "statist": [6, 16, 19, 24, 45, 63], "statu": [19, 23, 24, 33, 34, 48, 51, 60, 67, 69, 75, 78], "status_cod": 12, "std": 45, "stdin": 51, "stdio": 19, "steadi": 11, "step": [0, 10, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 34, 41, 46, 47, 48, 51, 55, 56, 58, 60, 63, 69, 77, 87], "step3": [21, 25], "stick": 24, "still": [5, 11, 12, 14, 21, 24, 25, 28, 31, 33, 37, 70, 76], "stochast": 3, "stock": 31, "stop": [10, 11, 21, 22, 23, 24, 33, 37, 39, 43, 44, 46, 67, 75], "stop_after_first": 23, "stop_expert_distribution_record": 33, "stop_profil": 45, "stop_regex": 43, "stop_str": 62, "stop_token_id": 43, "storag": [17, 21], "store": [7, 9, 10, 19, 21, 41, 46, 76], "storefront": 26, "stori": [35, 37], "str": [7, 12, 19, 21, 23, 24, 25, 43, 87], "straightforward": [11, 22, 24, 34], "strateg": 6, "strategi": [10, 11, 12, 14, 15, 21, 41, 79], "strawberri": 37, "stream": [19, 21, 23, 24, 27, 35, 37, 79, 87], "stream_and_merg": 34, "stream_interv": [20, 23, 24, 25, 26, 33, 34], "stream_output": [20, 23, 24, 25, 26, 33, 34], "stream_reason": 20, "streamabl": 19, "streamlin": [16, 80], "streams_per_devic": [55, 56], "street": [26, 39, 67], "strength": 67, "strengthen": 67, "strict": [45, 63], "strictli": [12, 15, 21], "stride": 22, "string": [3, 7, 10, 11, 12, 21, 23, 24, 25, 26, 27, 33, 37, 43, 78], "strip": [43, 44], "strong": [6, 10, 31, 42, 65, 81, 84], "strongest": 10, "strongli": [6, 16, 37, 53], "structal": 43, "structur": [6, 10, 15, 19, 25, 52, 63, 67, 76, 84], "structural_tag": [23, 24, 43], "stuck": 69, "student": [24, 67], "studi": 34, "studio": 48, "style": [21, 22, 45, 67, 88], "styliz": 39, "sub": [27, 33, 58], "subclass": [6, 20], "subdirectori": 0, "subdomainpolici": 70, "submit": [11, 45, 47, 71], "submodul": 7, "suboptim": 5, "subprocess": [21, 38, 39, 44], "subsequ": [10, 60], "subset": 65, "substanti": [10, 14], "succe": 70, "succeed": 33, "success": [12, 19, 33, 34, 48, 53], "successfulli": [10, 12, 51, 54, 69, 75], "successor": 81, "successthreshold": 73, "sudo": [53, 54, 59], "suffici": [10, 11, 60, 84], "suffix": 47, "sugar": 67, "sugari": 67, "suggest": [9, 11, 16, 23, 24, 30, 34, 42, 55, 59], "suitabl": [10, 21, 85], "sum": [20, 31], "summar": [67, 79, 81, 84], "summari": [34, 45, 67], "sunni": 37, "super": [81, 87], "supercharg": 53, "superior": [60, 81], "suppli": [17, 19, 21, 27, 65], "support": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 19, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 41, 42, 43, 46, 47, 51, 57, 59, 61, 63, 65, 67, 69, 74], "sure": [0, 20, 22, 24, 25, 37, 44, 46, 47, 54, 67, 69, 87], "surg": 31, "surpass": 81, "surprisingli": 81, "surround": 37, "svc": [70, 73], "swa": 21, "swa_full_tokens_ratio": [20, 23, 24, 25, 26, 33, 34], "swa_siz": 21, "swappi": 54, "switch": [6, 9, 15, 21, 45, 51, 69, 88], "sy": [53, 54, 73], "symbolic_correct": 28, "symm": 21, "symmetr": 21, "sync": 48, "synchron": [9, 27, 47], "synonym": 19, "syntact": 21, "syntax": [12, 24, 37], "synthet": 45, "sys_ptrac": 53, "sysctl": 54, "system": [2, 6, 8, 9, 12, 14, 16, 21, 23, 24, 25, 26, 31, 34, 37, 43, 45, 58, 62, 63, 67, 69, 70, 73, 74, 75, 79, 81, 85, 87], "system_fingerprint": [22, 25, 37, 44], "systemat": 60, "systemcut": 23, "systemprompt": 9, "t": [1, 7, 15, 21, 22, 24, 25, 26, 28, 31, 32, 34, 35, 37, 43, 46, 47, 48, 51, 53, 54, 58, 63, 69, 84, 87], "t4": 51, "t_": 22, "t_2": 22, "tabl": [1, 3, 21, 34, 37, 58, 61, 79, 81, 84, 87], "tag": [7, 20, 21, 25, 35, 43, 47, 63], "tailor": [14, 30, 42], "taint": [70, 73], "take": [0, 1, 7, 11, 14, 16, 21, 22, 27, 33, 37, 46, 47, 48, 53, 58, 60, 69, 83, 87], "taken": 34, "tar": 48, "target": [1, 7, 12, 16, 21, 22, 31, 45, 46, 63, 75], "target_modul": 21, "target_pattern": 7, "targetport": [69, 70, 73], "task": [2, 17, 32, 34, 35, 37, 39, 47, 71, 78, 80, 81, 84, 85, 86], "task_queue_en": 55, "taxi": [26, 39, 67], "tbo": 21, "tbo_token_distribution_threshold": [20, 23, 24, 25, 26, 33, 34], "tcp": [14, 19, 55, 69, 70, 73], "tcpsocket": [69, 70], "teach": 34, "teacher": [34, 67], "team": [16, 27, 34, 48], "tech": 28, "technic": [12, 23, 74], "techniqu": [6, 10, 12, 16, 17, 21, 34, 60, 80], "technologi": [34, 69], "tee": [46, 54], "tele": 81, "teleai": 81, "tell": [3, 31, 34, 35, 37, 46, 75], "temp": 3, "temperatur": [12, 16, 20, 21, 22, 23, 24, 25, 27, 28, 33, 34, 37, 39, 43, 44, 45, 67, 79, 82, 87], "templat": [19, 20, 21, 27, 28, 32, 33, 37, 43, 45, 52, 70, 73, 80, 84, 85, 87], "tempor": 84, "temporari": 14, "temporarili": 19, "tenant": 19, "tend": 69, "tensor": [4, 7, 10, 11, 12, 17, 18, 30, 42, 46, 47, 52, 58, 60, 63, 69, 70, 73, 82, 84, 86, 87], "tensorrt": [6, 45], "term": [10, 21], "termin": [2, 9, 10, 12, 20, 22, 23, 24, 25, 30, 33, 37, 38, 39, 42, 44, 46, 48, 51, 53, 58, 61, 67], "terminate_process": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "terminu": 28, "test": [1, 2, 3, 12, 17, 20, 22, 23, 24, 25, 30, 31, 33, 34, 37, 38, 39, 42, 44, 46, 50, 58, 59, 67, 69, 71, 84], "test_classify_api": 78, "test_determinist": 3, "test_eagle_infer_a": 47, "test_eagle_infer_b": 47, "test_eval_accuracy_larg": 47, "test_generation_model": 87, "test_gpt_oss_1gpu": 47, "test_oth": 87, "test_vision_openai_server_": 87, "test_vision_openai_server_a": 87, "test_vision_openai_server_b": 87, "testgenerationmodel": 87, "text": [3, 4, 12, 16, 19, 20, 21, 22, 23, 24, 25, 26, 30, 34, 35, 37, 38, 39, 42, 43, 44, 45, 78, 79, 80, 81, 82, 84, 87], "text_complet": 37, "text_embed": 38, "text_input": 80, "text_it": 67, "text_qa": 67, "textual": [4, 87], "textur": 4, "th": 21, "than": [10, 11, 12, 14, 15, 16, 17, 21, 22, 34, 43, 47, 51, 58, 67, 83, 87], "thank": [22, 34, 47, 59, 69, 71], "theater": 34, "thei": [0, 7, 12, 14, 22, 24, 39, 43, 58, 63, 69, 75, 81, 84, 85, 86, 87], "them": [1, 4, 13, 16, 24, 27, 31, 33, 45, 47, 48, 53, 58, 63, 64, 70, 75, 76, 84, 87], "therebi": 10, "therefor": [10, 11, 12, 15, 20, 33, 34, 37], "thi": [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 55, 59, 60, 62, 63, 64, 65, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88], "thing": [11, 87, 88], "think": [3, 20, 21, 22, 24, 25, 28, 41, 70, 73, 79, 84], "think_end_token": 24, "thinking_budget": [27, 29], "third": [31, 37], "thorough": 22, "thoroughli": 87, "those": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "though": 15, "thought": 24, "thousand": 10, "thread": [12, 14, 20, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 67, 76], "thread_finish_flag": 76, "thread_label": 76, "thread_span": 76, "three": [1, 3, 5, 9, 10, 22, 23, 37, 43, 44, 67], "threshold": [10, 13, 19, 21, 28, 63, 79], "threshold_acc": 21, "through": [6, 10, 12, 19, 25, 26, 27, 28, 37, 45, 46, 47, 53, 54, 58, 60, 68, 84], "throughput": [4, 6, 12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 33, 37, 38, 39, 42, 44, 45, 47, 52, 64, 67, 74, 75, 81, 84, 85, 87], "thu": [15, 37, 48, 84, 87, 88], "thudm": 81, "thumb": 11, "thunlp": 22, "tier": [5, 9, 10, 19], "tightli": 5, "tiktoken": 37, "tile": 21, "tilelang": [21, 28], "time": [0, 1, 2, 6, 10, 11, 12, 14, 15, 16, 18, 21, 22, 23, 24, 27, 30, 33, 34, 37, 38, 42, 43, 45, 46, 47, 48, 58, 63, 64, 69, 71, 75, 87], "time_per_output_token_second": 75, "time_per_output_token_seconds_bucket": 75, "time_per_output_token_seconds_count": 75, "time_per_output_token_seconds_sum": 75, "time_to_first_token_second": 75, "time_to_first_token_seconds_bucket": 75, "time_to_first_token_seconds_count": 75, "time_to_first_token_seconds_sum": 75, "timelin": 46, "timeout": [9, 10, 14, 19, 21, 27, 30, 32, 42, 55, 56, 63, 73], "timeoutsecond": 73, "timestamp": [45, 78], "timestep": 22, "timezon": [23, 24], "tinyllama": 16, "tip": [0, 19, 64, 67], "tip_suggest": 67, "titl": [34, 87], "tl": 22, "tmp": [13, 21, 46, 50, 60, 63, 76], "tmp_autoround": 16, "tn": 19, "to_str": [27, 29, 43], "todai": [25, 27, 34, 37], "todo": 54, "togeth": [10, 12, 14, 16, 20, 21, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67, 84], "tok": 45, "token": [1, 5, 6, 10, 14, 15, 16, 17, 19, 20, 23, 24, 25, 29, 32, 38, 41, 43, 51, 53, 55, 56, 58, 60, 62, 63, 69, 70, 73, 75, 76, 78, 79, 81, 84, 87], "token_capac": 33, "token_id": [33, 37, 43], "token_ids_logprob": 43, "token_length_norm": 65, "token_usag": 75, "tokenization_result": 33, "tokenize_payload": 33, "tokenize_respons": 33, "tokenize_url": 33, "tokenizer_free_server_process": 33, "tokenizer_manag": 25, "tokenizer_metrics_allowed_custom_label": [20, 23, 24, 25, 26, 33, 34], "tokenizer_metrics_custom_labels_head": [20, 23, 24, 25, 26, 33, 34], "tokenizer_mod": [20, 23, 24, 25, 26, 33, 34], "tokenizer_path": [20, 23, 24, 25, 26, 33, 34], "tokenizer_worker_num": [20, 23, 24, 25, 26, 33, 34], "tokenizers_parallel": [23, 24, 38], "tokens_to_gener": 28, "tokyo": [12, 22, 25, 37, 67], "tokyo3": 67, "toler": [14, 17, 70, 73], "tolist": 26, "toml": [47, 49, 53, 54, 58, 61], "tone": 34, "too": [11, 12, 15, 27, 45, 47, 60], "tool": [7, 21, 23, 24, 27, 28, 29, 46, 51, 52, 67, 76, 81, 84], "tool_cal": [22, 25, 27, 37, 39, 44, 70, 73], "tool_call_id": 25, "tool_call_pars": [20, 23, 24, 25, 26, 33, 34], "tool_chat_template_deepseekv3": [25, 27], "tool_chat_template_deepseekv31": 25, "tool_chat_template_deepseekv32": 28, "tool_chat_template_llama4_python": 25, "tool_choic": 25, "tool_dict": 25, "tool_get_current_d": [23, 24], "tool_get_current_weath": [23, 24], "tool_nam": 25, "tool_serv": [20, 23, 24, 25, 26, 33, 34], "tool_to_cal": 25, "tool_us": 67, "toolcallitem": 25, "toolkit": [54, 59], "toolkit_aarch64_20251121": 54, "tools_tag_list": 25, "top": [10, 22, 25, 34, 43, 47, 74, 81], "top_k": [33, 43, 87], "top_logprobs_num": 43, "top_p": [16, 20, 21, 23, 24, 25, 28, 33, 34, 37, 43, 45, 82], "topic": 37, "topk": [1, 6, 21, 22, 27, 28, 29, 32, 41, 55, 56, 60], "topkoutput": 6, "topo": 73, "topologi": [19, 73], "torch": [1, 6, 11, 14, 21, 27, 33, 38, 46, 54, 58, 61, 63, 69, 87, 88], "torch_compile_caching_tutori": 77, "torch_compile_max_b": [20, 23, 24, 25, 26, 33, 34], "torch_dtyp": [16, 26], "torch_log": 22, "torch_n": [1, 21, 33, 80, 85], "torch_npu": 54, "torch_npu_vers": 54, "torchao": [16, 21, 61], "torchao_config": [20, 23, 24, 25, 26, 33, 34], "torchaudio": 61, "torchinductor_cache_dir": [21, 77], "torchinductor_root": 21, "torchrun": 2, "torchvis": [54, 58, 61], "torchvision_vers": 54, "total": [10, 11, 14, 15, 19, 20, 21, 28, 37, 45, 46, 58, 78, 81], "total_input_token": 45, "total_kv_token": 28, "total_output_token": 45, "total_q_token": 28, "total_retract": [23, 24, 33, 44], "total_token": [22, 25, 27, 37, 38, 39, 44, 70, 73, 78], "tour": 34, "tourist": [25, 34], "toward": [31, 34, 43, 84, 86], "towel": 67, "tower": [22, 24, 34], "town": 24, "tp": [1, 4, 6, 9, 10, 14, 15, 19, 21, 25, 27, 28, 29, 30, 31, 32, 37, 41, 42, 46, 48, 53, 55, 56, 58, 60, 61, 69, 70, 71, 73, 82, 86], "tp0": 69, "tp1": 69, "tp16": 71, "tp2": 69, "tp3": 69, "tp4": 69, "tp5": 69, "tp6": [58, 69], "tp7": 69, "tp8": 27, "tp_rank": 76, "tp_size": [6, 10, 12, 20, 23, 24, 25, 26, 28, 33, 34, 71, 82], "tpot": 45, "tpu": [51, 52], "tpu_vm": 60, "tpuv6": 60, "tqdm": 45, "tr": 46, "trace": [13, 19, 21, 22, 45, 52, 63, 69], "trace_context": 76, "trace_get_proc_propagate_context": 76, "trace_get_remote_propagate_context": 76, "trace_req_finish": 76, "trace_req_start": 76, "trace_set_proc_propagate_context": 76, "trace_set_remote_propagate_context": 76, "trace_set_thread_info": 76, "trace_slice_end": 76, "trace_slice_start": 76, "tracing_compos": 76, "track": [10, 19, 21, 28, 32, 33, 46, 76, 78], "trade": [6, 29, 31, 41, 80], "tradeoff": 21, "tradit": [9, 15], "tradition": 14, "traffic": [19, 34, 60, 75], "trail": 24, "train": [3, 16, 22, 25, 28, 33, 46, 52, 67, 80, 81, 84], "trajectori": 31, "transact": 34, "transfer": [2, 5, 6, 9, 12, 14, 18, 21, 48, 54, 55, 76], "transfer_engin": 18, "transferengin": 10, "transform": [4, 15, 16, 20, 21, 23, 24, 25, 26, 31, 33, 38, 45, 52, 62, 81, 84, 87], "transformersmodel": 88, "transit": [37, 38, 39], "translat": 34, "transport": [19, 30, 34, 42], "travel": [25, 67], "travers": 10, "treat": [33, 63], "treatment": 34, "tree": [19, 21, 22, 33, 60], "trend": [34, 87], "trial": 3, "trigger": [10, 21, 23, 24, 33, 46, 58, 63], "triggered_tag": 23, "trillion": 81, "trim": [25, 43], "trip": 25, "triton": [1, 3, 6, 12, 21, 27, 32, 33, 51, 58, 61, 63, 80, 85], "triton_3_5_1": 33, "triton_ascend": 54, "triton_attention_num_kv_split": [20, 23, 24, 25, 26, 33, 34], "triton_attention_reduce_in_fp32": [20, 23, 24, 25, 26, 33, 34], "triton_attention_split_tile_s": [20, 23, 24, 25, 26, 33, 34], "triton_attn": 21, "triton_backend": 1, "triton_kernel": [6, 21], "triton_mm_10": 22, "triton_mm_102": 22, "triton_mm_103": 22, "triton_mm_106": 22, "triton_mm_107": 22, "triton_mm_11": 22, "triton_mm_111": 22, "triton_mm_113": 22, "triton_mm_114": 22, "triton_mm_115": 22, "triton_mm_116": 22, "triton_mm_119": 22, "triton_mm_12": 22, "triton_mm_120": 22, "triton_mm_123": 22, "triton_mm_124": 22, "triton_mm_128": 22, "triton_mm_133": 22, "triton_mm_136": 22, "triton_mm_137": 22, "triton_mm_139": 22, "triton_mm_14": 22, "triton_mm_140": 22, "triton_mm_141": 22, "triton_mm_142": 22, "triton_mm_143": 22, "triton_mm_145": 22, "triton_mm_147": 22, "triton_mm_148": 22, "triton_mm_149": 22, "triton_mm_150": 22, "triton_mm_153": 22, "triton_mm_154": 22, "triton_mm_157": 22, "triton_mm_158": 22, "triton_mm_162": 22, "triton_mm_164": 22, "triton_mm_167": 22, "triton_mm_17": 22, "triton_mm_170": 22, "triton_mm_171": 22, "triton_mm_172": 22, "triton_mm_174": 22, "triton_mm_175": 22, "triton_mm_176": 22, "triton_mm_179": 22, "triton_mm_18": 22, "triton_mm_20": 22, "triton_mm_22": 22, "triton_mm_23": 22, "triton_mm_26": 22, "triton_mm_27": 22, "triton_mm_30": 22, "triton_mm_31": 22, "triton_mm_36": 22, "triton_mm_37": 22, "triton_mm_4": 22, "triton_mm_45": 22, "triton_mm_46": 22, "triton_mm_47": 22, "triton_mm_48": 22, "triton_mm_49": 22, "triton_mm_50": 22, "triton_mm_54": 22, "triton_mm_55": 22, "triton_mm_56": 22, "triton_mm_58": 22, "triton_mm_60": 22, "triton_mm_61": 22, "triton_mm_64": 22, "triton_mm_65": 22, "triton_mm_68": 22, "triton_mm_69": 22, "triton_mm_7": 22, "triton_mm_74": 22, "triton_mm_75": 22, "triton_mm_8": 22, "triton_mm_83": 22, "triton_mm_84": 22, "triton_mm_85": 22, "triton_mm_87": 22, "triton_mm_88": 22, "triton_mm_89": 22, "triton_mm_92": 22, "triton_mm_93": 22, "triton_mm_94": 22, "triton_mm_96": 22, "triton_mm_97": 22, "triton_mm_98": 22, "triton_mm_99": 22, "tritonrunnercor": 6, "trivial": [20, 21, 23, 24, 25, 26, 33, 34], "troubleshoot": [52, 69], "trt": [6, 28, 45], "trtllm": [1, 21, 27], "trtllm_mha": [1, 21, 32], "trtllm_mla": [1, 21], "true": [1, 6, 11, 12, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 56, 60, 63, 67, 69, 70, 73, 75, 76, 79, 80, 83, 87, 88], "truncat": [21, 22, 46, 80], "truss": 45, "trust": [1, 14, 21, 22, 27, 28, 30, 32, 42, 47, 48, 53, 55, 56, 58, 60, 61, 69, 70, 73, 74, 80, 84, 85, 86], "trust_remote_cod": [16, 20, 23, 24, 25, 26, 33, 34, 79, 88], "try": [7, 10, 16, 21, 27, 33, 47, 51, 54, 64, 67, 69], "tse": 21, "ttft": [4, 14, 15, 30, 45, 60, 87], "tune": [6, 10, 12, 15, 21, 22, 25, 28, 30, 42, 52, 53, 61, 70, 74, 77, 81, 86], "tuned_8sm": 70, "tunix": 74, "tunnel": [35, 48], "tupl": 7, "turbo": 37, "turn": [7, 9, 19, 27], "tutori": [23, 26, 37, 38, 39, 77], "twelv": 37, "twice": [10, 64], "twine": 49, "twitter": 68, "two": [1, 2, 4, 7, 9, 10, 11, 12, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 39, 41, 43, 48, 51, 62, 63, 64, 67, 69, 70, 71, 76, 87, 88], "txt": 0, "type": [3, 6, 7, 17, 19, 23, 24, 25, 26, 27, 30, 31, 33, 34, 38, 39, 42, 43, 44, 45, 46, 47, 48, 55, 60, 67, 70, 73, 75, 78, 79, 84, 87], "typic": [4, 5, 11, 12, 17, 20, 21, 22, 23, 24, 25, 27, 32, 33, 37, 38, 39, 44, 45, 47, 51, 54, 58, 60, 67, 69], "typo": 24, "u": [25, 31, 60, 65, 70, 74, 87], "ubuntu": [46, 58, 69], "ubuntu1804": 46, "ubuntu22": 50, "ucx": 14, "ud": 2, "ui": [46, 75, 76], "ultra": [10, 81], "unabl": 87, "uncach": 3, "uncertainti": 24, "unchang": 43, "unconditional_likelihood_norm": 65, "unconfin": 53, "under": [0, 5, 7, 10, 12, 21, 25, 46, 47, 60, 61, 64, 75, 81, 87], "understand": [0, 10, 24, 33, 34, 37, 47, 60, 76, 81, 84], "understood": [4, 34], "unesco": 34, "unexpect": 12, "unifi": [5, 6, 12, 19, 27, 37, 74], "uniform": [15, 19, 21], "unintend": 43, "union": [12, 21, 43], "uniqu": [3, 34, 67, 78], "unit": [12, 23, 24, 25, 34, 37, 44, 67], "unittest": [47, 87], "univers": 37, "unix": [2, 78], "unknown": 63, "unless": [19, 45], "unlik": [17, 22, 79], "unload": 12, "unload_lora_adapt": 12, "unlock": [6, 19], "unnecessari": 34, "unpermut": 6, "unpin": 12, "unrel": 10, "unrestrict": 43, "unset": [21, 55], "unsloth": 74, "unspecifi": [1, 21, 45], "unsur": [81, 84], "until": [11, 12, 27, 43, 46, 60, 71], "unus": 73, "unusu": 39, "up": [6, 10, 11, 14, 15, 18, 19, 21, 22, 24, 27, 31, 32, 33, 39, 46, 47, 51, 53, 58, 59, 61, 69, 74, 75, 76, 81], "up_proj": [12, 21], "upcast": 27, "upcom": [28, 31], "updat": [2, 9, 12, 15, 16, 19, 21, 25, 46, 50, 63, 64, 68, 75, 87], "update_weight": 33, "update_weights_from_disk": 33, "upgrad": [28, 50, 51, 53, 58, 61], "upload_pypi": 49, "upon": [10, 12, 33, 37, 38, 75, 76, 82, 84], "upper": 10, "upsid": 31, "upstag": 81, "upstream": 19, "upward": 31, "urban": [26, 39], "urgent": 47, "url": [5, 12, 13, 19, 21, 22, 26, 30, 31, 33, 39, 42, 43, 44, 45, 46, 54, 58, 60, 61, 75, 76, 80, 84, 85], "us": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 41, 42, 43, 45, 47, 50, 52, 62, 65, 67, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 82, 84, 86, 87, 88], "us_president_exampl": 65, "usabl": [16, 59, 81], "usag": [9, 19, 21, 22, 25, 26, 29, 33, 35, 38, 39, 43, 44, 47, 59, 60, 64, 65, 69, 70, 73], "use_fast": 26, "use_fast_accum": 22, "use_mla_backend": 33, "user": [3, 6, 10, 11, 12, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 35, 37, 39, 42, 43, 44, 46, 47, 58, 62, 65, 67, 70, 73, 74, 78, 80, 82, 84], "usernam": [51, 75], "userwarn": 22, "usr": [22, 51, 54, 58], "usual": [37, 51, 58, 75], "utf": [43, 44], "util": [4, 5, 6, 10, 11, 12, 15, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 43, 44, 53, 58, 60, 67, 69, 74, 80], "uuid": 19, "uv": [14, 31, 58, 60], "uv_config_fil": 58, "uvicorn": [33, 69], "v": [3, 6, 16, 33, 48, 50, 51, 53, 58, 61, 78, 83, 84, 87], "v0": [25, 32, 33, 50, 51, 53, 54, 69, 81, 86], "v01": 81, "v1": [12, 16, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 37, 38, 39, 42, 43, 44, 45, 69, 70, 73, 76, 78, 80, 81, 84, 85], "v1_5": 81, "v1alpha1": 73, "v2": [21, 33, 45, 60, 81, 84, 85], "v3": [1, 6, 14, 16, 20, 21, 25, 40, 48, 73, 81, 82, 84], "v32": 73, "v6e": 60, "v7": 60, "v_proj": [12, 21], "v_scale": 17, "valid": [0, 2, 3, 16, 21, 23, 24, 25, 28, 43, 46, 47, 53, 60, 63, 80], "valu": [5, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 37, 42, 43, 46, 47, 55, 58, 63, 64, 69, 70, 73, 79, 84], "valuabl": 87, "value1": [21, 25], "value2": [21, 25], "value_st": 88, "valueerror": [7, 33], "valuefrom": [70, 73], "var": [54, 73], "vari": [3, 17, 24, 45], "variabl": [9, 12, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 37, 38, 39, 44, 45, 46, 50, 51, 52, 58, 60, 67, 69, 75, 76, 82, 83, 87], "varianc": [6, 47], "variant": [6, 20, 46, 51, 81, 84, 86], "varieti": [1, 34, 67], "variou": [1, 10, 14, 16, 34, 37, 39, 63, 67], "varlen": 28, "vast": [37, 81], "ve": [24, 34, 69], "vector": [22, 27, 47, 80], "veget": 67, "vehicl": [26, 34], "vendor": 19, "venv": [58, 60], "verbos": [13, 21], "veri": [4, 11, 15, 24, 28, 30, 34, 39, 42, 43, 47, 64, 87], "verif": [1, 22, 28, 63], "verifi": [1, 2, 3, 12, 17, 21, 24, 33, 45, 53, 58, 59, 60, 61, 63, 75, 78], "verl": 74, "versatil": [81, 84], "version": [2, 21, 27, 33, 34, 41, 47, 48, 51, 58, 60, 61, 63, 67, 69, 82, 84], "via": [5, 6, 7, 12, 13, 14, 16, 17, 18, 19, 21, 28, 31, 33, 43, 45, 46, 47, 58, 60, 61, 75, 76, 79, 81, 84], "vibrant": [24, 52], "vice": 34, "vicuna": 84, "video": [21, 50, 53, 68], "video_data": 84, "video_url": [30, 42, 84], "view": [0, 25, 26, 69, 75, 76], "vigor": 67, "vim": 58, "virtual": [12, 20, 22, 23, 24, 25, 26, 28, 33, 34, 37, 38, 39, 44, 58, 67], "visibl": [26, 46, 63], "vision": [4, 5, 34, 36, 37, 42, 43, 44, 45, 52, 81, 84, 87, 88], "vision_end": 26, "vision_flat": 26, "vision_model": 26, "vision_process": 39, "vision_start": 26, "visionattent": 87, "visit": [16, 24, 60], "visual": [4, 26, 43, 46, 48, 76, 84], "visualstudio": 48, "vit": [4, 5, 30, 80, 84, 87], "vital": 6, "vitamin": 67, "vl": [4, 16, 25, 39, 40, 45, 46, 67, 80, 84], "vl2": 84, "vllm": [16, 45, 46, 78], "vlm": [4, 5, 16, 34, 45, 52, 74, 84, 87], "vlm1": 84, "vm": [53, 54, 60], "vocab": 21, "vocabulari": [21, 22], "volum": [48, 54, 69, 70, 73], "volumemount": [69, 70, 73], "vscode_cli_alpine_x64_cli": 48, "w": [22, 23, 24, 37, 43, 54, 67], "w2a16": 16, "w3a16": 16, "w4a16": 16, "w4a8": [27, 55], "w4a8_awq": 21, "w4afp8": 21, "w8a16": 16, "w8a8": [27, 55, 58], "w8a8_fp8": [16, 21], "w8a8_int8": [16, 21, 58], "w8a8fp8config": 16, "wa": [12, 15, 22, 24, 25, 31, 37, 46, 69, 78], "wai": [0, 2, 15, 24, 25, 26, 34, 37, 46, 61, 67, 87], "wait": [2, 9, 10, 19, 22, 24, 33, 37, 38, 39, 46, 47, 63, 67, 69, 70, 71, 75], "wait_complet": [9, 10, 21], "wait_for_serv": [12, 20, 22, 23, 24, 25, 33, 37, 38, 39, 44, 67], "wake": 74, "walk": [47, 67], "walkthrough": 87, "wall": [45, 79], "wallet": 19, "walnut": 67, "wan": 52, "wand": 67, "want": [7, 13, 16, 21, 22, 24, 25, 33, 34, 37, 43, 46, 47, 51, 54, 58, 69, 76, 77, 84, 87], "warmup": [20, 21, 23, 24, 25, 26, 33, 34, 45, 46, 58, 60, 63], "warmup_name1": 21, "warmup_name2": 21, "warn": [7, 11, 12, 17, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 38, 39, 44, 45, 67], "warn_onc": 22, "washington": [12, 37, 44], "watch": [19, 21], "watchdog": [21, 55, 56], "watchdog_timeout": [20, 23, 24, 25, 26, 33, 34], "water": 67, "watsonx": 81, "wave": [1, 21], "we": [0, 5, 12, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 44, 46, 47, 48, 53, 54, 58, 60, 64, 67, 69, 70, 74, 76, 83, 87, 88], "weather": [23, 24, 25, 27, 37], "web": [24, 75, 76], "web_search_preview": 31, "websit": 82, "week": [25, 47, 67], "weekli": 68, "weight": [2, 6, 11, 16, 18, 45, 46, 48, 50, 55, 56, 59, 63, 67, 87], "weight_load_func": 21, "weight_loader_disable_mmap": [20, 23, 24, 25, 26, 33, 34], "weight_vers": [20, 22, 23, 24, 25, 26, 33, 34, 37, 39, 44], "weightlift": 67, "weilin": 22, "welcom": [9, 47, 60, 62], "well": [10, 21, 24, 31, 34, 67, 81, 87], "were": [24, 37], "wget": [48, 54], "what": [7, 16, 20, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 39, 42, 44, 65, 67, 74, 80, 84, 85, 87, 88], "whatev": 24, "wheel": 47, "when": [0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 30, 32, 33, 34, 37, 41, 42, 43, 45, 46, 47, 48, 51, 53, 55, 58, 62, 63, 64, 75, 76, 78, 84, 87], "whenev": [46, 47], "where": [3, 6, 10, 12, 14, 17, 21, 23, 24, 25, 27, 28, 30, 34, 37, 42, 43, 46, 65, 67, 87], "wherea": 10, "whether": [1, 10, 21, 33, 43, 46, 47, 63, 76], "which": [0, 3, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 33, 37, 41, 43, 44, 45, 46, 47, 51, 54, 58, 60, 61, 62, 64, 69, 76, 78, 81, 87, 88], "while": [3, 4, 5, 6, 10, 11, 12, 14, 17, 19, 20, 21, 22, 23, 24, 25, 30, 33, 37, 38, 39, 44, 46, 50, 54, 63, 64, 67, 71, 81], "whitespac": 21, "whl": [14, 54, 58, 61], "who": [18, 33, 34, 37, 60], "whole": 67, "whose": 43, "wide": [10, 21, 24, 27, 34, 52], "widespread": 52, "width": [16, 17], "wild": 80, "window": [1, 19, 21, 26, 47, 60, 81], "wise": 6, "wish": 76, "with_stack": [46, 63], "within": [5, 6, 10, 12, 14, 16, 17, 19, 21, 22, 24, 26, 28, 37, 47, 48, 51, 61, 67, 69, 75, 76], "without": [1, 6, 10, 17, 19, 21, 22, 28, 33, 34, 37, 46, 47, 60, 67, 87], "won": [1, 15, 87], "wonder": 24, "wood": 67, "word": [37, 43, 67], "work": [1, 9, 16, 24, 25, 28, 34, 43, 47, 50, 54, 62, 63, 69, 70, 73, 74, 78, 88], "workaround": [14, 46], "worker": [2, 14, 21, 27, 55, 60, 63, 69, 70, 73], "worker1": 19, "worker2": 19, "worker_id": 19, "worker_typ": 19, "workertempl": [69, 70], "workflow": [19, 33, 45, 47, 74, 81], "workload": [5, 10, 11, 12, 17, 19, 22, 27, 29, 30, 41, 42, 45, 46, 53, 60, 69, 73, 81], "workspac": [48, 70, 73], "world": [21, 24, 34, 44, 81], "worldwid": 52, "would": [12, 22, 23, 24, 25, 46, 58, 76], "wrap": [22, 24, 45], "wrapper": [1, 21, 22], "write": [0, 1, 9, 21, 24, 34, 37, 43, 79, 87], "write_back": [10, 21], "write_through": [9, 10, 20, 21, 23, 24, 25, 26, 33, 34], "write_through_select": [10, 21], "written": [10, 28, 70], "wrong": 33, "www": 68, "x": [19, 20, 21, 23, 24, 25, 26, 33, 34, 46, 54, 58, 68, 69, 70, 73, 79, 80, 81, 87], "x1": [70, 73], "x64": 50, "x86_64": [46, 54, 58], "x_": 71, "xai": [19, 81], "xeon": [27, 51, 52, 58], "xf": 48, "xgrammar": [20, 21, 23, 24, 25, 26, 33, 34, 43, 61, 71], "xiaomi": [22, 81, 84], "xiaomimimo": [22, 81, 84], "xml": 19, "xpu": [1, 21, 32, 51, 52], "xvers": 81, "xx": [14, 55], "xxx": [9, 14, 50], "xxxx": 14, "xxxxx": 46, "xxxxxx": 25, "y": [0, 28, 37, 46, 50, 61], "yaml": [21, 51, 60, 69, 70, 75, 76, 79], "ye": [3, 22, 37, 63, 70, 73], "yeah": [22, 24, 37], "year": [24, 31, 34, 37], "yearli": 24, "yellow": [26, 39, 67], "yet": [12, 45, 69, 84], "yield": [6, 10], "yieldoper": 6, "yml": [47, 51, 73], "york": [23, 24, 25, 26], "you": [0, 1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 73, 74, 75, 77, 78, 80, 81, 83, 84, 87, 88], "your": [0, 1, 3, 9, 11, 12, 16, 17, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 37, 38, 39, 44, 45, 46, 47, 48, 51, 53, 58, 60, 61, 64, 67, 69, 70, 71, 73, 74, 75, 76, 82, 84, 87], "your_aws_account": 51, "your_aws_region": 51, "your_exa_kei": 31, "your_image_tag": 51, "your_model_path": 75, "your_module_path": 9, "your_repository_nam": 51, "your_user_nam": 47, "yourhicacheclassnam": 9, "yourkei": 45, "yourself": 34, "yuanxiang": 81, "yum": 69, "z": 71, "zai": [25, 29, 30, 84], "zealand": 37, "zero": [9, 10, 16, 18, 25, 52, 63, 74], "zhao": 22, "zhipu": 81, "zhipuai": 81, "zhousx": 22, "zip": [23, 24, 34, 82, 87], "zmq": 76, "zmq_to_schedul": [5, 20, 23, 24, 25, 26, 33, 34], "zmq_to_token": 5, "zsh": 48, "\u00e9lys\u00e9": 22, "\u4e0d\u8fc7\u8981\u63a7\u5236\u8868\u60c5\u7b26\u53f7\u6570\u91cf": [70, 73], "\u4e5f\u53ef\u80fd\u662f\u60f3\u786e\u8ba4\u6211\u7684\u8eab\u4efd\u548c\u529f\u80fd\u8303\u56f4": [70, 73], "\u4f60\u53ef\u4ee5\u628a\u6211\u5f53\u6210\u4e00\u4e2a\u77e5\u8bc6\u4e30\u5bcc": [70, 73], "\u4f60\u662f\u8c01": [70, 73], "\u521a\u597d\u80fd\u4e2d\u548cai\u7684\u673a\u68b0\u611f": [70, 73], "\u529f\u80fd\u5b9a\u4f4d": [70, 73], "\u53c8\u80fd\u907f\u514d\u8ba9\u7528\u6237\u9762\u5bf9\u7a7a\u767d\u8f93\u5165\u6846\u65f6\u4e0d\u77e5\u6240\u63aa": [70, 73], "\u540c\u65f6\u7a81\u51fa\u5b9e\u7528\u4ef7\u503c\u6765\u964d\u4f4e\u964c\u751f\u611f": [70, 73], "\u540d\u5b57\u53eb": [70, 73], "\u5b66\u4e60": [70, 73], "\u5de5\u4f5c": [70, 73], "\u5e94\u8be5\u7528\u7b80\u4f53\u4e2d\u6587\u56de\u590d": [70, 73], "\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b": [70, 73], "\u6211\u662f\u4f60\u7684ai\u52a9\u624b": [70, 73], "\u65e2\u80fd\u4e86\u89e3\u9700\u6c42": [70, 73], "\u670d\u52a1\u8303\u56f4": [70, 73], "\u6df1\u5ea6\u6c42\u7d22": [70, 73], "\u751f\u6d3b": [70, 73], "\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u5f88\u57fa\u7840\u7684\u81ea\u6211\u4ecb\u7ecd\u95ee\u9898": [70, 73], "\u7531\u6df1\u5ea6\u6c42\u7d22\u516c\u53f8": [70, 73], "\u7ed3\u5c3e\u7528\u5f00\u653e\u6027\u95ee\u9898\u5f15\u5bfc\u5bf9\u8bdd\u5f88\u5173\u952e": [70, 73], "\u89e3\u7b54\u95ee\u9898": [70, 73], "\u8bed\u6c14\u7b80\u6d01\u4e2d\u6027": [70, 73], "\u8eab\u4efd\u5f52\u5c5e": [70, 73], "\u8fd9\u53ef\u80fd\u662f\u7b2c\u4e00\u6b21\u4e92\u52a8\u65f6\u7684\u5e38\u89c4\u5f00\u573a\u767d": [70, 73], "\u8fd9\u79cd\u573a\u666f\u4e0b\u65b0\u7528\u6237\u7684\u53ef\u80fd\u6027\u8f83\u9ad8": [70, 73], "\u907f\u514d\u663e\u5f97\u8f7b\u6d6e": [70, 73], "\u90a3\u4e2a\u7b11\u8138\u8868\u60c5": [70, 73], "\u91cd\u70b9\u8981\u8bf4\u660e\u4e09\u70b9": [70, 73], "\u9664\u975e": 22, "\u968f\u53eb\u968f\u5230\u7684\u5c0f\u5e2e\u624b": [70, 73], "\u9700\u8981\u7ed9\u51fa\u6e05\u6670\u53cb\u597d\u7684\u81ea\u6211\u4ecb\u7ecd": [70, 73]}, "titles": ["SGLang Documentation", "Attention Backend", "Checkpoint Engine Integration", "Deterministic Inference", "DP for Multi-Modal Encoder in SGLang", "EPD Disaggregation", "Expert Parallelism", "Model Hooks", "Hierarchical KV Caching (HiCache)", "SGLang HiCache Best Practices", "HiCache System Design and Optimization", "Hyperparameter Tuning", "LoRA Serving", "Observability", "PD Disaggregation", "Pipeline Parallelism for Long Context", "Quantization", "Quantized KV Cache", "R-Fork", "SGLang Model Gateway (formerly SGLang Router)", "Reasoning Parser", "Server Arguments", "Speculative Decoding", "Structured Outputs", "Structured Outputs For Reasoning Models", "Tool Parser", "Query VLM with Offline Engine", "DeepSeek V3/V3.1/R1 Usage", "DeepSeek V3.2 Usage", "Launch GLM-4.5 / GLM-4.6 / GLM-4.7 with SGLang", "GLM-4.6V / GLM-4.5V Usage", "GPT OSS Usage", "Llama4 Usage", "SGLang Native APIs", "Offline Engine API", "Ollama-Compatible API", "OpenAI-Compatible APIs", "OpenAI APIs - Completions", "OpenAI APIs - Embedding", "OpenAI APIs - Vision", "Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, Qwen, and more)", "Qwen3-Next Usage", "Qwen3-VL Usage", "Sampling Parameters", "Sending Requests", "Bench Serving Guide", "Benchmark and Profiling", "Contribution Guide", "Development Guide Using Docker", "PyPI Package Release Process", "Set Up Self-Hosted Runners for GitHub Action", "Install SGLang", "SGLang Documentation", "AMD GPUs", "SGLang installation with NPUs support", "DeepSeek examples", "Qwen3 examples", "Ascend NPUs", "CPU Servers", "NVIDIA Jetson Orin", "TPU", "XPU", "Custom Chat Template", "Environment Variables", "Troubleshooting and Frequently Asked Questions", "Choices Methods in SGLang", "Frontend Language", "SGLang Frontend Language", "Learn More and Join the Community", "Deploy On Kubernetes", "LWS Based PD Deploy", "Multi-Node Deployment", "Multi-Node Deployment", "DeepSeekV32-Exp RBG Based PD Deploy", "Post-Training Integration", "Production Metrics", "Production Request Tracing", "Enabling cache for torch.compile", "Classification API", "Diffusion Language Models", "Embedding Models", "Large Language Models", "MindSpore Models", "Use Models From ModelScope", "Multimodal Language Models", "Rerank Models", "Reward Models", "How to Support New Models", "Transformers fallback in SGLang"], "titleterms": {"": [3, 87], "0": [3, 64, 70, 73], "1": [26, 27, 35, 48, 50, 51, 53, 54, 55, 56, 58, 60, 70, 71, 73, 80], "16": 2, "2": [2, 22, 25, 26, 28, 35, 48, 50, 51, 54, 55, 58, 60, 70, 73, 80], "2025": 28, "235b": 56, "2507": 56, "3": [22, 25, 26, 35, 50, 51, 58, 60, 71], "30b": [3, 56], "32b": 56, "3b": 58, "4": [25, 26, 29, 30, 32, 51, 55, 60], "405b": 71, "5": [26, 29, 51], "5v": 30, "6": [29, 51], "6v": 30, "7": [29, 51], "7b": 60, "8": 27, "800i": [55, 56], "8b": [3, 56, 60], "A": [33, 37, 38, 39, 44, 67], "For": [21, 24, 26], "In": [46, 73], "On": 69, "One": 73, "The": [3, 64], "With": 51, "a22b": 56, "a3": [55, 56], "a3b": [3, 56], "about": 15, "abov": [30, 42], "access": 64, "accuraci": [17, 28, 32, 47], "achiev": 11, "action": 50, "adapt": 37, "adaptor": [12, 54], "add": [1, 47, 50, 76, 87], "adjust": 11, "adopt": 74, "advanc": [14, 16, 19, 34, 48, 52, 60, 63], "aim": 28, "all": [6, 73], "amd": 53, "an": 87, "api": [12, 16, 19, 20, 21, 23, 24, 25, 26, 31, 33, 34, 35, 36, 37, 38, 39, 44, 46, 78], "approach": 26, "ar": [64, 75], "architectur": [2, 10, 19], "area": 60, "arg": 21, "argument": [3, 12, 21], "ascend": [14, 54, 57], "ask": 64, "async": 15, "asynchron": 34, "asyncio": 34, "atla": [55, 56], "attent": [1, 21, 27, 60], "authent": [19, 45], "auto": [16, 53], "automat": 48, "avail": 16, "avoid": 11, "aw": 51, "awar": 19, "b": 11, "back": [10, 25], "backend": [1, 3, 6, 9, 10, 12, 18, 19, 21, 25, 45, 60], "balanc": [6, 19, 53, 54], "base": [15, 70, 73], "basic": [3, 26, 37, 52, 60, 67, 69], "batch": [6, 11, 34, 67], "behavior": [3, 7, 20], "being": 75, "bench": 45, "bench_offline_throughput": 46, "bench_serv": 46, "benchmark": [28, 32, 46, 47, 58, 60, 61, 63, 87], "benefit": [2, 16], "best": [9, 15, 17], "bf16": [30, 42], "bia": 37, "block": 27, "breaker": 19, "budget": [27, 29, 30], "bug": 46, "build": [28, 47], "built": 31, "cach": [8, 11, 17, 19, 21, 33, 41, 63, 77], "call": [25, 26, 27, 28, 63], "cann": 54, "capabl": 80, "capac": 11, "captur": 33, "case": 69, "caus": 3, "chat": [25, 37, 62], "check": [33, 75], "checkpoint": 2, "choic": [25, 65], "choos": [12, 45], "chunk": [11, 15, 60], "ci": [47, 63], "circuit": 19, "class": 78, "classif": 78, "classifi": 33, "cli": 35, "client": [25, 38, 39, 44, 79, 80, 85], "clone": 47, "cloud": [51, 60], "co": 19, "code": [47, 49, 79, 88], "collabor": 74, "collect": 75, "command": [1, 4, 21, 30, 42, 46, 58, 79, 81, 84, 85, 86, 88], "commit": 47, "common": [21, 51], "commun": [6, 9, 15, 68, 82], "comparison": 60, "compat": [12, 20, 23, 24, 25, 35, 36, 54, 78], "compil": [22, 60, 77], "complet": 37, "complex": [67, 76], "compos": 51, "comprehens": 60, "compressor": 16, "comput": [6, 63], "concurr": 45, "config": [7, 50], "configur": [2, 3, 7, 9, 14, 19, 21, 28, 29, 32, 37, 41, 50, 53, 60, 63, 75, 79], "connect": 60, "connector": 19, "consider": [17, 46], "constrain": [43, 67], "contain": [48, 50, 59], "content": [19, 27], "context": [15, 28], "contribut": [47, 60], "control": [11, 19, 67], "core": [9, 19, 43], "cpu": [54, 58], "crash": 13, "creat": 70, "cross": 33, "cuda": [11, 64], "curl": [38, 39, 44, 78], "current": 25, "custom": [9, 21, 26, 43, 60, 62], "customop": 54, "data": [10, 19, 21, 27], "dataset": 45, "debug": [21, 48, 63, 69, 82, 87], "debugg": 48, "decod": [1, 14, 19, 21, 22, 29, 32, 41, 43, 46, 60, 67, 70], "deepep": [54, 63], "deepgemm": 63, "deepseek": [14, 27, 28, 37, 40, 53, 55, 58, 71], "deepseekv32": 73, "default": [3, 43, 48], "defin": 25, "demo": 31, "depend": [0, 82], "deploi": [16, 69, 70, 73], "deploy": [9, 10, 19, 70, 71, 72], "deprec": 21, "design": 10, "detail": 78, "determin": 3, "determinist": [3, 21, 64], "detoken": 33, "dev": 48, "develop": [48, 52], "devic": 82, "dialog": 67, "diamond": 28, "differ": [1, 80], "diffus": 79, "dimens": 80, "disabl": [53, 54], "disaggreg": [5, 9, 10, 14, 15, 19, 21, 28, 46, 55], "discoveri": 19, "disk": 33, "distribut": [21, 33, 46, 60, 63], "doc": 0, "docker": [28, 48, 50, 51, 53, 54, 58, 60, 61], "document": [0, 47, 52, 60, 87], "doe": 45, "doubl": 21, "download": 27, "dp": [4, 11], "dsa": 28, "dump": [13, 21], "dynam": [9, 12, 15, 19], "eagl": [22, 29, 32, 41], "eagle3": [56, 60], "ebnf": [23, 24, 37, 43], "embed": [26, 33, 38, 80], "enabl": [9, 17, 25, 46, 77], "encod": [4, 33], "encount": 64, "end": 45, "end_profil": 46, "endpoint": [35, 43, 45, 46, 78], "engin": [2, 20, 23, 24, 25, 26, 34, 58, 60, 61, 87], "environ": [60, 63, 82], "ep": 6, "epd": 5, "error": [11, 60, 64, 78], "evalu": 48, "even": 64, "exampl": [2, 3, 4, 6, 16, 25, 27, 30, 33, 37, 42, 43, 45, 46, 53, 55, 56, 58, 60, 69, 78, 79, 80, 81, 84, 85, 86, 87, 88], "execut": 25, "exp": 73, "experiment": [1, 28], "expert": [6, 33], "explain": 45, "explicitli": 82, "export": 16, "express": [23, 24], "extend": 76, "extens": 6, "extern": [60, 87], "factor": [15, 17], "factori": 7, "fallback": 88, "faq": [27, 70, 73], "fault": 19, "featur": [16, 52, 60, 88], "field": [7, 78], "file": [21, 46, 70, 73, 75, 79], "flag": [30, 42], "flow": [19, 67], "flush": 33, "forc": 25, "fork": [18, 47], "format": [17, 25, 26, 45, 47, 62, 78], "formerli": 19, "forward": 21, "fp4": 17, "fp8": [17, 27, 30, 42], "fraction": 11, "framework": [6, 54, 76], "frequenc": 22, "frequent": 64, "from": [10, 28, 33, 47, 48, 51, 53, 54, 58, 60, 61, 83, 87], "frontend": [66, 67], "full": [30, 42], "function": [25, 27, 28, 63], "futur": 12, "gatewai": 19, "gemm": 21, "gener": [3, 33, 34, 43, 44, 63, 67], "get": [33, 37, 52], "github": [49, 50], "glm": [29, 30, 40], "gpqa": 28, "gpt": [31, 40], "gptqmodel": 16, "gpu": [12, 53], "grammar": 21, "graph": 11, "greedi": [3, 65], "grpc": 19, "grub": 53, "gsm8k": [28, 55], "guid": [1, 45, 47, 48, 52, 75, 76], "guidanc": [6, 15, 47], "guidelin": [0, 9], "h200": 27, "handl": [25, 78], "hang": 64, "hardwar": [30, 42, 52, 60], "head": 27, "health": 33, "hf3f": 9, "hicach": [8, 9, 10], "hierarch": [8, 21], "high": [11, 60], "highlight": 22, "hiradixtre": 10, "histori": 19, "hook": [7, 21], "hook_factori": 7, "host": [48, 50], "how": [25, 47, 60, 76, 87], "http": [19, 21, 46], "hybrid": 1, "hyperparamet": 11, "i": [5, 10, 14], "id": [37, 38], "illeg": 64, "imag": [26, 30, 39, 42, 70, 73], "impact": 17, "implement": [6, 15, 78, 87], "import": [30, 42, 46], "increas": 11, "infer": [3, 11, 21, 34, 59, 71, 82], "info": 33, "initi": 25, "input": [26, 30, 38, 39, 42, 84], "instal": [0, 2, 16, 28, 47, 51, 53, 54, 58, 59, 60, 61, 82], "instruct": 56, "integr": [2, 9, 10, 14, 74], "interact": 87, "interest": 76, "interfac": 10, "intern": 63, "introduct": 82, "issu": [14, 60, 69, 82], "item": 21, "jetson": 59, "jinja": 62, "join": 68, "json": [23, 24, 37, 43, 62], "jsonl": 45, "k8": 70, "kei": [9, 45, 69], "kernel": [21, 47, 54], "known": 4, "kubernet": [19, 51, 69], "kv": [8, 11, 17], "l3": 10, "languag": [66, 67, 79, 81, 84, 87], "larg": [81, 87], "latenc": 60, "latent": 27, "launch": [1, 19, 20, 21, 25, 27, 28, 29, 30, 32, 33, 35, 37, 38, 39, 41, 42, 44, 58, 60, 61, 67, 79, 80, 81, 84, 85, 86, 88], "layer": 46, "layerwis": 46, "layout": 9, "lb": 70, "learn": 68, "length": 65, "level": 7, "librari": [35, 54], "lifecycl": [7, 19], "likelihood": 65, "limit": [19, 47, 84], "line": 46, "list": [58, 60, 61], "llama": [3, 14, 25, 26, 32, 40, 58, 71, 87], "llama3": 53, "llama4": 32, "llm": 16, "lm_eval": 32, "lmcach": 21, "load": [9, 12, 19], "loader": 21, "local": 10, "log": [13, 21], "logit": [37, 43], "long": [15, 28, 60], "lora": [12, 21, 37], "low": 60, "lw": 70, "make": [49, 80], "mamba": [21, 41], "manag": 63, "manifest": [70, 73], "manual": 48, "marker": 46, "match": 10, "matrix": [1, 60], "matryoshka": 80, "matter": [3, 9], "max": 11, "maximum": 26, "mcp": 19, "mem": 11, "memfabr": 54, "memori": [9, 11, 17, 21, 54, 60, 63, 64], "merg": 47, "merger": 46, "messag": 25, "metadata": 10, "method": [16, 51, 54, 60, 65], "metric": [13, 45, 75], "mha": 1, "mindspor": 82, "minilb": 70, "mla": [1, 27], "modal": [4, 38, 67], "mode": [10, 14, 19, 25, 30, 42, 46, 82], "model": [3, 4, 7, 16, 19, 20, 21, 24, 25, 26, 27, 33, 37, 38, 40, 45, 52, 58, 60, 61, 63, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], "modelopt": 16, "modelscop": 83, "moe": [3, 6, 21, 33, 56], "mooncak": [9, 14], "more": [40, 68], "multi": [2, 4, 10, 14, 21, 22, 27, 28, 38, 46, 60, 67, 71, 72, 78], "multimod": [43, 80, 84, 87], "multipl": [3, 12, 39], "multiplex": 21, "name": 7, "nativ": [20, 23, 24, 25, 33, 44], "nccl": 18, "nest": 34, "new": [1, 6, 20, 25, 87], "newcom": 47, "next": 41, "ngram": 21, "nixl": 14, "node": [2, 14, 21, 27, 46, 60, 71, 72], "non": [3, 20, 25, 30, 34, 42], "normal": [43, 65], "note": [30, 31, 42, 43, 45, 46, 51, 84], "npu": [54, 57], "nsight": 46, "numa": [53, 54], "nvidia": [16, 59], "nvlink": 14, "nvtx": 46, "observ": [13, 19], "offlin": [11, 16, 20, 23, 24, 25, 26, 34, 82, 87], "offload": 21, "ollama": 35, "one": 27, "onlin": 16, "oom": 60, "openai": [12, 19, 20, 23, 24, 25, 36, 37, 38, 39, 44], "optim": [9, 10, 21, 27, 28, 30, 42, 58, 60, 61, 63, 84], "option": [2, 7, 11, 21, 25, 43, 45, 48, 63], "organ": 10, "orin": 59, "oss": [31, 40], "other": [11, 43, 45, 46], "our": 87, "out": [11, 54, 60, 64], "output": [23, 24, 25, 26, 37, 43, 45, 46, 59, 80], "overal": 10, "overlap": 6, "overrid": 21, "overview": [2, 6, 7, 19, 78], "packag": 49, "parallel": [2, 6, 15, 21, 27, 28, 67], "paramet": [9, 10, 30, 37, 42, 43, 78], "parser": [20, 25, 28, 31], "pd": [9, 10, 14, 15, 21, 28, 46, 55, 70, 73], "penal": 43, "perform": [2, 17, 22, 26, 54, 60, 63, 84], "pin": 12, "pip": 51, "pipelin": 15, "plane": 19, "platform": 52, "polici": [9, 19], "pool": 11, "popular": 40, "port": 87, "possibl": 46, "post": 74, "power": 54, "practic": [9, 15, 17], "pre": 47, "precis": [30, 42], "precomput": 26, "predict": [22, 27, 28], "prefetch": [9, 10], "prefil": [1, 11, 14, 15, 19, 46, 60, 70], "prepar": [70, 73], "preprocess": 26, "prerequisit": [35, 45, 54, 59, 69, 70, 73, 75], "prevent": 54, "privaci": 19, "process": 49, "processor": [26, 43], "product": [13, 75, 76], "profil": [14, 46, 48, 63], "prompt": 67, "protobuf": 82, "proxi": 19, "pypi": [49, 60], "python": [16, 25, 31, 35, 38, 39, 44, 54, 78], "pytorch": [46, 54], "quantis": [30, 42], "quantiz": [16, 17, 21, 59, 88], "queri": 26, "question": 64, "queu": 19, "queue": 11, "quick": [31, 35, 45, 80], "qwen": [5, 40, 60], "qwen2": 26, "qwen3": [3, 37, 41, 42, 56, 60], "r": 18, "r1": [27, 71], "radix": 41, "rank": [10, 22], "rate": [19, 45, 47], "raw": 26, "rbg": 73, "rdma": 69, "re": 76, "reason": [20, 24, 27, 28, 31, 37], "recommend": [30, 42, 53, 60], "refactor": 15, "refer": [2, 16, 19, 22, 52, 59, 60], "regex": [37, 43], "regist": 87, "regular": [23, 24], "relat": [10, 21], "releas": 49, "reliabl": 19, "remain": 69, "remot": [48, 88], "replai": 13, "repositori": 47, "reproduc": 3, "req": 11, "request": [11, 13, 20, 25, 30, 38, 39, 42, 44, 47, 58, 60, 61, 76, 78, 80, 85], "requir": [7, 14, 25, 60, 82], "rerank": [33, 85], "resourc": 60, "respons": [3, 31, 78], "result": [25, 28, 32, 64], "retri": 19, "review": 47, "reward": [33, 78, 86], "rich": 10, "roce": 69, "root": 3, "round": [16, 33], "router": [14, 19, 35], "run": [11, 27, 47, 50, 51, 53, 55, 56, 58, 59, 82], "runner": 50, "runtim": [21, 23, 24, 25], "sagemak": 51, "sampl": [3, 21, 22, 43], "save": 17, "sbo": 6, "scale": [17, 19], "scenario": [69, 76], "schedul": [14, 21], "schema": [7, 20], "scheme": 54, "score": [21, 78], "script": 60, "search": 31, "secur": 19, "select": [6, 33, 65, 82], "self": 50, "send": [25, 30, 42, 44], "separ": 19, "sequenc": 28, "serv": [12, 21, 45, 58, 60, 61, 87], "server": [2, 3, 14, 20, 21, 25, 30, 33, 35, 37, 38, 39, 42, 44, 46, 58, 64, 67, 80, 82], "servic": [19, 70], "set": [19, 50, 53, 54], "setup": [2, 48, 75, 76], "sgl": 47, "sglang": [0, 2, 3, 4, 9, 19, 20, 23, 24, 25, 27, 28, 29, 30, 32, 33, 35, 41, 42, 46, 47, 48, 51, 52, 53, 54, 59, 65, 67, 87, 88], "sh": 50, "share": 46, "simplest": 26, "singl": [2, 6, 12, 14, 78], "size": [11, 15], "skypilot": [51, 60], "slice": 76, "slurm": 71, "smart": 35, "smooth": 15, "snippet": 79, "softwar": 60, "solut": 3, "some": 82, "sourc": [28, 47, 51, 53, 54, 58, 60, 61], "sparsiti": 21, "spec": 7, "specif": [20, 25, 30, 42, 60, 63], "specul": [1, 21, 22, 29, 32, 41, 60], "speed": [11, 47], "srt": [23, 24, 25], "start": [35, 45, 48, 50, 52, 80, 82], "start_profil": 46, "static": 11, "step": [1, 50, 53], "storag": [9, 10, 19, 46, 63], "stream": [20, 25, 34, 43, 44, 45, 67], "structur": [23, 24, 37, 43, 59], "style": [0, 47], "submiss": 11, "success": 69, "suit": 87, "summari": [7, 35], "support": [1, 3, 4, 6, 9, 17, 20, 21, 24, 25, 37, 45, 52, 54, 60, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88], "surfac": 19, "swap": 54, "synchron": [10, 34], "system": [10, 46, 53, 54, 60], "tabl": 19, "tag": [23, 24], "target_modul": 7, "tbo": 6, "temperatur": [3, 64], "templat": [25, 62], "tensor": [2, 21, 27], "terminu": 58, "test": [28, 32, 47, 55, 60, 63, 78, 87], "text": 33, "think": [27, 29, 30, 37], "three": 26, "throughput": [11, 27, 60], "time": 60, "tip": [28, 29, 32, 41, 46, 47], "todo": 69, "token": [11, 21, 22, 27, 28, 33, 37, 45, 65], "toler": 19, "tool": [19, 25, 31, 63], "top": 7, "torch": [22, 77], "torchao": 59, "tp": [2, 11], "tpu": 60, "trace": [46, 76], "train": 74, "transfer": 10, "transferengin": 18, "transform": 88, "transport": 14, "trigger": 47, "trip": 33, "triton": 54, "troubleshoot": [2, 19, 45, 60, 64, 75, 82], "try": 11, "tune": [11, 19, 63], "turn": 67, "two": 6, "type": 21, "uncondit": 65, "understand": 26, "unifi": [10, 14], "unit": 47, "unsloth": 16, "up": [48, 50], "updat": [0, 33, 47, 49, 53], "upload": 49, "us": [16, 35, 37, 38, 39, 44, 46, 48, 51, 53, 54, 58, 60, 61, 63, 78, 83], "usag": [2, 3, 5, 11, 12, 14, 16, 17, 18, 20, 24, 27, 28, 30, 31, 32, 34, 37, 40, 41, 42, 46, 52, 58, 67, 75, 78, 84], "user": 1, "uv": 51, "v": 1, "v1": 33, "v3": [27, 28, 37, 53, 55, 58, 71], "variabl": 63, "verif": [3, 60], "version": [49, 54], "via": [22, 87], "video": [30, 42, 84], "view": 46, "vision": [26, 39], "vl": [5, 26, 42, 56], "vllm": 87, "vlm": 26, "vscode": 48, "warmup": 53, "web": 31, "weight": [21, 27, 33], "what": [5, 10, 14, 45], "why": [3, 5, 9, 10, 14, 15], "wise": [27, 46], "without": 25, "work": 12, "worker": [19, 46], "workflow": [0, 10, 16, 46], "workload": 6, "wrapper": 87, "write": [7, 10, 47], "x": [27, 55, 56], "xgrammar": 59, "xpu": 61, "you": 76}})