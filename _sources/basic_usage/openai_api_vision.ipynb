{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI APIs - Vision\n",
    "\n",
    "SGLang provides OpenAI-compatible APIs to enable a smooth transition from OpenAI services to self-hosted local models.\n",
    "A complete reference for the API is available in the [OpenAI API Reference](https://platform.openai.com/docs/guides/vision).\n",
    "This tutorial covers the vision APIs for vision language models.\n",
    "\n",
    "SGLang supports various vision language models such as Llama 3.2, LLaVA-OneVision, Qwen2.5-VL, Gemma3 and [more](../supported_models/multimodal_language_models.md).\n",
    "\n",
    "As an alternative to the OpenAI API, you can also use the [SGLang offline engine](https://github.com/sgl-project/sglang/blob/main/examples/runtime/engine/offline_batch_inference_vlm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch A Server\n",
    "\n",
    "Launch the server in your terminal and wait for it to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:14:43.374114Z",
     "iopub.status.busy": "2025-12-12T18:14:43.373995Z",
     "iopub.status.idle": "2025-12-12T18:15:24.998515Z",
     "shell.execute_reply": "2025-12-12T18:15:24.997319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:14:48] INFO utils.py:148: Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:14:48] INFO utils.py:151: Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:14:48] INFO utils.py:164: NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:14:54] INFO utils.py:148: Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2025-12-12 18:14:54] INFO utils.py:151: Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "[2025-12-12 18:14:54] INFO utils.py:164: NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:14:56] WARNING server_args.py:1416: Attention backend not explicitly specified. Use flashinfer backend by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:15:03] INFO utils.py:148: Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2025-12-12 18:15:03] INFO utils.py:151: Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "[2025-12-12 18:15:03] INFO utils.py:164: NumExpr defaulting to 16 threads.\n",
      "[2025-12-12 18:15:03] INFO utils.py:148: Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2025-12-12 18:15:03] INFO utils.py:151: Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "[2025-12-12 18:15:03] INFO utils.py:164: NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I1212 18:15:07.478304 809725 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)\n",
      "I1212 18:15:07.478327 809725 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.185.21.146 port: 12001\n",
      "I1212 18:15:07.478349 809725 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.185.21.146:16982\n",
      "I1212 18:15:07.478431 809725 transfer_engine.cpp:185] Auto-discovering topology...\n",
      "I1212 18:15:07.481238 809725 transfer_engine.cpp:200] Topology discovery complete. Found 9 HCAs.\n",
      "I1212 18:15:07.509670 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce0/\u0001\n",
      "I1212 18:15:07.510392 809725 rdma_context.cpp:126] RDMA device: mlx5_roce0, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:48:45:5d\n",
      "I1212 18:15:07.538134 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_eth0/\u0001\n",
      "I1212 18:15:07.539142 809725 rdma_context.cpp:126] RDMA device: mlx5_eth0, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:0a:b9:15:92\n",
      "I1212 18:15:07.565618 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce1/\u0001\n",
      "I1212 18:15:07.566234 809725 rdma_context.cpp:126] RDMA device: mlx5_roce1, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:48:c5:5d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1212 18:15:07.666572 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce2/\u0001\n",
      "I1212 18:15:07.667239 809725 rdma_context.cpp:126] RDMA device: mlx5_roce2, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:49:45:5d\n",
      "I1212 18:15:07.693626 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce3/\u0001\n",
      "I1212 18:15:07.694267 809725 rdma_context.cpp:126] RDMA device: mlx5_roce3, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:49:c5:5d\n",
      "I1212 18:15:07.721593 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce4/\u0001\n",
      "I1212 18:15:07.722249 809725 rdma_context.cpp:126] RDMA device: mlx5_roce4, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:4a:45:5d\n",
      "I1212 18:15:07.749625 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce5/\u0001\n",
      "I1212 18:15:07.750283 809725 rdma_context.cpp:126] RDMA device: mlx5_roce5, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:4a:c5:5d\n",
      "I1212 18:15:07.777586 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce6/\u0001\n",
      "I1212 18:15:07.778227 809725 rdma_context.cpp:126] RDMA device: mlx5_roce6, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:4b:45:5d\n",
      "I1212 18:15:07.805559 809725 rdma_context.cpp:533] Find best gid index: 3 on mlx5_roce7/\u0001\n",
      "I1212 18:15:07.806188 809725 rdma_context.cpp:126] RDMA device: mlx5_roce7, LID: 0, GID: (GID_Index 3) 00:00:00:00:00:00:00:00:00:00:ff:ff:16:4b:c5:5d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1212 18:15:08.486662 809725 memory_location.cpp:72] Failed to get NUMA node, addr: 0x7f7507fff010, len: 2147483648: Operation not permitted [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:15:11] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:02,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:02<00:01,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.79it/s]\n",
      "\r",
      "Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:03<00:00,  1.56it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]\r",
      "Capturing batches (bs=4 avail_mem=58.75 GB):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Capturing batches (bs=4 avail_mem=58.75 GB):  33%|███▎      | 1/3 [00:00<00:01,  1.65it/s]\r",
      "Capturing batches (bs=2 avail_mem=58.70 GB):  33%|███▎      | 1/3 [00:00<00:01,  1.65it/s]\r",
      "Capturing batches (bs=1 avail_mem=58.69 GB):  33%|███▎      | 1/3 [00:00<00:01,  1.65it/s]\r",
      "Capturing batches (bs=1 avail_mem=58.69 GB): 100%|██████████| 3/3 [00:00<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-12 18:15:20] Endpoint '/get_model_info' is deprecated and will be removed in a future version. Please use '/model_info' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    To reduce the log length, we set the log level to warning for the server, the default log level is info.<br>                    We are running those notebooks in a CI environment, so the throughput is not representative of the actual performance.<br>                    </strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sglang.test.doc_patch import launch_server_cmd\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "vision_process, port = launch_server_cmd(\n",
    "    \"\"\"\n",
    "python3 -m sglang.launch_server --model-path Qwen/Qwen2.5-VL-7B-Instruct --log-level warning\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "wait_for_server(f\"http://localhost:{port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cURL\n",
    "\n",
    "Once the server is up, you can send test requests using curl or requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:15:25.001469Z",
     "iopub.status.busy": "2025-12-12T18:15:25.000764Z",
     "iopub.status.idle": "2025-12-12T18:15:27.001154Z",
     "shell.execute_reply": "2025-12-12T18:15:27.000396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"d500c61416204b938a44adf3aea4edc5\",\"object\":\"chat.completion\",\"created\":1765563326,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be balancing carefully while performing this task.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":373,\"completion_tokens\":66,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"50b8592937f74bf5a9391ce0426b1b9e\",\"object\":\"chat.completion\",\"created\":1765563326,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be balancing carefully while performing this task.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":373,\"completion_tokens\":66,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "curl_command = f\"\"\"\n",
    "curl -s http://localhost:{port}/v1/chat/completions \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "      {{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What’s in this image?\"\n",
    "          }},\n",
    "          {{\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {{\n",
    "              \"url\": \"https://github.com/sgl-project/sglang/blob/main/examples/assets/example_image.png?raw=true\"\n",
    "            }}\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }}'\n",
    "\"\"\"\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)\n",
    "\n",
    "\n",
    "response = subprocess.check_output(curl_command, shell=True).decode()\n",
    "print_highlight(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:15:27.002994Z",
     "iopub.status.busy": "2025-12-12T18:15:27.002832Z",
     "iopub.status.idle": "2025-12-12T18:15:27.896045Z",
     "shell.execute_reply": "2025-12-12T18:15:27.895367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>{\"id\":\"1ea73b6d19a24be486a1718767b475dd\",\"object\":\"chat.completion\",\"created\":1765563327,\"model\":\"Qwen/Qwen2.5-VL-7B-Instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be balancing carefully while performing this task.\",\"reasoning_content\":null,\"tool_calls\":null},\"logprobs\":null,\"finish_reason\":\"stop\",\"matched_stop\":151645}],\"usage\":{\"prompt_tokens\":307,\"total_tokens\":373,\"completion_tokens\":66,\"prompt_tokens_details\":null,\"reasoning_tokens\":0},\"metadata\":{\"weight_version\":\"default\"}}</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"http://localhost:{port}/v1/chat/completions\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/examples/assets/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print_highlight(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:15:27.897729Z",
     "iopub.status.busy": "2025-12-12T18:15:27.897581Z",
     "iopub.status.idle": "2025-12-12T18:15:28.948545Z",
     "shell.execute_reply": "2025-12-12T18:15:28.947913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>The image shows a man standing on the back of a yellow taxi, using an iron to press or smooth out a pair of pants draped over an ironing board. The taxi is parked on a city street, and there are other taxis and buildings in the background. The man appears to be performing an unusual task, as ironing is typically done indoors.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is in this image?\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/examples/assets/example_image.png?raw=true\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-Image Inputs\n",
    "\n",
    "The server also supports multiple images and interleaved text and images if the model supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:15:28.950465Z",
     "iopub.status.busy": "2025-12-12T18:15:28.950314Z",
     "iopub.status.idle": "2025-12-12T18:15:30.043304Z",
     "shell.execute_reply": "2025-12-12T18:15:30.042649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong style='color: #00008B;'>The first image shows a man ironing clothes on the back of a taxi in a busy urban street. The second image is a stylized logo featuring the letters \"SGL\" with a book and a computer icon incorporated into the design.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"http://localhost:{port}/v1\", api_key=\"None\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://github.com/sgl-project/sglang/blob/main/examples/assets/example_image.png?raw=true\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"I have two very different images. They are not related at all. \"\n",
    "                    \"Please describe the first image in one sentence, and then describe the second image in another sentence.\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print_highlight(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T18:15:30.044838Z",
     "iopub.status.busy": "2025-12-12T18:15:30.044680Z",
     "iopub.status.idle": "2025-12-12T18:15:30.069765Z",
     "shell.execute_reply": "2025-12-12T18:15:30.069021Z"
    }
   },
   "outputs": [],
   "source": [
    "terminate_process(vision_process)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
