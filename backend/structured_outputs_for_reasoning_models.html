
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Structured Outputs For Reasoning Models &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=da9b0e0d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'backend/structured_outputs_for_reasoning_models';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Custom Chat Template" href="custom_chat_template.html" />
    <link rel="prev" title="Reasoning Parser" href="separate_reasoning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jun 03, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/deepseek.html">DeepSeek Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/llama4.html">Llama4 Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_completions.html">OpenAI APIs - Completions</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_vision.html">OpenAI APIs - Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="openai_api_embeddings.html">OpenAI APIs - Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_engine_api.html">Offline Engine API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Backend Configurations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention_backend.html">Attention Backend</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/generative_models.html">Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/multimodal_language_models.html">Multimodal Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/embedding_models.html">Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/reward_models.html">Reward Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/support_new_models.html">How to Support New Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="function_calling.html">Tool and Function Calling</a></li>
<li class="toctree-l1"><a class="reference internal" href="separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">LoRA Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="pd_disaggregation.html">PD Disaggregation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend Tutorial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontend/frontend.html">SGLang Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/choices_methods.html">Choices Methods in SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Router</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../router/router.html">Router for Data Parallelism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/general.html">General Guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/hardware.html">Hardware Supports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/advanced_deploy.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/performance_analysis_and_optimization.html">Performance Analysis &amp; Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/developer.html">Developer Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/backend/structured_outputs_for_reasoning_models.ipynb?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/backend/structured_outputs_for_reasoning_models.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fbackend/structured_outputs_for_reasoning_models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/backend/structured_outputs_for_reasoning_models.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Structured Outputs For Reasoning Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Supported-Models">Supported Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Usage">Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#OpenAI-Compatible-API">OpenAI Compatible API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#JSON">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#EBNF">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Regular-expression">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Structural-Tag">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Native-API-and-SGLang-Runtime-(SRT)">Native API and SGLang Runtime (SRT)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Offline-Engine-API">Offline Engine API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Regular expression</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <style>
    .output_area.stderr, .output_area.stdout {
        color: #d3d3d3 !important; /* light gray */
    }
</style><section id="Structured-Outputs-For-Reasoning-Models">
<h1>Structured Outputs For Reasoning Models<a class="headerlink" href="#Structured-Outputs-For-Reasoning-Models" title="Link to this heading">#</a></h1>
<p>When working with reasoning models that use special tokens like <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;...&lt;/think&gt;</span></code> to denote reasoning sections, you might want to allow free-form text within these sections while still enforcing grammar constraints on the rest of the output.</p>
<p>SGLang provides a feature to disable grammar restrictions within reasoning sections. This is particularly useful for models that need to perform complex reasoning steps before providing a structured output.</p>
<p>To enable this feature, use the <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> flag which decide the think_end_token, such as <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code>, when launching the server. You can also specify the reasoning parser using the <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> flag.</p>
<section id="Supported-Models">
<h2>Supported Models<a class="headerlink" href="#Supported-Models" title="Link to this heading">#</a></h2>
<p>Currently, SGLang supports the following reasoning models:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d">DeepSeek R1 series</a>: The reasoning content is wrapped with <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code> tags.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/Qwen/QwQ-32B">QwQ</a>: The reasoning content is wrapped with <code class="docutils literal notranslate"><span class="pre">&lt;think&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;/think&gt;</span></code> tags.</p></li>
</ul>
</section>
<section id="Usage">
<h2>Usage<a class="headerlink" href="#Usage" title="Link to this heading">#</a></h2>
</section>
<section id="OpenAI-Compatible-API">
<h2>OpenAI Compatible API<a class="headerlink" href="#OpenAI-Compatible-API" title="Link to this heading">#</a></h2>
<p>Specify the <code class="docutils literal notranslate"><span class="pre">--grammar-backend</span></code>, <code class="docutils literal notranslate"><span class="pre">--reasoning-parser</span></code> option.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.test.test_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_in_ci</span>

<span class="k">if</span> <span class="n">is_in_ci</span><span class="p">():</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">patch</span><span class="w"> </span><span class="kn">import</span> <span class="n">launch_server_cmd</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sglang.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">launch_server_cmd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sglang.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">wait_for_server</span><span class="p">,</span> <span class="n">print_highlight</span><span class="p">,</span> <span class="n">terminate_process</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>


<span class="n">server_process</span><span class="p">,</span> <span class="n">port</span> <span class="o">=</span> <span class="n">launch_server_cmd</span><span class="p">(</span>
    <span class="s2">&quot;python -m sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --host 0.0.0.0 --reasoning-parser deepseek-r1&quot;</span>
<span class="p">)</span>

<span class="n">wait_for_server</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;http://127.0.0.1:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/v1&quot;</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:14:49] server_args=ServerArgs(model_path=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, tokenizer_path=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, tokenizer_mode=&#39;auto&#39;, skip_tokenizer_init=False, load_format=&#39;auto&#39;, trust_remote_code=False, dtype=&#39;auto&#39;, kv_cache_dtype=&#39;auto&#39;, quantization=None, quantization_param_path=None, context_length=None, device=&#39;cuda&#39;, served_model_name=&#39;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&#39;, chat_template=None, completion_template=None, is_embedding=False, enable_multimodal=None, revision=None, host=&#39;0.0.0.0&#39;, port=38788, mem_fraction_static=0.88, max_running_requests=200, max_total_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy=&#39;fcfs&#39;, schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=648436233, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level=&#39;info&#39;, log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, bucket_time_to_first_token=None, bucket_e2e_request_latency=None, bucket_inter_token_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, file_storage_path=&#39;sglang_storage&#39;, enable_cache_report=False, reasoning_parser=&#39;deepseek-r1&#39;, dp_size=1, load_balance_method=&#39;round_robin&#39;, ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args=&#39;{}&#39;, preferred_sampling_params=None, lora_paths=None, max_loras_per_batch=8, lora_backend=&#39;triton&#39;, attention_backend=None, sampling_backend=&#39;flashinfer&#39;, grammar_backend=&#39;xgrammar&#39;, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type=&#39;qk&#39;, ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=True, disable_cuda_graph_padding=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_ep_moe=False, enable_deepep_moe=False, deepep_mode=&#39;auto&#39;, ep_num_redundant_experts=0, ep_dispatch_algorithm=&#39;static&#39;, init_expert_location=&#39;trivial&#39;, enable_eplb=False, eplb_algorithm=&#39;auto&#39;, eplb_rebalance_num_iterations=1000, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=None, cuda_graph_bs=None, torchao_config=&#39;&#39;, enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy=&#39;write_through_selective&#39;, flashinfer_mla_disable_ragged=False, warmups=None, moe_dense_tp_size=None, n_share_experts_fusion=0, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, mm_attention_backend=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode=&#39;null&#39;, disaggregation_bootstrap_port=8998, disaggregation_transfer_backend=&#39;mooncake&#39;, disaggregation_ib_device=None, pdlb_url=None)
[2025-06-03 07:15:01] Attention backend not set. Use fa3 backend by default.
[2025-06-03 07:15:01] Init torch distributed begin.
[2025-06-03 07:15:02] Init torch distributed ends. mem usage=0.00 GB
[2025-06-03 07:15:02] Load weight begin. avail mem=53.55 GB
[2025-06-03 07:15:02] Using model weights format [&#39;*.safetensors&#39;]
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01&lt;00:01,  1.49s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.38s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.40s/it]

[2025-06-03 07:15:06] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=39.20 GB, mem usage=14.35 GB.
[2025-06-03 07:15:06] KV Cache is allocated. #tokens: 20480, K size: 0.55 GB, V size: 0.55 GB
[2025-06-03 07:15:06] Memory pool end. avail mem=37.83 GB
[2025-06-03 07:15:06] max_total_num_tokens=20480, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=200, context_len=131072, available_gpu_mem=37.73 GB
[2025-06-03 07:15:07] INFO:     Started server process [1562888]
[2025-06-03 07:15:07] INFO:     Waiting for application startup.
[2025-06-03 07:15:07] INFO:     Application startup complete.
[2025-06-03 07:15:07] INFO:     Uvicorn running on http://0.0.0.0:38788 (Press CTRL+C to quit)
[2025-06-03 07:15:07] INFO:     127.0.0.1:47688 - &#34;GET /v1/models HTTP/1.1&#34; 200 OK
[2025-06-03 07:15:08] INFO:     127.0.0.1:47698 - &#34;GET /get_model_info HTTP/1.1&#34; 200 OK
[2025-06-03 07:15:08] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:10] INFO:     127.0.0.1:47704 - &#34;POST /generate HTTP/1.1&#34; 200 OK
[2025-06-03 07:15:10] The server is fired up and ready to roll!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'><br><br>                    NOTE: Typically, the server runs in a separate terminal.<br>                    In this notebook, we run the server and notebook code together, so their outputs are combined.<br>                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.<br>                    We are running those notebooks in a CI parallel environment, so the throughput is not representative of the actual performance.<br>                    </strong></div>
</div>
<section id="JSON">
<h3>JSON<a class="headerlink" href="#JSON" title="Link to this heading">#</a></h3>
<p>you can directly define a JSON schema or use <a class="reference external" href="https://docs.pydantic.dev/latest/">Pydantic</a> to define and validate the response.</p>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information and population of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">,</span>
        <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span>
            <span class="c1"># convert the pydantic model to json schema</span>
            <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:15:12] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:15] Decode batch. #running-req: 1, #token: 55, token usage: 0.00, cuda graph: False, gen throughput (token/s): 4.71, #queue-req: 0
[2025-06-03 07:15:15] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: False, gen throughput (token/s): 106.21, #queue-req: 0
[2025-06-03 07:15:16] Decode batch. #running-req: 1, #token: 135, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.70, #queue-req: 0
[2025-06-03 07:15:16] Decode batch. #running-req: 1, #token: 175, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.61, #queue-req: 0
[2025-06-03 07:15:16] Decode batch. #running-req: 1, #token: 215, token usage: 0.01, cuda graph: False, gen throughput (token/s): 103.23, #queue-req: 0
[2025-06-03 07:15:17] Decode batch. #running-req: 1, #token: 255, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.73, #queue-req: 0
[2025-06-03 07:15:17] Decode batch. #running-req: 1, #token: 295, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.17, #queue-req: 0
[2025-06-03 07:15:18] Decode batch. #running-req: 1, #token: 335, token usage: 0.02, cuda graph: False, gen throughput (token/s): 97.43, #queue-req: 0
[2025-06-03 07:15:18] Decode batch. #running-req: 1, #token: 375, token usage: 0.02, cuda graph: False, gen throughput (token/s): 103.19, #queue-req: 0
[2025-06-03 07:15:18] Decode batch. #running-req: 1, #token: 415, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.13, #queue-req: 0
[2025-06-03 07:15:19] Decode batch. #running-req: 1, #token: 455, token usage: 0.02, cuda graph: False, gen throughput (token/s): 102.90, #queue-req: 0
[2025-06-03 07:15:19] INFO:     127.0.0.1:47716 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Alright, so the user asked for the information and population of the capital of France in JSON format. I immediately thought about what the capital isâ€”Paris. Then, I considered the population. I know it's a big city, but I'm not exactly sure of the exact number. I remember it's over 3 million, but I'm not certain if it's 3.5 or 3.6. I should double-check that.<br><br>Wait, maybe I should think about recent data. I recall that Paris has been growing a bit, so perhaps it's around 3.6 million. But I'm not 100% sure. I should look up the latest statistics to confirm. Okay, checking a reliable source, and it says the population is approximately 3,600,000. That seems right.<br><br>Now, the user wants this in JSON format. I need to structure it properly. The key should be "capital" with the name "Paris," and another key for "population." I'll make sure the population number is correctly formatted as an integer in the JSON.<br><br>I also need to present this clearly. Maybe I should write it out in the response, showing the JSON structure so the user can see exactly what they'll get. That way, they can easily copy it or use it in their application.<br><br>I wonder if the user is a developer working on a project that requires population data. They might need it in JSON for integration or analysis. So providing the exact format they asked for is important. I should also make sure the response is concise and to the point, without any extra fluff.<br><br>Is there anything else I should consider? Maybe the date of the population count, but the user didn't specify that. I'll stick to the most recent data available. Also, I should ensure that the JSON is valid, so using proper syntax with quotes and commas.<br><br>In summary, I'll provide the JSON with the correct capital name and population number, making sure it's accurate and in the format the user requested. That should meet their needs effectively.<br><br><br>content: {"name": "Paris", "population": 3600000}</strong></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information and population of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">,</span>
        <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json_schema</span><span class="p">)},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:15:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:19] Decode batch. #running-req: 1, #token: 52, token usage: 0.00, cuda graph: False, gen throughput (token/s): 88.11, #queue-req: 0
[2025-06-03 07:15:20] Decode batch. #running-req: 1, #token: 92, token usage: 0.00, cuda graph: False, gen throughput (token/s): 104.81, #queue-req: 0
[2025-06-03 07:15:20] Decode batch. #running-req: 1, #token: 132, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.40, #queue-req: 0
[2025-06-03 07:15:20] Decode batch. #running-req: 1, #token: 172, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.20, #queue-req: 0
[2025-06-03 07:15:21] Decode batch. #running-req: 1, #token: 212, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.70, #queue-req: 0
[2025-06-03 07:15:21] Decode batch. #running-req: 1, #token: 252, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.46, #queue-req: 0
[2025-06-03 07:15:21] Decode batch. #running-req: 1, #token: 292, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.73, #queue-req: 0
[2025-06-03 07:15:22] Decode batch. #running-req: 1, #token: 332, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.14, #queue-req: 0
[2025-06-03 07:15:22] INFO:     127.0.0.1:47716 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Alright, so the user asked for the information and population of the capital of France in JSON format. I immediately thought about what the capital is. Paris is the capital, no doubt there. Now, I need to recall or look up the population. I remember it's a big city, so the population is in the millions. I think it's around 2 million, but I'm not 100% sure. Maybe I should double-check that. <br><br>Wait, I should consider the exact figure. I believe the population is approximately 2,175,000 as of 2023. That seems right, but I'm not certain. I should make sure to present it accurately. Also, the user wants it in JSON format, so I need to structure it properly with the key "capital" and the value as a string. <br><br>I wonder if the user is a student working on a project or maybe a developer needing data for an app. Either way, providing the correct and up-to-date information is crucial. Maybe they also need this for a presentation or a report, so accuracy is key. <br><br>I should also consider if there are any other details they might need, like the area or the time zone, but the user specifically asked for population. So I'll stick to that. I'll format the JSON correctly, making sure the syntax is right to avoid any errors. <br><br>In summary, I'll provide the JSON with the correct population number for Paris, the capital of France, ensuring it's accurate and formatted as requested.<br><br><br>content: {"name": "Paris", "population": 2175000}</strong></div>
</div>
</section>
<section id="EBNF">
<h3>EBNF<a class="headerlink" href="#EBNF" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ebnf_grammar</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">root ::= city | description</span>
<span class="s2">city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span>
<span class="s2">description ::= city &quot; is &quot; status</span>
<span class="s2">status ::= &quot;the capital of &quot; country</span>
<span class="s2">country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful geography bot.&quot;</span><span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information and population of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="n">ebnf_grammar</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:15:22] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:22] Decode batch. #running-req: 1, #token: 42, token usage: 0.00, cuda graph: False, gen throughput (token/s): 87.21, #queue-req: 0
[2025-06-03 07:15:23] Decode batch. #running-req: 1, #token: 82, token usage: 0.00, cuda graph: False, gen throughput (token/s): 104.22, #queue-req: 0
[2025-06-03 07:15:23] Decode batch. #running-req: 1, #token: 122, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.03, #queue-req: 0
[2025-06-03 07:15:23] Decode batch. #running-req: 1, #token: 162, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.16, #queue-req: 0
[2025-06-03 07:15:24] Decode batch. #running-req: 1, #token: 202, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.53, #queue-req: 0
[2025-06-03 07:15:24] Decode batch. #running-req: 1, #token: 242, token usage: 0.01, cuda graph: False, gen throughput (token/s): 107.01, #queue-req: 0
[2025-06-03 07:15:25] Decode batch. #running-req: 1, #token: 282, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.38, #queue-req: 0
[2025-06-03 07:15:25] Decode batch. #running-req: 1, #token: 322, token usage: 0.02, cuda graph: False, gen throughput (token/s): 106.16, #queue-req: 0
[2025-06-03 07:15:25] Decode batch. #running-req: 1, #token: 362, token usage: 0.02, cuda graph: False, gen throughput (token/s): 102.61, #queue-req: 0
[2025-06-03 07:15:26] Decode batch. #running-req: 1, #token: 402, token usage: 0.02, cuda graph: False, gen throughput (token/s): 106.18, #queue-req: 0
[2025-06-03 07:15:26] INFO:     127.0.0.1:47716 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so the user asked for the information and population of the capital of France in JSON format. I responded with Paris, its population of around 2.1 million, and included some key facts. Now, the user is following up with another query about the population of the United States. They want the data in JSON again, but this time for the entire country.<br><br>Hmm, I need to make sure I provide accurate and up-to-date information. The population of the US is a big number, so I should check the latest estimates. I remember it's over 300 million, maybe around 332 million as of 2023. I should include that. Also, adding some key facts about the US population would be helpful, like the diversity of states, the fastest-growing state, and the slowest-growing state. That gives a bit more context and makes the information more useful.<br><br>I should structure the JSON properly, making sure the keys are clear and the data is easy to read. Maybe include the country name, population, and the key facts as an array. I need to ensure the JSON syntax is correct, with proper commas and brackets. Also, I should avoid any markdown formatting as per the instructions, keeping it plain text.<br><br>Wait, should I mention the growth rate? The user didn't ask for it, but it's a related fact. Maybe just stick to what they asked for unless they specify more details. I'll focus on the population and the key facts they provided. <br><br>Double-checking the population number is crucial. I think it's 332.8 million as of the latest data, so I'll use that. For the key facts, I'll list the most populous and least populous states. That should cover the user's needs and provide a comprehensive answer in the JSON format they requested.<br><br><br>content: Rome is the capital of Italy</strong></div>
</div>
</section>
<section id="Regular-expression">
<h3>Regular expression<a class="headerlink" href="#Regular-expression" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(Paris|London)&quot;</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:15:26] Prefill batch. #new-seq: 1, #new-token: 11, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:26] Decode batch. #running-req: 1, #token: 41, token usage: 0.00, cuda graph: False, gen throughput (token/s): 96.44, #queue-req: 0
[2025-06-03 07:15:26] Decode batch. #running-req: 1, #token: 81, token usage: 0.00, cuda graph: False, gen throughput (token/s): 104.90, #queue-req: 0
[2025-06-03 07:15:27] INFO:     127.0.0.1:47716 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Alright, so the user just asked, "What is the capital of France?" Hmm, that's a pretty straightforward question. I should make sure I provide a clear and accurate answer. Let me think, Paris is definitely the capital. But wait, is there any chance I might have mixed it up with another country? No, I'm pretty sure France's capital is Paris. Maybe I should double-check that to be safe. Yeah, Paris is correct. I'll go with that.<br><br><br>content: London</strong></div>
</div>
</section>
<section id="Structural-Tag">
<h3>Structural Tag<a class="headerlink" href="#Structural-Tag" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tool_get_current_weather</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_current_weather&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current weather in a given location&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;city&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The city to find the weather for, e.g. &#39;San Francisco&#39;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">&quot;state&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;the two-letter abbreviation for the state that the city is&quot;</span>
                    <span class="s2">&quot; in, e.g. &#39;CA&#39; which would mean &#39;California&#39;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The unit to fetch the temperature in&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;celsius&quot;</span><span class="p">,</span> <span class="s2">&quot;fahrenheit&quot;</span><span class="p">],</span>
                <span class="p">},</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;city&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="s2">&quot;unit&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">tool_get_current_date</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_current_date&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current date and time for a given timezone&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;timezone&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The timezone to fetch the current date and time for, e.g. &#39;America/New_York&#39;&quot;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;timezone&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">schema_get_current_weather</span> <span class="o">=</span> <span class="n">tool_get_current_weather</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">][</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
<span class="n">schema_get_current_date</span> <span class="o">=</span> <span class="n">tool_get_current_date</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">][</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_messages</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2"># Tool Instructions</span>
<span class="s2">- Always execute python code in messages that you share.</span>
<span class="s2">- When looking for real time information use relevant functions if available else fallback to brave_search</span>
<span class="s2">You have access to the following functions:</span>
<span class="s2">Use the function &#39;get_current_weather&#39; to: Get the current weather in a given location</span>
<span class="si">{</span><span class="n">tool_get_current_weather</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span><span class="si">}</span>
<span class="s2">Use the function &#39;get_current_date&#39; to: Get the current date and time for a given timezone</span>
<span class="si">{</span><span class="n">tool_get_current_date</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span><span class="si">}</span>
<span class="s2">If a you choose to call a function ONLY reply in the following format:</span>
<span class="s2">&lt;</span><span class="se">{{</span><span class="s2">start_tag</span><span class="se">}}</span><span class="s2">=</span><span class="se">{{</span><span class="s2">function_name</span><span class="se">}}</span><span class="s2">&gt;</span><span class="se">{{</span><span class="s2">parameters</span><span class="se">}}{{</span><span class="s2">end_tag</span><span class="se">}}</span>
<span class="s2">where</span>
<span class="s2">start_tag =&gt; `&lt;function`</span>
<span class="s2">parameters =&gt; a JSON dict with the function argument name as key and function argument value as value.</span>
<span class="s2">end_tag =&gt; `&lt;/function&gt;`</span>
<span class="s2">Here is an example,</span>
<span class="s2">&lt;function=example_function_name&gt;</span><span class="se">{{</span><span class="s2">&quot;example_name&quot;: &quot;example_value&quot;</span><span class="se">}}</span><span class="s2">&lt;/function&gt;</span>
<span class="s2">Reminder:</span>
<span class="s2">- Function calls MUST follow the specified format</span>
<span class="s2">- Required parameters MUST be specified</span>
<span class="s2">- Only call one function at a time</span>
<span class="s2">- Put the entire function call reply on one line</span>
<span class="s2">- Always add your sources when using search results to answer the user query</span>
<span class="s2">You are a helpful assistant.&quot;&quot;&quot;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are in New York. Please get the current date and time, and the weather.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">]</span>


<span class="n">messages</span> <span class="o">=</span> <span class="n">get_messages</span><span class="p">()</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
        <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">],</span>
        <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:15:27] Prefill batch. #new-seq: 1, #new-token: 472, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:15:27] Decode batch. #running-req: 1, #token: 480, token usage: 0.02, cuda graph: False, gen throughput (token/s): 51.34, #queue-req: 0
[2025-06-03 07:15:28] Decode batch. #running-req: 1, #token: 520, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.69, #queue-req: 0
[2025-06-03 07:15:28] Decode batch. #running-req: 1, #token: 560, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.20, #queue-req: 0
[2025-06-03 07:15:28] Decode batch. #running-req: 1, #token: 600, token usage: 0.03, cuda graph: False, gen throughput (token/s): 101.90, #queue-req: 0
[2025-06-03 07:15:29] Decode batch. #running-req: 1, #token: 640, token usage: 0.03, cuda graph: False, gen throughput (token/s): 97.32, #queue-req: 0
[2025-06-03 07:15:29] Decode batch. #running-req: 1, #token: 680, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.42, #queue-req: 0
[2025-06-03 07:15:30] Decode batch. #running-req: 1, #token: 720, token usage: 0.04, cuda graph: False, gen throughput (token/s): 103.10, #queue-req: 0
[2025-06-03 07:15:30] Decode batch. #running-req: 1, #token: 760, token usage: 0.04, cuda graph: False, gen throughput (token/s): 102.61, #queue-req: 0
[2025-06-03 07:15:30] Decode batch. #running-req: 1, #token: 800, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.62, #queue-req: 0
[2025-06-03 07:15:31] Decode batch. #running-req: 1, #token: 840, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.07, #queue-req: 0
[2025-06-03 07:15:31] Decode batch. #running-req: 1, #token: 880, token usage: 0.04, cuda graph: False, gen throughput (token/s): 100.96, #queue-req: 0
[2025-06-03 07:15:32] Decode batch. #running-req: 1, #token: 920, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:15:32] Decode batch. #running-req: 1, #token: 960, token usage: 0.05, cuda graph: False, gen throughput (token/s): 99.65, #queue-req: 0
[2025-06-03 07:15:32] Decode batch. #running-req: 1, #token: 1000, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.39, #queue-req: 0
[2025-06-03 07:15:33] Decode batch. #running-req: 1, #token: 1040, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.31, #queue-req: 0
[2025-06-03 07:15:33] Decode batch. #running-req: 1, #token: 1080, token usage: 0.05, cuda graph: False, gen throughput (token/s): 102.17, #queue-req: 0
[2025-06-03 07:15:34] Decode batch. #running-req: 1, #token: 1120, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.22, #queue-req: 0
[2025-06-03 07:15:34] Decode batch. #running-req: 1, #token: 1160, token usage: 0.06, cuda graph: False, gen throughput (token/s): 103.12, #queue-req: 0
[2025-06-03 07:15:34] Decode batch. #running-req: 1, #token: 1200, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.48, #queue-req: 0
[2025-06-03 07:15:35] Decode batch. #running-req: 1, #token: 1240, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.77, #queue-req: 0
[2025-06-03 07:15:35] Decode batch. #running-req: 1, #token: 1280, token usage: 0.06, cuda graph: False, gen throughput (token/s): 103.23, #queue-req: 0
[2025-06-03 07:15:35] Decode batch. #running-req: 1, #token: 1320, token usage: 0.06, cuda graph: False, gen throughput (token/s): 103.83, #queue-req: 0
[2025-06-03 07:15:36] Decode batch. #running-req: 1, #token: 1360, token usage: 0.07, cuda graph: False, gen throughput (token/s): 102.11, #queue-req: 0
[2025-06-03 07:15:36] Decode batch. #running-req: 1, #token: 1400, token usage: 0.07, cuda graph: False, gen throughput (token/s): 100.50, #queue-req: 0
[2025-06-03 07:15:37] Decode batch. #running-req: 1, #token: 1440, token usage: 0.07, cuda graph: False, gen throughput (token/s): 98.08, #queue-req: 0
[2025-06-03 07:15:37] Decode batch. #running-req: 1, #token: 1480, token usage: 0.07, cuda graph: False, gen throughput (token/s): 103.31, #queue-req: 0
[2025-06-03 07:15:37] Decode batch. #running-req: 1, #token: 1520, token usage: 0.07, cuda graph: False, gen throughput (token/s): 103.92, #queue-req: 0
[2025-06-03 07:15:38] Decode batch. #running-req: 1, #token: 1560, token usage: 0.08, cuda graph: False, gen throughput (token/s): 102.75, #queue-req: 0
[2025-06-03 07:15:38] Decode batch. #running-req: 1, #token: 1600, token usage: 0.08, cuda graph: False, gen throughput (token/s): 102.92, #queue-req: 0
[2025-06-03 07:15:39] Decode batch. #running-req: 1, #token: 1640, token usage: 0.08, cuda graph: False, gen throughput (token/s): 102.37, #queue-req: 0
[2025-06-03 07:15:39] Decode batch. #running-req: 1, #token: 1680, token usage: 0.08, cuda graph: False, gen throughput (token/s): 93.80, #queue-req: 0
[2025-06-03 07:15:40] Decode batch. #running-req: 1, #token: 1720, token usage: 0.08, cuda graph: False, gen throughput (token/s): 83.65, #queue-req: 0
[2025-06-03 07:15:40] Decode batch. #running-req: 1, #token: 1760, token usage: 0.09, cuda graph: False, gen throughput (token/s): 82.96, #queue-req: 0
[2025-06-03 07:15:40] Decode batch. #running-req: 1, #token: 1800, token usage: 0.09, cuda graph: False, gen throughput (token/s): 99.55, #queue-req: 0
[2025-06-03 07:15:41] Decode batch. #running-req: 1, #token: 1840, token usage: 0.09, cuda graph: False, gen throughput (token/s): 102.95, #queue-req: 0
[2025-06-03 07:15:41] Decode batch. #running-req: 1, #token: 1880, token usage: 0.09, cuda graph: False, gen throughput (token/s): 91.35, #queue-req: 0
[2025-06-03 07:15:42] Decode batch. #running-req: 1, #token: 1920, token usage: 0.09, cuda graph: False, gen throughput (token/s): 101.99, #queue-req: 0
[2025-06-03 07:15:42] Decode batch. #running-req: 1, #token: 1960, token usage: 0.10, cuda graph: False, gen throughput (token/s): 80.59, #queue-req: 0
[2025-06-03 07:15:43] Decode batch. #running-req: 1, #token: 2000, token usage: 0.10, cuda graph: False, gen throughput (token/s): 93.35, #queue-req: 0
[2025-06-03 07:15:43] Decode batch. #running-req: 1, #token: 2040, token usage: 0.10, cuda graph: False, gen throughput (token/s): 93.96, #queue-req: 0
[2025-06-03 07:15:43] Decode batch. #running-req: 1, #token: 2080, token usage: 0.10, cuda graph: False, gen throughput (token/s): 96.63, #queue-req: 0
[2025-06-03 07:15:44] Decode batch. #running-req: 1, #token: 2120, token usage: 0.10, cuda graph: False, gen throughput (token/s): 99.29, #queue-req: 0
[2025-06-03 07:15:44] Decode batch. #running-req: 1, #token: 2160, token usage: 0.11, cuda graph: False, gen throughput (token/s): 97.02, #queue-req: 0
[2025-06-03 07:15:45] Decode batch. #running-req: 1, #token: 2200, token usage: 0.11, cuda graph: False, gen throughput (token/s): 99.29, #queue-req: 0
[2025-06-03 07:15:45] Decode batch. #running-req: 1, #token: 2240, token usage: 0.11, cuda graph: False, gen throughput (token/s): 97.39, #queue-req: 0
[2025-06-03 07:15:45] Decode batch. #running-req: 1, #token: 2280, token usage: 0.11, cuda graph: False, gen throughput (token/s): 90.48, #queue-req: 0
[2025-06-03 07:15:46] Decode batch. #running-req: 1, #token: 2320, token usage: 0.11, cuda graph: False, gen throughput (token/s): 93.23, #queue-req: 0
[2025-06-03 07:15:46] Decode batch. #running-req: 1, #token: 2360, token usage: 0.12, cuda graph: False, gen throughput (token/s): 93.11, #queue-req: 0
[2025-06-03 07:15:47] Decode batch. #running-req: 1, #token: 2400, token usage: 0.12, cuda graph: False, gen throughput (token/s): 95.89, #queue-req: 0
[2025-06-03 07:15:47] Decode batch. #running-req: 1, #token: 2440, token usage: 0.12, cuda graph: False, gen throughput (token/s): 100.04, #queue-req: 0
[2025-06-03 07:15:48] Decode batch. #running-req: 1, #token: 2480, token usage: 0.12, cuda graph: False, gen throughput (token/s): 101.86, #queue-req: 0
[2025-06-03 07:15:48] Decode batch. #running-req: 1, #token: 2520, token usage: 0.12, cuda graph: False, gen throughput (token/s): 101.33, #queue-req: 0
[2025-06-03 07:15:48] Decode batch. #running-req: 1, #token: 2560, token usage: 0.12, cuda graph: False, gen throughput (token/s): 101.70, #queue-req: 0
[2025-06-03 07:15:49] Decode batch. #running-req: 1, #token: 2600, token usage: 0.13, cuda graph: False, gen throughput (token/s): 100.67, #queue-req: 0
[2025-06-03 07:15:49] Decode batch. #running-req: 1, #token: 2640, token usage: 0.13, cuda graph: False, gen throughput (token/s): 101.68, #queue-req: 0
[2025-06-03 07:15:49] Decode batch. #running-req: 1, #token: 2680, token usage: 0.13, cuda graph: False, gen throughput (token/s): 103.13, #queue-req: 0
[2025-06-03 07:15:50] Decode batch. #running-req: 1, #token: 2720, token usage: 0.13, cuda graph: False, gen throughput (token/s): 103.25, #queue-req: 0
[2025-06-03 07:15:50] Decode batch. #running-req: 1, #token: 2760, token usage: 0.13, cuda graph: False, gen throughput (token/s): 98.83, #queue-req: 0
[2025-06-03 07:15:51] Decode batch. #running-req: 1, #token: 2800, token usage: 0.14, cuda graph: False, gen throughput (token/s): 101.59, #queue-req: 0
[2025-06-03 07:15:51] Decode batch. #running-req: 1, #token: 2840, token usage: 0.14, cuda graph: False, gen throughput (token/s): 102.57, #queue-req: 0
[2025-06-03 07:15:51] Decode batch. #running-req: 1, #token: 2880, token usage: 0.14, cuda graph: False, gen throughput (token/s): 100.68, #queue-req: 0
[2025-06-03 07:15:52] Decode batch. #running-req: 1, #token: 2920, token usage: 0.14, cuda graph: False, gen throughput (token/s): 100.40, #queue-req: 0
[2025-06-03 07:15:52] Decode batch. #running-req: 1, #token: 2960, token usage: 0.14, cuda graph: False, gen throughput (token/s): 102.27, #queue-req: 0
[2025-06-03 07:15:53] Decode batch. #running-req: 1, #token: 3000, token usage: 0.15, cuda graph: False, gen throughput (token/s): 102.27, #queue-req: 0
[2025-06-03 07:15:53] Decode batch. #running-req: 1, #token: 3040, token usage: 0.15, cuda graph: False, gen throughput (token/s): 100.82, #queue-req: 0
[2025-06-03 07:15:53] Decode batch. #running-req: 1, #token: 3080, token usage: 0.15, cuda graph: False, gen throughput (token/s): 100.36, #queue-req: 0
[2025-06-03 07:15:54] Decode batch. #running-req: 1, #token: 3120, token usage: 0.15, cuda graph: False, gen throughput (token/s): 99.15, #queue-req: 0
[2025-06-03 07:15:54] Decode batch. #running-req: 1, #token: 3160, token usage: 0.15, cuda graph: False, gen throughput (token/s): 97.44, #queue-req: 0
[2025-06-03 07:15:55] Decode batch. #running-req: 1, #token: 3200, token usage: 0.16, cuda graph: False, gen throughput (token/s): 100.64, #queue-req: 0
[2025-06-03 07:15:55] Decode batch. #running-req: 1, #token: 3240, token usage: 0.16, cuda graph: False, gen throughput (token/s): 101.17, #queue-req: 0
[2025-06-03 07:15:55] Decode batch. #running-req: 1, #token: 3280, token usage: 0.16, cuda graph: False, gen throughput (token/s): 102.62, #queue-req: 0
[2025-06-03 07:15:56] Decode batch. #running-req: 1, #token: 3320, token usage: 0.16, cuda graph: False, gen throughput (token/s): 102.59, #queue-req: 0
[2025-06-03 07:15:56] Decode batch. #running-req: 1, #token: 3360, token usage: 0.16, cuda graph: False, gen throughput (token/s): 103.28, #queue-req: 0
[2025-06-03 07:15:57] Decode batch. #running-req: 1, #token: 3400, token usage: 0.17, cuda graph: False, gen throughput (token/s): 102.39, #queue-req: 0
[2025-06-03 07:15:57] Decode batch. #running-req: 1, #token: 3440, token usage: 0.17, cuda graph: False, gen throughput (token/s): 102.32, #queue-req: 0
[2025-06-03 07:15:57] Decode batch. #running-req: 1, #token: 3480, token usage: 0.17, cuda graph: False, gen throughput (token/s): 102.43, #queue-req: 0
[2025-06-03 07:15:58] Decode batch. #running-req: 1, #token: 3520, token usage: 0.17, cuda graph: False, gen throughput (token/s): 102.46, #queue-req: 0
[2025-06-03 07:15:58] Decode batch. #running-req: 1, #token: 3560, token usage: 0.17, cuda graph: False, gen throughput (token/s): 102.17, #queue-req: 0
[2025-06-03 07:15:59] Decode batch. #running-req: 1, #token: 3600, token usage: 0.18, cuda graph: False, gen throughput (token/s): 100.53, #queue-req: 0
[2025-06-03 07:15:59] Decode batch. #running-req: 1, #token: 3640, token usage: 0.18, cuda graph: False, gen throughput (token/s): 101.35, #queue-req: 0
[2025-06-03 07:15:59] Decode batch. #running-req: 1, #token: 3680, token usage: 0.18, cuda graph: False, gen throughput (token/s): 96.64, #queue-req: 0
[2025-06-03 07:16:00] Decode batch. #running-req: 1, #token: 3720, token usage: 0.18, cuda graph: False, gen throughput (token/s): 102.33, #queue-req: 0
[2025-06-03 07:16:00] Decode batch. #running-req: 1, #token: 3760, token usage: 0.18, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:16:01] Decode batch. #running-req: 1, #token: 3800, token usage: 0.19, cuda graph: False, gen throughput (token/s): 102.50, #queue-req: 0
[2025-06-03 07:16:01] Decode batch. #running-req: 1, #token: 3840, token usage: 0.19, cuda graph: False, gen throughput (token/s): 100.54, #queue-req: 0
[2025-06-03 07:16:01] Decode batch. #running-req: 1, #token: 3880, token usage: 0.19, cuda graph: False, gen throughput (token/s): 101.90, #queue-req: 0
[2025-06-03 07:16:02] Decode batch. #running-req: 1, #token: 3920, token usage: 0.19, cuda graph: False, gen throughput (token/s): 102.16, #queue-req: 0
[2025-06-03 07:16:02] Decode batch. #running-req: 1, #token: 3960, token usage: 0.19, cuda graph: False, gen throughput (token/s): 102.48, #queue-req: 0
[2025-06-03 07:16:03] Decode batch. #running-req: 1, #token: 4000, token usage: 0.20, cuda graph: False, gen throughput (token/s): 102.04, #queue-req: 0
[2025-06-03 07:16:03] Decode batch. #running-req: 1, #token: 4040, token usage: 0.20, cuda graph: False, gen throughput (token/s): 101.35, #queue-req: 0
[2025-06-03 07:16:03] Decode batch. #running-req: 1, #token: 4080, token usage: 0.20, cuda graph: False, gen throughput (token/s): 100.43, #queue-req: 0
[2025-06-03 07:16:04] Decode batch. #running-req: 1, #token: 4120, token usage: 0.20, cuda graph: False, gen throughput (token/s): 101.92, #queue-req: 0
[2025-06-03 07:16:04] Decode batch. #running-req: 1, #token: 4160, token usage: 0.20, cuda graph: False, gen throughput (token/s): 102.29, #queue-req: 0
[2025-06-03 07:16:04] Decode batch. #running-req: 1, #token: 4200, token usage: 0.21, cuda graph: False, gen throughput (token/s): 101.29, #queue-req: 0
[2025-06-03 07:16:05] Decode batch. #running-req: 1, #token: 4240, token usage: 0.21, cuda graph: False, gen throughput (token/s): 101.51, #queue-req: 0
[2025-06-03 07:16:05] Decode batch. #running-req: 1, #token: 4280, token usage: 0.21, cuda graph: False, gen throughput (token/s): 97.47, #queue-req: 0
[2025-06-03 07:16:06] Decode batch. #running-req: 1, #token: 4320, token usage: 0.21, cuda graph: False, gen throughput (token/s): 102.04, #queue-req: 0
[2025-06-03 07:16:06] Decode batch. #running-req: 1, #token: 4360, token usage: 0.21, cuda graph: False, gen throughput (token/s): 102.37, #queue-req: 0
[2025-06-03 07:16:06] Decode batch. #running-req: 1, #token: 4400, token usage: 0.21, cuda graph: False, gen throughput (token/s): 101.67, #queue-req: 0
[2025-06-03 07:16:07] Decode batch. #running-req: 1, #token: 4440, token usage: 0.22, cuda graph: False, gen throughput (token/s): 101.70, #queue-req: 0
[2025-06-03 07:16:07] Decode batch. #running-req: 1, #token: 4480, token usage: 0.22, cuda graph: False, gen throughput (token/s): 102.71, #queue-req: 0
[2025-06-03 07:16:08] Decode batch. #running-req: 1, #token: 4520, token usage: 0.22, cuda graph: False, gen throughput (token/s): 102.18, #queue-req: 0
[2025-06-03 07:16:08] Decode batch. #running-req: 1, #token: 4560, token usage: 0.22, cuda graph: False, gen throughput (token/s): 90.21, #queue-req: 0
[2025-06-03 07:16:08] Decode batch. #running-req: 1, #token: 4600, token usage: 0.22, cuda graph: False, gen throughput (token/s): 98.38, #queue-req: 0
[2025-06-03 07:16:09] Decode batch. #running-req: 1, #token: 4640, token usage: 0.23, cuda graph: False, gen throughput (token/s): 99.87, #queue-req: 0
[2025-06-03 07:16:09] Decode batch. #running-req: 1, #token: 4680, token usage: 0.23, cuda graph: False, gen throughput (token/s): 102.84, #queue-req: 0
[2025-06-03 07:16:10] Decode batch. #running-req: 1, #token: 4720, token usage: 0.23, cuda graph: False, gen throughput (token/s): 102.43, #queue-req: 0
[2025-06-03 07:16:10] Decode batch. #running-req: 1, #token: 4760, token usage: 0.23, cuda graph: False, gen throughput (token/s): 101.02, #queue-req: 0
[2025-06-03 07:16:10] Decode batch. #running-req: 1, #token: 4800, token usage: 0.23, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:16:11] Decode batch. #running-req: 1, #token: 4840, token usage: 0.24, cuda graph: False, gen throughput (token/s): 101.36, #queue-req: 0
[2025-06-03 07:16:11] Decode batch. #running-req: 1, #token: 4880, token usage: 0.24, cuda graph: False, gen throughput (token/s): 101.45, #queue-req: 0
[2025-06-03 07:16:12] Decode batch. #running-req: 1, #token: 4920, token usage: 0.24, cuda graph: False, gen throughput (token/s): 102.14, #queue-req: 0
[2025-06-03 07:16:12] Decode batch. #running-req: 1, #token: 4960, token usage: 0.24, cuda graph: False, gen throughput (token/s): 102.17, #queue-req: 0
[2025-06-03 07:16:12] Decode batch. #running-req: 1, #token: 5000, token usage: 0.24, cuda graph: False, gen throughput (token/s): 93.60, #queue-req: 0
[2025-06-03 07:16:13] Decode batch. #running-req: 1, #token: 5040, token usage: 0.25, cuda graph: False, gen throughput (token/s): 101.38, #queue-req: 0
[2025-06-03 07:16:13] Decode batch. #running-req: 1, #token: 5080, token usage: 0.25, cuda graph: False, gen throughput (token/s): 101.27, #queue-req: 0
[2025-06-03 07:16:14] Decode batch. #running-req: 1, #token: 5120, token usage: 0.25, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:16:14] Decode batch. #running-req: 1, #token: 5160, token usage: 0.25, cuda graph: False, gen throughput (token/s): 99.97, #queue-req: 0
[2025-06-03 07:16:14] Decode batch. #running-req: 1, #token: 5200, token usage: 0.25, cuda graph: False, gen throughput (token/s): 100.04, #queue-req: 0
[2025-06-03 07:16:15] Decode batch. #running-req: 1, #token: 5240, token usage: 0.26, cuda graph: False, gen throughput (token/s): 101.57, #queue-req: 0
[2025-06-03 07:16:15] Decode batch. #running-req: 1, #token: 5280, token usage: 0.26, cuda graph: False, gen throughput (token/s): 101.44, #queue-req: 0
[2025-06-03 07:16:16] Decode batch. #running-req: 1, #token: 5320, token usage: 0.26, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:16:16] Decode batch. #running-req: 1, #token: 5360, token usage: 0.26, cuda graph: False, gen throughput (token/s): 98.19, #queue-req: 0
[2025-06-03 07:16:16] Decode batch. #running-req: 1, #token: 5400, token usage: 0.26, cuda graph: False, gen throughput (token/s): 103.47, #queue-req: 0
[2025-06-03 07:16:17] Decode batch. #running-req: 1, #token: 5440, token usage: 0.27, cuda graph: False, gen throughput (token/s): 103.94, #queue-req: 0
[2025-06-03 07:16:17] Decode batch. #running-req: 1, #token: 5480, token usage: 0.27, cuda graph: False, gen throughput (token/s): 103.42, #queue-req: 0
[2025-06-03 07:16:18] Decode batch. #running-req: 1, #token: 5520, token usage: 0.27, cuda graph: False, gen throughput (token/s): 103.28, #queue-req: 0
[2025-06-03 07:16:18] Decode batch. #running-req: 1, #token: 5560, token usage: 0.27, cuda graph: False, gen throughput (token/s): 102.23, #queue-req: 0
[2025-06-03 07:16:18] Decode batch. #running-req: 1, #token: 5600, token usage: 0.27, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:16:19] Decode batch. #running-req: 1, #token: 5640, token usage: 0.28, cuda graph: False, gen throughput (token/s): 100.36, #queue-req: 0
[2025-06-03 07:16:19] Decode batch. #running-req: 1, #token: 5680, token usage: 0.28, cuda graph: False, gen throughput (token/s): 102.34, #queue-req: 0
[2025-06-03 07:16:20] Decode batch. #running-req: 1, #token: 5720, token usage: 0.28, cuda graph: False, gen throughput (token/s): 102.08, #queue-req: 0
[2025-06-03 07:16:20] Decode batch. #running-req: 1, #token: 5760, token usage: 0.28, cuda graph: False, gen throughput (token/s): 103.02, #queue-req: 0
[2025-06-03 07:16:20] Decode batch. #running-req: 1, #token: 5800, token usage: 0.28, cuda graph: False, gen throughput (token/s): 102.87, #queue-req: 0
[2025-06-03 07:16:21] Decode batch. #running-req: 1, #token: 5840, token usage: 0.29, cuda graph: False, gen throughput (token/s): 101.82, #queue-req: 0
[2025-06-03 07:16:21] Decode batch. #running-req: 1, #token: 5880, token usage: 0.29, cuda graph: False, gen throughput (token/s): 101.62, #queue-req: 0
[2025-06-03 07:16:22] Decode batch. #running-req: 1, #token: 5920, token usage: 0.29, cuda graph: False, gen throughput (token/s): 100.42, #queue-req: 0
[2025-06-03 07:16:22] Decode batch. #running-req: 1, #token: 5960, token usage: 0.29, cuda graph: False, gen throughput (token/s): 102.24, #queue-req: 0
[2025-06-03 07:16:22] Decode batch. #running-req: 1, #token: 6000, token usage: 0.29, cuda graph: False, gen throughput (token/s): 101.57, #queue-req: 0
[2025-06-03 07:16:23] Decode batch. #running-req: 1, #token: 6040, token usage: 0.29, cuda graph: False, gen throughput (token/s): 102.19, #queue-req: 0
[2025-06-03 07:16:23] Decode batch. #running-req: 1, #token: 6080, token usage: 0.30, cuda graph: False, gen throughput (token/s): 101.57, #queue-req: 0
[2025-06-03 07:16:23] Decode batch. #running-req: 1, #token: 6120, token usage: 0.30, cuda graph: False, gen throughput (token/s): 101.49, #queue-req: 0
[2025-06-03 07:16:24] Decode batch. #running-req: 1, #token: 6160, token usage: 0.30, cuda graph: False, gen throughput (token/s): 100.70, #queue-req: 0
[2025-06-03 07:16:24] Decode batch. #running-req: 1, #token: 6200, token usage: 0.30, cuda graph: False, gen throughput (token/s): 102.11, #queue-req: 0
[2025-06-03 07:16:25] Decode batch. #running-req: 1, #token: 6240, token usage: 0.30, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:16:25] Decode batch. #running-req: 1, #token: 6280, token usage: 0.31, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:16:25] Decode batch. #running-req: 1, #token: 6320, token usage: 0.31, cuda graph: False, gen throughput (token/s): 102.68, #queue-req: 0
[2025-06-03 07:16:26] Decode batch. #running-req: 1, #token: 6360, token usage: 0.31, cuda graph: False, gen throughput (token/s): 102.36, #queue-req: 0
[2025-06-03 07:16:26] Decode batch. #running-req: 1, #token: 6400, token usage: 0.31, cuda graph: False, gen throughput (token/s): 100.19, #queue-req: 0
[2025-06-03 07:16:27] Decode batch. #running-req: 1, #token: 6440, token usage: 0.31, cuda graph: False, gen throughput (token/s): 102.61, #queue-req: 0
[2025-06-03 07:16:27] Decode batch. #running-req: 1, #token: 6480, token usage: 0.32, cuda graph: False, gen throughput (token/s): 102.10, #queue-req: 0
[2025-06-03 07:16:27] Decode batch. #running-req: 1, #token: 6520, token usage: 0.32, cuda graph: False, gen throughput (token/s): 102.36, #queue-req: 0
[2025-06-03 07:16:28] Decode batch. #running-req: 1, #token: 6560, token usage: 0.32, cuda graph: False, gen throughput (token/s): 95.16, #queue-req: 0
[2025-06-03 07:16:28] Decode batch. #running-req: 1, #token: 6600, token usage: 0.32, cuda graph: False, gen throughput (token/s): 98.02, #queue-req: 0
[2025-06-03 07:16:29] Decode batch. #running-req: 1, #token: 6640, token usage: 0.32, cuda graph: False, gen throughput (token/s): 102.45, #queue-req: 0
[2025-06-03 07:16:29] Decode batch. #running-req: 1, #token: 6680, token usage: 0.33, cuda graph: False, gen throughput (token/s): 102.32, #queue-req: 0
[2025-06-03 07:16:29] Decode batch. #running-req: 1, #token: 6720, token usage: 0.33, cuda graph: False, gen throughput (token/s): 103.42, #queue-req: 0
[2025-06-03 07:16:30] Decode batch. #running-req: 1, #token: 6760, token usage: 0.33, cuda graph: False, gen throughput (token/s): 102.83, #queue-req: 0
[2025-06-03 07:16:30] Decode batch. #running-req: 1, #token: 6800, token usage: 0.33, cuda graph: False, gen throughput (token/s): 103.58, #queue-req: 0
[2025-06-03 07:16:31] Decode batch. #running-req: 1, #token: 6840, token usage: 0.33, cuda graph: False, gen throughput (token/s): 102.73, #queue-req: 0
[2025-06-03 07:16:31] Decode batch. #running-req: 1, #token: 6880, token usage: 0.34, cuda graph: False, gen throughput (token/s): 98.04, #queue-req: 0
[2025-06-03 07:16:31] Decode batch. #running-req: 1, #token: 6920, token usage: 0.34, cuda graph: False, gen throughput (token/s): 99.39, #queue-req: 0
[2025-06-03 07:16:32] Decode batch. #running-req: 1, #token: 6960, token usage: 0.34, cuda graph: False, gen throughput (token/s): 97.26, #queue-req: 0
[2025-06-03 07:16:32] Decode batch. #running-req: 1, #token: 7000, token usage: 0.34, cuda graph: False, gen throughput (token/s): 81.91, #queue-req: 0
[2025-06-03 07:16:33] Decode batch. #running-req: 1, #token: 7040, token usage: 0.34, cuda graph: False, gen throughput (token/s): 81.02, #queue-req: 0
[2025-06-03 07:16:33] Decode batch. #running-req: 1, #token: 7080, token usage: 0.35, cuda graph: False, gen throughput (token/s): 83.97, #queue-req: 0
[2025-06-03 07:16:34] Decode batch. #running-req: 1, #token: 7120, token usage: 0.35, cuda graph: False, gen throughput (token/s): 81.96, #queue-req: 0
[2025-06-03 07:16:34] Decode batch. #running-req: 1, #token: 7160, token usage: 0.35, cuda graph: False, gen throughput (token/s): 89.44, #queue-req: 0
[2025-06-03 07:16:35] Decode batch. #running-req: 1, #token: 7200, token usage: 0.35, cuda graph: False, gen throughput (token/s): 101.06, #queue-req: 0
[2025-06-03 07:16:35] Decode batch. #running-req: 1, #token: 7240, token usage: 0.35, cuda graph: False, gen throughput (token/s): 101.28, #queue-req: 0
[2025-06-03 07:16:35] Decode batch. #running-req: 1, #token: 7280, token usage: 0.36, cuda graph: False, gen throughput (token/s): 100.94, #queue-req: 0
[2025-06-03 07:16:36] Decode batch. #running-req: 1, #token: 7320, token usage: 0.36, cuda graph: False, gen throughput (token/s): 86.45, #queue-req: 0
[2025-06-03 07:16:36] Decode batch. #running-req: 1, #token: 7360, token usage: 0.36, cuda graph: False, gen throughput (token/s): 94.29, #queue-req: 0
[2025-06-03 07:16:37] Decode batch. #running-req: 1, #token: 7400, token usage: 0.36, cuda graph: False, gen throughput (token/s): 90.27, #queue-req: 0
[2025-06-03 07:16:37] Decode batch. #running-req: 1, #token: 7440, token usage: 0.36, cuda graph: False, gen throughput (token/s): 97.28, #queue-req: 0
[2025-06-03 07:16:38] Decode batch. #running-req: 1, #token: 7480, token usage: 0.37, cuda graph: False, gen throughput (token/s): 96.41, #queue-req: 0
[2025-06-03 07:16:38] Decode batch. #running-req: 1, #token: 7520, token usage: 0.37, cuda graph: False, gen throughput (token/s): 89.20, #queue-req: 0
[2025-06-03 07:16:38] Decode batch. #running-req: 1, #token: 7560, token usage: 0.37, cuda graph: False, gen throughput (token/s): 79.24, #queue-req: 0
[2025-06-03 07:16:39] Decode batch. #running-req: 1, #token: 7600, token usage: 0.37, cuda graph: False, gen throughput (token/s): 92.48, #queue-req: 0
[2025-06-03 07:16:39] Decode batch. #running-req: 1, #token: 7640, token usage: 0.37, cuda graph: False, gen throughput (token/s): 91.11, #queue-req: 0
[2025-06-03 07:16:40] Decode batch. #running-req: 1, #token: 7680, token usage: 0.38, cuda graph: False, gen throughput (token/s): 90.47, #queue-req: 0
[2025-06-03 07:16:40] Decode batch. #running-req: 1, #token: 7720, token usage: 0.38, cuda graph: False, gen throughput (token/s): 91.53, #queue-req: 0
[2025-06-03 07:16:41] Decode batch. #running-req: 1, #token: 7760, token usage: 0.38, cuda graph: False, gen throughput (token/s): 93.49, #queue-req: 0
[2025-06-03 07:16:41] Decode batch. #running-req: 1, #token: 7800, token usage: 0.38, cuda graph: False, gen throughput (token/s): 98.92, #queue-req: 0
[2025-06-03 07:16:41] Decode batch. #running-req: 1, #token: 7840, token usage: 0.38, cuda graph: False, gen throughput (token/s): 92.59, #queue-req: 0
[2025-06-03 07:16:42] Decode batch. #running-req: 1, #token: 7880, token usage: 0.38, cuda graph: False, gen throughput (token/s): 99.20, #queue-req: 0
[2025-06-03 07:16:42] Decode batch. #running-req: 1, #token: 7920, token usage: 0.39, cuda graph: False, gen throughput (token/s): 99.73, #queue-req: 0
[2025-06-03 07:16:43] Decode batch. #running-req: 1, #token: 7960, token usage: 0.39, cuda graph: False, gen throughput (token/s): 98.30, #queue-req: 0
[2025-06-03 07:16:43] Decode batch. #running-req: 1, #token: 8000, token usage: 0.39, cuda graph: False, gen throughput (token/s): 99.08, #queue-req: 0
[2025-06-03 07:16:43] Decode batch. #running-req: 1, #token: 8040, token usage: 0.39, cuda graph: False, gen throughput (token/s): 98.84, #queue-req: 0
[2025-06-03 07:16:44] Decode batch. #running-req: 1, #token: 8080, token usage: 0.39, cuda graph: False, gen throughput (token/s): 98.75, #queue-req: 0
[2025-06-03 07:16:44] Decode batch. #running-req: 1, #token: 8120, token usage: 0.40, cuda graph: False, gen throughput (token/s): 99.31, #queue-req: 0
[2025-06-03 07:16:45] Decode batch. #running-req: 1, #token: 8160, token usage: 0.40, cuda graph: False, gen throughput (token/s): 96.96, #queue-req: 0
[2025-06-03 07:16:45] Decode batch. #running-req: 1, #token: 8200, token usage: 0.40, cuda graph: False, gen throughput (token/s): 99.86, #queue-req: 0
[2025-06-03 07:16:46] Decode batch. #running-req: 1, #token: 8240, token usage: 0.40, cuda graph: False, gen throughput (token/s): 100.38, #queue-req: 0
[2025-06-03 07:16:46] Decode batch. #running-req: 1, #token: 8280, token usage: 0.40, cuda graph: False, gen throughput (token/s): 96.47, #queue-req: 0
[2025-06-03 07:16:46] Decode batch. #running-req: 1, #token: 8320, token usage: 0.41, cuda graph: False, gen throughput (token/s): 86.63, #queue-req: 0
[2025-06-03 07:16:47] Decode batch. #running-req: 1, #token: 8360, token usage: 0.41, cuda graph: False, gen throughput (token/s): 81.57, #queue-req: 0
[2025-06-03 07:16:47] Decode batch. #running-req: 1, #token: 8400, token usage: 0.41, cuda graph: False, gen throughput (token/s): 81.90, #queue-req: 0
[2025-06-03 07:16:48] Decode batch. #running-req: 1, #token: 8440, token usage: 0.41, cuda graph: False, gen throughput (token/s): 93.14, #queue-req: 0
[2025-06-03 07:16:48] Decode batch. #running-req: 1, #token: 8480, token usage: 0.41, cuda graph: False, gen throughput (token/s): 96.04, #queue-req: 0
[2025-06-03 07:16:49] Decode batch. #running-req: 1, #token: 8520, token usage: 0.42, cuda graph: False, gen throughput (token/s): 95.58, #queue-req: 0
[2025-06-03 07:16:49] Decode batch. #running-req: 1, #token: 8560, token usage: 0.42, cuda graph: False, gen throughput (token/s): 98.12, #queue-req: 0
[2025-06-03 07:16:49] Decode batch. #running-req: 1, #token: 8600, token usage: 0.42, cuda graph: False, gen throughput (token/s): 101.25, #queue-req: 0
[2025-06-03 07:16:50] Decode batch. #running-req: 1, #token: 8640, token usage: 0.42, cuda graph: False, gen throughput (token/s): 98.78, #queue-req: 0
[2025-06-03 07:16:50] Decode batch. #running-req: 1, #token: 8680, token usage: 0.42, cuda graph: False, gen throughput (token/s): 97.51, #queue-req: 0
[2025-06-03 07:16:51] Decode batch. #running-req: 1, #token: 8720, token usage: 0.43, cuda graph: False, gen throughput (token/s): 99.45, #queue-req: 0
[2025-06-03 07:16:51] Decode batch. #running-req: 1, #token: 8760, token usage: 0.43, cuda graph: False, gen throughput (token/s): 102.09, #queue-req: 0
[2025-06-03 07:16:51] Decode batch. #running-req: 1, #token: 8800, token usage: 0.43, cuda graph: False, gen throughput (token/s): 101.51, #queue-req: 0
[2025-06-03 07:16:52] Decode batch. #running-req: 1, #token: 8840, token usage: 0.43, cuda graph: False, gen throughput (token/s): 100.81, #queue-req: 0
[2025-06-03 07:16:52] Decode batch. #running-req: 1, #token: 8880, token usage: 0.43, cuda graph: False, gen throughput (token/s): 101.94, #queue-req: 0
[2025-06-03 07:16:53] Decode batch. #running-req: 1, #token: 8920, token usage: 0.44, cuda graph: False, gen throughput (token/s): 100.85, #queue-req: 0
[2025-06-03 07:16:53] Decode batch. #running-req: 1, #token: 8960, token usage: 0.44, cuda graph: False, gen throughput (token/s): 100.17, #queue-req: 0
[2025-06-03 07:16:53] Decode batch. #running-req: 1, #token: 9000, token usage: 0.44, cuda graph: False, gen throughput (token/s): 100.26, #queue-req: 0
[2025-06-03 07:16:54] Decode batch. #running-req: 1, #token: 9040, token usage: 0.44, cuda graph: False, gen throughput (token/s): 101.10, #queue-req: 0
[2025-06-03 07:16:54] Decode batch. #running-req: 1, #token: 9080, token usage: 0.44, cuda graph: False, gen throughput (token/s): 101.09, #queue-req: 0
[2025-06-03 07:16:55] Decode batch. #running-req: 1, #token: 9120, token usage: 0.45, cuda graph: False, gen throughput (token/s): 101.20, #queue-req: 0
[2025-06-03 07:16:55] Decode batch. #running-req: 1, #token: 9160, token usage: 0.45, cuda graph: False, gen throughput (token/s): 100.79, #queue-req: 0
[2025-06-03 07:16:55] Decode batch. #running-req: 1, #token: 9200, token usage: 0.45, cuda graph: False, gen throughput (token/s): 101.18, #queue-req: 0
[2025-06-03 07:16:56] Decode batch. #running-req: 1, #token: 9240, token usage: 0.45, cuda graph: False, gen throughput (token/s): 101.62, #queue-req: 0
[2025-06-03 07:16:56] Decode batch. #running-req: 1, #token: 9280, token usage: 0.45, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:16:57] Decode batch. #running-req: 1, #token: 9320, token usage: 0.46, cuda graph: False, gen throughput (token/s): 100.55, #queue-req: 0
[2025-06-03 07:16:57] Decode batch. #running-req: 1, #token: 9360, token usage: 0.46, cuda graph: False, gen throughput (token/s): 101.30, #queue-req: 0
[2025-06-03 07:16:57] Decode batch. #running-req: 1, #token: 9400, token usage: 0.46, cuda graph: False, gen throughput (token/s): 102.24, #queue-req: 0
[2025-06-03 07:16:58] Decode batch. #running-req: 1, #token: 9440, token usage: 0.46, cuda graph: False, gen throughput (token/s): 101.34, #queue-req: 0
[2025-06-03 07:16:58] Decode batch. #running-req: 1, #token: 9480, token usage: 0.46, cuda graph: False, gen throughput (token/s): 101.64, #queue-req: 0
[2025-06-03 07:16:59] Decode batch. #running-req: 1, #token: 9520, token usage: 0.46, cuda graph: False, gen throughput (token/s): 101.91, #queue-req: 0
[2025-06-03 07:16:59] Decode batch. #running-req: 1, #token: 9560, token usage: 0.47, cuda graph: False, gen throughput (token/s): 101.82, #queue-req: 0
[2025-06-03 07:16:59] Decode batch. #running-req: 1, #token: 9600, token usage: 0.47, cuda graph: False, gen throughput (token/s): 102.03, #queue-req: 0
[2025-06-03 07:17:00] Decode batch. #running-req: 1, #token: 9640, token usage: 0.47, cuda graph: False, gen throughput (token/s): 101.99, #queue-req: 0
[2025-06-03 07:17:00] Decode batch. #running-req: 1, #token: 9680, token usage: 0.47, cuda graph: False, gen throughput (token/s): 102.30, #queue-req: 0
[2025-06-03 07:17:01] Decode batch. #running-req: 1, #token: 9720, token usage: 0.47, cuda graph: False, gen throughput (token/s): 101.19, #queue-req: 0
[2025-06-03 07:17:01] Decode batch. #running-req: 1, #token: 9760, token usage: 0.48, cuda graph: False, gen throughput (token/s): 101.23, #queue-req: 0
[2025-06-03 07:17:01] Decode batch. #running-req: 1, #token: 9800, token usage: 0.48, cuda graph: False, gen throughput (token/s): 101.92, #queue-req: 0
[2025-06-03 07:17:02] Decode batch. #running-req: 1, #token: 9840, token usage: 0.48, cuda graph: False, gen throughput (token/s): 100.29, #queue-req: 0
[2025-06-03 07:17:02] Decode batch. #running-req: 1, #token: 9880, token usage: 0.48, cuda graph: False, gen throughput (token/s): 100.19, #queue-req: 0
[2025-06-03 07:17:03] Decode batch. #running-req: 1, #token: 9920, token usage: 0.48, cuda graph: False, gen throughput (token/s): 101.16, #queue-req: 0
[2025-06-03 07:17:03] Decode batch. #running-req: 1, #token: 9960, token usage: 0.49, cuda graph: False, gen throughput (token/s): 100.88, #queue-req: 0
[2025-06-03 07:17:03] Decode batch. #running-req: 1, #token: 10000, token usage: 0.49, cuda graph: False, gen throughput (token/s): 99.69, #queue-req: 0
[2025-06-03 07:17:04] Decode batch. #running-req: 1, #token: 10040, token usage: 0.49, cuda graph: False, gen throughput (token/s): 99.29, #queue-req: 0
[2025-06-03 07:17:04] Decode batch. #running-req: 1, #token: 10080, token usage: 0.49, cuda graph: False, gen throughput (token/s): 99.69, #queue-req: 0
[2025-06-03 07:17:05] Decode batch. #running-req: 1, #token: 10120, token usage: 0.49, cuda graph: False, gen throughput (token/s): 88.46, #queue-req: 0
[2025-06-03 07:17:05] Decode batch. #running-req: 1, #token: 10160, token usage: 0.50, cuda graph: False, gen throughput (token/s): 100.83, #queue-req: 0
[2025-06-03 07:17:05] Decode batch. #running-req: 1, #token: 10200, token usage: 0.50, cuda graph: False, gen throughput (token/s): 97.84, #queue-req: 0
[2025-06-03 07:17:06] Decode batch. #running-req: 1, #token: 10240, token usage: 0.50, cuda graph: False, gen throughput (token/s): 96.58, #queue-req: 0
[2025-06-03 07:17:06] Decode batch. #running-req: 1, #token: 10280, token usage: 0.50, cuda graph: False, gen throughput (token/s): 101.72, #queue-req: 0
[2025-06-03 07:17:07] Decode batch. #running-req: 1, #token: 10320, token usage: 0.50, cuda graph: False, gen throughput (token/s): 101.05, #queue-req: 0
[2025-06-03 07:17:07] Decode batch. #running-req: 1, #token: 10360, token usage: 0.51, cuda graph: False, gen throughput (token/s): 92.86, #queue-req: 0
[2025-06-03 07:17:07] Decode batch. #running-req: 1, #token: 10400, token usage: 0.51, cuda graph: False, gen throughput (token/s): 100.77, #queue-req: 0
[2025-06-03 07:17:08] Decode batch. #running-req: 1, #token: 10440, token usage: 0.51, cuda graph: False, gen throughput (token/s): 99.38, #queue-req: 0
[2025-06-03 07:17:08] Decode batch. #running-req: 1, #token: 10480, token usage: 0.51, cuda graph: False, gen throughput (token/s): 94.07, #queue-req: 0
[2025-06-03 07:17:09] Decode batch. #running-req: 1, #token: 10520, token usage: 0.51, cuda graph: False, gen throughput (token/s): 101.42, #queue-req: 0
[2025-06-03 07:17:09] Decode batch. #running-req: 1, #token: 10560, token usage: 0.52, cuda graph: False, gen throughput (token/s): 101.17, #queue-req: 0
[2025-06-03 07:17:09] Decode batch. #running-req: 1, #token: 10600, token usage: 0.52, cuda graph: False, gen throughput (token/s): 101.79, #queue-req: 0
[2025-06-03 07:17:10] Decode batch. #running-req: 1, #token: 10640, token usage: 0.52, cuda graph: False, gen throughput (token/s): 101.78, #queue-req: 0
[2025-06-03 07:17:10] Decode batch. #running-req: 1, #token: 10680, token usage: 0.52, cuda graph: False, gen throughput (token/s): 101.29, #queue-req: 0
[2025-06-03 07:17:11] Decode batch. #running-req: 1, #token: 10720, token usage: 0.52, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:17:11] Decode batch. #running-req: 1, #token: 10760, token usage: 0.53, cuda graph: False, gen throughput (token/s): 100.95, #queue-req: 0
[2025-06-03 07:17:11] Decode batch. #running-req: 1, #token: 10800, token usage: 0.53, cuda graph: False, gen throughput (token/s): 100.65, #queue-req: 0
[2025-06-03 07:17:12] Decode batch. #running-req: 1, #token: 10840, token usage: 0.53, cuda graph: False, gen throughput (token/s): 102.14, #queue-req: 0
[2025-06-03 07:17:12] Decode batch. #running-req: 1, #token: 10880, token usage: 0.53, cuda graph: False, gen throughput (token/s): 102.67, #queue-req: 0
[2025-06-03 07:17:13] Decode batch. #running-req: 1, #token: 10920, token usage: 0.53, cuda graph: False, gen throughput (token/s): 102.76, #queue-req: 0
[2025-06-03 07:17:13] Decode batch. #running-req: 1, #token: 10960, token usage: 0.54, cuda graph: False, gen throughput (token/s): 103.59, #queue-req: 0
[2025-06-03 07:17:13] Decode batch. #running-req: 1, #token: 11000, token usage: 0.54, cuda graph: False, gen throughput (token/s): 101.30, #queue-req: 0
[2025-06-03 07:17:14] Decode batch. #running-req: 1, #token: 11040, token usage: 0.54, cuda graph: False, gen throughput (token/s): 102.03, #queue-req: 0
[2025-06-03 07:17:14] Decode batch. #running-req: 1, #token: 11080, token usage: 0.54, cuda graph: False, gen throughput (token/s): 101.81, #queue-req: 0
[2025-06-03 07:17:15] Decode batch. #running-req: 1, #token: 11120, token usage: 0.54, cuda graph: False, gen throughput (token/s): 101.26, #queue-req: 0
[2025-06-03 07:17:15] Decode batch. #running-req: 1, #token: 11160, token usage: 0.54, cuda graph: False, gen throughput (token/s): 97.11, #queue-req: 0
[2025-06-03 07:17:15] Decode batch. #running-req: 1, #token: 11200, token usage: 0.55, cuda graph: False, gen throughput (token/s): 96.21, #queue-req: 0
[2025-06-03 07:17:16] Decode batch. #running-req: 1, #token: 11240, token usage: 0.55, cuda graph: False, gen throughput (token/s): 101.94, #queue-req: 0
[2025-06-03 07:17:16] Decode batch. #running-req: 1, #token: 11280, token usage: 0.55, cuda graph: False, gen throughput (token/s): 94.15, #queue-req: 0
[2025-06-03 07:17:17] Decode batch. #running-req: 1, #token: 11320, token usage: 0.55, cuda graph: False, gen throughput (token/s): 103.27, #queue-req: 0
[2025-06-03 07:17:17] Decode batch. #running-req: 1, #token: 11360, token usage: 0.55, cuda graph: False, gen throughput (token/s): 103.74, #queue-req: 0
[2025-06-03 07:17:17] Decode batch. #running-req: 1, #token: 11400, token usage: 0.56, cuda graph: False, gen throughput (token/s): 102.97, #queue-req: 0
[2025-06-03 07:17:18] Decode batch. #running-req: 1, #token: 11440, token usage: 0.56, cuda graph: False, gen throughput (token/s): 102.28, #queue-req: 0
[2025-06-03 07:17:18] Decode batch. #running-req: 1, #token: 11480, token usage: 0.56, cuda graph: False, gen throughput (token/s): 103.46, #queue-req: 0
[2025-06-03 07:17:18] Decode batch. #running-req: 1, #token: 11520, token usage: 0.56, cuda graph: False, gen throughput (token/s): 103.31, #queue-req: 0
[2025-06-03 07:17:19] Decode batch. #running-req: 1, #token: 11560, token usage: 0.56, cuda graph: False, gen throughput (token/s): 93.56, #queue-req: 0
[2025-06-03 07:17:19] Decode batch. #running-req: 1, #token: 11600, token usage: 0.57, cuda graph: False, gen throughput (token/s): 94.58, #queue-req: 0
[2025-06-03 07:17:20] Decode batch. #running-req: 1, #token: 11640, token usage: 0.57, cuda graph: False, gen throughput (token/s): 93.97, #queue-req: 0
[2025-06-03 07:17:20] Decode batch. #running-req: 1, #token: 11680, token usage: 0.57, cuda graph: False, gen throughput (token/s): 90.35, #queue-req: 0
[2025-06-03 07:17:21] Decode batch. #running-req: 1, #token: 11720, token usage: 0.57, cuda graph: False, gen throughput (token/s): 100.30, #queue-req: 0
[2025-06-03 07:17:21] Decode batch. #running-req: 1, #token: 11760, token usage: 0.57, cuda graph: False, gen throughput (token/s): 97.86, #queue-req: 0
[2025-06-03 07:17:21] Decode batch. #running-req: 1, #token: 11800, token usage: 0.58, cuda graph: False, gen throughput (token/s): 99.62, #queue-req: 0
[2025-06-03 07:17:22] Decode batch. #running-req: 1, #token: 11840, token usage: 0.58, cuda graph: False, gen throughput (token/s): 96.58, #queue-req: 0
[2025-06-03 07:17:22] Decode batch. #running-req: 1, #token: 11880, token usage: 0.58, cuda graph: False, gen throughput (token/s): 101.49, #queue-req: 0
[2025-06-03 07:17:23] Decode batch. #running-req: 1, #token: 11920, token usage: 0.58, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:17:23] Decode batch. #running-req: 1, #token: 11960, token usage: 0.58, cuda graph: False, gen throughput (token/s): 102.13, #queue-req: 0
[2025-06-03 07:17:23] Decode batch. #running-req: 1, #token: 12000, token usage: 0.59, cuda graph: False, gen throughput (token/s): 102.07, #queue-req: 0
[2025-06-03 07:17:24] Decode batch. #running-req: 1, #token: 12040, token usage: 0.59, cuda graph: False, gen throughput (token/s): 102.44, #queue-req: 0
[2025-06-03 07:17:24] Decode batch. #running-req: 1, #token: 12080, token usage: 0.59, cuda graph: False, gen throughput (token/s): 101.97, #queue-req: 0
[2025-06-03 07:17:25] Decode batch. #running-req: 1, #token: 12120, token usage: 0.59, cuda graph: False, gen throughput (token/s): 101.80, #queue-req: 0
[2025-06-03 07:17:25] Decode batch. #running-req: 1, #token: 12160, token usage: 0.59, cuda graph: False, gen throughput (token/s): 102.09, #queue-req: 0
[2025-06-03 07:17:25] Decode batch. #running-req: 1, #token: 12200, token usage: 0.60, cuda graph: False, gen throughput (token/s): 101.11, #queue-req: 0
[2025-06-03 07:17:26] Decode batch. #running-req: 1, #token: 12240, token usage: 0.60, cuda graph: False, gen throughput (token/s): 101.82, #queue-req: 0
[2025-06-03 07:17:26] Decode batch. #running-req: 1, #token: 12280, token usage: 0.60, cuda graph: False, gen throughput (token/s): 91.76, #queue-req: 0
[2025-06-03 07:17:27] Decode batch. #running-req: 1, #token: 12320, token usage: 0.60, cuda graph: False, gen throughput (token/s): 100.96, #queue-req: 0
[2025-06-03 07:17:27] Decode batch. #running-req: 1, #token: 12360, token usage: 0.60, cuda graph: False, gen throughput (token/s): 101.51, #queue-req: 0
[2025-06-03 07:17:27] Decode batch. #running-req: 1, #token: 12400, token usage: 0.61, cuda graph: False, gen throughput (token/s): 101.56, #queue-req: 0
[2025-06-03 07:17:28] Decode batch. #running-req: 1, #token: 12440, token usage: 0.61, cuda graph: False, gen throughput (token/s): 101.12, #queue-req: 0
[2025-06-03 07:17:28] Decode batch. #running-req: 1, #token: 12480, token usage: 0.61, cuda graph: False, gen throughput (token/s): 100.91, #queue-req: 0
[2025-06-03 07:17:29] Decode batch. #running-req: 1, #token: 12520, token usage: 0.61, cuda graph: False, gen throughput (token/s): 101.39, #queue-req: 0
[2025-06-03 07:17:29] Decode batch. #running-req: 1, #token: 12560, token usage: 0.61, cuda graph: False, gen throughput (token/s): 101.18, #queue-req: 0
[2025-06-03 07:17:30] Decode batch. #running-req: 1, #token: 12600, token usage: 0.62, cuda graph: False, gen throughput (token/s): 70.42, #queue-req: 0
[2025-06-03 07:17:30] Decode batch. #running-req: 1, #token: 12640, token usage: 0.62, cuda graph: False, gen throughput (token/s): 63.96, #queue-req: 0
[2025-06-03 07:17:31] Decode batch. #running-req: 1, #token: 12680, token usage: 0.62, cuda graph: False, gen throughput (token/s): 63.96, #queue-req: 0
[2025-06-03 07:17:31] Decode batch. #running-req: 1, #token: 12720, token usage: 0.62, cuda graph: False, gen throughput (token/s): 85.28, #queue-req: 0
[2025-06-03 07:17:32] Decode batch. #running-req: 1, #token: 12760, token usage: 0.62, cuda graph: False, gen throughput (token/s): 63.27, #queue-req: 0
[2025-06-03 07:17:33] Decode batch. #running-req: 1, #token: 12800, token usage: 0.62, cuda graph: False, gen throughput (token/s): 63.03, #queue-req: 0
[2025-06-03 07:17:33] Decode batch. #running-req: 1, #token: 12840, token usage: 0.63, cuda graph: False, gen throughput (token/s): 62.43, #queue-req: 0
[2025-06-03 07:17:34] Decode batch. #running-req: 1, #token: 12880, token usage: 0.63, cuda graph: False, gen throughput (token/s): 62.29, #queue-req: 0
[2025-06-03 07:17:34] Decode batch. #running-req: 1, #token: 12920, token usage: 0.63, cuda graph: False, gen throughput (token/s): 64.11, #queue-req: 0
[2025-06-03 07:17:35] Decode batch. #running-req: 1, #token: 12960, token usage: 0.63, cuda graph: False, gen throughput (token/s): 62.56, #queue-req: 0
[2025-06-03 07:17:36] Decode batch. #running-req: 1, #token: 13000, token usage: 0.63, cuda graph: False, gen throughput (token/s): 62.47, #queue-req: 0
[2025-06-03 07:17:36] Decode batch. #running-req: 1, #token: 13040, token usage: 0.64, cuda graph: False, gen throughput (token/s): 62.34, #queue-req: 0
[2025-06-03 07:17:37] Decode batch. #running-req: 1, #token: 13080, token usage: 0.64, cuda graph: False, gen throughput (token/s): 84.60, #queue-req: 0
[2025-06-03 07:17:37] Decode batch. #running-req: 1, #token: 13120, token usage: 0.64, cuda graph: False, gen throughput (token/s): 102.65, #queue-req: 0
[2025-06-03 07:17:38] Decode batch. #running-req: 1, #token: 13160, token usage: 0.64, cuda graph: False, gen throughput (token/s): 103.26, #queue-req: 0
[2025-06-03 07:17:38] Decode batch. #running-req: 1, #token: 13200, token usage: 0.64, cuda graph: False, gen throughput (token/s): 83.92, #queue-req: 0
[2025-06-03 07:17:38] Decode batch. #running-req: 1, #token: 13240, token usage: 0.65, cuda graph: False, gen throughput (token/s): 97.68, #queue-req: 0
[2025-06-03 07:17:39] Decode batch. #running-req: 1, #token: 13280, token usage: 0.65, cuda graph: False, gen throughput (token/s): 62.78, #queue-req: 0
[2025-06-03 07:17:40] Decode batch. #running-req: 1, #token: 13320, token usage: 0.65, cuda graph: False, gen throughput (token/s): 62.97, #queue-req: 0
[2025-06-03 07:17:40] Decode batch. #running-req: 1, #token: 13360, token usage: 0.65, cuda graph: False, gen throughput (token/s): 64.07, #queue-req: 0
[2025-06-03 07:17:41] Decode batch. #running-req: 1, #token: 13400, token usage: 0.65, cuda graph: False, gen throughput (token/s): 69.97, #queue-req: 0
[2025-06-03 07:17:41] Decode batch. #running-req: 1, #token: 13440, token usage: 0.66, cuda graph: False, gen throughput (token/s): 100.86, #queue-req: 0
[2025-06-03 07:17:42] Decode batch. #running-req: 1, #token: 13480, token usage: 0.66, cuda graph: False, gen throughput (token/s): 102.49, #queue-req: 0
[2025-06-03 07:17:42] Decode batch. #running-req: 1, #token: 13520, token usage: 0.66, cuda graph: False, gen throughput (token/s): 100.42, #queue-req: 0
[2025-06-03 07:17:43] Decode batch. #running-req: 1, #token: 13560, token usage: 0.66, cuda graph: False, gen throughput (token/s): 102.04, #queue-req: 0
[2025-06-03 07:17:43] Decode batch. #running-req: 1, #token: 13600, token usage: 0.66, cuda graph: False, gen throughput (token/s): 100.74, #queue-req: 0
[2025-06-03 07:17:43] Decode batch. #running-req: 1, #token: 13640, token usage: 0.67, cuda graph: False, gen throughput (token/s): 101.97, #queue-req: 0
[2025-06-03 07:17:44] Decode batch. #running-req: 1, #token: 13680, token usage: 0.67, cuda graph: False, gen throughput (token/s): 102.46, #queue-req: 0
[2025-06-03 07:17:44] Decode batch. #running-req: 1, #token: 13720, token usage: 0.67, cuda graph: False, gen throughput (token/s): 101.90, #queue-req: 0
[2025-06-03 07:17:44] Decode batch. #running-req: 1, #token: 13760, token usage: 0.67, cuda graph: False, gen throughput (token/s): 102.14, #queue-req: 0
[2025-06-03 07:17:45] Decode batch. #running-req: 1, #token: 13800, token usage: 0.67, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:17:45] Decode batch. #running-req: 1, #token: 13840, token usage: 0.68, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:17:46] Decode batch. #running-req: 1, #token: 13880, token usage: 0.68, cuda graph: False, gen throughput (token/s): 102.15, #queue-req: 0
[2025-06-03 07:17:46] Decode batch. #running-req: 1, #token: 13920, token usage: 0.68, cuda graph: False, gen throughput (token/s): 96.25, #queue-req: 0
[2025-06-03 07:17:47] Decode batch. #running-req: 1, #token: 13960, token usage: 0.68, cuda graph: False, gen throughput (token/s): 90.56, #queue-req: 0
[2025-06-03 07:17:47] Decode batch. #running-req: 1, #token: 14000, token usage: 0.68, cuda graph: False, gen throughput (token/s): 101.72, #queue-req: 0
[2025-06-03 07:17:47] Decode batch. #running-req: 1, #token: 14040, token usage: 0.69, cuda graph: False, gen throughput (token/s): 102.96, #queue-req: 0
[2025-06-03 07:17:48] Decode batch. #running-req: 1, #token: 14080, token usage: 0.69, cuda graph: False, gen throughput (token/s): 102.07, #queue-req: 0
[2025-06-03 07:17:48] Decode batch. #running-req: 1, #token: 14120, token usage: 0.69, cuda graph: False, gen throughput (token/s): 99.64, #queue-req: 0
[2025-06-03 07:17:48] Decode batch. #running-req: 1, #token: 14160, token usage: 0.69, cuda graph: False, gen throughput (token/s): 101.20, #queue-req: 0
[2025-06-03 07:17:49] Decode batch. #running-req: 1, #token: 14200, token usage: 0.69, cuda graph: False, gen throughput (token/s): 101.92, #queue-req: 0
[2025-06-03 07:17:49] Decode batch. #running-req: 1, #token: 14240, token usage: 0.70, cuda graph: False, gen throughput (token/s): 102.24, #queue-req: 0
[2025-06-03 07:17:50] Decode batch. #running-req: 1, #token: 14280, token usage: 0.70, cuda graph: False, gen throughput (token/s): 101.66, #queue-req: 0
[2025-06-03 07:17:50] Decode batch. #running-req: 1, #token: 14320, token usage: 0.70, cuda graph: False, gen throughput (token/s): 103.09, #queue-req: 0
[2025-06-03 07:17:50] Decode batch. #running-req: 1, #token: 14360, token usage: 0.70, cuda graph: False, gen throughput (token/s): 102.00, #queue-req: 0
[2025-06-03 07:17:51] Decode batch. #running-req: 1, #token: 14400, token usage: 0.70, cuda graph: False, gen throughput (token/s): 102.19, #queue-req: 0
[2025-06-03 07:17:51] Decode batch. #running-req: 1, #token: 14440, token usage: 0.71, cuda graph: False, gen throughput (token/s): 101.76, #queue-req: 0
[2025-06-03 07:17:52] Decode batch. #running-req: 1, #token: 14480, token usage: 0.71, cuda graph: False, gen throughput (token/s): 101.35, #queue-req: 0
[2025-06-03 07:17:52] Decode batch. #running-req: 1, #token: 14520, token usage: 0.71, cuda graph: False, gen throughput (token/s): 101.46, #queue-req: 0
[2025-06-03 07:17:52] Decode batch. #running-req: 1, #token: 14560, token usage: 0.71, cuda graph: False, gen throughput (token/s): 102.54, #queue-req: 0
[2025-06-03 07:17:53] Decode batch. #running-req: 1, #token: 14600, token usage: 0.71, cuda graph: False, gen throughput (token/s): 102.06, #queue-req: 0
[2025-06-03 07:17:53] Decode batch. #running-req: 1, #token: 14640, token usage: 0.71, cuda graph: False, gen throughput (token/s): 102.57, #queue-req: 0
[2025-06-03 07:17:54] Decode batch. #running-req: 1, #token: 14680, token usage: 0.72, cuda graph: False, gen throughput (token/s): 102.53, #queue-req: 0
[2025-06-03 07:17:54] Decode batch. #running-req: 1, #token: 14720, token usage: 0.72, cuda graph: False, gen throughput (token/s): 102.65, #queue-req: 0
[2025-06-03 07:17:54] Decode batch. #running-req: 1, #token: 14760, token usage: 0.72, cuda graph: False, gen throughput (token/s): 103.20, #queue-req: 0
[2025-06-03 07:17:55] Decode batch. #running-req: 1, #token: 14800, token usage: 0.72, cuda graph: False, gen throughput (token/s): 102.30, #queue-req: 0
[2025-06-03 07:17:55] Decode batch. #running-req: 1, #token: 14840, token usage: 0.72, cuda graph: False, gen throughput (token/s): 103.66, #queue-req: 0
[2025-06-03 07:17:56] Decode batch. #running-req: 1, #token: 14880, token usage: 0.73, cuda graph: False, gen throughput (token/s): 103.09, #queue-req: 0
[2025-06-03 07:17:56] Decode batch. #running-req: 1, #token: 14920, token usage: 0.73, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:17:56] Decode batch. #running-req: 1, #token: 14960, token usage: 0.73, cuda graph: False, gen throughput (token/s): 100.56, #queue-req: 0
[2025-06-03 07:17:57] Decode batch. #running-req: 1, #token: 15000, token usage: 0.73, cuda graph: False, gen throughput (token/s): 101.71, #queue-req: 0
[2025-06-03 07:17:57] Decode batch. #running-req: 1, #token: 15040, token usage: 0.73, cuda graph: False, gen throughput (token/s): 97.39, #queue-req: 0
[2025-06-03 07:17:58] Decode batch. #running-req: 1, #token: 15080, token usage: 0.74, cuda graph: False, gen throughput (token/s): 99.05, #queue-req: 0
[2025-06-03 07:17:58] Decode batch. #running-req: 1, #token: 15120, token usage: 0.74, cuda graph: False, gen throughput (token/s): 99.82, #queue-req: 0
[2025-06-03 07:17:58] Decode batch. #running-req: 1, #token: 15160, token usage: 0.74, cuda graph: False, gen throughput (token/s): 101.32, #queue-req: 0
[2025-06-03 07:17:59] Decode batch. #running-req: 1, #token: 15200, token usage: 0.74, cuda graph: False, gen throughput (token/s): 102.17, #queue-req: 0
[2025-06-03 07:17:59] Decode batch. #running-req: 1, #token: 15240, token usage: 0.74, cuda graph: False, gen throughput (token/s): 91.93, #queue-req: 0
[2025-06-03 07:18:00] Decode batch. #running-req: 1, #token: 15280, token usage: 0.75, cuda graph: False, gen throughput (token/s): 99.83, #queue-req: 0
[2025-06-03 07:18:00] Decode batch. #running-req: 1, #token: 15320, token usage: 0.75, cuda graph: False, gen throughput (token/s): 95.01, #queue-req: 0
[2025-06-03 07:18:00] Decode batch. #running-req: 1, #token: 15360, token usage: 0.75, cuda graph: False, gen throughput (token/s): 98.57, #queue-req: 0
[2025-06-03 07:18:01] Decode batch. #running-req: 1, #token: 15400, token usage: 0.75, cuda graph: False, gen throughput (token/s): 101.99, #queue-req: 0
[2025-06-03 07:18:01] Decode batch. #running-req: 1, #token: 15440, token usage: 0.75, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:18:02] Decode batch. #running-req: 1, #token: 15480, token usage: 0.76, cuda graph: False, gen throughput (token/s): 101.34, #queue-req: 0
[2025-06-03 07:18:02] Decode batch. #running-req: 1, #token: 15520, token usage: 0.76, cuda graph: False, gen throughput (token/s): 102.65, #queue-req: 0
[2025-06-03 07:18:02] Decode batch. #running-req: 1, #token: 15560, token usage: 0.76, cuda graph: False, gen throughput (token/s): 102.91, #queue-req: 0
[2025-06-03 07:18:03] Decode batch. #running-req: 1, #token: 15600, token usage: 0.76, cuda graph: False, gen throughput (token/s): 103.12, #queue-req: 0
[2025-06-03 07:18:03] Decode batch. #running-req: 1, #token: 15640, token usage: 0.76, cuda graph: False, gen throughput (token/s): 102.51, #queue-req: 0
[2025-06-03 07:18:04] Decode batch. #running-req: 1, #token: 15680, token usage: 0.77, cuda graph: False, gen throughput (token/s): 100.10, #queue-req: 0
[2025-06-03 07:18:04] Decode batch. #running-req: 1, #token: 15720, token usage: 0.77, cuda graph: False, gen throughput (token/s): 102.84, #queue-req: 0
[2025-06-03 07:18:04] Decode batch. #running-req: 1, #token: 15760, token usage: 0.77, cuda graph: False, gen throughput (token/s): 103.05, #queue-req: 0
[2025-06-03 07:18:05] Decode batch. #running-req: 1, #token: 15800, token usage: 0.77, cuda graph: False, gen throughput (token/s): 102.77, #queue-req: 0
[2025-06-03 07:18:05] Decode batch. #running-req: 1, #token: 15840, token usage: 0.77, cuda graph: False, gen throughput (token/s): 102.87, #queue-req: 0
[2025-06-03 07:18:05] Decode batch. #running-req: 1, #token: 15880, token usage: 0.78, cuda graph: False, gen throughput (token/s): 101.63, #queue-req: 0
[2025-06-03 07:18:06] Decode batch. #running-req: 1, #token: 15920, token usage: 0.78, cuda graph: False, gen throughput (token/s): 102.16, #queue-req: 0
[2025-06-03 07:18:06] Decode batch. #running-req: 1, #token: 15960, token usage: 0.78, cuda graph: False, gen throughput (token/s): 101.26, #queue-req: 0
[2025-06-03 07:18:07] Decode batch. #running-req: 1, #token: 16000, token usage: 0.78, cuda graph: False, gen throughput (token/s): 101.67, #queue-req: 0
[2025-06-03 07:18:07] Decode batch. #running-req: 1, #token: 16040, token usage: 0.78, cuda graph: False, gen throughput (token/s): 101.82, #queue-req: 0
[2025-06-03 07:18:07] Decode batch. #running-req: 1, #token: 16080, token usage: 0.79, cuda graph: False, gen throughput (token/s): 100.65, #queue-req: 0
[2025-06-03 07:18:08] Decode batch. #running-req: 1, #token: 16120, token usage: 0.79, cuda graph: False, gen throughput (token/s): 101.24, #queue-req: 0
[2025-06-03 07:18:08] Decode batch. #running-req: 1, #token: 16160, token usage: 0.79, cuda graph: False, gen throughput (token/s): 101.96, #queue-req: 0
[2025-06-03 07:18:09] Decode batch. #running-req: 1, #token: 16200, token usage: 0.79, cuda graph: False, gen throughput (token/s): 103.45, #queue-req: 0
[2025-06-03 07:18:09] Decode batch. #running-req: 1, #token: 16240, token usage: 0.79, cuda graph: False, gen throughput (token/s): 102.16, #queue-req: 0
[2025-06-03 07:18:09] Decode batch. #running-req: 1, #token: 16280, token usage: 0.79, cuda graph: False, gen throughput (token/s): 103.48, #queue-req: 0
[2025-06-03 07:18:10] Decode batch. #running-req: 1, #token: 16320, token usage: 0.80, cuda graph: False, gen throughput (token/s): 103.57, #queue-req: 0
[2025-06-03 07:18:10] Decode batch. #running-req: 1, #token: 16360, token usage: 0.80, cuda graph: False, gen throughput (token/s): 99.91, #queue-req: 0
[2025-06-03 07:18:11] Decode batch. #running-req: 1, #token: 16400, token usage: 0.80, cuda graph: False, gen throughput (token/s): 102.26, #queue-req: 0
[2025-06-03 07:18:11] Decode batch. #running-req: 1, #token: 16440, token usage: 0.80, cuda graph: False, gen throughput (token/s): 101.81, #queue-req: 0
[2025-06-03 07:18:11] Decode batch. #running-req: 1, #token: 16480, token usage: 0.80, cuda graph: False, gen throughput (token/s): 102.42, #queue-req: 0
[2025-06-03 07:18:12] Decode batch. #running-req: 1, #token: 16520, token usage: 0.81, cuda graph: False, gen throughput (token/s): 90.87, #queue-req: 0
[2025-06-03 07:18:12] Decode batch. #running-req: 1, #token: 16560, token usage: 0.81, cuda graph: False, gen throughput (token/s): 102.47, #queue-req: 0
[2025-06-03 07:18:13] Decode batch. #running-req: 1, #token: 16600, token usage: 0.81, cuda graph: False, gen throughput (token/s): 102.63, #queue-req: 0
[2025-06-03 07:18:13] Decode batch. #running-req: 1, #token: 16640, token usage: 0.81, cuda graph: False, gen throughput (token/s): 101.31, #queue-req: 0
[2025-06-03 07:18:13] Decode batch. #running-req: 1, #token: 16680, token usage: 0.81, cuda graph: False, gen throughput (token/s): 101.18, #queue-req: 0
[2025-06-03 07:18:14] Decode batch. #running-req: 1, #token: 16720, token usage: 0.82, cuda graph: False, gen throughput (token/s): 100.28, #queue-req: 0
[2025-06-03 07:18:14] Decode batch. #running-req: 1, #token: 16760, token usage: 0.82, cuda graph: False, gen throughput (token/s): 100.72, #queue-req: 0
[2025-06-03 07:18:15] Decode batch. #running-req: 1, #token: 16800, token usage: 0.82, cuda graph: False, gen throughput (token/s): 101.49, #queue-req: 0
[2025-06-03 07:18:15] Decode batch. #running-req: 1, #token: 16840, token usage: 0.82, cuda graph: False, gen throughput (token/s): 103.00, #queue-req: 0
[2025-06-03 07:18:15] Decode batch. #running-req: 1, #token: 16880, token usage: 0.82, cuda graph: False, gen throughput (token/s): 103.61, #queue-req: 0
[2025-06-03 07:18:16] Decode batch. #running-req: 1, #token: 16920, token usage: 0.83, cuda graph: False, gen throughput (token/s): 103.41, #queue-req: 0
[2025-06-03 07:18:16] Decode batch. #running-req: 1, #token: 16960, token usage: 0.83, cuda graph: False, gen throughput (token/s): 101.08, #queue-req: 0
[2025-06-03 07:18:17] Decode batch. #running-req: 1, #token: 17000, token usage: 0.83, cuda graph: False, gen throughput (token/s): 92.26, #queue-req: 0
[2025-06-03 07:18:17] Decode batch. #running-req: 1, #token: 17040, token usage: 0.83, cuda graph: False, gen throughput (token/s): 76.59, #queue-req: 0
[2025-06-03 07:18:18] Decode batch. #running-req: 1, #token: 17080, token usage: 0.83, cuda graph: False, gen throughput (token/s): 76.06, #queue-req: 0
[2025-06-03 07:18:18] Decode batch. #running-req: 1, #token: 17120, token usage: 0.84, cuda graph: False, gen throughput (token/s): 75.39, #queue-req: 0
[2025-06-03 07:18:19] Decode batch. #running-req: 1, #token: 17160, token usage: 0.84, cuda graph: False, gen throughput (token/s): 76.78, #queue-req: 0
[2025-06-03 07:18:19] Decode batch. #running-req: 1, #token: 17200, token usage: 0.84, cuda graph: False, gen throughput (token/s): 102.60, #queue-req: 0
[2025-06-03 07:18:19] Decode batch. #running-req: 1, #token: 17240, token usage: 0.84, cuda graph: False, gen throughput (token/s): 103.54, #queue-req: 0
[2025-06-03 07:18:20] Decode batch. #running-req: 1, #token: 17280, token usage: 0.84, cuda graph: False, gen throughput (token/s): 102.01, #queue-req: 0
[2025-06-03 07:18:20] Decode batch. #running-req: 1, #token: 17320, token usage: 0.85, cuda graph: False, gen throughput (token/s): 99.29, #queue-req: 0
[2025-06-03 07:18:21] Decode batch. #running-req: 1, #token: 17360, token usage: 0.85, cuda graph: False, gen throughput (token/s): 102.36, #queue-req: 0
[2025-06-03 07:18:21] Decode batch. #running-req: 1, #token: 17400, token usage: 0.85, cuda graph: False, gen throughput (token/s): 102.36, #queue-req: 0
[2025-06-03 07:18:21] Decode batch. #running-req: 1, #token: 17440, token usage: 0.85, cuda graph: False, gen throughput (token/s): 101.93, #queue-req: 0
[2025-06-03 07:18:22] Decode batch. #running-req: 1, #token: 17480, token usage: 0.85, cuda graph: False, gen throughput (token/s): 102.30, #queue-req: 0
[2025-06-03 07:18:22] Decode batch. #running-req: 1, #token: 17520, token usage: 0.86, cuda graph: False, gen throughput (token/s): 102.51, #queue-req: 0
[2025-06-03 07:18:23] Decode batch. #running-req: 1, #token: 17560, token usage: 0.86, cuda graph: False, gen throughput (token/s): 102.39, #queue-req: 0
[2025-06-03 07:18:23] Decode batch. #running-req: 1, #token: 17600, token usage: 0.86, cuda graph: False, gen throughput (token/s): 102.61, #queue-req: 0
[2025-06-03 07:18:23] Decode batch. #running-req: 1, #token: 17640, token usage: 0.86, cuda graph: False, gen throughput (token/s): 101.45, #queue-req: 0
[2025-06-03 07:18:24] Decode batch. #running-req: 1, #token: 17680, token usage: 0.86, cuda graph: False, gen throughput (token/s): 103.18, #queue-req: 0
[2025-06-03 07:18:24] Decode batch. #running-req: 1, #token: 17720, token usage: 0.87, cuda graph: False, gen throughput (token/s): 103.03, #queue-req: 0
[2025-06-03 07:18:24] Decode batch. #running-req: 1, #token: 17760, token usage: 0.87, cuda graph: False, gen throughput (token/s): 102.47, #queue-req: 0
[2025-06-03 07:18:25] Decode batch. #running-req: 1, #token: 17800, token usage: 0.87, cuda graph: False, gen throughput (token/s): 102.54, #queue-req: 0
[2025-06-03 07:18:25] Decode batch. #running-req: 1, #token: 17840, token usage: 0.87, cuda graph: False, gen throughput (token/s): 101.62, #queue-req: 0
[2025-06-03 07:18:26] Decode batch. #running-req: 1, #token: 17880, token usage: 0.87, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:18:26] Decode batch. #running-req: 1, #token: 17920, token usage: 0.88, cuda graph: False, gen throughput (token/s): 101.84, #queue-req: 0
[2025-06-03 07:18:26] Decode batch. #running-req: 1, #token: 17960, token usage: 0.88, cuda graph: False, gen throughput (token/s): 100.99, #queue-req: 0
[2025-06-03 07:18:27] Decode batch. #running-req: 1, #token: 18000, token usage: 0.88, cuda graph: False, gen throughput (token/s): 100.95, #queue-req: 0
[2025-06-03 07:18:27] Decode batch. #running-req: 1, #token: 18040, token usage: 0.88, cuda graph: False, gen throughput (token/s): 99.83, #queue-req: 0
[2025-06-03 07:18:28] Decode batch. #running-req: 1, #token: 18080, token usage: 0.88, cuda graph: False, gen throughput (token/s): 100.17, #queue-req: 0
[2025-06-03 07:18:28] Decode batch. #running-req: 1, #token: 18120, token usage: 0.88, cuda graph: False, gen throughput (token/s): 99.91, #queue-req: 0
[2025-06-03 07:18:28] Decode batch. #running-req: 1, #token: 18160, token usage: 0.89, cuda graph: False, gen throughput (token/s): 99.34, #queue-req: 0
[2025-06-03 07:18:29] Decode batch. #running-req: 1, #token: 18200, token usage: 0.89, cuda graph: False, gen throughput (token/s): 99.13, #queue-req: 0
[2025-06-03 07:18:29] Decode batch. #running-req: 1, #token: 18240, token usage: 0.89, cuda graph: False, gen throughput (token/s): 99.84, #queue-req: 0
[2025-06-03 07:18:30] Decode batch. #running-req: 1, #token: 18280, token usage: 0.89, cuda graph: False, gen throughput (token/s): 100.23, #queue-req: 0
[2025-06-03 07:18:30] Decode batch. #running-req: 1, #token: 18320, token usage: 0.89, cuda graph: False, gen throughput (token/s): 99.09, #queue-req: 0
[2025-06-03 07:18:30] Decode batch. #running-req: 1, #token: 18360, token usage: 0.90, cuda graph: False, gen throughput (token/s): 97.55, #queue-req: 0
[2025-06-03 07:18:31] Decode batch. #running-req: 1, #token: 18400, token usage: 0.90, cuda graph: False, gen throughput (token/s): 100.34, #queue-req: 0
[2025-06-03 07:18:31] Decode batch. #running-req: 1, #token: 18440, token usage: 0.90, cuda graph: False, gen throughput (token/s): 101.36, #queue-req: 0
[2025-06-03 07:18:32] Decode batch. #running-req: 1, #token: 18480, token usage: 0.90, cuda graph: False, gen throughput (token/s): 100.73, #queue-req: 0
[2025-06-03 07:18:32] Decode batch. #running-req: 1, #token: 18520, token usage: 0.90, cuda graph: False, gen throughput (token/s): 98.86, #queue-req: 0
[2025-06-03 07:18:33] Decode batch. #running-req: 1, #token: 18560, token usage: 0.91, cuda graph: False, gen throughput (token/s): 93.34, #queue-req: 0
[2025-06-03 07:18:33] Decode batch. #running-req: 1, #token: 18600, token usage: 0.91, cuda graph: False, gen throughput (token/s): 99.28, #queue-req: 0
[2025-06-03 07:18:33] Decode batch. #running-req: 1, #token: 18640, token usage: 0.91, cuda graph: False, gen throughput (token/s): 99.52, #queue-req: 0
[2025-06-03 07:18:34] Decode batch. #running-req: 1, #token: 18680, token usage: 0.91, cuda graph: False, gen throughput (token/s): 97.95, #queue-req: 0
[2025-06-03 07:18:34] Decode batch. #running-req: 1, #token: 18720, token usage: 0.91, cuda graph: False, gen throughput (token/s): 103.21, #queue-req: 0
[2025-06-03 07:18:35] Decode batch. #running-req: 1, #token: 18760, token usage: 0.92, cuda graph: False, gen throughput (token/s): 96.29, #queue-req: 0
[2025-06-03 07:18:35] Decode batch. #running-req: 1, #token: 18800, token usage: 0.92, cuda graph: False, gen throughput (token/s): 99.62, #queue-req: 0
[2025-06-03 07:18:35] Decode batch. #running-req: 1, #token: 18840, token usage: 0.92, cuda graph: False, gen throughput (token/s): 101.18, #queue-req: 0
[2025-06-03 07:18:36] Decode batch. #running-req: 1, #token: 18880, token usage: 0.92, cuda graph: False, gen throughput (token/s): 92.05, #queue-req: 0
[2025-06-03 07:18:36] Decode batch. #running-req: 1, #token: 18920, token usage: 0.92, cuda graph: False, gen throughput (token/s): 91.19, #queue-req: 0
[2025-06-03 07:18:37] Decode batch. #running-req: 1, #token: 18960, token usage: 0.93, cuda graph: False, gen throughput (token/s): 92.07, #queue-req: 0
[2025-06-03 07:18:37] Decode batch. #running-req: 1, #token: 19000, token usage: 0.93, cuda graph: False, gen throughput (token/s): 90.34, #queue-req: 0
[2025-06-03 07:18:38] Decode batch. #running-req: 1, #token: 19040, token usage: 0.93, cuda graph: False, gen throughput (token/s): 91.06, #queue-req: 0
[2025-06-03 07:18:38] Decode batch. #running-req: 1, #token: 19080, token usage: 0.93, cuda graph: False, gen throughput (token/s): 92.26, #queue-req: 0
[2025-06-03 07:18:38] Decode batch. #running-req: 1, #token: 19120, token usage: 0.93, cuda graph: False, gen throughput (token/s): 90.87, #queue-req: 0
[2025-06-03 07:18:39] Decode batch. #running-req: 1, #token: 19160, token usage: 0.94, cuda graph: False, gen throughput (token/s): 91.17, #queue-req: 0
[2025-06-03 07:18:39] Decode batch. #running-req: 1, #token: 19200, token usage: 0.94, cuda graph: False, gen throughput (token/s): 89.93, #queue-req: 0
[2025-06-03 07:18:40] Decode batch. #running-req: 1, #token: 19240, token usage: 0.94, cuda graph: False, gen throughput (token/s): 94.22, #queue-req: 0
[2025-06-03 07:18:40] Decode batch. #running-req: 1, #token: 19280, token usage: 0.94, cuda graph: False, gen throughput (token/s): 102.21, #queue-req: 0
[2025-06-03 07:18:40] Decode batch. #running-req: 1, #token: 19320, token usage: 0.94, cuda graph: False, gen throughput (token/s): 103.30, #queue-req: 0
[2025-06-03 07:18:41] Decode batch. #running-req: 1, #token: 19360, token usage: 0.95, cuda graph: False, gen throughput (token/s): 104.08, #queue-req: 0
[2025-06-03 07:18:41] Decode batch. #running-req: 1, #token: 19400, token usage: 0.95, cuda graph: False, gen throughput (token/s): 103.38, #queue-req: 0
[2025-06-03 07:18:42] Decode batch. #running-req: 1, #token: 19440, token usage: 0.95, cuda graph: False, gen throughput (token/s): 102.89, #queue-req: 0
[2025-06-03 07:18:42] Decode batch. #running-req: 1, #token: 19480, token usage: 0.95, cuda graph: False, gen throughput (token/s): 103.20, #queue-req: 0
[2025-06-03 07:18:42] Decode batch. #running-req: 1, #token: 19520, token usage: 0.95, cuda graph: False, gen throughput (token/s): 101.68, #queue-req: 0
[2025-06-03 07:18:43] Decode batch. #running-req: 1, #token: 19560, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.62, #queue-req: 0
[2025-06-03 07:18:43] Decode batch. #running-req: 1, #token: 19600, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.87, #queue-req: 0
[2025-06-03 07:18:44] Decode batch. #running-req: 1, #token: 19640, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.76, #queue-req: 0
[2025-06-03 07:18:44] Decode batch. #running-req: 1, #token: 19680, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.58, #queue-req: 0
[2025-06-03 07:18:44] Decode batch. #running-req: 1, #token: 19720, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.65, #queue-req: 0
[2025-06-03 07:18:45] Decode batch. #running-req: 1, #token: 19760, token usage: 0.96, cuda graph: False, gen throughput (token/s): 101.37, #queue-req: 0
[2025-06-03 07:18:45] Decode batch. #running-req: 1, #token: 19800, token usage: 0.97, cuda graph: False, gen throughput (token/s): 101.11, #queue-req: 0
[2025-06-03 07:18:46] Decode batch. #running-req: 1, #token: 19840, token usage: 0.97, cuda graph: False, gen throughput (token/s): 101.85, #queue-req: 0
[2025-06-03 07:18:46] Decode batch. #running-req: 1, #token: 19880, token usage: 0.97, cuda graph: False, gen throughput (token/s): 101.85, #queue-req: 0
[2025-06-03 07:18:46] Decode batch. #running-req: 1, #token: 19920, token usage: 0.97, cuda graph: False, gen throughput (token/s): 102.49, #queue-req: 0
[2025-06-03 07:18:47] Decode batch. #running-req: 1, #token: 19960, token usage: 0.97, cuda graph: False, gen throughput (token/s): 101.72, #queue-req: 0
[2025-06-03 07:18:47] Decode batch. #running-req: 1, #token: 20000, token usage: 0.98, cuda graph: False, gen throughput (token/s): 101.90, #queue-req: 0
[2025-06-03 07:18:48] Decode batch. #running-req: 1, #token: 20040, token usage: 0.98, cuda graph: False, gen throughput (token/s): 101.79, #queue-req: 0
[2025-06-03 07:18:48] Decode batch. #running-req: 1, #token: 20080, token usage: 0.98, cuda graph: False, gen throughput (token/s): 101.84, #queue-req: 0
[2025-06-03 07:18:48] Decode batch. #running-req: 1, #token: 20120, token usage: 0.98, cuda graph: False, gen throughput (token/s): 100.96, #queue-req: 0
[2025-06-03 07:18:49] Decode batch. #running-req: 1, #token: 20160, token usage: 0.98, cuda graph: False, gen throughput (token/s): 98.48, #queue-req: 0
[2025-06-03 07:18:49] Decode batch. #running-req: 1, #token: 20200, token usage: 0.99, cuda graph: False, gen throughput (token/s): 100.30, #queue-req: 0
[2025-06-03 07:18:49] Decode batch. #running-req: 1, #token: 20240, token usage: 0.99, cuda graph: False, gen throughput (token/s): 103.12, #queue-req: 0
[2025-06-03 07:18:50] Decode batch. #running-req: 1, #token: 20280, token usage: 0.99, cuda graph: False, gen throughput (token/s): 97.98, #queue-req: 0
[2025-06-03 07:18:50] Decode batch. #running-req: 1, #token: 20320, token usage: 0.99, cuda graph: False, gen throughput (token/s): 96.02, #queue-req: 0
[2025-06-03 07:18:51] Decode batch. #running-req: 1, #token: 20360, token usage: 0.99, cuda graph: False, gen throughput (token/s): 102.22, #queue-req: 0
[2025-06-03 07:18:51] Decode batch. #running-req: 1, #token: 20400, token usage: 1.00, cuda graph: False, gen throughput (token/s): 102.58, #queue-req: 0
[2025-06-03 07:18:51] Decode batch. #running-req: 1, #token: 20440, token usage: 1.00, cuda graph: False, gen throughput (token/s): 102.01, #queue-req: 0
[2025-06-03 07:18:52] INFO:     127.0.0.1:47716 - &#34;POST /v1/chat/completions HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, the user is in New York and wants the current date and time along with the weather. I need to figure out how to structure the response.<br><br>First, I should use the get_current_date function because it provides the date and time for a given timezone. The user mentioned New York, so I'll set the timezone parameter to 'America/New_York'. <br><br>Next, I'll need the weather information. The get_current_weather function requires a city and state. New York's state is NY, so I'll include both 'New York' and 'NY' as the city and state parameters respectively. The unit isn't specified, so I'll leave it out to avoid errors.<br><br>Now, I should format both results. For the date and time, I'll put it into the standard format like MM/DD/YYYY HH:MM. For the weather, I'll mention the condition, temperature, and feel-like temperature to give a complete picture.<br><br>I need to make sure each function call is properly formatted with the start_tag and end_tag, and include the parameters correctly. Also, I should check that all required parameters are specified and no extra ones are added.<br><br>Finally, I'll structure the response by first stating the date and time, then the weather details, each clearly separated so the user can easily understand the information.<br><br><br>content: <function=get_current_date>{"timezone": "America/New_York"}</function>  <br><function=get_current_weather>{"city": "New York", "state": "NY"  <br>    <br>        <br>    <br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>   <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>   <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br><br>    <br>                <br> <br><br>     ,</strong></div>
</div>
</section>
</section>
<section id="Native-API-and-SGLang-Runtime-(SRT)">
<h2>Native API and SGLang Runtime (SRT)<a class="headerlink" href="#Native-API-and-SGLang-Runtime-(SRT)" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>JSON<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">)</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information and population of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1"># Make API request</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()),</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>


<span class="n">reasoing_content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;/think&gt;&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;/think&gt;&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">print_highlight</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reasoing_content: </span><span class="si">{</span><span class="n">reasoing_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">content: </span><span class="si">{</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:18:56] Prefill batch. #new-seq: 1, #new-token: 22, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:18:56] Decode batch. #running-req: 1, #token: 25, token usage: 0.00, cuda graph: False, gen throughput (token/s): 9.12, #queue-req: 0
[2025-06-03 07:18:56] Decode batch. #running-req: 1, #token: 65, token usage: 0.00, cuda graph: False, gen throughput (token/s): 105.35, #queue-req: 0
[2025-06-03 07:18:57] Decode batch. #running-req: 1, #token: 105, token usage: 0.01, cuda graph: False, gen throughput (token/s): 105.45, #queue-req: 0
[2025-06-03 07:18:57] Decode batch. #running-req: 1, #token: 145, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.97, #queue-req: 0
[2025-06-03 07:18:57] Decode batch. #running-req: 1, #token: 185, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.40, #queue-req: 0
[2025-06-03 07:18:58] Decode batch. #running-req: 1, #token: 225, token usage: 0.01, cuda graph: False, gen throughput (token/s): 107.52, #queue-req: 0
[2025-06-03 07:18:58] Decode batch. #running-req: 1, #token: 265, token usage: 0.01, cuda graph: False, gen throughput (token/s): 107.24, #queue-req: 0
[2025-06-03 07:18:59] Decode batch. #running-req: 1, #token: 305, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.83, #queue-req: 0
[2025-06-03 07:18:59] Decode batch. #running-req: 1, #token: 345, token usage: 0.02, cuda graph: False, gen throughput (token/s): 105.37, #queue-req: 0
[2025-06-03 07:18:59] Decode batch. #running-req: 1, #token: 385, token usage: 0.02, cuda graph: False, gen throughput (token/s): 105.72, #queue-req: 0
[2025-06-03 07:18:59] INFO:     127.0.0.1:58854 - &#34;POST /generate HTTP/1.1&#34; 200 OK
{&#39;text&#39;: &#39;Okay, so the user is asking for the information and population of the capital of France in JSON format. Let me break this down.\n\nFirst, I need to identify the capital of France. I know that Paris is the capital, so that\&#39;s straightforward. Now, I should find the most recent population data. I remember that the population of Paris has been growing, but I\&#39;m not sure of the exact number. I think it\&#39;s around 2 million, but I should verify that.\n\nWait, I should check the latest statistics to be accurate. Maybe I can recall that as of 2023, the population was approximately 2,150,000. That seems about right. I should make sure to include this number in the JSON.\n\nNext, I need to structure this information into a JSON format. JSON typically uses key-value pairs, so I\&#39;ll create an object with keys like &#34;city&#34;, &#34;population&#34;, and &#34;country&#34;. The city is Paris, the population is 2,150,000, and the country is France.\n\nI should also consider the format. The user wants it in JSON, so I\&#39;ll make sure to use proper syntax with quotes and commas. I\&#39;ll avoid any markdown since they specified that, so just plain JSON.\n\nPutting it all together, the JSON object will have the city, population, and country. I\&#39;ll double-check the numbers to ensure accuracy. I think 2,150,000 is correct, but if I\&#39;m unsure, I might mention that the data is approximate.\n\nFinally, I\&#39;ll present the JSON without any additional text, just the code, as per the user\&#39;s request. That should fulfill their query effectively.\n&lt;/think&gt;{\n  &#34;name&#34;: &#34;Paris&#34;,\n  &#34;population&#34;: 2150000\n}&#39;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;1589be614dad403c8ce41e73c26457d1&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 23, &#39;completion_tokens&#39;: 374, &#39;cached_tokens&#39;: 1, &#39;e2e_latency&#39;: 3.5539276599884033}}
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>reasoing_content: Okay, so the user is asking for the information and population of the capital of France in JSON format. Let me break this down.<br><br>First, I need to identify the capital of France. I know that Paris is the capital, so that's straightforward. Now, I should find the most recent population data. I remember that the population of Paris has been growing, but I'm not sure of the exact number. I think it's around 2 million, but I should verify that.<br><br>Wait, I should check the latest statistics to be accurate. Maybe I can recall that as of 2023, the population was approximately 2,150,000. That seems about right. I should make sure to include this number in the JSON.<br><br>Next, I need to structure this information into a JSON format. JSON typically uses key-value pairs, so I'll create an object with keys like "city", "population", and "country". The city is Paris, the population is 2,150,000, and the country is France.<br><br>I should also consider the format. The user wants it in JSON, so I'll make sure to use proper syntax with quotes and commas. I'll avoid any markdown since they specified that, so just plain JSON.<br><br>Putting it all together, the JSON object will have the city, population, and country. I'll double-check the numbers to ensure accuracy. I think 2,150,000 is correct, but if I'm unsure, I might mention that the data is approximate.<br><br>Finally, I'll present the JSON without any additional text, just the code, as per the user's request. That should fulfill their query effectively.<br><br><br>content: {<br>  "name": "Paris",<br>  "population": 2150000<br>}</strong></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># JSON</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json_schema</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">print_highlight</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:18:59] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:19:00] Decode batch. #running-req: 1, #token: 51, token usage: 0.00, cuda graph: False, gen throughput (token/s): 100.06, #queue-req: 0
[2025-06-03 07:19:00] Decode batch. #running-req: 1, #token: 91, token usage: 0.00, cuda graph: False, gen throughput (token/s): 105.06, #queue-req: 0
[2025-06-03 07:19:00] Decode batch. #running-req: 1, #token: 131, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.85, #queue-req: 0
[2025-06-03 07:19:01] Decode batch. #running-req: 1, #token: 171, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.59, #queue-req: 0
[2025-06-03 07:19:01] Decode batch. #running-req: 1, #token: 211, token usage: 0.01, cuda graph: False, gen throughput (token/s): 107.04, #queue-req: 0
[2025-06-03 07:19:02] Decode batch. #running-req: 1, #token: 251, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.02, #queue-req: 0
[2025-06-03 07:19:02] Decode batch. #running-req: 1, #token: 291, token usage: 0.01, cuda graph: False, gen throughput (token/s): 106.89, #queue-req: 0
[2025-06-03 07:19:02] Decode batch. #running-req: 1, #token: 331, token usage: 0.02, cuda graph: False, gen throughput (token/s): 107.80, #queue-req: 0
[2025-06-03 07:19:03] Decode batch. #running-req: 1, #token: 371, token usage: 0.02, cuda graph: False, gen throughput (token/s): 107.51, #queue-req: 0
[2025-06-03 07:19:03] Decode batch. #running-req: 1, #token: 411, token usage: 0.02, cuda graph: False, gen throughput (token/s): 106.39, #queue-req: 0
[2025-06-03 07:19:03] Decode batch. #running-req: 1, #token: 451, token usage: 0.02, cuda graph: False, gen throughput (token/s): 105.13, #queue-req: 0
[2025-06-03 07:19:04] Decode batch. #running-req: 1, #token: 491, token usage: 0.02, cuda graph: False, gen throughput (token/s): 102.04, #queue-req: 0
[2025-06-03 07:19:04] INFO:     127.0.0.1:49942 - &#34;POST /generate HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>{'text': 'Okay, so the user is asking for the information and population of the capital of France in JSON format. Let me break this down. First, I need to identify what the capital of France is. I know that Paris is the capital, so that\'s the starting point.\n\nNext, I need to find the population of Paris. I remember that Paris is a major city with a large population, but I\'m not exactly sure of the current number. I think it\'s around 2 million, but I should double-check that. Maybe I can recall that it\'s approximately 2,150,000 as of recent estimates.\n\nNow, the user wants this information in JSON format. JSON stands for JavaScript Object Notation, which is a way to structure data. I need to create a JSON object that includes the key "capital" with the value "Paris" and another key "population" with the number I just thought of.\n\nI should make sure the JSON syntax is correct. That means using double quotes for keys and string values, and commas appropriately between key-value pairs. Also, the numbers should be in quotes if they\'re strings, but population is a number, so it should be without quotes.\n\nPutting it all together, the JSON object should look like this: {"capital": "Paris", "population": 2150000}. I should present this clearly so the user can easily understand and use the information.\n\nI wonder if the user needs more details, like the population figure\'s source or the exact year it was recorded. But since they didn\'t ask for that, I\'ll stick to the information requested. Maybe they just need a straightforward data structure for a program or a report.\n\nAlso, considering the user\'s request, they might be a student working on a project, or perhaps someone developing an app that requires capital cities and their populations. Either way, providing accurate and concise data is key.\n\nI should ensure that the JSON is correctly formatted to avoid any errors when the user tries to use it. No markdown, just plain JSON. That way, it\'s easy to copy and paste into their code or document.\n\nIn summary, I identified the capital, found the population number, structured it into a JSON object, and made sure the syntax is correct. I think this should meet the user\'s needs effectively.\n</think>{\n  "name": "Paris",\n  "population": 2150000\n}', 'meta_info': {'id': 'a748ecabd0be4dd085bfaf334f5500b1', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 23, 'completion_tokens': 497, 'cached_tokens': 22, 'e2e_latency': 4.708061933517456}}</strong></div>
</div>
</section>
<section id="id2">
<h3>EBNF<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Give me the information of the capital of France.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;n&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;root ::= city | description</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s1">&#39;city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;description ::= city &quot; is &quot; status</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;status ::= &quot;the capital of &quot; country</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;&#39;</span>
            <span class="p">),</span>
        <span class="p">},</span>
        <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;return_logprob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:19:04] Prefill batch. #new-seq: 1, #new-token: 10, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:19:04] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:19:04] Decode batch. #running-req: 3, #token: 41, token usage: 0.00, cuda graph: False, gen throughput (token/s): 105.12, #queue-req: 0
[2025-06-03 07:19:05] Decode batch. #running-req: 3, #token: 161, token usage: 0.01, cuda graph: False, gen throughput (token/s): 294.04, #queue-req: 0
[2025-06-03 07:19:05] Decode batch. #running-req: 3, #token: 281, token usage: 0.01, cuda graph: False, gen throughput (token/s): 293.72, #queue-req: 0
[2025-06-03 07:19:06] Decode batch. #running-req: 3, #token: 401, token usage: 0.02, cuda graph: False, gen throughput (token/s): 293.82, #queue-req: 0
[2025-06-03 07:19:06] Decode batch. #running-req: 3, #token: 521, token usage: 0.03, cuda graph: False, gen throughput (token/s): 280.47, #queue-req: 0
[2025-06-03 07:19:06] INFO:     127.0.0.1:49948 - &#34;POST /generate HTTP/1.1&#34; 200 OK
[{&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThat&#39;s all the information I have.\n\nOkay, so I need to figure out the capital of France. I know that Paris is the capital, but I&#39;m not entirely sure. Let me think about why I think that. I&#39;ve heard it mentioned a lot, especially in movies and TV shows. People often go there for business or tourism. Also, I remember learning in school that Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. Those places are famous worldwide, which makes me think that Paris is indeed the capital. Maybe I can cross-check this with some other sources or my notes. Wait, I don&#39;t have any other information right now, but based on what I know, Paris is the capital of France. I don&#39;t recall any other major city in France being referred to as the capital. So, I&#39;m pretty confident that Paris is correct.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;2379cc6b24944d1c8cb01d25b11e818c&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 201, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.2282779216766357}}, {&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThat&#39;s all the information I have.\n\nOkay, so I need to figure out the capital of France. I know that Paris is the capital, but I&#39;m not entirely sure. Let me think about why I think that. I&#39;ve heard it mentioned a lot, especially in movies and TV shows. People often go there for business or tourism. Also, I remember learning in school that Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. Those places are famous worldwide, which makes me think that Paris is indeed the capital. Maybe I can cross-check this with some other sources or my notes. Wait, I don&#39;t have any other information right now, but based on what I know, Paris is the capital of France. I don&#39;t recall any other major city in France being referred to as the capital. So, I&#39;m pretty confident that Paris is correct.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;da4a3264097a4c088557fb445329f8ac&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 201, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.2282826900482178}}, {&#39;text&#39;: &#34;\nThe capital of France is Paris.\n\nThat&#39;s all the information I have.\n\nOkay, so I need to figure out the capital of France. I know that Paris is the capital, but I&#39;m not entirely sure. Let me think about why I think that. I&#39;ve heard it mentioned a lot, especially in movies and TV shows. People often go there for business or tourism. Also, I remember learning in school that Paris is a major city in France, known for landmarks like the Eiffel Tower and the Louvre Museum. Those places are famous worldwide, which makes me think that Paris is indeed the capital. Maybe I can cross-check this with some other sources or my notes. Wait, I don&#39;t have any other information right now, but based on what I know, Paris is the capital of France. I don&#39;t recall any other major city in France being referred to as the capital. So, I&#39;m pretty confident that Paris is correct.\n&lt;/think&gt;Paris is the capital of France&#34;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;61edf0764daa48ab983a3369ac0b5874&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;stop&#39;, &#39;matched&#39;: 151643}, &#39;prompt_tokens&#39;: 11, &#39;completion_tokens&#39;: 201, &#39;cached_tokens&#39;: 10, &#39;e2e_latency&#39;: 2.228285551071167}}]
</pre></div></div>
</div>
</section>
<section id="id3">
<h3>Regular expression<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span>
    <span class="n">json</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Paris is the capital of&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(France|England)&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:19:06] Prefill batch. #new-seq: 1, #new-token: 5, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:19:06] Decode batch. #running-req: 1, #token: 15, token usage: 0.00, cuda graph: False, gen throughput (token/s): 238.91, #queue-req: 0
[2025-06-03 07:19:07] Decode batch. #running-req: 1, #token: 55, token usage: 0.00, cuda graph: False, gen throughput (token/s): 104.62, #queue-req: 0
[2025-06-03 07:19:07] Decode batch. #running-req: 1, #token: 95, token usage: 0.00, cuda graph: False, gen throughput (token/s): 105.87, #queue-req: 0
[2025-06-03 07:19:08] Decode batch. #running-req: 1, #token: 135, token usage: 0.01, cuda graph: False, gen throughput (token/s): 104.48, #queue-req: 0
[2025-06-03 07:19:08] Decode batch. #running-req: 1, #token: 175, token usage: 0.01, cuda graph: False, gen throughput (token/s): 104.81, #queue-req: 0
[2025-06-03 07:19:08] Decode batch. #running-req: 1, #token: 215, token usage: 0.01, cuda graph: False, gen throughput (token/s): 104.53, #queue-req: 0
[2025-06-03 07:19:09] Decode batch. #running-req: 1, #token: 255, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.68, #queue-req: 0
[2025-06-03 07:19:09] Decode batch. #running-req: 1, #token: 295, token usage: 0.01, cuda graph: False, gen throughput (token/s): 104.55, #queue-req: 0
[2025-06-03 07:19:10] Decode batch. #running-req: 1, #token: 335, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.25, #queue-req: 0
[2025-06-03 07:19:10] Decode batch. #running-req: 1, #token: 375, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.73, #queue-req: 0
[2025-06-03 07:19:10] Decode batch. #running-req: 1, #token: 415, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.32, #queue-req: 0
[2025-06-03 07:19:11] Decode batch. #running-req: 1, #token: 455, token usage: 0.02, cuda graph: False, gen throughput (token/s): 100.17, #queue-req: 0
[2025-06-03 07:19:11] Decode batch. #running-req: 1, #token: 495, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.44, #queue-req: 0
[2025-06-03 07:19:11] Decode batch. #running-req: 1, #token: 535, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.93, #queue-req: 0
[2025-06-03 07:19:12] Decode batch. #running-req: 1, #token: 575, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.50, #queue-req: 0
[2025-06-03 07:19:12] Decode batch. #running-req: 1, #token: 615, token usage: 0.03, cuda graph: False, gen throughput (token/s): 101.43, #queue-req: 0
[2025-06-03 07:19:13] Decode batch. #running-req: 1, #token: 655, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.18, #queue-req: 0
[2025-06-03 07:19:13] Decode batch. #running-req: 1, #token: 695, token usage: 0.03, cuda graph: False, gen throughput (token/s): 102.42, #queue-req: 0
[2025-06-03 07:19:13] Decode batch. #running-req: 1, #token: 735, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.94, #queue-req: 0
[2025-06-03 07:19:14] Decode batch. #running-req: 1, #token: 775, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.90, #queue-req: 0
[2025-06-03 07:19:14] Decode batch. #running-req: 1, #token: 815, token usage: 0.04, cuda graph: False, gen throughput (token/s): 96.88, #queue-req: 0
[2025-06-03 07:19:15] Decode batch. #running-req: 1, #token: 855, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.92, #queue-req: 0
[2025-06-03 07:19:15] Decode batch. #running-req: 1, #token: 895, token usage: 0.04, cuda graph: False, gen throughput (token/s): 101.84, #queue-req: 0
[2025-06-03 07:19:15] Decode batch. #running-req: 1, #token: 935, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.23, #queue-req: 0
[2025-06-03 07:19:16] Decode batch. #running-req: 1, #token: 975, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.39, #queue-req: 0
[2025-06-03 07:19:16] Decode batch. #running-req: 1, #token: 1015, token usage: 0.05, cuda graph: False, gen throughput (token/s): 101.72, #queue-req: 0
[2025-06-03 07:19:17] Decode batch. #running-req: 1, #token: 1055, token usage: 0.05, cuda graph: False, gen throughput (token/s): 103.85, #queue-req: 0
[2025-06-03 07:19:17] Decode batch. #running-req: 1, #token: 1095, token usage: 0.05, cuda graph: False, gen throughput (token/s): 102.55, #queue-req: 0
[2025-06-03 07:19:17] Decode batch. #running-req: 1, #token: 1135, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.80, #queue-req: 0
[2025-06-03 07:19:18] Decode batch. #running-req: 1, #token: 1175, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.21, #queue-req: 0
[2025-06-03 07:19:18] Decode batch. #running-req: 1, #token: 1215, token usage: 0.06, cuda graph: False, gen throughput (token/s): 103.14, #queue-req: 0
[2025-06-03 07:19:19] Decode batch. #running-req: 1, #token: 1255, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.69, #queue-req: 0
[2025-06-03 07:19:19] Decode batch. #running-req: 1, #token: 1295, token usage: 0.06, cuda graph: False, gen throughput (token/s): 102.27, #queue-req: 0
[2025-06-03 07:19:19] Decode batch. #running-req: 1, #token: 1335, token usage: 0.07, cuda graph: False, gen throughput (token/s): 102.66, #queue-req: 0
[2025-06-03 07:19:20] Decode batch. #running-req: 1, #token: 1375, token usage: 0.07, cuda graph: False, gen throughput (token/s): 102.00, #queue-req: 0
[2025-06-03 07:19:20] Decode batch. #running-req: 1, #token: 1415, token usage: 0.07, cuda graph: False, gen throughput (token/s): 100.12, #queue-req: 0
[2025-06-03 07:19:20] Decode batch. #running-req: 1, #token: 1455, token usage: 0.07, cuda graph: False, gen throughput (token/s): 100.32, #queue-req: 0
[2025-06-03 07:19:21] Decode batch. #running-req: 1, #token: 1495, token usage: 0.07, cuda graph: False, gen throughput (token/s): 101.21, #queue-req: 0
[2025-06-03 07:19:21] Decode batch. #running-req: 1, #token: 1535, token usage: 0.07, cuda graph: False, gen throughput (token/s): 101.21, #queue-req: 0
[2025-06-03 07:19:22] Decode batch. #running-req: 1, #token: 1575, token usage: 0.08, cuda graph: False, gen throughput (token/s): 101.22, #queue-req: 0
[2025-06-03 07:19:22] Decode batch. #running-req: 1, #token: 1615, token usage: 0.08, cuda graph: False, gen throughput (token/s): 100.30, #queue-req: 0
[2025-06-03 07:19:22] Decode batch. #running-req: 1, #token: 1655, token usage: 0.08, cuda graph: False, gen throughput (token/s): 98.24, #queue-req: 0
[2025-06-03 07:19:23] Decode batch. #running-req: 1, #token: 1695, token usage: 0.08, cuda graph: False, gen throughput (token/s): 100.44, #queue-req: 0
[2025-06-03 07:19:23] Decode batch. #running-req: 1, #token: 1735, token usage: 0.08, cuda graph: False, gen throughput (token/s): 100.72, #queue-req: 0
[2025-06-03 07:19:24] Decode batch. #running-req: 1, #token: 1775, token usage: 0.09, cuda graph: False, gen throughput (token/s): 102.24, #queue-req: 0
[2025-06-03 07:19:24] Decode batch. #running-req: 1, #token: 1815, token usage: 0.09, cuda graph: False, gen throughput (token/s): 98.39, #queue-req: 0
[2025-06-03 07:19:24] Decode batch. #running-req: 1, #token: 1855, token usage: 0.09, cuda graph: False, gen throughput (token/s): 102.80, #queue-req: 0
[2025-06-03 07:19:25] Decode batch. #running-req: 1, #token: 1895, token usage: 0.09, cuda graph: False, gen throughput (token/s): 103.81, #queue-req: 0
[2025-06-03 07:19:25] Decode batch. #running-req: 1, #token: 1935, token usage: 0.09, cuda graph: False, gen throughput (token/s): 102.70, #queue-req: 0
[2025-06-03 07:19:26] Decode batch. #running-req: 1, #token: 1975, token usage: 0.10, cuda graph: False, gen throughput (token/s): 103.59, #queue-req: 0
[2025-06-03 07:19:26] Decode batch. #running-req: 1, #token: 2015, token usage: 0.10, cuda graph: False, gen throughput (token/s): 103.27, #queue-req: 0
[2025-06-03 07:19:26] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, cuda graph: False, gen throughput (token/s): 105.94, #queue-req: 0
[2025-06-03 07:19:26] INFO:     127.0.0.1:49956 - &#34;POST /generate HTTP/1.1&#34; 200 OK
{&#39;text&#39;: &#39; France, and the \n\\( n \\)  \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\( l \\) \\( m \\) \\( k \\) \\(&#39;, &#39;meta_info&#39;: {&#39;id&#39;: &#39;bbdd48b7cac94f63a35bebbd71d1f7ac&#39;, &#39;finish_reason&#39;: {&#39;type&#39;: &#39;length&#39;, &#39;length&#39;: 2048}, &#39;prompt_tokens&#39;: 6, &#39;completion_tokens&#39;: 2048, &#39;cached_tokens&#39;: 1, &#39;e2e_latency&#39;: 20.031532764434814}}
</pre></div></div>
</div>
</section>
<section id="id4">
<h3>Structural Tag<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
    <span class="s2">&quot;sampling_params&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="s2">&quot;structural_tag&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
                <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                        <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                        <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">],</span>
                <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="p">),</span>
    <span class="p">},</span>
<span class="p">}</span>


<span class="c1"># Send POST request to the API endpoint</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;http://localhost:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">/generate&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
<span class="n">print_highlight</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:19:26] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0
[2025-06-03 07:19:27] Decode batch. #running-req: 1, #token: 64, token usage: 0.00, cuda graph: False, gen throughput (token/s): 96.49, #queue-req: 0
[2025-06-03 07:19:27] Decode batch. #running-req: 1, #token: 104, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.39, #queue-req: 0
[2025-06-03 07:19:28] Decode batch. #running-req: 1, #token: 144, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.57, #queue-req: 0
[2025-06-03 07:19:28] Decode batch. #running-req: 1, #token: 184, token usage: 0.01, cuda graph: False, gen throughput (token/s): 103.26, #queue-req: 0
[2025-06-03 07:19:28] Decode batch. #running-req: 1, #token: 224, token usage: 0.01, cuda graph: False, gen throughput (token/s): 102.75, #queue-req: 0
[2025-06-03 07:19:29] Decode batch. #running-req: 1, #token: 264, token usage: 0.01, cuda graph: False, gen throughput (token/s): 103.59, #queue-req: 0
[2025-06-03 07:19:29] Decode batch. #running-req: 1, #token: 304, token usage: 0.01, cuda graph: False, gen throughput (token/s): 103.93, #queue-req: 0
[2025-06-03 07:19:30] Decode batch. #running-req: 1, #token: 344, token usage: 0.02, cuda graph: False, gen throughput (token/s): 103.89, #queue-req: 0
[2025-06-03 07:19:30] Decode batch. #running-req: 1, #token: 384, token usage: 0.02, cuda graph: False, gen throughput (token/s): 104.18, #queue-req: 0
[2025-06-03 07:19:30] Decode batch. #running-req: 1, #token: 424, token usage: 0.02, cuda graph: False, gen throughput (token/s): 103.96, #queue-req: 0
[2025-06-03 07:19:30] INFO:     127.0.0.1:50866 - &#34;POST /generate HTTP/1.1&#34; 200 OK
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<strong style='color: #00008B;'>{'text': 'Okay, I need to help the user by providing the information and population of the capital of France in JSON format. First, I should recall what the capital of France is. I know it\'s Paris. \n\nNext, I need to find the most recent population data for Paris. I remember that population figures can change yearly, so I should look for the latest estimate. I think the population is around 2 million, but let me verify that.\n\nTo get accurate data, I might check a reliable source like a recent census or a trustworthy statistical website. For example, I\'ve seen figures around 2,175,000 people as of 2023. That seems up-to-date and accurate.\n\nNow, the user specifically asked for this information in JSON format. JSON stands for JavaScript Object Notation, so I\'ll structure it with a key "capital" and a key "population." The key for population should have the unit, probably in parentheses.\n\nPutting it all together, the JSON object should reflect that Paris is the capital and its population is approximately 2,175,000 people as of 2023. I\'ll make sure the syntax is correct, using double quotes and commas appropriately to avoid any errors.\n\nI should also consider if the user needs the data for a specific purpose, like a report or a presentation. Providing the population with the year specified should be helpful. \n\nAdditionally, I should check if the user wants more details, such as the year of the data or any projections, but since they didn\'t ask for that, I\'ll stick to providing just the population they requested.\n\nIn summary, I\'ll structure the answer with the correct JSON formatting, accurate information about Paris, and the latest population figure to meet the user\'s needs effectively.\n</think>\n\nHere is the information and population of the capital of France in JSON format:\n\n```json\n{\n  "capital": "Paris",\n  "population": "2,175,000 (as of 2023)"\n}\n```', 'meta_info': {'id': '600a9409af75497bbfe77c63f93ee031', 'finish_reason': {'type': 'stop', 'matched': 151643}, 'prompt_tokens': 23, 'completion_tokens': 419, 'cached_tokens': 22, 'e2e_latency': 4.062058210372925}}</strong></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">terminate_process</span><span class="p">(</span><span class="n">server_process</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[2025-06-03 07:19:30] Child process unexpectedly failed with exitcode=9. pid=1563382
</pre></div></div>
</div>
</section>
</section>
<section id="Offline-Engine-API">
<h2>Offline Engine API<a class="headerlink" href="#Offline-Engine-API" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sglang</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sgl</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">sgl</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;</span><span class="p">,</span>
    <span class="n">reasoning_parser</span><span class="o">=</span><span class="s2">&quot;deepseek-r1&quot;</span><span class="p">,</span>
    <span class="n">grammar_backend</span><span class="o">=</span><span class="s2">&quot;xgrammar&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00&lt;?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01&lt;00:01,  1.38s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.28s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02&lt;00:00,  1.30s/it]

</pre></div></div>
</div>
<section id="id5">
<h3>JSON<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p><strong>Using Pydantic</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of China in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Ireland in the JSON format.&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="c1"># Define the schema using Pydantic</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CapitalInfo</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;^\w+$&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the capital city&quot;</span><span class="p">)</span>
    <span class="n">population</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Population of the capital city&quot;</span><span class="p">)</span>


<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">CapitalInfo</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()),</span>
<span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of China in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of China, Beijing, in JSON format:

```json
{
  &#34;name&#34;: &#34;Beijing&#34;,
  &#34;capital&#34;: &#34;Yes&#34;,
  &#34;population&#34;: &#34;Over 30 million&#34;,
  &#34;founded&#34;: &#34;1248&#34;,
  &#34;Nickname&#34;: &#34;The Heaven on Earth&#34;,
  &#34;Location&#34;: &#34;Northern China&#34;,
  &#34;OfficialLanguages&#34;: [
    &#34;Mandarin Chinese&#34;,
    &#34;Bingyuan Chinese&#34;,
    &#34;Tibetan&#34;,
    &#34;Hui&#34;,
    &#34;Mongolian&#34;,
    &#34;Yugoslav&#34;,
    &#34;Other&#34;
  ],
  &#34;KeySights&#34;: [
    &#34;The Great Wall&#34;,
    &#34;Tiananmen Square&#34;,
    &#34;Forbidden City&#34;,
    &#34;Beijing Museum&#34;,
    &#34;Yuanmingyuan&#34;
  ],
  &#34;Climate&#34;: &#34;Temperate&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of France in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of France, Paris, in JSON format:

```json
{
  &#34;name&#34;: &#34;Paris&#34;,
  &#34;country&#34;: &#34;France&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 48.8566,
    &#34;longitude&#34;: 2.3522
  },
  &#34;founded&#34;: &#34;1340&#34;,
  &#34;population&#34;: &#34;9.7 million&#34;,
  &#34;area&#34;: &#34;105.5 square kilometers&#34;,
  &#34;features&#34;: {
    &#34;bridges&#34;: &#34;The Eiffel Tower, Notre-Dame, and the Seine River&#34;,
    &#34;landmarks&#34;: &#34;The Louvre Museum, Montmartre, and the Champs-Ã‰lysÃ©es&#34;
  },
  &#34;elevation&#34;: &#34;2 meters&#34;,
  &#34;time_zone&#34;: &#34;Central European Time (CET)&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of Ireland in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of Ireland in JSON format:

```json
{
  &#34;capital&#34;: &#34;Dublin&#34;,
  &#34;official_name&#34;: &#34;Dublin City&#34;,
  &#34;region&#34;: &#34;Dublin&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 53.3489,
    &#34;longitude&#34;: -6.2009
  },
  &#34;founded&#34;: &#34;1543&#34;,
  &#34;population&#34;: 1,234,567,
  &#34;area&#34;: {
    &#34;total&#34;: 123.45,
    &#34;land&#34;: 112.34,
    &#34;water&#34;: 11.11
  },
  &#34;climate&#34;: &#34; temperate&#34;,
  &#34;key_features&#34;: [
    &#34;City Walls&#34;,
    &#34;Trinity College&#34;,
    &#34;Leaving Certificate&#34;,
    &#34;St. Stephen&#39;s Cathedral&#34;,
    &#34;Glynn Bridge&#34;
  ],
  &#34;tourism&#34;: [
    &#34;The GAA&#34;,
    &#34;The National Library of Ireland&#34;,
    &#34;The SSE St. Patrick&#39;s Cathedral&#34;,
    &#34;The Phoenix Park&#34;,
    &#34;The Book of Kells&#34;
  ]
}
```

Let me know if you need any adjustments!
</pre></div></div>
</div>
<p><strong>JSON Schema Directly</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of China in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of France in the JSON format.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Ireland in the JSON format.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">json_schema</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
        <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span> <span class="s2">&quot;^[</span><span class="se">\\</span><span class="s2">w]+$&quot;</span><span class="p">},</span>
            <span class="s2">&quot;population&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;integer&quot;</span><span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="n">json_schema</span><span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of China in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of China, Beijing, in JSON format:

```json
{
  &#34;name&#34;: &#34;Beijing&#34;,
  &#34;capital&#34;: &#34;Yes&#34;,
  &#34;population&#34;: &#34;Over 30 million&#34;,
  &#34;founded&#34;: &#34;1248&#34;,
  &#34;Nickname&#34;: &#34;The Heaven on Earth&#34;,
  &#34;Location&#34;: &#34;Northern China&#34;,
  &#34;OfficialLanguages&#34;: [
    &#34;Mandarin Chinese&#34;,
    &#34;Bingyuan Chinese&#34;,
    &#34;Tibetan&#34;,
    &#34;Hui&#34;,
    &#34;Mongolian&#34;,
    &#34;Yugoslav&#34;,
    &#34;Other&#34;
  ],
  &#34;KeySights&#34;: [
    &#34;The Great Wall&#34;,
    &#34;Forbidden City&#34;,
    &#34;Tiananmen Square&#34;,
    &#34;Beijing Museum&#34;,
    &#34;Yuanmingyuan&#34;
  ],
  &#34;Climate&#34;: &#34;Temperate&#34;
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of France in the JSON format.
Generated text:
Sure! Here&#39;s the information about the capital of France, Paris, in JSON format:

```json
{
  &#34;name&#34;: &#34;Paris&#34;,
  &#34;country&#34;: &#34;France&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 48.8566,
    &#34;longitude&#34;: 2.3522
  },
  &#34;founded&#34;: &#34;1340&#34;,
  &#34;population&#34;: &#34;9.7 million&#34;,
  &#34;area&#34;: &#34;105.5 square kilometers&#34;,
  &#34;WX&#34;: {
    &#34;averageTemperature&#34;: &#34;12Â°C&#34;,
    &#34;precipitation&#34;: &#34;540 mm/year&#34;
  },
  &#34;landmarks&#34;: [
    {
      &#34;name&#34;: &#34;Eiffel Tower&#34;,
      &#34;location&#34;: &#34;City of Light&#34;,
      &#34;height&#34;: &#34;330 meters&#34;
    },
    {
      &#34;name&#34;: &#34;Notre-Dame Cathedral&#34;,
      &#34;location&#34;: &#34;Center of Paris&#34;,
      &#34;height&#34;: &#34;415 meters&#34;
    }
  ],
  &#34;Transport&#34;: {
    &#34;publicTransport&#34;: &#34;Boulevards, trams, and subways&#34;,
    &#34;airport&#34;: &#34;Paris International Airport&#34;,
    &#34;railway&#34;: &#34;Leå·´é»Ž-Charles de Gaulle&#34;
  }
}
```

Let me know if you need any other information!
===============================
Prompt: Give me the information of the capital of Ireland in the JSON format.
Generated text:
Sure, here&#39;s the information about the capital of Ireland in JSON format:

```json
{
  &#34;capital&#34;: &#34;Dublin&#34;,
  &#34;official_name&#34;: &#34;Dublin City&#34;,
  &#34;region&#34;: &#34;Dublin&#34;,
  &#34;coordinates&#34;: {
    &#34;latitude&#34;: 53.3489,
    &#34;longitude&#34;: -6.2009
  },
  &#34;founded&#34;: &#34;1241&#34;,
  &#34;population&#34;: 1,234,567,
  &#34;area&#34;: {
    &#34;total&#34;: 123.45,
    &#34;land&#34;: 112.34,
    &#34;water&#34;: 11.11
  },
  &#34;climate&#34;: &#34; temperate&#34;,
  &#34;key_features&#34;: [
    &#34;City Walls&#34;,
    &#34;Trinity College&#34;,
    &#34;Leaving Certificate&#34;,
    &#34;St. Stephen&#39;s Cathedral&#34;,
    &#34;Glynn Bridge&#34;
  ],
  &#34;tourism&#34;: [
    &#34;The GAA&#34;,
    &#34;The National Library of Ireland&#34;,
    &#34;The University of Dublin&#34;,
    &#34;The Phoenix Park&#34;,
    &#34;The SSE St. Patrick&#39;s Cathedral Quarter&#34;
  ]
}
```

Let me know if you need any adjustments!
</pre></div></div>
</div>
</section>
<section id="id6">
<h3>EBNF<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Give me the information of the capital of France.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Germany.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Give me the information of the capital of Italy.&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;ebnf&quot;</span><span class="p">:</span> <span class="p">(</span>
        <span class="s2">&quot;root ::= city | description</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="s1">&#39;city ::= &quot;London&quot; | &quot;Paris&quot; | &quot;Berlin&quot; | &quot;Rome&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;description ::= city &quot; is &quot; status</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;status ::= &quot;the capital of &quot; country</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;country ::= &quot;England&quot; | &quot;France&quot; | &quot;Germany&quot; | &quot;Italy&quot;&#39;</span>
    <span class="p">),</span>
<span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Give me the information of the capital of France.
Generated text:
The capital of France is Paris. If you have any other questions, feel free to ask.

Step-by-step explanation:

1. The question is asking for the information of the capital of France.

2. Paris is the capital city of France.

3. Paris serves as the administrative center of the country.

4. It holds significant political, economic, and cultural importance within France.
&lt;/think&gt;Paris is the capital of France
===============================
Prompt: Give me the information of the capital of Germany.
Generated text:
The capital of Germany is Berlin.

Of course, I can provide more information about the capital of Germany, Berlin.
Berlin, the capital of Germany, is a city located in the northern part of the country. It is known for its rich history, vibrant culture, and is one of the most significant cultural, political, and economic centers in Europe. The city is surrounded by the Berlin Brand, a large man-made lake in the middle of the city. Berlin has a population of over 3.7 million people, making it the second-largest city in Germany after Munich. The city is divided into several boroughs, each with its
===============================
Prompt: Give me the information of the capital of Italy.
Generated text:
The capital of Italy is Rome.

The capital of Italy is Rome. Why is that? Because the question is simply asking for the information of the capital of Italy. So, the answer should be straightforward.

Okay, so the user is asking for the information of the capital of Italy. They&#39;ve already provided that the capital is Rome. But they want me to elaborate on why that is the case. So, I need to explain the historical and political reasons behind Rome being the capital.

First, I remember that Rome has a long history as a powerful city-state. It was a republic, and for a long time, its power was
</pre></div></div>
</div>
</section>
<section id="id7">
<h3>Regular expression<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Please provide information about London as a major global city:&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Please provide information about Paris as a major global city:&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s2">&quot;regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(France|England)&quot;</span><span class="p">}</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: Please provide information about London as a major global city:
Generated text:  the population, average temperature, number of museums, and landmarks.

 . Please also provide information on how to get to London from different cities: specifically from New York, Paris, and Tokyo.

Additionally, you need to describe a typical day in London for an international student.

Finally, offer two recommendations for visitors to London.

You must present all information in a clear and organized manner, using headings and subheadings as needed, but avoiding markdown. The text should be easy to read, with proper paragraph breaks.
Alright, the user is asking for information about London as a major global city. They specifically want details on population, average temperature,
===============================
Prompt: Please provide information about Paris as a major global city:
Generated text:  its history, culture, economy, and geography.

800-1000 words.
Certainly! I&#39;ll provide a detailed overview of Paris, covering its rich history, vibrant culture, dynamic economy, and intricate geography. I&#39;ll structure the information in a way that flows naturally, ensuring each section builds upon the previous one. I&#39;ll make sure to highlight key landmarks and events to give a comprehensive picture of what makes Paris a global powerhouse. I&#39;ll also include information on its economic sectors and cultural contributions, as well as the unique geographical features that define the city.

First, I&#39;ll start with Paris&#39;s historical background, discussing its
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>


<span class="n">sampling_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
    <span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;structural_tag&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;structural_tag&quot;</span><span class="p">,</span>
            <span class="s2">&quot;structures&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_weather&gt;&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_weather</span><span class="p">,</span>
                    <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;begin&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;function=get_current_date&gt;&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="n">schema_get_current_date</span><span class="p">,</span>
                    <span class="s2">&quot;end&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;/function&gt;&quot;</span><span class="p">,</span>
                <span class="p">},</span>
            <span class="p">],</span>
            <span class="s2">&quot;triggers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&lt;function=&quot;</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">),</span>
<span class="p">}</span>


<span class="c1"># Send POST request to the API endpoint</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===============================&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n</span><span class="s2">Generated text: </span><span class="si">{</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
===============================
Prompt: &lt;ï½œbeginâ–ofâ–sentenceï½œ&gt;&lt;ï½œAssistantï½œ&gt;Give me the information and population of the capital of France in the JSON format.&lt;ï½œendâ–ofâ–sentenceï½œ&gt;&lt;ï½œAssistantï½œ&gt;&lt;think&gt;

Generated text: Alright, the user is asking for the information and population of France&#39;s capital in JSON format. Let me break this down. First, I need to identify what exactly they&#39;re asking for. The capital of France is Paris, so I should provide data about Paris, specifically its population.

I should make sure to format this information properly in JSON. JSON requires key-value pairs, so I&#39;ll need to choose relevant keys. The main piece of data here is the population, so the key &#34;capital_population&#34; makes sense.

Next, I need accurate information. The population of Paris is quite large, around 2.1 million people. I&#39;ll include this number as an integer to keep it precise.

I wonder if the user is a student working on a project, maybe a geography assignment, or perhaps someone planning a visit and needs up-to-date stats. Either way, providing a clear and concise JSON structure will be helpful.

I should also consider if there&#39;s any additional information that might be useful. Maybe including the metropolitan area population could add more context, so I&#39;ll add that as well.

Lastly, I&#39;ll format the response with proper indentation for readability, making it easy for the user to understand and use the data. I should double-check the population numbers to ensure accuracy and present them in a helpful manner.
&lt;/think&gt;

Here is the information about the capital of France (Paris) in JSON format:

```json
{
  &#34;capital&#34;: &#34;Paris&#34;,
  &#34;capital_population&#34;: 2161000
}
```
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="separate_reasoning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Reasoning Parser</p>
      </div>
    </a>
    <a class="right-next"
       href="custom_chat_template.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Custom Chat Template</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Supported-Models">Supported Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Usage">Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#OpenAI-Compatible-API">OpenAI Compatible API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#JSON">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#EBNF">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Regular-expression">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Structural-Tag">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Native-API-and-SGLang-Runtime-(SRT)">Native API and SGLang Runtime (SRT)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Regular expression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Structural Tag</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Offline-Engine-API">Offline Engine API</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">JSON</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">EBNF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Regular expression</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023-2025, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Jun 03, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  
    <!-- RunLLM Widget Script -->
    <script type="module" id="runllm-widget-script" src="https://widget.runllm.com" crossorigin="true" version="stable" runllm-keyboard-shortcut="Mod+j" runllm-name="SGLang Chatbot" runllm-position="BOTTOM_RIGHT" runllm-assistant-id="629" async></script>
    
</body>
</html>