
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Expert Parallelism &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=b7a0e4dc"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'advanced_features/expert_parallelism';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DP, DPA and SGLang DP Router" href="dp_dpa_smg_guide.html" />
    <link rel="prev" title="Quantized KV Cache" href="quantized_kv_cache.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Feb 27, 2026"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Usage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/openai_api.html">OpenAI-Compatible APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/ollama_api.html">Ollama-Compatible API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/offline_engine_api.html">Offline Engine API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/popular_model_usage.html">Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_tuning.html">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention_backend.html">Attention Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs_for_reasoning_models.html">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_parser.html">Tool Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantized_kv_cache.html">Quantized KV Cache</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Expert Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="dp_dpa_smg_guide.html">DP, DPA and SGLang DP Router</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">LoRA Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="pd_disaggregation.html">PD Disaggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="epd_disaggregation.html">EPD Disaggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_parallelism.html">Pipeline Parallelism for Long Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="hicache.html">Hierarchical KV Caching (HiCache)</a></li>
<li class="toctree-l1"><a class="reference internal" href="vlm_query.html">Query VLM with Offline Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="dp_for_multi_modal_encoder.html">DP for Multi-Modal Encoder in SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda_graph_for_multi_modal_encoder.html">Cuda Graph for Multi-Modal Encoder in SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="sgl_model_gateway.html">SGLang Model Gateway</a></li>
<li class="toctree-l1"><a class="reference internal" href="deterministic_inference.html">Deterministic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="observability.html">Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint_engine.html">Checkpoint Engine Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="sglang_for_rl.html">SGLang for RL Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/text_generation/index.html">Text Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/retrieval_ranking/index.html">Retrieval &amp; Ranking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/specialized/index.html">Specialized Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/extending/index.html">Extending SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Diffusion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../diffusion/index.html">SGLang Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/installation.html">Install SGLang-Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/compatibility_matrix.html">Compatibility Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/api/cli.html">SGLang diffusion CLI Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/api/openai_api.html">SGLang Diffusion OpenAI API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/index.html">Performance Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/attention_backends.html">Attention Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/profiling.html">Profiling Multimodal Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/index.html">Caching Acceleration for Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/cache_dit.html">Cache-DiT Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/teacache.html">TeaCache Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/support_new_models.html">How to Support New Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/contributing.html">Contributing to SGLang Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/ci_perf.html">Perf Baseline Generation Script</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/environment_variables.html">Caching Acceleration</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../platforms/amd_gpu.html">AMD GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/cpu_server.html">CPU Servers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/tpu.html">TPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/nvidia_jetson.html">NVIDIA Jetson Orin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/ascend_npu_support.html">Ascend NPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/xpu.html">XPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/contribution_guide.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/development_guide_using_docker.html">Development Guide Using Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/development_jit_kernel_guide.html">Development Guide for JIT Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/benchmark_and_profiling.html">Benchmark and Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/bench_serving.html">Bench Serving Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/evaluating_new_models.html">Evaluating New Models with SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/faq.html">Troubleshooting and Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/environment_variables.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/production_metrics.html">Production Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/production_request_trace.html">Production Request Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/multi_node_deployment/multi_node_index.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/frontend/frontend_index.html">Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/post_training_integration.html">Post-Training Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/release_lookup.html">Release Lookup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/learn_more.html">Learn More and Join the Community</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/advanced_features/expert_parallelism.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/advanced_features/expert_parallelism.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fadvanced_features/expert_parallelism.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/advanced_features/expert_parallelism.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Expert Parallelism</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-backends-and-selection-guidance">Supported Backends and Selection Guidance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backends-for-all-to-all-communication">Backends for All-to-All Communication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backends-for-moe-computation">Backends for MoE Computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extensible-ep-framework">Extensible EP Framework</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#framework-overview">Framework Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-new-backends">Implementing New Backends</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-and-communication-overlap">Computation and Communication Overlap</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-batch-overlap-tbo">Two-Batch Overlap (TBO)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-batch-overlap-sbo">Single-Batch Overlap (SBO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workload-balancer">Workload Balancer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ep-with-spectulative-decoding">EP with Spectulative Decoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ascend-npu-guidance">Ascend NPU Guidance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guidance-on-sglang-configuration-in-ascend-npu">Guidance on SGLang configuration in Ascend NPU</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deepep-ascend-introduction">DeepEP Ascend Introduction</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="expert-parallelism">
<h1>Expert Parallelism<a class="headerlink" href="#expert-parallelism" title="Link to this heading">#</a></h1>
<p>Expert Parallelism (EP) in SGLang distributes expert weights across multiple devices in Mixture-of-Experts (MoE) models, addressing memory bottlenecks and enabling efficient scaling for high-performance inference. It is particularly vital for serving large-scale MoE models where tokens are dynamically routed to specialized experts across GPUs. By leveraging optimized all-to-all communication and grouped matrix multiplications (GEMMs), EP reduces latency, boosts throughput, and minimizes idle GPU time. SGLang’s EP offers strong extensibility through its modular framework, allowing seamless integration of custom kernels, backends, and optimizations without refactoring core logic, supporting diverse hardware and quantization schemes.</p>
<section id="supported-backends-and-selection-guidance">
<h2>Supported Backends and Selection Guidance<a class="headerlink" href="#supported-backends-and-selection-guidance" title="Link to this heading">#</a></h2>
<p>SGLang’s EP integrates diverse, highly efficient backends for different use cases, allowing fine-grained control over performance trade-offs. Users specify backends via command-line flags:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--moe-a2a-backend</span></code>: Selects the backend for all-to-all communication.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--moe-runner-backend</span></code>: Selects the backend for MoE computation.</p></li>
</ul>
<section id="backends-for-all-to-all-communication">
<h3>Backends for All-to-All Communication<a class="headerlink" href="#backends-for-all-to-all-communication" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Backend</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Use Cases</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">none</span></code> (default)</strong></p></td>
<td><p>Disables all-to-all for EP. Uses All-Reduce or All-Gather for token dispatch.</p></td>
<td><p>Hybrid EP and TP setups.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">deepep</span></code></p></td>
<td><p>DeepEP, a communication library for efficient token shuffling in MoE models.</p></td>
<td><p>Large-scale EP deployments.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mooncake</span></code></p></td>
<td><p>An extension of DeepEP for elastic inference, leveraging RDMA for high-performance data transfers.</p></td>
<td><p>Elastic EP serving.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mori</span></code></p></td>
<td><p>MORI-EP, AMD’s native all-to-all communication implementation optimized for ROCm.</p></td>
<td><p>AMD GPU deployments.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">flashinfer</span></code></p></td>
<td><p>Flashinfer implementation of all-to-all.</p></td>
<td><p>Large-scale EP deployments.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ascend_fuseep</span></code></p></td>
<td><p>Ascend NPU native fused all-to-all communication.</p></td>
<td><p>Ascend NPU deployments.</p></td>
</tr>
</tbody>
</table>
</div>
<p>DeepEP and Mooncake backends support two modes for token dispatch: <code class="docutils literal notranslate"><span class="pre">normal</span></code> mode (optimized for prefill workloads with high throughput) and <code class="docutils literal notranslate"><span class="pre">low_latency</span></code> mode (optimized for decode workloads with low latency and CUDA Graph compatibility). MORI backend only supports <code class="docutils literal notranslate"><span class="pre">normal</span></code> mode now. Users are recommended to set <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">auto</span></code> to enable automatic dispatch mode switching during runtime. Setting <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">normal</span></code> or <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">low_latency</span></code> is useful for debugging or development purposes.</p>
<p>Currently, DeepEP, Mooncake, <code class="docutils literal notranslate"><span class="pre">ascend_fuseep</span></code> and MORI only support cases where <code class="docutils literal notranslate"><span class="pre">ep_size</span> <span class="pre">=</span> <span class="pre">tp_size</span></code>. For hybrid EP and TP (i.e., <code class="docutils literal notranslate"><span class="pre">ep_size</span> <span class="pre">&lt;</span> <span class="pre">tp_size</span></code>), only the <code class="docutils literal notranslate"><span class="pre">none</span></code> backend (All-Reduce or All-Gather-based dispatching) is supported.</p>
</section>
<section id="backends-for-moe-computation">
<h3>Backends for MoE Computation<a class="headerlink" href="#backends-for-moe-computation" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Backend</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Use Cases</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">auto</span></code> (default)</strong></p></td>
<td><p>Automatically selects the optimal backend based on model architecture, hardware (e.g., NVIDIA architecture like Ampere, Hopper, Blackwell), quantization scheme (e.g., FP8, FP4), and runtime conditions.</p></td>
<td><p>General-purpose deployments; ensures compatibility and performance without user intervention.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">triton</span></code></p></td>
<td><p>Triton-based implementation for grouped GEMMs. To achieve higher performance, it’s highly recommended to create <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/benchmark/kernels/fused_moe_triton/README.md">tuned configurations</a>.</p></td>
<td><p>Custom kernel development or scenarios requiring high extensibility with Torch compilation support.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">deep_gemm</span></code></p></td>
<td><p>DeepGEMM backend optimized for MoE matrix multiplications, supporting contiguous layouts for prefill and masked layouts for decode; often JIT-compiled for performance.</p></td>
<td><p>Large-scale EP deployments with FP8 block-wise quantization.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cutlass</span></code></p></td>
<td><p>CUTLASS-based backend for efficient GEMMs.</p></td>
<td><p>NVIDIA architectures with CUTLASS support.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">flashinfer_trtllm</span></code></p></td>
<td><p>FlashInfer integrated with TensorRT-LLM for accelerated MoE computations, supporting FP4 communication operators and high-performance GEMMs.</p></td>
<td><p>Blackwell with TRT-LLM.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">flashinfer_cutlass</span></code></p></td>
<td><p>FlashInfer combined with CUTLASS for high-performance grouped GEMMs in MoE layers, handling FP4/FP8 quantization efficiently.</p></td>
<td><p>Blackwell with FP4/FP8 models.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">flashinfer_mxfp4</span></code></p></td>
<td><p>FlashInfer variant optimized for MXFP4 (mixed FP4) quantization in MoE runners, focusing on memory-efficient low-precision inference.</p></td>
<td><p>Low-precision models with MXFP4.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">flashinfer_cutedsl</span></code></p></td>
<td><p>FlashInfer with a custom DSL for flexible and efficient MoE kernel generation, integrated with ModelOpt FP4 quantization.</p></td>
<td><p>Low-precision models with NVFP4.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h3>
<p>Launch with DeepEP and DeepGEMM for DeepSeek-V3:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span>--model-path<span class="w"> </span>deepseek-ai/DeepSeek-V3<span class="w"> </span>--moe-a2a-backend<span class="w"> </span>deepep<span class="w"> </span>--moe-runner-backend<span class="w"> </span>deep_gemm<span class="w"> </span>--tp<span class="w"> </span><span class="m">8</span><span class="w"> </span>--ep<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
</section>
</section>
<section id="extensible-ep-framework">
<h2>Extensible EP Framework<a class="headerlink" href="#extensible-ep-framework" title="Link to this heading">#</a></h2>
<p>SGLang’s EP framework provides modular abstractions for easy integration of custom kernels, backends, and optimizations. It decouples the MoE forward pass into stages (dispatch → pre-permute → core runner → post-permute → combine), enabling seamless extensions without refactoring core logic.</p>
<section id="framework-overview">
<h3>Framework Overview<a class="headerlink" href="#framework-overview" title="Link to this heading">#</a></h3>
<p>The framework centers on <code class="docutils literal notranslate"><span class="pre">FusedMoE</span></code> as the unified entry point for a single, extensible structure. Key components include:</p>
<ul class="simple">
<li><p><strong>Dispatcher</strong>: Manages dispatch/combine for backends like DeepEP (implements <code class="docutils literal notranslate"><span class="pre">BaseDispatcher</span></code> subclasses).</p></li>
<li><p><strong>MoeRunner</strong>: Orchestrates grouped-GEMM execution via <code class="docutils literal notranslate"><span class="pre">MoeRunnerCore</span></code> implementations (e.g., <code class="docutils literal notranslate"><span class="pre">TritonRunnerCore</span></code>).</p></li>
<li><p><strong>PermuteMethodPool</strong>: Auto-registers layout conversions (e.g., pre/post-permute via <code class="docutils literal notranslate"><span class="pre">register_pre_permute</span></code> and <code class="docutils literal notranslate"><span class="pre">register_post_permute</span></code> for dynamic modes, or <code class="docutils literal notranslate"><span class="pre">register_fused_func</span></code> for static, torch.compile-compatible fused operations).</p></li>
<li><p><strong>TopK Router</strong>: Backend-agnostic expert selection.</p></li>
</ul>
<p>This design supports multiple backends via <code class="docutils literal notranslate"><span class="pre">--moe-a2a-backend</span></code> and <code class="docutils literal notranslate"><span class="pre">--moe-runner-backend</span></code>, with quantization integrated through a standardized <code class="docutils literal notranslate"><span class="pre">apply()</span></code> method. The computation flow ensures modularity:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">input_hidden_states</span><span class="p">]</span>
          <span class="o">|</span>
          <span class="n">v</span>
     <span class="n">TopK</span><span class="o">.</span><span class="n">forward</span> <span class="o">-&gt;</span> <span class="n">select_experts</span> <span class="o">/</span> <span class="n">triton_kernels</span><span class="o">.</span><span class="n">routing</span> <span class="o">/</span> <span class="n">bypass</span>
          <span class="o">|</span>
          <span class="n">v</span>
     <span class="p">[</span><span class="n">TopKOutput</span><span class="p">]</span>
          <span class="o">|</span>
          <span class="n">v</span>
   <span class="n">FusedMoE</span><span class="o">.</span><span class="n">forward</span> <span class="o">-&gt;</span> <span class="n">Dispatcher</span><span class="o">.</span><span class="n">dispatch</span> <span class="o">-&gt;</span> <span class="n">DeepEP</span> <span class="o">/</span> <span class="n">bypass</span>
          <span class="o">|</span>                     <span class="o">|</span>
          <span class="o">|</span>                     <span class="n">v</span>
          <span class="o">|</span>              <span class="p">[</span><span class="n">DispatchOutput</span><span class="p">]</span>
          <span class="o">|</span>                     <span class="o">|</span>
          <span class="o">|</span>                     <span class="n">v</span>
          <span class="o">|</span>             <span class="n">quant_method</span><span class="o">.</span><span class="n">apply</span> <span class="o">-&gt;</span> <span class="n">MoeRunner</span><span class="o">.</span><span class="n">forward</span>
          <span class="o">|</span>                     <span class="o">|</span>              <span class="o">|</span>
          <span class="o">|</span>                     <span class="o">|</span>              <span class="n">v</span>
          <span class="o">|</span>                     <span class="o">|</span> <span class="n">pre</span><span class="o">-</span><span class="n">permute</span> <span class="o">+</span> <span class="n">grouped_gemm</span> <span class="o">+</span> <span class="n">post</span><span class="o">-</span><span class="n">permute</span>
          <span class="o">|</span>                     <span class="o">|</span>              <span class="o">|</span>
          <span class="o">|</span>                     <span class="o">|--------------</span>
          <span class="o">|</span>                     <span class="n">v</span>
          <span class="o">|</span>               <span class="p">[</span><span class="n">CombineInput</span><span class="p">]</span>
          <span class="o">|</span>                     <span class="o">|</span>
          <span class="o">|</span>                     <span class="n">v</span>
          <span class="o">|</span>            <span class="n">Dispatcher</span><span class="o">.</span><span class="n">combine</span> <span class="o">-&gt;</span> <span class="n">DeepEP</span> <span class="o">/</span> <span class="n">bypass</span>
          <span class="o">|</span>                     <span class="o">|</span>
          <span class="o">|---------------------</span>
          <span class="n">v</span>
<span class="p">[</span><span class="n">final_hidden_states</span><span class="p">]</span>
</pre></div>
</div>
<p>For details, see the <a class="reference external" href="https://github.com/sgl-project/sglang/issues/8715">MoE Refactor Roadmap</a>.</p>
</section>
<section id="implementing-new-backends">
<h3>Implementing New Backends<a class="headerlink" href="#implementing-new-backends" title="Link to this heading">#</a></h3>
<p>To add a new backend:</p>
<ol class="arabic simple">
<li><p>For a new all-to-all dispatcher, implement a <code class="docutils literal notranslate"><span class="pre">BaseDispatcher</span></code> subclass with <code class="docutils literal notranslate"><span class="pre">dispatch</span></code> and <code class="docutils literal notranslate"><span class="pre">combine</span></code> methods.</p></li>
<li><p>For a new MoE runner backend, define a <code class="docutils literal notranslate"><span class="pre">MoeRunnerCore</span></code> subclass for core operations (e.g., grouped GEMMs).</p></li>
<li><p>Define new input/output formats for the dispatcher or model runner (e.g., <code class="docutils literal notranslate"><span class="pre">RunnerInput</span></code>, <code class="docutils literal notranslate"><span class="pre">RunnerOutput</span></code>).</p></li>
<li><p>Register permute/unpermute methods to ensure compatibility:</p>
<ul class="simple">
<li><p><strong>Fused Mode</strong> (static, torch.compile-compatible): Use <code class="docutils literal notranslate"><span class="pre">register_fused_func</span></code> for end-to-end operations.</p></li>
<li><p><strong>Permute Mode</strong> (dynamic): Register <code class="docutils literal notranslate"><span class="pre">register_pre_permute</span></code> and <code class="docutils literal notranslate"><span class="pre">register_post_permute</span></code> for flexible layouts.</p></li>
</ul>
</li>
</ol>
<p>See the <a class="reference external" href="https://github.com/sgl-project/sglang/pull/9269">MoE Refactor Implementation PR</a> for full changes, including type hints and config expansions.</p>
</section>
<section id="id1">
<h3>Examples<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>For an example implementation, see <a class="reference external" href="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/layers/moe/moe_runner/triton.py">moe_runner/triton.py</a>, which demonstrates Triton-based grouped GEMMs with registered fused and permutation functions.</p>
</section>
</section>
<section id="computation-and-communication-overlap">
<h2>Computation and Communication Overlap<a class="headerlink" href="#computation-and-communication-overlap" title="Link to this heading">#</a></h2>
<p>SGLang’s EP employs advanced overlap techniques to hide communication latency behind computation, maximizing GPU utilization in MoE layers.</p>
<section id="two-batch-overlap-tbo">
<h3>Two-Batch Overlap (TBO)<a class="headerlink" href="#two-batch-overlap-tbo" title="Link to this heading">#</a></h3>
<p>TBO splits requests into micro-batches, interleaving attention computation with dispatch/combine operations. Yield points in the execution graph allow pausing for overlaps, increasing overall throughput without peak memory spikes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">operations</span> <span class="o">=</span> <span class="p">[</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_attn</span><span class="p">,</span>
    <span class="n">YieldOperation</span><span class="p">(),</span>  <span class="c1"># Overlap with dispatch of prior micro-batch</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_dispatch</span><span class="p">,</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_mlp</span><span class="p">,</span>
    <span class="n">YieldOperation</span><span class="p">(),</span>  <span class="c1"># Overlap with combine</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_combine</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Users need to specify <code class="docutils literal notranslate"><span class="pre">--enable-two-batch-overlap</span></code> to unlock up to 2x throughput. For details, see the <a class="reference external" href="https://lmsys.org/blog/2025-05-05-large-scale-ep/#two-batch-overlap">Large-Scale EP Blog</a>.</p>
</section>
<section id="single-batch-overlap-sbo">
<h3>Single-Batch Overlap (SBO)<a class="headerlink" href="#single-batch-overlap-sbo" title="Link to this heading">#</a></h3>
<p>SGLang introduces a dispatcher-hook system for Single-Batch Overlap (SBO), enabling the overlap of operations within a single batch—such as shared experts computation with communication—while decentralizing logic to enhance modularity. These hooks execute before and after the <code class="docutils literal notranslate"><span class="pre">dispatch</span></code> and <code class="docutils literal notranslate"><span class="pre">combine</span></code> operations without modifying core MoE modules. This design simplifies interfaces, reduces coupling, and improves extensibility. For implementation details and an example of overlapping shared experts with DeepEP’s combine operation, refer to <a class="reference external" href="https://github.com/sgl-project/sglang/pull/13327">PR #13327</a>. Users can set <code class="docutils literal notranslate"><span class="pre">--enable-single-batch-overlap</span></code> to enable this feature.</p>
</section>
</section>
<section id="workload-balancer">
<h2>Workload Balancer<a class="headerlink" href="#workload-balancer" title="Link to this heading">#</a></h2>
<p>SGLang integrates the <a class="reference external" href="https://github.com/deepseek-ai/EPLB">Expert Parallelism Load Balancer (EPLB)</a> from DeepSeek to address routing imbalances in MoE models. By analyzing expert activation statistics, EPLB computes an optimal expert arrangement, strategically placing or replicating experts to minimize GPU utilization variance, reduce idle cycles, and enhance scalability.</p>
<p>To enable EPLB, use the flags <code class="docutils literal notranslate"><span class="pre">--enable-eplb</span></code>. For optimal performance, increase batch sizes to stabilize activation statistics and configure periodic rebalancing (e.g., every 1000 requests) to adapt to evolving workloads. Simulations demonstrate significant improvements in load balancedness (ratio of mean to max computation time), correlating strongly with throughput gains.</p>
<p>For more details, refer to the <a class="reference external" href="https://lmsys.org/blog/2025-05-05-large-scale-ep/#expert-parallelism-load-balancer">EPLB Section in the Large-Scale EP Blog</a> and the <a class="reference external" href="https://github.com/deepseek-ai/eplb">EPLB Repository</a>.</p>
</section>
<section id="ep-with-spectulative-decoding">
<h2>EP with Spectulative Decoding<a class="headerlink" href="#ep-with-spectulative-decoding" title="Link to this heading">#</a></h2>
<p>When utilizing speculative decoding with MTP on MoE architectures, use the <code class="docutils literal notranslate"><span class="pre">--speculative-moe-runner-backend</span></code> and <code class="docutils literal notranslate"><span class="pre">--speculative-moe-a2a-backend</span></code> arguments to customize the MoE layer behavior for the draft model. While they default to the target model’s settings, users can differentiate them for varying precisions between target and draft models.</p>
<p>For model like <code class="docutils literal notranslate"><span class="pre">nvidia/DeepSeek-R1-0528-NVFP4-v2</span></code>, the target model uses NVFP4 precision while the draft model uses BF16. To apply <code class="docutils literal notranslate"><span class="pre">flashinfer_trtllm</span></code> kernel for target MoE layer while falling back to triton fused MoE kernel for draft MoE layer, users can set the arguments as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="o">--</span><span class="n">moe</span><span class="o">-</span><span class="n">runner</span><span class="o">-</span><span class="n">backend</span> <span class="n">flashinfer_trtllm</span> \
<span class="o">--</span><span class="n">speculative</span><span class="o">-</span><span class="n">moe</span><span class="o">-</span><span class="n">runner</span><span class="o">-</span><span class="n">backend</span> <span class="n">triton</span> \
<span class="o">...</span>
</pre></div>
</div>
</section>
<section id="ascend-npu-guidance">
<h2>Ascend NPU Guidance<a class="headerlink" href="#ascend-npu-guidance" title="Link to this heading">#</a></h2>
<section id="guidance-on-sglang-configuration-in-ascend-npu">
<h3>Guidance on SGLang configuration in Ascend NPU<a class="headerlink" href="#guidance-on-sglang-configuration-in-ascend-npu" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--moe-a2a-backend</span></code> only supports <code class="docutils literal notranslate"><span class="pre">deepep</span></code> and <code class="docutils literal notranslate"><span class="pre">ascend_fuseep</span></code> backends,</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">deepep</span></code>: The mechanism is consistent with the above description.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ascend_fuseep</span></code>: Offer a large fused operator which integrates all operations between dispatch and combine to boost MoE computation. Only used for decode stage in PD Disaggregation Mode.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--moe-runner-backend</span></code> parameter does not need to be configured.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--deepep-mode</span></code>:</p>
<ul>
<li><p>In PD mixed mode, please set <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">auto</span></code>.</p></li>
<li><p>In PD Disaggregation Mode, prefill instance sets <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">normal</span></code>, and decode instance sets <code class="docutils literal notranslate"><span class="pre">--deepep-mode</span> <span class="pre">low_latency</span></code>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="deepep-ascend-introduction">
<h3>DeepEP Ascend Introduction<a class="headerlink" href="#deepep-ascend-introduction" title="Link to this heading">#</a></h3>
<p>DeepEP Ascend is the adapted version of the DeepEP communication library for Huawei Ascend NPUs, specifically designed for Mixture-of-Experts (MoE) model Expert Parallelism (EP).
It supports the Ant-moving Function (Split the sequence length into rounds for streaming batch transmission) to optimize the buffer size occupied during collective communication in prefill stage, especially for long sequences.</p>
<p>Ant-moving Function can be enabled for both the dispatch and combine phases via the following environment variables:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS</span></code>: Enable ant-moving function in dispatch stage. Indicates the number of tokens transmitted per round on each rank, default 8192.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEEPEP_NORMAL_LONG_SEQ_ROUND</span></code>: Enable ant-moving function in dispatch stage. Indicates the number of rounds transmitted on each rank, default 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DEEPEP_NORMAL_COMBINE_ENABLE_LONG_SEQ</span></code>: Enable ant-moving function in combine stage, default 0 (means disabled).</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS</span> <span class="pre">*</span> <span class="pre">DEEPEP_NORMAL_LONG_SEQ_ROUND</span></code> means input sequence length. When the input sequence length exceeds 8192, it is recommended to enable the ant-moving function in both dispatch and combine phase.</p>
<p>The environment variable <code class="docutils literal notranslate"><span class="pre">HCCL_BUFFSIZE</span></code> is used to configure the buffer size (MB) actually allocated. Its calculation formula is as follows:</p>
<div class="highlight-angular2html notranslate"><div class="highlight"><pre><span></span># Enable Ant-moving Function
HCCL_BUFFSIZE &gt;= 2 * (102MB + 4MB + DEEPEP_NORMAL_LONG_SEQ_PER_ROUND_TOKENS * (hidden_size + hidden_size + hidden_size) * topk) + PADDING_BUFFSIZE

# Disable Ant-moving Function
HCCL_BUFFSIZE &gt;= 2 * (102MB + 4MB + TOTAL_SEQ_LEN * (hidden_size + hidden_size) * topk) + PADDING_BUFFSIZE
</pre></div>
</div>
<p>Wherein the parameters are described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>: hidden size in model config.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">topk</span></code>: The number of selected routing experts.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TOTAL_SEQ_LEN</span></code>: input sequence length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PADDING_BUFFSIZE</span></code>: A value of 20 or greater is recommended.</p></li>
</ul>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="quantized_kv_cache.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quantized KV Cache</p>
      </div>
    </a>
    <a class="right-next"
       href="dp_dpa_smg_guide.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DP, DPA and SGLang DP Router</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-backends-and-selection-guidance">Supported Backends and Selection Guidance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backends-for-all-to-all-communication">Backends for All-to-All Communication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backends-for-moe-computation">Backends for MoE Computation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extensible-ep-framework">Extensible EP Framework</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#framework-overview">Framework Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-new-backends">Implementing New Backends</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-and-communication-overlap">Computation and Communication Overlap</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-batch-overlap-tbo">Two-Batch Overlap (TBO)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-batch-overlap-sbo">Single-Batch Overlap (SBO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workload-balancer">Workload Balancer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ep-with-spectulative-decoding">EP with Spectulative Decoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ascend-npu-guidance">Ascend NPU Guidance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guidance-on-sglang-configuration-in-ascend-npu">Guidance on SGLang configuration in Ascend NPU</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deepep-ascend-introduction">DeepEP Ascend Introduction</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2026, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Feb 27, 2026.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  
    <!-- RunLLM Widget Script -->
    <script type="module" id="runllm-widget-script" src="https://widget.runllm.com" crossorigin="true" version="stable" runllm-keyboard-shortcut="Mod+j" runllm-name="SGLang Chatbot" runllm-position="BOTTOM_RIGHT" runllm-assistant-id="629" async></script>
    
</body>
</html>