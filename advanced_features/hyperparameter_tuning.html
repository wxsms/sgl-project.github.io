
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hyperparameter Tuning &#8212; SGLang</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=64db06da"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'advanced_features/hyperparameter_tuning';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Attention Backend" href="attention_backend.html" />
    <link rel="prev" title="Server Arguments" href="server_arguments.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Feb 24, 2026"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="SGLang - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="SGLang - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/install.html">Install SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Usage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/send_request.html">Sending Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/openai_api.html">OpenAI-Compatible APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/ollama_api.html">Ollama-Compatible API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/offline_engine_api.html">Offline Engine API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/native_api.html">SGLang Native APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/sampling_params.html">Sampling Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage/popular_model_usage.html">Popular Model Usage (DeepSeek, GPT-OSS, GLM, Llama, MiniMax, Qwen, and more)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="server_arguments.html">Server Arguments</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Hyperparameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="attention_backend.html">Attention Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="speculative_decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs.html">Structured Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured_outputs_for_reasoning_models.html">Structured Outputs For Reasoning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tool_parser.html">Tool Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="separate_reasoning.html">Reasoning Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantized_kv_cache.html">Quantized KV Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="expert_parallelism.html">Expert Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="dp_dpa_smg_guide.html">DP, DPA and SGLang DP Router</a></li>
<li class="toctree-l1"><a class="reference internal" href="lora.html">LoRA Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="pd_disaggregation.html">PD Disaggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="epd_disaggregation.html">EPD Disaggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_parallelism.html">Pipeline Parallelism for Long Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="hicache.html">Hierarchical KV Caching (HiCache)</a></li>
<li class="toctree-l1"><a class="reference internal" href="vlm_query.html">Query VLM with Offline Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="dp_for_multi_modal_encoder.html">DP for Multi-Modal Encoder in SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda_graph_for_multi_modal_encoder.html">Cuda Graph for Multi-Modal Encoder in SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="sgl_model_gateway.html">SGLang Model Gateway</a></li>
<li class="toctree-l1"><a class="reference internal" href="deterministic_inference.html">Deterministic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="observability.html">Observability</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint_engine.html">Checkpoint Engine Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="sglang_for_rl.html">SGLang for RL Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supported Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supported_models/text_generation/index.html">Text Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/retrieval_ranking/index.html">Retrieval &amp; Ranking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/specialized/index.html">Specialized Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_models/extending/index.html">Extending SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SGLang Diffusion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../diffusion/index.html">SGLang Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/installation.html">Install SGLang-Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/compatibility_matrix.html">Compatibility Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/api/cli.html">SGLang diffusion CLI Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/api/openai_api.html">SGLang Diffusion OpenAI API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/index.html">Performance Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/attention_backends.html">Attention Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/profiling.html">Profiling Multimodal Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/index.html">Caching Acceleration for Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/cache_dit.html">Cache-DiT Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/performance/cache/teacache.html">TeaCache Acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/support_new_models.html">How to Support New Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/contributing.html">Contributing to SGLang Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/ci_perf.html">Perf Baseline Generation Script</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diffusion/environment_variables.html">Caching Acceleration</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../platforms/amd_gpu.html">AMD GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/cpu_server.html">CPU Servers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/tpu.html">TPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/nvidia_jetson.html">NVIDIA Jetson Orin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/ascend_npu_support.html">Ascend NPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platforms/xpu.html">XPU</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/contribution_guide.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/development_guide_using_docker.html">Development Guide Using Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/development_jit_kernel_guide.html">Development Guide for JIT Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/benchmark_and_profiling.html">Benchmark and Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/bench_serving.html">Bench Serving Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/evaluating_new_models.html">Evaluating New Models with SGLang</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/faq.html">Troubleshooting and Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/environment_variables.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/production_metrics.html">Production Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/production_request_trace.html">Production Request Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/multi_node_deployment/multi_node_index.html">Multi-Node Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/custom_chat_template.html">Custom Chat Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/frontend/frontend_index.html">Frontend Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/post_training_integration.html">Post-Training Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/learn_more.html">Learn More and Join the Community</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/advanced_features/hyperparameter_tuning.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/advanced_features/hyperparameter_tuning.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fadvanced_features/hyperparameter_tuning.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/advanced_features/hyperparameter_tuning.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Hyperparameter Tuning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#achieving-high-throughput-for-offline-batch-inference">Achieving high throughput for offline batch inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adjust-the-request-submission-speed-to-control-queue-req">Adjust the request submission speed to control <code class="docutils literal notranslate"><span class="pre">#queue-req</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#achieve-a-high-token-usage">Achieve a high <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-mem-fraction-static-to-increase-kv-cache-pool-capacity">Tune <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> to increase KV cache pool capacity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests">Avoid out-of-memory errors by tuning <code class="docutils literal notranslate"><span class="pre">--chunked-prefill-size</span></code>, <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code>, and <code class="docutils literal notranslate"><span class="pre">--max-running-requests</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-cuda-graph-max-bs">Tune <code class="docutils literal notranslate"><span class="pre">--cuda-graph-max-bs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-dp-size-and-tp-size">Tune <code class="docutils literal notranslate"><span class="pre">--dp-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--tp-size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#try-other-options">Try other options</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="hyperparameter-tuning">
<h1>Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading">#</a></h1>
<section id="achieving-high-throughput-for-offline-batch-inference">
<h2>Achieving high throughput for offline batch inference<a class="headerlink" href="#achieving-high-throughput-for-offline-batch-inference" title="Link to this heading">#</a></h2>
<p>Achieving a large batch size is the most important thing for attaining high throughput in offline batch inference.
When the server is running at full load in a steady state, look for the following in the log:</p>
<p><code class="docutils literal notranslate"><span class="pre">Decode</span> <span class="pre">batch.</span> <span class="pre">#running-req:</span> <span class="pre">233,</span> <span class="pre">#token:</span> <span class="pre">370959,</span> <span class="pre">token</span> <span class="pre">usage:</span> <span class="pre">0.82,</span> <span class="pre">cuda</span> <span class="pre">graph:</span> <span class="pre">True,</span> <span class="pre">gen</span> <span class="pre">throughput</span> <span class="pre">(token/s):</span> <span class="pre">4594.01,</span> <span class="pre">#queue-req:</span> <span class="pre">317</span></code></p>
<section id="adjust-the-request-submission-speed-to-control-queue-req">
<h3>Adjust the request submission speed to control <code class="docutils literal notranslate"><span class="pre">#queue-req</span></code><a class="headerlink" href="#adjust-the-request-submission-speed-to-control-queue-req" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">#queue-req</span></code> indicates the number of requests in the queue.
If you frequently see <code class="docutils literal notranslate"><span class="pre">#queue-req:</span> <span class="pre">0</span></code>, it suggests that your client code is submitting requests too slowly.
A healthy range for <code class="docutils literal notranslate"><span class="pre">#queue-req</span></code> is <code class="docutils literal notranslate"><span class="pre">100</span> <span class="pre">-</span> <span class="pre">2000</span></code>.
However, avoid making <code class="docutils literal notranslate"><span class="pre">#queue-req</span></code> too large, as this will increase the scheduling overhead on the server.</p>
</section>
<section id="achieve-a-high-token-usage">
<h3>Achieve a high <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span></code><a class="headerlink" href="#achieve-a-high-token-usage" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span></code> indicates the KV cache memory utilization of the server. <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span> <span class="pre">&gt;</span> <span class="pre">0.9</span></code> means good utilization.</p>
<p>If you frequently see <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span> <span class="pre">&lt;</span> <span class="pre">0.9</span></code> and <code class="docutils literal notranslate"><span class="pre">#queue-req</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, it means the server is too conservative about taking in new requests. You can decrease <code class="docutils literal notranslate"><span class="pre">--schedule-conservativeness</span></code> to a value like 0.3.
The case of a server being too conservative can happen when users send many requests with a large <code class="docutils literal notranslate"><span class="pre">max_new_tokens</span></code> but the requests stop very early due to EOS or stop strings.</p>
<p>On the other hand, if you see <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span></code> very high and you frequently see warnings like
<code class="docutils literal notranslate"><span class="pre">KV</span> <span class="pre">cache</span> <span class="pre">pool</span> <span class="pre">is</span> <span class="pre">full.</span> <span class="pre">Retract</span> <span class="pre">requests.</span> <span class="pre">#retracted_reqs:</span> <span class="pre">1,</span> <span class="pre">#new_token_ratio:</span> <span class="pre">0.9998</span> <span class="pre">-&gt;</span> <span class="pre">1.0000</span></code>, you can increase <code class="docutils literal notranslate"><span class="pre">--schedule-conservativeness</span></code> to a value like 1.3.
If you see <code class="docutils literal notranslate"><span class="pre">KV</span> <span class="pre">cache</span> <span class="pre">pool</span> <span class="pre">is</span> <span class="pre">full.</span> <span class="pre">Retract</span> <span class="pre">requests.</span></code> occasionally but not frequently (~1 time per minute), it is okay.</p>
</section>
<section id="tune-mem-fraction-static-to-increase-kv-cache-pool-capacity">
<h3>Tune <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> to increase KV cache pool capacity<a class="headerlink" href="#tune-mem-fraction-static-to-increase-kv-cache-pool-capacity" title="Link to this heading">#</a></h3>
<p>SGLang allocates memory as follows:</p>
<p>Total memory usage = model weights + KV cache pool + CUDA graph buffers + activations</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> parameter determines how much memory is allocated to the first two components:</p>
<p>mem_fraction_static = (model weights + KV cache pool) / GPU memory capacity</p>
<p>To support higher concurrency, you should maximize the KV cache pool capacity by setting <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> as high as possible while still reserving enough memory for activations and CUDA graph buffers.</p>
<p>SGLang uses simple heuristics to set the default value of <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code>, but you can optimize it for your use cases.
As a rule of thumb, reserving 5–8 GB of memory for activations is typically sufficient. You can check this by inspecting the logs just before the server is ready.
Look for log entries like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span> <span class="mi">17</span><span class="p">:</span><span class="mi">17</span><span class="p">:</span><span class="mi">03</span><span class="p">]</span> <span class="n">max_total_num_tokens</span><span class="o">=</span><span class="mi">665690</span><span class="p">,</span> <span class="n">chunked_prefill_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span> <span class="n">max_prefill_tokens</span><span class="o">=</span><span class="mi">16384</span><span class="p">,</span> <span class="n">max_running_requests</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">context_len</span><span class="o">=</span><span class="mi">65536</span><span class="p">,</span> <span class="n">available_gpu_mem</span><span class="o">=</span><span class="mf">13.50</span> <span class="n">GB</span>
</pre></div>
</div>
<p>Check the <code class="docutils literal notranslate"><span class="pre">available_gpu_mem</span></code> value.</p>
<ul class="simple">
<li><p>If it is between 5–8 GB, the setting is good.</p></li>
<li><p>If it is too high (e.g., 10 - 20 GB), increase <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> to allocate more memory to the KV cache.</p></li>
<li><p>If it is too low, you risk out-of-memory (OOM) errors later, so decrease <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code>.</p></li>
</ul>
<p>Another straightforward approach is to increase <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> in increments of 0.01 until you encounter OOM errors for your workloads.</p>
</section>
<section id="avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests">
<h3>Avoid out-of-memory errors by tuning <code class="docutils literal notranslate"><span class="pre">--chunked-prefill-size</span></code>, <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code>, and <code class="docutils literal notranslate"><span class="pre">--max-running-requests</span></code><a class="headerlink" href="#avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests" title="Link to this heading">#</a></h3>
<p>If you encounter out-of-memory (OOM) errors, you can adjust the following parameters:</p>
<ul class="simple">
<li><p>If OOM occurs during prefill, try reducing <code class="docutils literal notranslate"><span class="pre">--chunked-prefill-size</span></code> to <code class="docutils literal notranslate"><span class="pre">4096</span></code> or <code class="docutils literal notranslate"><span class="pre">2048</span></code>. This saves memory but slows down the prefill speed for long prompts.</p></li>
<li><p>If OOM occurs during decoding, try lowering <code class="docutils literal notranslate"><span class="pre">--max-running-requests</span></code>.</p></li>
<li><p>You can also reduce <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> to a smaller value, such as 0.8 or 0.7. This decreases the memory usage of the KV cache memory pool and helps prevent OOM errors during both prefill and decoding. However, it limits maximum concurrency and reduces peak throughput.</p></li>
</ul>
</section>
<section id="tune-cuda-graph-max-bs">
<h3>Tune <code class="docutils literal notranslate"><span class="pre">--cuda-graph-max-bs</span></code><a class="headerlink" href="#tune-cuda-graph-max-bs" title="Link to this heading">#</a></h3>
<p>By default, CUDA graph is enabled only for small batch sizes (e.g., less than 160 or 256).
However, for some models, especially at large tensor parallelism sizes, CUDA graph can be useful for batch sizes up to 512 or 768.
Therefore, it may be beneficial to increase <code class="docutils literal notranslate"><span class="pre">--cuda-graph-max-bs</span></code> to a larger value.
Note that CUDA graph consumes more memory, so you may need to reduce <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> at the same time.</p>
</section>
<section id="tune-dp-size-and-tp-size">
<h3>Tune <code class="docutils literal notranslate"><span class="pre">--dp-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--tp-size</span></code><a class="headerlink" href="#tune-dp-size-and-tp-size" title="Link to this heading">#</a></h3>
<p>Data parallelism is better for throughput. When there is enough GPU memory, always favor data parallelism for throughput. Refer to <a class="reference internal" href="sgl_model_gateway.html"><span class="std std-doc">SGLang Model Gateway (former Router)</span></a> for a better data parallelism rather than using <code class="docutils literal notranslate"><span class="pre">dp_size</span></code> parameter.</p>
</section>
<section id="try-other-options">
<h3>Try other options<a class="headerlink" href="#try-other-options" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> accelerates small models on small batch sizes. You can enable it with <code class="docutils literal notranslate"><span class="pre">--enable-torch-compile</span></code>.</p></li>
<li><p>Try other quantization (e.g. FP8 quantization with <code class="docutils literal notranslate"><span class="pre">--quantization</span> <span class="pre">fp8</span></code>)</p></li>
<li><p>Try other parallelism strategies (e.g. <a class="reference external" href="https://lmsys.org/blog/2025-05-05-large-scale-ep/">expert parallelism</a>) or DP attention for deepseek models (with <code class="docutils literal notranslate"><span class="pre">--enable-dp-attention</span> <span class="pre">--dp-size</span> <span class="pre">8</span></code>).</p></li>
<li><p>If the workload has many shared prefixes, try <code class="docutils literal notranslate"><span class="pre">--schedule-policy</span> <span class="pre">lpm</span></code>. Here, <code class="docutils literal notranslate"><span class="pre">lpm</span></code> stands for longest prefix match. It reorders requests to encourage more cache hits but introduces more scheduling overhead.</p></li>
</ul>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="server_arguments.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Server Arguments</p>
      </div>
    </a>
    <a class="right-next"
       href="attention_backend.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Attention Backend</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#achieving-high-throughput-for-offline-batch-inference">Achieving high throughput for offline batch inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adjust-the-request-submission-speed-to-control-queue-req">Adjust the request submission speed to control <code class="docutils literal notranslate"><span class="pre">#queue-req</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#achieve-a-high-token-usage">Achieve a high <code class="docutils literal notranslate"><span class="pre">token</span> <span class="pre">usage</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-mem-fraction-static-to-increase-kv-cache-pool-capacity">Tune <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code> to increase KV cache pool capacity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#avoid-out-of-memory-errors-by-tuning-chunked-prefill-size-mem-fraction-static-and-max-running-requests">Avoid out-of-memory errors by tuning <code class="docutils literal notranslate"><span class="pre">--chunked-prefill-size</span></code>, <code class="docutils literal notranslate"><span class="pre">--mem-fraction-static</span></code>, and <code class="docutils literal notranslate"><span class="pre">--max-running-requests</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-cuda-graph-max-bs">Tune <code class="docutils literal notranslate"><span class="pre">--cuda-graph-max-bs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tune-dp-size-and-tp-size">Tune <code class="docutils literal notranslate"><span class="pre">--dp-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--tp-size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#try-other-options">Try other options</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SGLang Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-2026, SGLang.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Feb 24, 2026.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  
    <!-- RunLLM Widget Script -->
    <script type="module" id="runllm-widget-script" src="https://widget.runllm.com" crossorigin="true" version="stable" runllm-keyboard-shortcut="Mod+j" runllm-name="SGLang Chatbot" runllm-position="BOTTOM_RIGHT" runllm-assistant-id="629" async></script>
    
</body>
</html>